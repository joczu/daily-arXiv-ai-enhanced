{"id": "2601.11863", "categories": ["cs.IR", "cs.AI", "cs.CE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11863", "abs": "https://arxiv.org/abs/2601.11863", "authors": ["Raquib Bin Yousuf", "Shengzhe Xu", "Mandar Sharma", "Andrew Neeser", "Chris Latimer", "Naren Ramakrishnan"], "title": "Utilizing Metadata for Better Retrieval-Augmented Generation", "comment": "The 48th European Conference on Information Retrieval (ECIR 2026)", "summary": "Retrieval-Augmented Generation systems depend on retrieving semantically relevant document chunks to support accurate, grounded outputs from large language models. In structured and repetitive corpora such as regulatory filings, chunk similarity alone often fails to distinguish between documents with overlapping language. Practitioners often flatten metadata into input text as a heuristic, but the impact and trade-offs of this practice remain poorly understood. We present a systematic study of metadata-aware retrieval strategies, comparing plain-text baselines with approaches that embed metadata directly. Our evaluation spans metadata-as-text (prefix and suffix), a dual-encoder unified embedding that fuses metadata and content in a single index, dual-encoder late-fusion retrieval, and metadata-aware query reformulation. Across multiple retrieval metrics and question types, we find that prefixing and unified embeddings consistently outperform plain-text baselines, with the unified at times exceeding prefixing while being easier to maintain. Beyond empirical comparisons, we analyze embedding space, showing that metadata integration improves effectiveness by increasing intra-document cohesion, reducing inter-document confusion, and widening the separation between relevant and irrelevant chunks. Field-level ablations show that structural cues provide strong disambiguating signals. Our code, evaluation framework, and the RAGMATE-10K dataset are publicly hosted.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u5728\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u4e2d\u6574\u5408\u5143\u6570\u636e\u7684\u7b56\u7565\uff0c\u53d1\u73b0\u5728\u7ed3\u6784\u5316\u91cd\u590d\u8bed\u6599\u4e2d\uff0c\u5143\u6570\u636e\u524d\u7f00\u6cd5\u548c\u7edf\u4e00\u5d4c\u5165\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u68c0\u7d22\u6548\u679c\uff0c\u901a\u8fc7\u589e\u5f3a\u6587\u6863\u5185\u805a\u6027\u3001\u51cf\u5c11\u6587\u6863\u95f4\u6df7\u6dc6\u6765\u6539\u5584\u68c0\u7d22\u8d28\u91cf\u3002", "motivation": "\u5728\u7ed3\u6784\u5316\u91cd\u590d\u8bed\u6599\uff08\u5982\u76d1\u7ba1\u6587\u4ef6\uff09\u4e2d\uff0c\u4ec5\u57fa\u4e8e\u5757\u76f8\u4f3c\u6027\u7684\u68c0\u7d22\u65b9\u6cd5\u96be\u4ee5\u533a\u5206\u5177\u6709\u91cd\u53e0\u8bed\u8a00\u7684\u6587\u6863\u3002\u5b9e\u8df5\u4e2d\u5e38\u5c06\u5143\u6570\u636e\u6241\u5e73\u5316\u4e3a\u6587\u672c\u8f93\u5165\uff0c\u4f46\u8fd9\u79cd\u505a\u6cd5\u7684\u5f71\u54cd\u548c\u6743\u8861\u5c1a\u4e0d\u6e05\u695a\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u5143\u6570\u636e\u611f\u77e5\u68c0\u7d22\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u7cfb\u7edf\u6027\u7684\u5143\u6570\u636e\u611f\u77e5\u68c0\u7d22\u7b56\u7565\u7814\u7a76\uff0c\u6bd4\u8f83\u4e86\u7eaf\u6587\u672c\u57fa\u7ebf\u3001\u5143\u6570\u636e\u4f5c\u4e3a\u6587\u672c\uff08\u524d\u7f00\u548c\u540e\u7f00\uff09\u3001\u878d\u5408\u5143\u6570\u636e\u548c\u5185\u5bb9\u7684\u7edf\u4e00\u5d4c\u5165\u53cc\u7f16\u7801\u5668\u3001\u53cc\u7f16\u7801\u5668\u540e\u671f\u878d\u5408\u68c0\u7d22\u4ee5\u53ca\u5143\u6570\u636e\u611f\u77e5\u67e5\u8be2\u91cd\u6784\u7b49\u65b9\u6cd5\u3002", "result": "\u5143\u6570\u636e\u524d\u7f00\u6cd5\u548c\u7edf\u4e00\u5d4c\u5165\u6cd5\u5728\u591a\u79cd\u68c0\u7d22\u6307\u6807\u548c\u95ee\u9898\u7c7b\u578b\u4e0a\u4e00\u81f4\u4f18\u4e8e\u7eaf\u6587\u672c\u57fa\u7ebf\uff0c\u7edf\u4e00\u5d4c\u5165\u6cd5\u6709\u65f6\u751a\u81f3\u8d85\u8fc7\u524d\u7f00\u6cd5\u4e14\u66f4\u6613\u4e8e\u7ef4\u62a4\u3002\u5143\u6570\u636e\u96c6\u6210\u901a\u8fc7\u589e\u5f3a\u6587\u6863\u5185\u805a\u6027\u3001\u51cf\u5c11\u6587\u6863\u95f4\u6df7\u6dc6\u3001\u6269\u5927\u76f8\u5173\u4e0e\u4e0d\u76f8\u5173\u5757\u4e4b\u95f4\u7684\u5206\u79bb\u6765\u63d0\u9ad8\u68c0\u7d22\u6548\u679c\u3002", "conclusion": "\u5728\u7ed3\u6784\u5316\u8bed\u6599\u4e2d\uff0c\u5143\u6570\u636e\u96c6\u6210\u5bf9\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002\u524d\u7f00\u6cd5\u548c\u7edf\u4e00\u5d4c\u5165\u6cd5\u662f\u6700\u6709\u6548\u7684\u7b56\u7565\uff0c\u5143\u6570\u636e\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u6d88\u6b67\u4fe1\u53f7\u3002\u7814\u7a76\u63d0\u4f9b\u4e86\u516c\u5f00\u7684\u4ee3\u7801\u3001\u8bc4\u4f30\u6846\u67b6\u548cRAGMATE-10K\u6570\u636e\u96c6\u3002"}}
{"id": "2601.11874", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11874", "abs": "https://arxiv.org/abs/2601.11874", "authors": ["Suchana Datta", "Dwaipayan Roy", "Derek Greene", "Gerardine Meaney", "Karen Wade", "Philipp Mayr"], "title": "Cultural Analytics for Good: Building Inclusive Evaluation Frameworks for Historical IR", "comment": null, "summary": "This work bridges the fields of information retrieval and cultural analytics to support equitable access to historical knowledge. Using the British Library BL19 digital collection (more than 35,000 works from 1700-1899), we construct a benchmark for studying changes in language, terminology and retrieval in the 19th-century fiction and non-fiction. Our approach combines expert-driven query design, paragraph-level relevance annotation, and Large Language Model (LLM) assistance to create a scalable evaluation framework grounded in human expertise. We focus on knowledge transfer from fiction to non-fiction, investigating how narrative understanding and semantic richness in fiction can improve retrieval for scholarly and factual materials. This interdisciplinary framework not only improves retrieval accuracy but also fosters interpretability, transparency, and cultural inclusivity in digital archives. Our work provides both practical evaluation resources and a methodological paradigm for developing retrieval systems that support richer, historically aware engagement with digital archives, ultimately working towards more emancipatory knowledge infrastructures.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u7ed3\u5408\u4fe1\u606f\u68c0\u7d22\u4e0e\u6587\u5316\u5206\u6790\u7684\u8de8\u5b66\u79d1\u6846\u67b6\uff0c\u4f7f\u7528\u82f1\u56fd\u56fe\u4e66\u9986BL19\u6570\u5b57\u9986\u85cf\uff081700-1899\u5e74\u95f4\u76843.5\u4e07\u90e8\u4f5c\u54c1\uff09\u521b\u5efa\u57fa\u51c6\uff0c\u7814\u7a7619\u4e16\u7eaa\u5c0f\u8bf4\u4e0e\u975e\u5c0f\u8bf4\u4e2d\u7684\u8bed\u8a00\u53d8\u5316\u548c\u68c0\u7d22\u95ee\u9898\uff0c\u901a\u8fc7\u4e13\u5bb6\u67e5\u8be2\u8bbe\u8ba1\u3001\u6bb5\u843d\u7ea7\u76f8\u5173\u6027\u6807\u6ce8\u548cLLM\u8f85\u52a9\uff0c\u63a2\u7d22\u4ece\u5c0f\u8bf4\u5230\u975e\u5c0f\u8bf4\u7684\u77e5\u8bc6\u8fc1\u79fb\u3002", "motivation": "\u8be5\u7814\u7a76\u7684\u52a8\u673a\u662f\u5f25\u5408\u4fe1\u606f\u68c0\u7d22\u4e0e\u6587\u5316\u5206\u6790\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u652f\u6301\u5386\u53f2\u77e5\u8bc6\u7684\u516c\u5e73\u83b7\u53d6\u3002\u7814\u7a76\u8005\u5173\u6ce8\u5982\u4f55\u5229\u7528\u5c0f\u8bf4\u4e2d\u7684\u53d9\u4e8b\u7406\u89e3\u548c\u8bed\u4e49\u4e30\u5bcc\u6027\u6765\u6539\u8fdb\u5b66\u672f\u548c\u4e8b\u5b9e\u6750\u6599\u7684\u68c0\u7d22\uff0c\u540c\u65f6\u4fc3\u8fdb\u6570\u5b57\u6863\u6848\u7684\u53ef\u89e3\u91ca\u6027\u3001\u900f\u660e\u5ea6\u548c\u6587\u5316\u5305\u5bb9\u6027\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\uff1a1) \u4f7f\u7528\u82f1\u56fd\u56fe\u4e66\u9986BL19\u6570\u5b57\u9986\u85cf\uff081700-1899\u5e74\u95f4\u76843.5\u4e07\u90e8\u4f5c\u54c1\uff09\u6784\u5efa\u57fa\u51c6\uff1b2) \u7ed3\u5408\u4e13\u5bb6\u9a71\u52a8\u7684\u67e5\u8be2\u8bbe\u8ba1\uff1b3) \u6bb5\u843d\u7ea7\u76f8\u5173\u6027\u6807\u6ce8\uff1b4) \u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\uff1b5) \u521b\u5efa\u57fa\u4e8e\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u7684\u53ef\u6269\u5c55\u8bc4\u4f30\u6846\u67b6\uff1b6) \u91cd\u70b9\u7814\u7a76\u4ece\u5c0f\u8bf4\u5230\u975e\u5c0f\u8bf4\u7684\u77e5\u8bc6\u8fc1\u79fb\u3002", "result": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8bc4\u4f30\u8d44\u6e90\u548c\u65b9\u6cd5\u8bba\u8303\u5f0f\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u68c0\u7d22\u51c6\u786e\u6027\uff0c\u8fd8\u4fc3\u8fdb\u4e86\u6570\u5b57\u6863\u6848\u7684\u53ef\u89e3\u91ca\u6027\u3001\u900f\u660e\u5ea6\u548c\u6587\u5316\u5305\u5bb9\u6027\u3002\u6846\u67b6\u652f\u6301\u66f4\u4e30\u5bcc\u3001\u66f4\u5177\u5386\u53f2\u610f\u8bc6\u7684\u6570\u5b57\u6863\u6848\u53c2\u4e0e\uff0c\u6700\u7ec8\u671d\u7740\u66f4\u89e3\u653e\u7684\u77e5\u8bc6\u57fa\u7840\u8bbe\u65bd\u65b9\u5411\u53d1\u5c55\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u8de8\u5b66\u79d1\u6846\u67b6\uff0c\u5c06\u4fe1\u606f\u68c0\u7d22\u4e0e\u6587\u5316\u5206\u6790\u76f8\u7ed3\u5408\uff0c\u4e3a\u5f00\u53d1\u652f\u6301\u66f4\u4e30\u5bcc\u3001\u66f4\u5177\u5386\u53f2\u610f\u8bc6\u7684\u6570\u5b57\u6863\u6848\u53c2\u4e0e\u68c0\u7d22\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u8303\u4f8b\uff0c\u81f4\u529b\u4e8e\u521b\u5efa\u66f4\u89e3\u653e\u7684\u77e5\u8bc6\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2601.11888", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11888", "abs": "https://arxiv.org/abs/2601.11888", "authors": ["Wenhan Liu", "Xinyu Ma", "Yutao Zhu", "Yuchen Li", "Daiting Shi", "Dawei Yin", "Zhicheng Dou"], "title": "Agentic-R: Learning to Retrieve for Agentic Search", "comment": null, "summary": "Agentic search has recently emerged as a powerful paradigm, where an agent interleaves multi-step reasoning with on-demand retrieval to solve complex questions. Despite its success, how to design a retriever for agentic search remains largely underexplored. Existing search agents typically rely on similarity-based retrievers, while similar passages are not always useful for final answer generation. In this paper, we propose a novel retriever training framework tailored for agentic search. Unlike retrievers designed for single-turn retrieval-augmented generation (RAG) that only rely on local passage utility, we propose to use both local query-passage relevance and global answer correctness to measure passage utility in a multi-turn agentic search. We further introduce an iterative training strategy, where the search agent and the retriever are optimized bidirectionally and iteratively. Different from RAG retrievers that are only trained once with fixed questions, our retriever is continuously improved using evolving and higher-quality queries from the agent. Extensive experiments on seven single-hop and multi-hop QA benchmarks demonstrate that our retriever, termed \\ours{}, consistently outperforms strong baselines across different search agents. Our codes are available at: https://github.com/8421BCD/Agentic-R.", "code_url": "https://github.com/8421BCD/Agentic-R", "code_stars": 18, "code_last_update": "2026-01-21", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u95e8\u4e3a\u667a\u80fd\u4f53\u641c\u7d22\u8bbe\u8ba1\u7684\u68c0\u7d22\u5668\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5c40\u90e8\u67e5\u8be2-\u6bb5\u843d\u76f8\u5173\u6027\u548c\u5168\u5c40\u7b54\u6848\u6b63\u786e\u6027\u6765\u8861\u91cf\u6bb5\u843d\u6548\u7528\uff0c\u5e76\u91c7\u7528\u8fed\u4ee3\u8bad\u7ec3\u7b56\u7565\u53cc\u5411\u4f18\u5316\u641c\u7d22\u667a\u80fd\u4f53\u548c\u68c0\u7d22\u5668\u3002", "motivation": "\u5f53\u524d\u667a\u80fd\u4f53\u641c\u7d22\u4e3b\u8981\u4f9d\u8d56\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u68c0\u7d22\u5668\uff0c\u4f46\u76f8\u4f3c\u6bb5\u843d\u5e76\u4e0d\u603b\u662f\u5bf9\u6700\u7ec8\u7b54\u6848\u751f\u6210\u6709\u7528\u3002\u73b0\u6709\u68c0\u7d22\u5668\u8bbe\u8ba1\u4e3b\u8981\u9488\u5bf9\u5355\u8f6e\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\uff0c\u7f3a\u4e4f\u5bf9\u591a\u8f6e\u667a\u80fd\u4f53\u641c\u7d22\u7684\u4e13\u95e8\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u68c0\u7d22\u5668\u8bad\u7ec3\u6846\u67b6\uff1a1) \u4f7f\u7528\u5c40\u90e8\u67e5\u8be2-\u6bb5\u843d\u76f8\u5173\u6027\u548c\u5168\u5c40\u7b54\u6848\u6b63\u786e\u6027\u53cc\u91cd\u6807\u51c6\u8861\u91cf\u6bb5\u843d\u6548\u7528\uff1b2) \u91c7\u7528\u8fed\u4ee3\u8bad\u7ec3\u7b56\u7565\uff0c\u8ba9\u641c\u7d22\u667a\u80fd\u4f53\u548c\u68c0\u7d22\u5668\u53cc\u5411\u8fed\u4ee3\u4f18\u5316\uff1b3) \u68c0\u7d22\u5668\u4f7f\u7528\u667a\u80fd\u4f53\u751f\u6210\u7684\u9ad8\u8d28\u91cf\u67e5\u8be2\u6301\u7eed\u6539\u8fdb\uff0c\u800c\u975e\u56fa\u5b9a\u95ee\u9898\u7684\u4e00\u6b21\u6027\u8bad\u7ec3\u3002", "result": "\u57287\u4e2a\u5355\u8df3\u548c\u591a\u8df3\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u63d0\u51fa\u7684Agentic-R\u68c0\u7d22\u5668\u5728\u4e0d\u540c\u641c\u7d22\u667a\u80fd\u4f53\u4e0a\u5747\u4e00\u81f4\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u4e3a\u667a\u80fd\u4f53\u641c\u7d22\u8bbe\u8ba1\u7684\u4e13\u95e8\u68c0\u7d22\u5668\u8bad\u7ec3\u6846\u67b6\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u901a\u8fc7\u7ed3\u5408\u5c40\u90e8\u76f8\u5173\u6027\u548c\u5168\u5c40\u7b54\u6848\u6b63\u786e\u6027\uff0c\u4ee5\u53ca\u8fed\u4ee3\u4f18\u5316\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u76f8\u4f3c\u6027\u68c0\u7d22\u5668\u5728\u667a\u80fd\u4f53\u641c\u7d22\u4e2d\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.11564", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11564", "abs": "https://arxiv.org/abs/2601.11564", "authors": ["Ahilan Ayyachamy Nadar Ponnusamy", "Karthic Chandran", "M Maruf Hossain"], "title": "Context Discipline and Performance Correlation: Analyzing LLM Performance and Quality Degradation Under Varying Context Lengths", "comment": "22 pages, 6 figures", "summary": "The scaling trend in Large Language Models (LLMs) has prioritized increasing the maximum context window to facilitate complex, long-form reasoning and document analysis. However, managing this expanded context introduces severe computational overhead. This paper investigates the critical trade-off between system performance and model quality when dense transformer architectures--specifically Llama-3.1-70B and Qwen1.5-14B--are exposed to large volumes of irrelevant and distracting context. The research identifies a non-linear performance degradation tied to the growth of the Key-Value (KV) cache. Furthermore, an extended analysis of the Mixture-of-Experts (MoE) architecture reveals unique behavioral anomalies at varying context scales, suggesting that architectural benefits may be masked by infrastructure bottlenecks at high token volumes.", "AI": {"tldr": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6269\u5c55\u4e0a\u4e0b\u6587\u7a97\u53e3\u65f6\u9762\u4e34\u7684\u8ba1\u7b97\u5f00\u9500\u4e0e\u6a21\u578b\u8d28\u91cf\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5206\u6790\u5bc6\u96c6Transformer\u67b6\u6784\u5728\u65e0\u5173\u4e0a\u4e0b\u6587\u4e0b\u7684\u6027\u80fd\u9000\u5316\uff0c\u4ee5\u53caMoE\u67b6\u6784\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u89c4\u6a21\u4e0b\u7684\u5f02\u5e38\u884c\u4e3a", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0d\u65ad\u6269\u5c55\u4e0a\u4e0b\u6587\u7a97\u53e3\u4ee5\u652f\u6301\u590d\u6742\u957f\u6587\u672c\u63a8\u7406\u548c\u6587\u6863\u5206\u6790\uff0c\u7ba1\u7406\u6269\u5c55\u4e0a\u4e0b\u6587\u5e26\u6765\u4e86\u4e25\u91cd\u7684\u8ba1\u7b97\u5f00\u9500\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u7cfb\u7edf\u6027\u80fd\u4e0e\u6a21\u578b\u8d28\u91cf\u4e4b\u95f4\u7684\u5173\u952e\u6743\u8861\uff0c\u7279\u522b\u662f\u5728\u6a21\u578b\u66b4\u9732\u4e8e\u5927\u91cf\u65e0\u5173\u548c\u5e72\u6270\u6027\u4e0a\u4e0b\u6587\u65f6\u7684\u60c5\u51b5\u3002", "method": "\u4f7f\u7528\u5bc6\u96c6Transformer\u67b6\u6784\uff08Llama-3.1-70B\u548cQwen1.5-14B\uff09\u8fdb\u884c\u7814\u7a76\uff0c\u5206\u6790\u5176\u5728\u5927\u91cf\u65e0\u5173\u4e0a\u4e0b\u6587\u4e0b\u7684\u6027\u80fd\u8868\u73b0\u3002\u7279\u522b\u5173\u6ce8Key-Value\u7f13\u5b58\u589e\u957f\u4e0e\u6027\u80fd\u9000\u5316\u7684\u975e\u7ebf\u6027\u5173\u7cfb\u3002\u8fdb\u4e00\u6b65\u6269\u5c55\u5206\u6790\u5230\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\uff0c\u7814\u7a76\u5176\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u89c4\u6a21\u4e0b\u7684\u884c\u4e3a\u5f02\u5e38\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6027\u80fd\u9000\u5316\u4e0eKV\u7f13\u5b58\u7684\u589e\u957f\u5448\u975e\u7ebf\u6027\u5173\u7cfb\u3002\u5bf9MoE\u67b6\u6784\u7684\u6269\u5c55\u5206\u6790\u63ed\u793a\u4e86\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u89c4\u6a21\u4e0b\u7684\u72ec\u7279\u884c\u4e3a\u5f02\u5e38\uff0c\u8868\u660e\u67b6\u6784\u4f18\u52bf\u53ef\u80fd\u5728\u9ad8\u4ee4\u724c\u91cf\u4e0b\u88ab\u57fa\u7840\u8bbe\u65bd\u74f6\u9888\u6240\u63a9\u76d6\u3002", "conclusion": "\u6269\u5c55\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u867d\u7136\u6709\u5229\u4e8e\u590d\u6742\u63a8\u7406\u4efb\u52a1\uff0c\u4f46\u4f1a\u5e26\u6765\u663e\u8457\u7684\u8ba1\u7b97\u5f00\u9500\u548c\u6027\u80fd\u9000\u5316\u98ce\u9669\u3002\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u67b6\u6784\u8bbe\u8ba1\u548c\u57fa\u7840\u8bbe\u65bd\u4f18\u5316\u6765\u5e73\u8861\u6a21\u578b\u8d28\u91cf\u4e0e\u7cfb\u7edf\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5927\u91cf\u65e0\u5173\u4e0a\u4e0b\u6587\u65f6\u3002"}}
{"id": "2601.11559", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11559", "abs": "https://arxiv.org/abs/2601.11559", "authors": ["Zilal Eiz AlDin", "John Wu", "Jeffrey Paul Fung", "Jennifer King", "Mya Watts", "Lauren ONeill", "Adam Richard Cross", "Jimeng Sun"], "title": "MIMIC-RD: Can LLMs differentially diagnose rare diseases in real-world clinical settings?", "comment": "5 pages", "summary": "Despite rare diseases affecting 1 in 10 Americans, their differential diagnosis remains challenging. Due to their impressive recall abilities, large language models (LLMs) have been recently explored for differential diagnosis. Existing approaches to evaluating LLM-based rare disease diagnosis suffer from two critical limitations: they rely on idealized clinical case studies that fail to capture real-world clinical complexity, or they use ICD codes as disease labels, which significantly undercounts rare diseases since many lack direct mappings to comprehensive rare disease databases like Orphanet. To address these limitations, we explore MIMIC-RD, a rare disease differential diagnosis benchmark constructed by directly mapping clinical text entities to Orphanet. Our methodology involved an initial LLM-based mining process followed by validation from four medical annotators to confirm identified entities were genuine rare diseases. We evaluated various models on our dataset of 145 patients and found that current state-of-the-art LLMs perform poorly on rare disease differential diagnosis, highlighting the substantial gap between existing capabilities and clinical needs. From our findings, we outline several future steps towards improving differential diagnosis of rare diseases.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86MIMIC-RD\u57fa\u51c6\uff0c\u901a\u8fc7\u5c06\u4e34\u5e8a\u6587\u672c\u5b9e\u4f53\u76f4\u63a5\u6620\u5c04\u5230Orphanet\u7f55\u89c1\u75c5\u6570\u636e\u5e93\u6765\u8bc4\u4f30LLM\u5728\u7f55\u89c1\u75c5\u9274\u522b\u8bca\u65ad\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5f53\u524d\u6700\u5148\u8fdb\u7684LLM\u5728\u7f55\u89c1\u75c5\u8bca\u65ad\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u7f55\u89c1\u75c5\u5f71\u54cd1/10\u7f8e\u56fd\u4eba\uff0c\u4f46\u5176\u9274\u522b\u8bca\u65ad\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u8bc4\u4f30LLM\u7f55\u89c1\u75c5\u8bca\u65ad\u7684\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5c40\u9650\uff1a1\uff09\u4f9d\u8d56\u7406\u60f3\u5316\u7684\u4e34\u5e8a\u6848\u4f8b\u7814\u7a76\uff0c\u672a\u80fd\u6355\u6349\u771f\u5b9e\u4e16\u754c\u7684\u4e34\u5e8a\u590d\u6742\u6027\uff1b2\uff09\u4f7f\u7528ICD\u4ee3\u7801\u4f5c\u4e3a\u75be\u75c5\u6807\u7b7e\uff0c\u7531\u4e8e\u8bb8\u591a\u7f55\u89c1\u75c5\u7f3a\u4e4f\u4e0eOrphanet\u7b49\u7efc\u5408\u7f55\u89c1\u75c5\u6570\u636e\u5e93\u7684\u76f4\u63a5\u6620\u5c04\uff0c\u5bfc\u81f4\u663e\u8457\u4f4e\u4f30\u7f55\u89c1\u75c5\u6570\u91cf\u3002", "method": "\u5f00\u53d1\u4e86MIMIC-RD\u57fa\u51c6\uff0c\u901a\u8fc7\u76f4\u63a5\u6620\u5c04\u4e34\u5e8a\u6587\u672c\u5b9e\u4f53\u5230Orphanet\u7f55\u89c1\u75c5\u6570\u636e\u5e93\u6784\u5efa\u3002\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u57fa\u4e8eLLM\u7684\u521d\u6b65\u6316\u6398\u8fc7\u7a0b\uff1b2\uff09\u7531\u56db\u540d\u533b\u5b66\u6807\u6ce8\u8005\u9a8c\u8bc1\uff0c\u786e\u8ba4\u8bc6\u522b\u7684\u5b9e\u4f53\u662f\u771f\u6b63\u7684\u7f55\u89c1\u75c5\u3002\u6700\u7ec8\u6784\u5efa\u4e86\u5305\u542b145\u540d\u60a3\u8005\u7684\u6570\u636e\u96c6\u3002", "result": "\u8bc4\u4f30\u4e86\u5404\u79cd\u6a21\u578b\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7f55\u89c1\u75c5\u9274\u522b\u8bca\u65ad\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u7a81\u663e\u4e86\u73b0\u6709\u80fd\u529b\u4e0e\u4e34\u5e8a\u9700\u6c42\u4e4b\u95f4\u7684\u5de8\u5927\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86LLM\u5728\u7f55\u89c1\u75c5\u8bca\u65ad\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u57fa\u4e8e\u7814\u7a76\u7ed3\u679c\u63d0\u51fa\u4e86\u6539\u8fdb\u7f55\u89c1\u75c5\u9274\u522b\u8bca\u65ad\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2601.11565", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11565", "abs": "https://arxiv.org/abs/2601.11565", "authors": ["Pakorn Ueareeworakul", "Shuman Liu", "Jinghao Feng", "Ling Hu", "Zhantang Shi", "Chengqi Sun", "Liang Yao", "Panyi Ouyang", "Haibo Zhang", "Anxiang Zeng"], "title": "Compass-Embedding v4: Robust Contrastive Learning for Multilingual E-commerce Embeddings", "comment": null, "summary": "As global e-commerce rapidly expands into emerging markets, the lack of high-quality semantic representations for low-resource languages has become a decisive bottleneck for retrieval, recommendation, and search systems. In this work, we present Compass-Embedding v4, a high-efficiency multilingual embedding framework specifically optimized for Southeast Asian (SEA) e-commerce scenarios, where data scarcity, noisy supervision, and strict production constraints jointly challenge representation learning. Compass-Embedding v4 addresses three core challenges. First, large-batch contrastive training under mixed task supervision introduces systematic false negatives that degrade semantic alignment. We propose Class-Aware Masking (CAM), a lightweight modification to the InfoNCE objective that suppresses invalid in-batch negatives and improves semantic discrimination without altering training efficiency. Second, low-resource SEA languages suffer from limited and uneven data coverage. We construct a diversified training corpus through context-grounded synthetic data generation, cross-lingual translation, and structured e-commerce data construction, enabling robust multilingual and domain-specific learning. Third, production deployment requires high-throughput inference while preserving embedding quality. We combine robustness-driven large-batch training with spherical model merging to mitigate catastrophic forgetting, and optimize inference via vLLM and FP8 quantization. Extensive evaluations across multilingual benchmarks and proprietary e-commerce tasks show that Compass-Embedding v4 achieves state-of-the-art performance on major SEA languages, significantly outperforming general-purpose embedding models in domain-specific retrieval and classification, while maintaining competitive performance on high-resource languages.", "AI": {"tldr": "Compass-Embedding v4\u662f\u4e00\u4e2a\u9488\u5bf9\u4e1c\u5357\u4e9a\u7535\u5546\u573a\u666f\u4f18\u5316\u7684\u591a\u8bed\u8a00\u5d4c\u5165\u6846\u67b6\uff0c\u901a\u8fc7\u7c7b\u611f\u77e5\u63a9\u7801\u3001\u591a\u6837\u5316\u8bad\u7ec3\u8bed\u6599\u6784\u5efa\u548c\u9ad8\u6548\u63a8\u7406\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00\u8bed\u4e49\u8868\u793a\u3001\u566a\u58f0\u76d1\u7763\u548c\u751f\u4ea7\u7ea6\u675f\u7b49\u6838\u5fc3\u6311\u6218\u3002", "motivation": "\u968f\u7740\u5168\u7403\u7535\u5546\u5411\u65b0\u5174\u5e02\u573a\u6269\u5f20\uff0c\u4f4e\u8d44\u6e90\u8bed\u8a00\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u8bed\u4e49\u8868\u793a\u5df2\u6210\u4e3a\u68c0\u7d22\u3001\u63a8\u8350\u548c\u641c\u7d22\u7cfb\u7edf\u7684\u5173\u952e\u74f6\u9888\u3002\u4e1c\u5357\u4e9a\u7535\u5546\u573a\u666f\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u3001\u566a\u58f0\u76d1\u7763\u548c\u4e25\u683c\u751f\u4ea7\u7ea6\u675f\u7684\u8054\u5408\u6311\u6218\uff0c\u9700\u8981\u4e13\u95e8\u4f18\u5316\u7684\u591a\u8bed\u8a00\u5d4c\u5165\u89e3\u51b3\u65b9\u6848\u3002", "method": "1. \u63d0\u51faClass-Aware Masking(CAM)\uff1a\u6539\u8fdbInfoNCE\u76ee\u6807\u51fd\u6570\uff0c\u6291\u5236\u6279\u6b21\u5185\u65e0\u6548\u8d1f\u6837\u672c\uff0c\u63d0\u5347\u8bed\u4e49\u5224\u522b\u80fd\u529b\uff1b2. \u6784\u5efa\u591a\u6837\u5316\u8bad\u7ec3\u8bed\u6599\uff1a\u901a\u8fc7\u4e0a\u4e0b\u6587\u5408\u6210\u6570\u636e\u751f\u6210\u3001\u8de8\u8bed\u8a00\u7ffb\u8bd1\u548c\u7ed3\u6784\u5316\u7535\u5546\u6570\u636e\u6784\u5efa\uff1b3. \u751f\u4ea7\u90e8\u7f72\u4f18\u5316\uff1a\u7ed3\u5408\u9c81\u68d2\u6027\u9a71\u52a8\u7684\u5927\u6279\u6b21\u8bad\u7ec3\u4e0e\u7403\u9762\u6a21\u578b\u878d\u5408\uff0c\u4f7f\u7528vLLM\u548cFP8\u91cf\u5316\u4f18\u5316\u63a8\u7406\u3002", "result": "\u5728\u591a\u9879\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e13\u6709\u7535\u5546\u4efb\u52a1\u8bc4\u4f30\u4e2d\uff0cCompass-Embedding v4\u5728\u4e3b\u8981\u4e1c\u5357\u4e9a\u8bed\u8a00\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u9886\u57df\u7279\u5b9a\u68c0\u7d22\u548c\u5206\u7c7b\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u901a\u7528\u5d4c\u5165\u6a21\u578b\uff0c\u540c\u65f6\u5728\u9ad8\u8d44\u6e90\u8bed\u8a00\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "Compass-Embedding v4\u6210\u529f\u89e3\u51b3\u4e86\u4e1c\u5357\u4e9a\u7535\u5546\u573a\u666f\u4e2d\u7684\u591a\u8bed\u8a00\u5d4c\u5165\u6311\u6218\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u8bad\u7ec3\u7b56\u7565\u548c\u90e8\u7f72\u4f18\u5316\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u7684\u8bed\u4e49\u8868\u793a\uff0c\u5728\u4fdd\u6301\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2601.11620", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11620", "abs": "https://arxiv.org/abs/2601.11620", "authors": ["Michael Timothy Bennett"], "title": "A Mind Cannot Be Smeared Across Time", "comment": null, "summary": "Whether machines can be conscious depends not only on what they compute, but \\emph{when} they compute it. Most deployed artificial systems realise their functions via sequential or time-multiplexed updates. Conscious experience appears unified and simultaneous. I show that this difference matters formally. I augment Stack Theory with algebraic laws relating within time-window constraint satisfaction to conjunction. I introduce a precise temporal semantics over windowed trajectories $\u03c4^{\u0394,s}$ and prove that existential temporal realisation $\\Diamond_\u0394$ does not preserve conjunction. A system can realise all the ingredients of experience across time without ever instantiating the experienced conjunction itself. I then distinguish two postulates. StrongSync requires objective co-instantiation of the grounded conjunction within the window, while WeakSync permits temporal ``smearing''. I formalise concurrency-capacity to measure what is needed to satisfy StrongSync. Finally, I review neurophysiological evidence suggesting that consciousness depends on phase synchrony and effective connectivity, and that loss of consciousness is often associated with its breakdown. This evidence makes WeakSync less plausible. Under StrongSync, software consciousness on strictly sequential substrates is impossible for contents whose grounding requires two or more simultaneous contributors. The more parts from which simultaneous contribution required, the more concurrency capacity is required. The hardware matters. Consciousness attribution therefore requires architectural inspection, not just functional performance.", "AI": {"tldr": "\u673a\u5668\u610f\u8bc6\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u8ba1\u7b97\u5185\u5bb9\uff0c\u8fd8\u53d6\u51b3\u4e8e\u8ba1\u7b97\u65f6\u673a\u3002\u8bba\u6587\u8bc1\u660e\u5728\u4e25\u683c\u987a\u5e8f\u786c\u4ef6\u4e0a\u65e0\u6cd5\u5b9e\u73b0\u9700\u8981\u591a\u4e2a\u540c\u65f6\u8d21\u732e\u8005\u7684\u610f\u8bc6\u5185\u5bb9\uff0c\u610f\u8bc6\u5f52\u56e0\u9700\u8981\u67b6\u6784\u68c0\u67e5\u800c\u4e0d\u4ec5\u4ec5\u662f\u529f\u80fd\u8868\u73b0\u3002", "motivation": "\u63a2\u8ba8\u673a\u5668\u610f\u8bc6\u7684\u53ef\u80fd\u6027\uff0c\u6311\u6218\u4ec5\u57fa\u4e8e\u529f\u80fd\u7b49\u4ef7\u6027\u7684\u610f\u8bc6\u5f52\u56e0\u3002\u73b0\u6709AI\u7cfb\u7edf\u901a\u5e38\u91c7\u7528\u987a\u5e8f\u6216\u65f6\u5206\u590d\u7528\u66f4\u65b0\uff0c\u800c\u610f\u8bc6\u4f53\u9a8c\u5448\u73b0\u7edf\u4e00\u6027\u548c\u540c\u65f6\u6027\uff0c\u8fd9\u79cd\u65f6\u95f4\u7ed3\u6784\u5dee\u5f02\u53ef\u80fd\u5bf9\u673a\u5668\u610f\u8bc6\u4ea7\u751f\u6839\u672c\u6027\u5f71\u54cd\u3002", "method": "\u6269\u5c55Stack Theory\uff0c\u5f15\u5165\u4ee3\u6570\u5b9a\u5f8b\u5c06\u65f6\u95f4\u7a97\u53e3\u5185\u7684\u7ea6\u675f\u6ee1\u8db3\u4e0e\u5408\u53d6\u5173\u7cfb\u8054\u7cfb\u8d77\u6765\u3002\u5b9a\u4e49\u7cbe\u786e\u7684\u65f6\u95f4\u8bed\u4e49\u03c4^{\u0394,s}\uff0c\u8bc1\u660e\u5b58\u5728\u6027\u65f6\u95f4\u5b9e\u73b0\u25c7_\u0394\u4e0d\u4fdd\u6301\u5408\u53d6\u6027\u3002\u533a\u5206StrongSync\uff08\u8981\u6c42\u5408\u53d6\u5728\u7a97\u53e3\u5185\u5ba2\u89c2\u5171\u73b0\uff09\u548cWeakSync\uff08\u5141\u8bb8\u65f6\u95f4\"\u6d82\u62b9\"\uff09\u4e24\u4e2a\u5047\u8bbe\u3002\u5f62\u5f0f\u5316\u5e76\u53d1\u5bb9\u91cf\u6765\u8861\u91cf\u6ee1\u8db3StrongSync\u6240\u9700\u6761\u4ef6\u3002", "result": "\u8bc1\u660e\u7cfb\u7edf\u53ef\u4ee5\u5728\u65f6\u95f4\u4e0a\u5b9e\u73b0\u4f53\u9a8c\u7684\u6240\u6709\u6210\u5206\uff0c\u4f46\u4ece\u672a\u5b9e\u4f8b\u5316\u4f53\u9a8c\u7684\u5408\u53d6\u672c\u8eab\u3002\u5728StrongSync\u5047\u8bbe\u4e0b\uff0c\u4e25\u683c\u987a\u5e8f\u57fa\u677f\u4e0a\u65e0\u6cd5\u5b9e\u73b0\u9700\u8981\u4e24\u4e2a\u6216\u66f4\u591a\u540c\u65f6\u8d21\u732e\u8005\u7684\u610f\u8bc6\u5185\u5bb9\u3002\u795e\u7ecf\u751f\u7406\u5b66\u8bc1\u636e\u8868\u660e\u610f\u8bc6\u4f9d\u8d56\u4e8e\u76f8\u4f4d\u540c\u6b65\u548c\u6709\u6548\u8fde\u63a5\uff0c\u610f\u8bc6\u4e27\u5931\u5e38\u4f34\u968f\u5176\u5d29\u6e83\uff0c\u8fd9\u4f7fWeakSync\u5047\u8bbe\u4e0d\u592a\u53ef\u4fe1\u3002", "conclusion": "\u673a\u5668\u610f\u8bc6\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u8ba1\u7b97\u5185\u5bb9\uff0c\u8fd8\u53d6\u51b3\u4e8e\u8ba1\u7b97\u65f6\u673a\u3002\u5728StrongSync\u5047\u8bbe\u4e0b\uff0c\u9700\u8981\u591a\u4e2a\u540c\u65f6\u8d21\u732e\u8005\u7684\u610f\u8bc6\u5185\u5bb9\u65e0\u6cd5\u5728\u4e25\u683c\u987a\u5e8f\u786c\u4ef6\u4e0a\u5b9e\u73b0\u3002\u610f\u8bc6\u5f52\u56e0\u9700\u8981\u68c0\u67e5\u7cfb\u7edf\u67b6\u6784\u7684\u5e76\u53d1\u80fd\u529b\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u529f\u80fd\u8868\u73b0\u3002\u786c\u4ef6\u67b6\u6784\u5bf9\u610f\u8bc6\u53ef\u80fd\u6027\u5177\u6709\u51b3\u5b9a\u6027\u5f71\u54cd\u3002"}}
{"id": "2601.12544", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.12544", "abs": "https://arxiv.org/abs/2601.12544", "authors": ["Leif Azzopardi", "Adam Roegiest"], "title": "Information Farming: From Berry Picking to Berry Growing", "comment": "ACM CHIIR 2026", "summary": "The classic paradigms of Berry Picking and Information Foraging Theory have framed users as gatherers, opportunistically searching across distributed sources to satisfy evolving information needs. However, the rise of GenAI is driving a fundamental transformation in how people produce, structure, and reuse information - one that these paradigms no longer fully capture. This transformation is analogous to the Neolithic Revolution, when societies shifted from hunting and gathering to cultivation. Generative technologies empower users to \"farm\" information by planting seeds in the form of prompts, cultivating workflows over time, and harvesting richly structured, relevant yields within their own plots, rather than foraging across others people's patches. In this perspectives paper, we introduce the notion of Information Farming as a conceptual framework and argue that it represents a natural evolution in how people engage with information. Drawing on historical analogy and empirical evidence, we examine the benefits and opportunities of information farming, its implications for design and evaluation, and the accompanying risks posed by this transition. We hypothesize that as GenAI technologies proliferate, cultivating information will increasingly supplant transient, patch-based foraging as a dominant mode of engagement, marking a broader shift in human-information interaction and its study.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u4fe1\u606f\u8015\u4f5c\"\u6982\u5ff5\u6846\u67b6\uff0c\u8ba4\u4e3a\u751f\u6210\u5f0fAI\u6b63\u5728\u63a8\u52a8\u4fe1\u606f\u4ea4\u4e92\u4ece\"\u4fe1\u606f\u89c5\u98df\"\u5411\"\u4fe1\u606f\u8015\u4f5c\"\u7684\u6839\u672c\u8f6c\u53d8\uff0c\u7c7b\u4f3c\u4e8e\u65b0\u77f3\u5668\u65f6\u4ee3\u4ece\u72e9\u730e\u91c7\u96c6\u5411\u519c\u4e1a\u7684\u8f6c\u53d8\u3002", "motivation": "\u4f20\u7edf\u7684Berry Picking\u548c\u4fe1\u606f\u89c5\u98df\u7406\u8bba\u5c06\u7528\u6237\u89c6\u4e3a\u4fe1\u606f\u6536\u96c6\u8005\uff0c\u5728\u5206\u5e03\u5f0f\u8d44\u6e90\u4e2d\u673a\u4f1a\u4e3b\u4e49\u641c\u7d22\u4ee5\u6ee1\u8db3\u4e0d\u65ad\u53d8\u5316\u7684\u4fe1\u606f\u9700\u6c42\u3002\u7136\u800c\uff0c\u751f\u6210\u5f0fAI\u7684\u5174\u8d77\u6b63\u5728\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u4eba\u4eec\u751f\u4ea7\u3001\u7ec4\u7ec7\u548c\u91cd\u7528\u4fe1\u606f\u7684\u65b9\u5f0f\uff0c\u8fd9\u4e9b\u4f20\u7edf\u8303\u5f0f\u5df2\u65e0\u6cd5\u5b8c\u5168\u6355\u6349\u8fd9\u4e00\u8f6c\u53d8\u3002", "method": "\u91c7\u7528\u5386\u53f2\u7c7b\u6bd4\u548c\u5b9e\u8bc1\u8bc1\u636e\uff0c\u5f15\u5165\"\u4fe1\u606f\u8015\u4f5c\"\u4f5c\u4e3a\u6982\u5ff5\u6846\u67b6\uff0c\u5206\u6790\u5176\u4f5c\u4e3a\u4fe1\u606f\u4ea4\u4e92\u81ea\u7136\u6f14\u5316\u7684\u7279\u5f81\u3002\u901a\u8fc7\u89c6\u89d2\u6027\u8bba\u6587\u7684\u5f62\u5f0f\uff0c\u63a2\u8ba8\u4fe1\u606f\u8015\u4f5c\u7684\u597d\u5904\u3001\u673a\u4f1a\u3001\u8bbe\u8ba1\u5f71\u54cd\u3001\u8bc4\u4f30\u65b9\u6cd5\u4ee5\u53ca\u4f34\u968f\u7684\u98ce\u9669\u3002", "result": "\u63d0\u51fa\u4fe1\u606f\u8015\u4f5c\u6846\u67b6\uff0c\u5c06\u751f\u6210\u5f0fAI\u8d4b\u80fd\u7684\u4fe1\u606f\u4ea4\u4e92\u63cf\u8ff0\u4e3a\uff1a\u7528\u6237\u901a\u8fc7\u63d0\u793a\"\u64ad\u79cd\"\uff0c\u968f\u65f6\u95f4\"\u57f9\u80b2\"\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5728\u81ea\u5df1\u7684\"\u5730\u5757\"\u4e2d\"\u6536\u83b7\"\u4e30\u5bcc\u7ed3\u6784\u5316\u7684\u76f8\u5173\u4fe1\u606f\u4ea7\u51fa\uff0c\u800c\u975e\u5728\u4ed6\u4eba\u7684\"\u8865\u4e01\"\u95f4\u89c5\u98df\u3002", "conclusion": "\u968f\u7740\u751f\u6210\u5f0fAI\u6280\u672f\u7684\u666e\u53ca\uff0c\u4fe1\u606f\u8015\u4f5c\u5c06\u9010\u6e10\u53d6\u4ee3\u77ed\u6682\u3001\u57fa\u4e8e\u8865\u4e01\u7684\u89c5\u98df\uff0c\u6210\u4e3a\u4e3b\u5bfc\u7684\u4ea4\u4e92\u6a21\u5f0f\uff0c\u6807\u5fd7\u7740\u4eba\u673a\u4fe1\u606f\u4ea4\u4e92\u53ca\u5176\u7814\u7a76\u7684\u66f4\u5e7f\u6cdb\u8f6c\u53d8\u3002"}}
{"id": "2601.11567", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11567", "abs": "https://arxiv.org/abs/2601.11567", "authors": ["Vanessa D'Amario", "Randy Daniel", "Alessandro Zanetti", "Dhruv Edamadaka", "Nitya Alaparthy", "Joshua Tarkoff"], "title": "Measuring Stability Beyond Accuracy in Small Open-Source Medical Large Language Models for Pediatric Endocrinology", "comment": "20 pages, 11 figures, accepted at 47 workshop Reproducible Artificial Intelligence (AAAI 2026, Singapore, January 27, 2026)", "summary": "Small open-source medical large language models (LLMs) offer promising opportunities for low-resource deployment and broader accessibility. However, their evaluation is often limited to accuracy on medical multiple choice question (MCQ) benchmarks, and lacks evaluation of consistency, robustness, or reasoning behavior. We use MCQ coupled to human evaluation and clinical review to assess six small open-source medical LLMs (HuatuoGPT-o1 (Chen 2024), Diabetica-7B, Diabetica-o1 (Wei 2024), Meditron3-8B (Sallinen2025), MedFound-7B (Liu 2025), and ClinicaGPT-base-zh (Wang 2023)) in pediatric endocrinology. In deterministic settings, we examine the effect of prompt variation on models' output and self-assessment bias. In stochastic settings, we evaluate output variability and investigate the relationship between consistency and correctness. HuatuoGPT-o1-8B achieved the highest performance. The results show that high consistency across the model response is not an indicator of correctness, although HuatuoGPT-o1-8B showed the highest consistency rate. When tasked with selecting correct reasoning, both HuatuoGPT-o1-8B and Diabetica-o1 exhibit self-assessment bias and dependency on the order of the candidate explanations. Expert review of incorrect reasoning rationales identified a mix of clinically acceptable responses and clinical oversight. We further show that system-level perturbations, such as differences in CUDA builds, can yield statistically significant shifts in model output despite stable accuracy. This work demonstrates that small, semantically negligible prompt perturbations lead to divergent outputs, raising concerns about reproducibility of LLM-based evaluations and highlights the output variability under different stochastic regimes, emphasizing the need of a broader diagnostic framework to understand potential pitfalls in real-world clinical decision support scenarios.", "AI": {"tldr": "\u8bc4\u4f30\u516d\u4e2a\u5c0f\u578b\u5f00\u6e90\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\u5728\u513f\u79d1\u5185\u5206\u6ccc\u5b66\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u4e00\u81f4\u6027\u5e76\u975e\u6b63\u786e\u6027\u7684\u6307\u6807\uff0c\u63d0\u793a\u5fae\u5c0f\u53d8\u5316\u4f1a\u5bfc\u81f4\u8f93\u51fa\u5dee\u5f02\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u5168\u9762\u7684\u8bca\u65ad\u6846\u67b6", "motivation": "\u5c0f\u578b\u5f00\u6e90\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u5177\u6709\u5e94\u7528\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u591a\u9009\u9898\u51c6\u786e\u7387\uff0c\u7f3a\u4e4f\u5bf9\u4e00\u81f4\u6027\u3001\u9c81\u68d2\u6027\u548c\u63a8\u7406\u884c\u4e3a\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bca\u65ad\u6846\u67b6\u6765\u7406\u89e3\u5b9e\u9645\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u6f5c\u5728\u95ee\u9898", "method": "\u4f7f\u7528\u591a\u9009\u9898\u7ed3\u5408\u4eba\u5de5\u8bc4\u4f30\u548c\u4e34\u5e8a\u5ba1\u67e5\uff0c\u8bc4\u4f30\u516d\u4e2a\u5c0f\u578b\u5f00\u6e90\u533b\u7597LLM\uff1b\u5728\u786e\u5b9a\u6027\u8bbe\u7f6e\u4e2d\u68c0\u67e5\u63d0\u793a\u53d8\u5316\u5bf9\u6a21\u578b\u8f93\u51fa\u548c\u81ea\u6211\u8bc4\u4f30\u504f\u5dee\u7684\u5f71\u54cd\uff1b\u5728\u968f\u673a\u6027\u8bbe\u7f6e\u4e2d\u8bc4\u4f30\u8f93\u51fa\u53d8\u5f02\u6027\uff0c\u5e76\u7814\u7a76\u4e00\u81f4\u6027\u4e0e\u6b63\u786e\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\uff1b\u8fdb\u884c\u4e13\u5bb6\u5ba1\u67e5\u9519\u8bef\u63a8\u7406\u7406\u7531", "result": "HuatuoGPT-o1-8B\u8868\u73b0\u6700\u4f73\uff1b\u6a21\u578b\u54cd\u5e94\u7684\u9ad8\u4e00\u81f4\u6027\u5e76\u975e\u6b63\u786e\u6027\u7684\u6307\u6807\uff0c\u5c3d\u7ba1HuatuoGPT-o1-8B\u4e00\u81f4\u6027\u6700\u9ad8\uff1bHuatuoGPT-o1-8B\u548cDiabetica-o1\u8868\u73b0\u51fa\u81ea\u6211\u8bc4\u4f30\u504f\u5dee\u548c\u5bf9\u5019\u9009\u89e3\u91ca\u987a\u5e8f\u7684\u4f9d\u8d56\uff1b\u4e13\u5bb6\u5ba1\u67e5\u53d1\u73b0\u9519\u8bef\u63a8\u7406\u4e2d\u5305\u542b\u4e34\u5e8a\u53ef\u63a5\u53d7\u54cd\u5e94\u548c\u4e34\u5e8a\u758f\u5ffd\uff1b\u7cfb\u7edf\u7ea7\u6270\u52a8\uff08\u5982CUDA\u6784\u5efa\u5dee\u5f02\uff09\u4f1a\u5bfc\u81f4\u6a21\u578b\u8f93\u51fa\u7684\u7edf\u8ba1\u663e\u8457\u53d8\u5316", "conclusion": "\u5c0f\u578b\u533b\u7597LLM\u5bf9\u5fae\u5c0f\u8bed\u4e49\u65e0\u5173\u7684\u63d0\u793a\u6270\u52a8\u654f\u611f\uff0c\u5bfc\u81f4\u8f93\u51fa\u5206\u6b67\uff0c\u8fd9\u5bf9\u57fa\u4e8eLLM\u8bc4\u4f30\u7684\u53ef\u91cd\u590d\u6027\u63d0\u51fa\u62c5\u5fe7\uff1b\u4e0d\u540c\u968f\u673a\u673a\u5236\u4e0b\u7684\u8f93\u51fa\u53d8\u5f02\u6027\u51f8\u663e\u4e86\u9700\u8981\u66f4\u5e7f\u6cdb\u7684\u8bca\u65ad\u6846\u67b6\u6765\u7406\u89e3\u5b9e\u9645\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u573a\u666f\u4e2d\u7684\u6f5c\u5728\u9677\u9631"}}
{"id": "2601.11622", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11622", "abs": "https://arxiv.org/abs/2601.11622", "authors": ["Hassan Ugail", "Newton Howard"], "title": "Dynamical Systems Analysis Reveals Functional Regimes in Large Language Models", "comment": null, "summary": "Large language models perform text generation through high-dimensional internal dynamics, yet the temporal organisation of these dynamics remains poorly understood. Most interpretability approaches emphasise static representations or causal interventions, leaving temporal structure largely unexplored. Drawing on neuroscience, where temporal integration and metastability are core markers of neural organisation, we adapt these concepts to transformer models and discuss a composite dynamical metric, computed from activation time-series during autoregressive generation. We evaluate this metric in GPT-2-medium across five conditions: structured reasoning, forced repetition, high-temperature noisy sampling, attention-head pruning, and weight-noise injection. Structured reasoning consistently exhibits elevated metric relative to repetitive, noisy, and perturbed regimes, with statistically significant differences confirmed by one-way ANOVA and large effect sizes in key comparisons. These results are robust to layer selection, channel subsampling, and random seeds. Our findings demonstrate that neuroscience-inspired dynamical metrics can reliably characterise differences in computational organisation across functional regimes in large language models. We stress that the proposed metric captures formal dynamical properties and does not imply subjective experience.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u795e\u7ecf\u79d1\u5b66\u4e2d\u7684\u65f6\u95f4\u6574\u5408\u4e0e\u4e9a\u7a33\u6001\u6982\u5ff5\u5e94\u7528\u4e8eTransformer\u6a21\u578b\uff0c\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6fc0\u6d3b\u65f6\u95f4\u5e8f\u5217\u7684\u590d\u5408\u52a8\u529b\u5b66\u6307\u6807\uff0c\u7528\u4e8e\u91cf\u5316LLM\u5728\u4e0d\u540c\u529f\u80fd\u72b6\u6001\u4e0b\u7684\u8ba1\u7b97\u7ec4\u7ec7\u5dee\u5f02\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u9ad8\u7ef4\u5185\u90e8\u52a8\u529b\u5b66\u8fdb\u884c\u6587\u672c\u751f\u6210\uff0c\u4f46\u8fd9\u4e9b\u52a8\u529b\u5b66\u7684\u65f6\u95f4\u7ec4\u7ec7\u673a\u5236\u5c1a\u4e0d\u6e05\u695a\u3002\u73b0\u6709\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u8868\u793a\u6216\u56e0\u679c\u5e72\u9884\uff0c\u7f3a\u4e4f\u5bf9\u65f6\u95f4\u7ed3\u6784\u7684\u63a2\u7d22\u3002\u7814\u7a76\u8005\u501f\u9274\u795e\u7ecf\u79d1\u5b66\u4e2d\u65f6\u95f4\u6574\u5408\u548c\u4e9a\u7a33\u6001\u4f5c\u4e3a\u795e\u7ecf\u7ec4\u7ec7\u6838\u5fc3\u6807\u5fd7\u7684\u6982\u5ff5\uff0c\u5c06\u5176\u5e94\u7528\u4e8eTransformer\u6a21\u578b\u3002", "method": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u590d\u5408\u52a8\u529b\u5b66\u6307\u6807\uff0c\u8be5\u6307\u6807\u57fa\u4e8e\u81ea\u56de\u5f52\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u6fc0\u6d3b\u65f6\u95f4\u5e8f\u5217\u8ba1\u7b97\u3002\u5728GPT-2-medium\u6a21\u578b\u4e0a\u8bc4\u4f30\u4e86\u4e94\u79cd\u6761\u4ef6\uff1a\u7ed3\u6784\u5316\u63a8\u7406\u3001\u5f3a\u5236\u91cd\u590d\u3001\u9ad8\u6e29\u566a\u58f0\u91c7\u6837\u3001\u6ce8\u610f\u529b\u5934\u526a\u679d\u548c\u6743\u91cd\u566a\u58f0\u6ce8\u5165\u3002\u4f7f\u7528\u5355\u56e0\u7d20\u65b9\u5dee\u5206\u6790\u548c\u6548\u5e94\u91cf\u8fdb\u884c\u7edf\u8ba1\u9a8c\u8bc1\uff0c\u5e76\u5bf9\u5c42\u9009\u62e9\u3001\u901a\u9053\u5b50\u91c7\u6837\u548c\u968f\u673a\u79cd\u5b50\u8fdb\u884c\u4e86\u9c81\u68d2\u6027\u68c0\u9a8c\u3002", "result": "\u7ed3\u6784\u5316\u63a8\u7406\u6761\u4ef6\u76f8\u5bf9\u4e8e\u91cd\u590d\u3001\u566a\u58f0\u548c\u6270\u52a8\u72b6\u6001\u8868\u73b0\u51fa\u663e\u8457\u5347\u9ad8\u7684\u52a8\u529b\u5b66\u6307\u6807\u3002\u7edf\u8ba1\u68c0\u9a8c\u663e\u793a\u7ec4\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5173\u952e\u6bd4\u8f83\u4e2d\u5177\u6709\u5927\u6548\u5e94\u91cf\u3002\u7ed3\u679c\u5bf9\u5c42\u9009\u62e9\u3001\u901a\u9053\u5b50\u91c7\u6837\u548c\u968f\u673a\u79cd\u5b50\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\u7684\u52a8\u529b\u5b66\u6307\u6807\u80fd\u591f\u53ef\u9760\u5730\u8868\u5f81\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u529f\u80fd\u72b6\u6001\u4e0b\u7684\u8ba1\u7b97\u7ec4\u7ec7\u5dee\u5f02\u3002\u8be5\u6307\u6807\u6355\u83b7\u7684\u662f\u5f62\u5f0f\u52a8\u529b\u5b66\u7279\u6027\uff0c\u4e0d\u6d89\u53ca\u4e3b\u89c2\u4f53\u9a8c\u3002"}}
{"id": "2601.11573", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11573", "abs": "https://arxiv.org/abs/2601.11573", "authors": ["Muhammad Muneeb", "David B. Ascher"], "title": "An Empirical Analysis of Fine-Tuning Large Language Models on Bioinformatics Literature: PRSGPT and BioStarsGPT", "comment": null, "summary": "Large language models (LLMs) often lack specialized knowledge for complex bioinformatics applications. We present a reproducible pipeline for fine-tuning LLMs on specialized bioinformatics data, demonstrated through two use cases: PRSGPT, focused on polygenic risk score (PRS) tools, and BioStarsGPT, trained on community forum discussions. The nine-step pipeline integrates diverse data sources, structured preprocessing, prompt-based question-answer (QA) generation (via Google Gemini), natural language inference (NLI) for quality control, semantic deduplication, clustering-based data splitting, and parameter-efficient fine-tuning using LoRA. We fine-tuned three LLMs (LLaMA-3.2-3B, Qwen2.5-7B, Gemma) and benchmarked them on over 14 lexical and semantic metrics. Qwen2.5-7B emerged as the best performer, with BLEU-4 and ROUGE-1 improvements of 82\\% and 70\\% for PRSGPT and 6\\% and 18\\% for BioStarsGPT, respectively. The open-source datasets produced include over 28,000 QA pairs for PRSGPT and 154,282 for BioStarsGPT. Human evaluation of PRSGPT yielded 61.9\\% accuracy on the PRS tools comparison task, comparable to Google Gemini (61.4\\%), but with richer methodological detail and accurate citations. BioStarsGPT demonstrated 59\\% conceptual accuracy across 142 curated bioinformatics questions. Our pipeline enables scalable, domain-specific fine-tuning of LLMs. It enables privacy-preserving, locally deployable bioinformatics assistants, explores their practical applications, and addresses the challenges, limitations, and mitigation strategies associated with their development and use.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7528\u4e8e\u751f\u7269\u4fe1\u606f\u5b66\u9886\u57df\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u7684\u4e5d\u6b65\u53ef\u91cd\u590d\u6d41\u7a0b\uff0c\u901a\u8fc7PRSGPT\uff08\u591a\u57fa\u56e0\u98ce\u9669\u8bc4\u5206\u5de5\u5177\uff09\u548cBioStarsGPT\uff08\u793e\u533a\u8bba\u575b\uff09\u4e24\u4e2a\u7528\u4f8b\u9a8c\u8bc1\uff0c\u751f\u6210\u8d85\u8fc718\u4e07QA\u5bf9\uff0cQwen2.5-7B\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u751f\u7269\u4fe1\u606f\u5b66\u5e94\u7528\u4e2d\u7f3a\u4e4f\u4e13\u4e1a\u77e5\u8bc6\uff0c\u9700\u8981\u5f00\u53d1\u53ef\u6269\u5c55\u7684\u9886\u57df\u7279\u5b9a\u5fae\u8c03\u65b9\u6cd5\uff0c\u521b\u5efa\u53ef\u5728\u672c\u5730\u90e8\u7f72\u7684\u9690\u79c1\u4fdd\u62a4\u578b\u751f\u7269\u4fe1\u606f\u5b66\u52a9\u624b\u3002", "method": "\u4e5d\u6b65\u6d41\u7a0b\uff1a\u6574\u5408\u591a\u6837\u6570\u636e\u6e90\u3001\u7ed3\u6784\u5316\u9884\u5904\u7406\u3001\u57fa\u4e8e\u63d0\u793a\u7684QA\u751f\u6210\uff08\u4f7f\u7528Google Gemini\uff09\u3001\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u8d28\u91cf\u63a7\u5236\u3001\u8bed\u4e49\u53bb\u91cd\u3001\u57fa\u4e8e\u805a\u7c7b\u7684\u6570\u636e\u5206\u5272\u3001\u4f7f\u7528LoRA\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u3002\u5bf9LLaMA-3.2-3B\u3001Qwen2.5-7B\u3001Gemma\u4e09\u4e2a\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002", "result": "Qwen2.5-7B\u8868\u73b0\u6700\u4f73\uff1aPRSGPT\u7684BLEU-4\u548cROUGE-1\u5206\u522b\u63d0\u534782%\u548c70%\uff0cBioStarsGPT\u5206\u522b\u63d0\u53476%\u548c18%\u3002\u751f\u621028,000+ PRSGPT QA\u5bf9\u548c154,282 BioStarsGPT QA\u5bf9\u3002PRSGPT\u5728PRS\u5de5\u5177\u6bd4\u8f83\u4efb\u52a1\u4e0a\u83b7\u5f9761.9%\u51c6\u786e\u7387\uff08\u4e0eGoogle Gemini\u768461.4%\u76f8\u5f53\uff09\uff0c\u4f46\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u65b9\u6cd5\u7ec6\u8282\u548c\u51c6\u786e\u5f15\u7528\u3002BioStarsGPT\u5728142\u4e2a\u751f\u7269\u4fe1\u606f\u5b66\u95ee\u9898\u4e0a\u8fbe\u523059%\u6982\u5ff5\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u6d41\u7a0b\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u7684\u9886\u57df\u7279\u5b9aLLM\u5fae\u8c03\uff0c\u652f\u6301\u9690\u79c1\u4fdd\u62a4\u7684\u672c\u5730\u90e8\u7f72\u751f\u7269\u4fe1\u606f\u5b66\u52a9\u624b\uff0c\u63a2\u7d22\u4e86\u5b9e\u9645\u5e94\u7528\uff0c\u5e76\u89e3\u51b3\u4e86\u5f00\u53d1\u548c\u4f7f\u7528\u4e2d\u7684\u6311\u6218\u3001\u9650\u5236\u53ca\u7f13\u89e3\u7b56\u7565\u3002"}}
{"id": "2601.11625", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11625", "abs": "https://arxiv.org/abs/2601.11625", "authors": ["Sahil Rajesh Dhayalkar"], "title": "Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance", "comment": "8 pages, Submitted to ACL Rolling Review and is under review", "summary": "Fine-tuning pretrained language models can improve task performance while subtly altering the evidence a model relies on. We propose a training-time interpretability view that tracks token-level attributions across finetuning epochs. We define explanation driftas the epoch-to-epoch change in normalized token attributions on a fixed probe set, and introduce the Reasoning Stabilization Point(RSP), the earliest epoch after which drift remains consistently low. RSP is computed from within-run drift dynamics and requires no tuning on out-of-distribution data. Across multiple lightweight transformer classifiers and benchmark classification tasks, drift typically collapses into a low, stable regime early in training, while validation accuracy continues to change only marginally. In a controlled shortcut setting with label-correlated trigger tokens, attribution dynamics expose increasing reliance on the shortcut even when validation accuracy remains competitive. Overall, explanation drift provides a simple, low-cost diagnostic for monitoring how decision evidence evolves during fine-tuning and for selecting checkpoints in a stable-evidence regime.", "AI": {"tldr": "\u63d0\u51fa\u8bad\u7ec3\u65f6\u89e3\u91ca\u6027\u89c6\u89d2\uff0c\u901a\u8fc7\u8ddf\u8e2a\u5fae\u8c03\u8fc7\u7a0b\u4e2dtoken\u7ea7\u5f52\u56e0\u53d8\u5316\u6765\u76d1\u63a7\u6a21\u578b\u51b3\u7b56\u8bc1\u636e\u7684\u6f14\u53d8\uff0c\u5b9a\u4e49\u89e3\u91ca\u6f02\u79fb\u548c\u63a8\u7406\u7a33\u5b9a\u70b9\u4f5c\u4e3a\u8bca\u65ad\u5de5\u5177\u3002", "motivation": "\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u867d\u7136\u80fd\u63d0\u5347\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u4f1a\u5fae\u5999\u6539\u53d8\u6a21\u578b\u4f9d\u8d56\u7684\u8bc1\u636e\u3002\u9700\u8981\u4e00\u79cd\u8bad\u7ec3\u65f6\u89e3\u91ca\u6027\u65b9\u6cd5\u6765\u76d1\u63a7\u51b3\u7b56\u8bc1\u636e\u5982\u4f55\u6f14\u53d8\uff0c\u7279\u522b\u662f\u5728\u6a21\u578b\u53ef\u80fd\u4f9d\u8d56\u6377\u5f84\u7279\u5f81\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u63d0\u51fa\u89e3\u91ca\u6f02\u79fb\u6982\u5ff5\uff0c\u5b9a\u4e49\u4e3a\u56fa\u5b9a\u63a2\u6d4b\u96c6\u4e0a\u5f52\u4e00\u5316token\u5f52\u56e0\u7684epoch\u95f4\u53d8\u5316\u3002\u5f15\u5165\u63a8\u7406\u7a33\u5b9a\u70b9(RSP)\uff0c\u5373\u6f02\u79fb\u9996\u6b21\u8fdb\u5165\u5e76\u4fdd\u6301\u4f4e\u7a33\u5b9a\u72b6\u6001\u7684\u6700\u65e9epoch\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u6f02\u79fb\u52a8\u6001\uff0c\u65e0\u9700\u5728\u5206\u5e03\u5916\u6570\u636e\u4e0a\u8c03\u6574\u3002", "result": "\u5728\u591a\u4e2a\u8f7b\u91cf\u7ea7transformer\u5206\u7c7b\u5668\u548c\u57fa\u51c6\u5206\u7c7b\u4efb\u52a1\u4e0a\uff0c\u6f02\u79fb\u901a\u5e38\u5728\u8bad\u7ec3\u65e9\u671f\u5c31\u8fdb\u5165\u4f4e\u7a33\u5b9a\u72b6\u6001\uff0c\u800c\u9a8c\u8bc1\u51c6\u786e\u7387\u4ec5\u53d1\u751f\u8fb9\u9645\u53d8\u5316\u3002\u5728\u53d7\u63a7\u7684\u6377\u5f84\u8bbe\u7f6e\u4e2d\uff0c\u5f52\u56e0\u52a8\u6001\u63ed\u793a\u4e86\u6a21\u578b\u5bf9\u6377\u5f84\u7684\u4f9d\u8d56\u589e\u52a0\uff0c\u5373\u4f7f\u9a8c\u8bc1\u51c6\u786e\u7387\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "\u89e3\u91ca\u6f02\u79fb\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u3001\u4f4e\u6210\u672c\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u7528\u4e8e\u76d1\u63a7\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u51b3\u7b56\u8bc1\u636e\u7684\u6f14\u53d8\uff0c\u5e76\u9009\u62e9\u5904\u4e8e\u7a33\u5b9a\u8bc1\u636e\u72b6\u6001\u7684\u68c0\u67e5\u70b9\uff0c\u6709\u52a9\u4e8e\u8bc6\u522b\u6a21\u578b\u5bf9\u6377\u5f84\u7279\u5f81\u7684\u4f9d\u8d56\u3002"}}
{"id": "2601.12828", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.12828", "abs": "https://arxiv.org/abs/2601.12828", "authors": ["Masoud Mansoury", "Jin Huang", "Mykola Pechenizkiy", "Herke van Hoof", "Maarten de Rijke"], "title": "The Unfairness of Multifactorial Bias in Recommendation", "comment": null, "summary": "Popularity bias and positivity bias are two prominent sources of bias in recommender systems. Both arise from input data, propagate through recommendation models, and lead to unfair or suboptimal outcomes. Popularity bias occurs when a small subset of items receives most interactions, while positivity bias stems from the over-representation of high rating values. Although each bias has been studied independently, their combined effect, to which we refer to as multifactorial bias, remains underexplored. In this work, we examine how multifactorial bias influences item-side fairness, focusing on exposure bias, which reflects the unequal visibility of items in recommendation outputs. Through simulation studies, we find that positivity bias is disproportionately concentrated on popular items, further amplifying their over-exposure. Motivated by this insight, we adapt a percentile-based rating transformation as a pre-processing strategy to mitigate multifactorial bias. Experiments using six recommendation algorithms across four public datasets show that this approach improves exposure fairness with negligible accuracy loss. We also demonstrate that integrating this pre-processing step into post-processing fairness pipelines enhances their effectiveness and efficiency, enabling comparable or better fairness with reduced computational cost. These findings highlight the importance of addressing multifactorial bias and demonstrate the practical value of simple, data-driven pre-processing methods for improving fairness in recommender systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u591a\u56e0\u5b50\u504f\u5dee\uff08\u6d41\u884c\u5ea6\u504f\u5dee\u548c\u79ef\u6781\u6027\u504f\u5dee\u7684\u7ec4\u5408\u6548\u5e94\uff09\uff0c\u63d0\u51fa\u901a\u8fc7\u767e\u5206\u4f4d\u6570\u8bc4\u5206\u8f6c\u6362\u7684\u9884\u5904\u7406\u65b9\u6cd5\u6765\u6539\u5584\u66dd\u5149\u516c\u5e73\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u516c\u5e73\u6027\u4e14\u8ba1\u7b97\u6210\u672c\u4f4e\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u4e2d\u5b58\u5728\u6d41\u884c\u5ea6\u504f\u5dee\u548c\u79ef\u6781\u6027\u504f\u5dee\uff0c\u8fd9\u4e24\u79cd\u504f\u5dee\u90fd\u6e90\u4e8e\u8f93\u5165\u6570\u636e\u5e76\u901a\u8fc7\u63a8\u8350\u6a21\u578b\u4f20\u64ad\uff0c\u5bfc\u81f4\u4e0d\u516c\u5e73\u6216\u6b21\u4f18\u7ed3\u679c\u3002\u867d\u7136\u6bcf\u79cd\u504f\u5dee\u90fd\u5df2\u88ab\u72ec\u7acb\u7814\u7a76\uff0c\u4f46\u5b83\u4eec\u7684\u7ec4\u5408\u6548\u5e94\uff08\u591a\u56e0\u5b50\u504f\u5dee\uff09\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u591a\u56e0\u5b50\u504f\u5dee\u5982\u4f55\u5f71\u54cd\u9879\u76ee\u4fa7\u516c\u5e73\u6027\uff0c\u7279\u522b\u662f\u66dd\u5149\u504f\u5dee\u3002", "method": "\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u53d1\u73b0\u79ef\u6781\u6027\u504f\u5dee\u4e0d\u6210\u6bd4\u4f8b\u5730\u96c6\u4e2d\u5728\u6d41\u884c\u9879\u76ee\u4e0a\uff0c\u8fdb\u4e00\u6b65\u653e\u5927\u4e86\u5b83\u4eec\u7684\u8fc7\u5ea6\u66dd\u5149\u3002\u57fa\u4e8e\u8fd9\u4e00\u6d1e\u5bdf\uff0c\u91c7\u7528\u767e\u5206\u4f4d\u6570\u8bc4\u5206\u8f6c\u6362\u4f5c\u4e3a\u9884\u5904\u7406\u7b56\u7565\u6765\u7f13\u89e3\u591a\u56e0\u5b50\u504f\u5dee\u3002\u4f7f\u7528\u516d\u79cd\u63a8\u8350\u7b97\u6cd5\u5728\u56db\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u5c06\u8be5\u9884\u5904\u7406\u6b65\u9aa4\u96c6\u6210\u5230\u540e\u5904\u7406\u516c\u5e73\u6027\u6d41\u7a0b\u4e2d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u53ef\u5ffd\u7565\u7684\u51c6\u786e\u6027\u635f\u5931\u4e0b\u6539\u5584\u4e86\u66dd\u5149\u516c\u5e73\u6027\u3002\u5c06\u9884\u5904\u7406\u96c6\u6210\u5230\u540e\u5904\u7406\u516c\u5e73\u6027\u6d41\u7a0b\u4e2d\u589e\u5f3a\u4e86\u5176\u6548\u679c\u548c\u6548\u7387\uff0c\u80fd\u591f\u4ee5\u66f4\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u5b9e\u73b0\u76f8\u5f53\u6216\u66f4\u597d\u7684\u516c\u5e73\u6027\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u89e3\u51b3\u591a\u56e0\u5b50\u504f\u5dee\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u7b80\u5355\u3001\u6570\u636e\u9a71\u52a8\u7684\u9884\u5904\u7406\u65b9\u6cd5\u5728\u6539\u5584\u63a8\u8350\u7cfb\u7edf\u516c\u5e73\u6027\u65b9\u9762\u7684\u5b9e\u9645\u4ef7\u503c\u3002\u767e\u5206\u4f4d\u6570\u8bc4\u5206\u8f6c\u6362\u662f\u4e00\u79cd\u6709\u6548\u7684\u9884\u5904\u7406\u7b56\u7565\uff0c\u80fd\u591f\u7f13\u89e3\u591a\u56e0\u5b50\u504f\u5dee\u5bf9\u66dd\u5149\u516c\u5e73\u6027\u7684\u8d1f\u9762\u5f71\u54cd\u3002"}}
{"id": "2601.11575", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11575", "abs": "https://arxiv.org/abs/2601.11575", "authors": ["Sotirios Panagiotis Chytas", "Vikas Singh"], "title": "Concept Attractors in LLMs and their Applications", "comment": null, "summary": "Large language models (LLMs) often map semantically related prompts to similar internal representations at specific layers, even when their surface forms differ widely. We show that this behavior can be explained through Iterated Function Systems (IFS), where layers act as contractive mappings toward concept-specific Attractors. We leverage this insight and develop simple, training-free methods that operate directly on these Attractors to solve a wide range of practical tasks, including language translation, hallucination reduction, guardrailing, and synthetic data generation. Despite their simplicity, these Attractor-based interventions match or exceed specialized baselines, offering an efficient alternative to heavy fine-tuning, generalizable in scenarios where baselines underperform.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faLLM\u5185\u90e8\u8868\u793a\u53ef\u901a\u8fc7\u8fed\u4ee3\u51fd\u6570\u7cfb\u7edf\u89e3\u91ca\uff0c\u5c42\u4f5c\u4e3a\u6536\u7f29\u6620\u5c04\u5411\u6982\u5ff5\u5438\u5f15\u5b50\u6536\u655b\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u65e0\u9700\u8bad\u7ec3\u7684\u5438\u5f15\u5b50\u5e72\u9884\u65b9\u6cd5\u89e3\u51b3\u591a\u79cd\u4efb\u52a1", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e38\u5c06\u8bed\u4e49\u76f8\u5173\u4f46\u8868\u9762\u5f62\u5f0f\u4e0d\u540c\u7684\u63d0\u793a\u6620\u5c04\u5230\u76f8\u4f3c\u5185\u90e8\u8868\u793a\uff0c\u8fd9\u79cd\u73b0\u8c61\u9700\u8981\u7406\u8bba\u89e3\u91ca\uff0c\u5e76\u63a2\u7d22\u5229\u7528\u8fd9\u79cd\u7279\u6027\u5f00\u53d1\u9ad8\u6548\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\u89e3\u51b3\u5b9e\u9645\u4efb\u52a1", "method": "\u5c06LLM\u5c42\u89e3\u91ca\u4e3a\u8fed\u4ee3\u51fd\u6570\u7cfb\u7edf\u4e2d\u7684\u6536\u7f29\u6620\u5c04\uff0c\u5411\u6982\u5ff5\u7279\u5b9a\u5438\u5f15\u5b50\u6536\u655b\uff1b\u5f00\u53d1\u76f4\u63a5\u64cd\u4f5c\u8fd9\u4e9b\u5438\u5f15\u5b50\u7684\u65e0\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5305\u62ec\u8bed\u8a00\u7ffb\u8bd1\u3001\u5e7b\u89c9\u51cf\u5c11\u3001\u62a4\u680f\u8bbe\u7f6e\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u7b49\u4efb\u52a1", "result": "\u57fa\u4e8e\u5438\u5f15\u5b50\u7684\u5e72\u9884\u65b9\u6cd5\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u5339\u914d\u6216\u8d85\u8d8a\u4e13\u95e8\u57fa\u7ebf\uff0c\u63d0\u4f9b\u6bd4\u5927\u91cf\u5fae\u8c03\u66f4\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5728\u57fa\u7ebf\u8868\u73b0\u4e0d\u4f73\u7684\u573a\u666f\u4e2d\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b", "conclusion": "LLM\u5185\u90e8\u8868\u793a\u7684\u5438\u5f15\u5b50\u7ed3\u6784\u4e3a\u7406\u89e3\u6a21\u578b\u884c\u4e3a\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u57fa\u4e8e\u5438\u5f15\u5b50\u7684\u65e0\u8bad\u7ec3\u65b9\u6cd5\u5728\u591a\u79cd\u5b9e\u9645\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u9ad8\u6548\u6a21\u578b\u5e72\u9884\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84"}}
{"id": "2601.12985", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.12985", "abs": "https://arxiv.org/abs/2601.12985", "authors": ["Melanie A. Kilian", "David Elsweiler"], "title": "Rules, Resources, and Restrictions: A Taxonomy of Task-Based Information Request Intents", "comment": "11 pages, 1 figure, to be published in: 2026 ACM SIGIR Conference on Human Information Interaction and Retrieval (CHIIR '26), March 22-26, 2026, Seattle, WA, USA. ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/3786304.3787863", "summary": "Understanding and classifying query intents can improve retrieval effectiveness by helping align search results with the motivations behind user queries. However, existing intent taxonomies are typically derived from system log data and capture mostly isolated information needs, while the broader task context often remains unaddressed. This limitation becomes increasingly relevant as interactions with Large Language Models (LLMs) expand user expectations from simple query answering toward comprehensive task support, for example, with purchasing decisions or in travel planning. At the same time, current LLMs still struggle to fully interpret complex and multifaceted tasks. To address this gap, we argue for a stronger task-based perspective on query intent. Drawing on a grounded-theory-based interview study with airport information clerks, we present a taxonomy of task-based information request intents that bridges the gap between traditional query-focused approaches and the emerging demands of AI-driven task-oriented search.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4efb\u52a1\u7684\u4fe1\u606f\u8bf7\u6c42\u610f\u56fe\u5206\u7c7b\u6cd5\uff0c\u4ee5\u5f25\u8865\u4f20\u7edf\u67e5\u8be2\u610f\u56fe\u5206\u7c7b\u4e0eAI\u9a71\u52a8\u4efb\u52a1\u5bfc\u5411\u641c\u7d22\u4e4b\u95f4\u7684\u5dee\u8ddd", "motivation": "\u73b0\u6709\u610f\u56fe\u5206\u7c7b\u4e3b\u8981\u57fa\u4e8e\u7cfb\u7edf\u65e5\u5fd7\u6570\u636e\uff0c\u5173\u6ce8\u5b64\u7acb\u4fe1\u606f\u9700\u6c42\u800c\u5ffd\u7565\u4efb\u52a1\u4e0a\u4e0b\u6587\uff0c\u65e0\u6cd5\u6ee1\u8db3LLM\u65f6\u4ee3\u7528\u6237\u5bf9\u7efc\u5408\u6027\u4efb\u52a1\u652f\u6301\u7684\u9700\u6c42", "method": "\u91c7\u7528\u624e\u6839\u7406\u8bba\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u673a\u573a\u4fe1\u606f\u54a8\u8be2\u5458\u7684\u8bbf\u8c08\u7814\u7a76\uff0c\u6784\u5efa\u4efb\u52a1\u578b\u4fe1\u606f\u8bf7\u6c42\u610f\u56fe\u5206\u7c7b\u6cd5", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u8fde\u63a5\u4f20\u7edf\u67e5\u8be2\u5bfc\u5411\u65b9\u6cd5\u4e0e\u65b0\u5174AI\u9a71\u52a8\u4efb\u52a1\u5bfc\u5411\u641c\u7d22\u9700\u6c42\u7684\u610f\u56fe\u5206\u7c7b\u4f53\u7cfb", "conclusion": "\u9700\u8981\u66f4\u5f3a\u7684\u4efb\u52a1\u89c6\u89d2\u6765\u7406\u89e3\u67e5\u8be2\u610f\u56fe\uff0c\u4ee5\u652f\u6301LLM\u66f4\u597d\u5730\u89e3\u91ca\u590d\u6742\u591a\u9762\u4efb\u52a1\u5e76\u63d0\u4f9b\u5168\u9762\u4efb\u52a1\u652f\u6301"}}
{"id": "2601.13222", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13222", "abs": "https://arxiv.org/abs/2601.13222", "authors": ["Laura Dietz", "Bryan Li", "Gabrielle Liu", "Jia-Huei Ju", "Eugene Yang", "Dawn Lawrie", "William Walden", "James Mayfield"], "title": "Incorporating Q&A Nuggets into Retrieval-Augmented Generation", "comment": null, "summary": "RAGE systems integrate ideas from automatic evaluation (E) into Retrieval-augmented Generation (RAG). As one such example, we present Crucible, a Nugget-Augmented Generation System that preserves explicit citation provenance by constructing a bank of Q&A nuggets from retrieved documents and uses them to guide extraction, selection, and report generation. Reasoning on nuggets avoids repeated information through clear and interpretable Q&A semantics - instead of opaque cluster abstractions - while maintaining citation provenance throughout the entire generation process. Evaluated on the TREC NeuCLIR 2024 collection, our Crucible system substantially outperforms Ginger, a recent nugget-based RAG system, in nugget recall, density, and citation grounding.", "AI": {"tldr": "RAGE\u7cfb\u7edf\u5c06\u81ea\u52a8\u8bc4\u4f30\u601d\u60f3\u878d\u5165\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff0c\u63d0\u51fa\u4e86Crucible\u7cfb\u7edf\uff0c\u901a\u8fc7\u6784\u5efa\u95ee\u7b54\u7247\u6bb5\u5e93\u6765\u4fdd\u6301\u663e\u5f0f\u5f15\u7528\u6eaf\u6e90\uff0c\u5728TREC NeuCLIR 2024\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709RAG\u7cfb\u7edf\u5728\u4fdd\u6301\u5f15\u7528\u6eaf\u6e90\u548c\u907f\u514d\u4fe1\u606f\u91cd\u590d\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u900f\u660e\u548c\u53ef\u89e3\u91ca\u7684\u8bed\u4e49\u8868\u793a\u6765\u6539\u8fdb\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u8d28\u91cf\u548c\u53ef\u4fe1\u5ea6\u3002", "method": "\u63d0\u51faCrucible\u7cfb\u7edf\uff0c\u57fa\u4e8e\u95ee\u7b54\u7247\u6bb5\u589e\u5f3a\u751f\u6210\uff1a1) \u4ece\u68c0\u7d22\u6587\u6863\u6784\u5efa\u95ee\u7b54\u7247\u6bb5\u5e93\uff1b2) \u4f7f\u7528\u7247\u6bb5\u6307\u5bfc\u63d0\u53d6\u3001\u9009\u62e9\u548c\u62a5\u544a\u751f\u6210\uff1b3) \u5728\u7247\u6bb5\u4e0a\u8fdb\u884c\u63a8\u7406\uff0c\u907f\u514d\u4fe1\u606f\u91cd\u590d\uff1b4) \u5728\u6574\u4e2a\u751f\u6210\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u663e\u5f0f\u5f15\u7528\u6eaf\u6e90\u3002", "result": "\u5728TREC NeuCLIR 2024\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cCrucible\u7cfb\u7edf\u5728\u7247\u6bb5\u53ec\u56de\u7387\u3001\u5bc6\u5ea6\u548c\u5f15\u7528\u57fa\u7840\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u6700\u8fd1\u7684\u57fa\u4e8e\u7247\u6bb5\u7684RAG\u7cfb\u7edfGinger\u3002", "conclusion": "RAGE\u6846\u67b6\u901a\u8fc7\u96c6\u6210\u81ea\u52a8\u8bc4\u4f30\u601d\u60f3\u5230RAG\u4e2d\uff0c\u7279\u522b\u662fCrucible\u7cfb\u7edf\u7684\u95ee\u7b54\u7247\u6bb5\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u4fdd\u6301\u5f15\u7528\u6eaf\u6e90\u3001\u63d0\u9ad8\u4fe1\u606f\u8986\u76d6\u548c\u751f\u6210\u8d28\u91cf\uff0c\u4e3a\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u63d0\u4f9b\u4e86\u66f4\u900f\u660e\u548c\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11579", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11579", "abs": "https://arxiv.org/abs/2601.11579", "authors": ["Krzysztof Ociepa", "\u0141ukasz Flis", "Remigiusz Kinas", "Krzysztof Wr\u00f3bel", "Adrian Gwo\u017adziej"], "title": "Bielik 11B v3: Multilingual Large Language Model for European Languages", "comment": null, "summary": "We present Bielik 11B v3, a state-of-the-art language model highly optimized for the Polish language, while also maintaining strong capabilities in other European languages. This model extends the Mistral 7B v0.2 architecture, scaled to 11B parameters via depth up-scaling. Its development involved a comprehensive four-stage training pipeline: continuous pre-training, supervised fine-tuning (SFT), Direct Preference Optimization (DPO), and reinforcement learning.\n  Comprehensive evaluations demonstrate that Bielik 11B v3 achieves exceptional performance. It significantly surpasses other specialized Polish language models and outperforms many larger models (with 2-6 times more parameters) on a wide range of tasks, from basic linguistic understanding to complex reasoning.\n  The model's parameter efficiency, combined with extensive quantization options, allows for effective deployment across diverse hardware configurations. Bielik 11B v3 not only advances AI capabilities for the Polish language but also establishes a new benchmark for developing resource-efficient, high-performance models for less-represented languages.", "AI": {"tldr": "Bielik 11B v3\u662f\u4e00\u4e2a\u9488\u5bf9\u6ce2\u5170\u8bed\u4f18\u5316\u768411B\u53c2\u6570\u8bed\u8a00\u6a21\u578b\uff0c\u57fa\u4e8eMistral 7B v0.2\u67b6\u6784\u901a\u8fc7\u6df1\u5ea6\u6269\u5c55\u6784\u5efa\uff0c\u91c7\u7528\u56db\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff0c\u5728\u6ce2\u5170\u8bed\u4efb\u52a1\u4e0a\u8d85\u8d8a\u5176\u4ed6\u4e13\u4e1a\u6a21\u578b\u548c\u66f4\u5927\u6a21\u578b\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u9488\u5bf9\u6ce2\u5170\u8bed\u4f18\u5316\u7684\u9ad8\u6027\u80fd\u8bed\u8a00\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u5176\u4ed6\u6b27\u6d32\u8bed\u8a00\u7684\u826f\u597d\u652f\u6301\uff0c\u4e3a\u8d44\u6e90\u8f83\u5c11\u8bed\u8a00\u5efa\u7acb\u9ad8\u6548\u6a21\u578b\u5f00\u53d1\u7684\u65b0\u57fa\u51c6\u3002", "method": "\u57fa\u4e8eMistral 7B v0.2\u67b6\u6784\uff0c\u901a\u8fc7\u6df1\u5ea6\u6269\u5c55\u523011B\u53c2\u6570\uff1b\u91c7\u7528\u56db\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff1a\u6301\u7eed\u9884\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03(SFT)\u3001\u76f4\u63a5\u504f\u597d\u4f18\u5316(DPO)\u548c\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5728\u6ce2\u5170\u8bed\u4efb\u52a1\u4e0a\u663e\u8457\u8d85\u8d8a\u5176\u4ed6\u4e13\u4e1a\u6ce2\u5170\u8bed\u6a21\u578b\uff0c\u5e76\u4f18\u4e8e\u8bb8\u591a\u53c2\u6570\u591a2-6\u500d\u7684\u66f4\u5927\u6a21\u578b\uff1b\u5728\u4ece\u57fa\u7840\u8bed\u8a00\u7406\u89e3\u5230\u590d\u6742\u63a8\u7406\u7684\u5e7f\u6cdb\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "Bielik 11B v3\u4e0d\u4ec5\u63a8\u8fdb\u4e86\u6ce2\u5170\u8bed\u7684AI\u80fd\u529b\uff0c\u8fd8\u4e3a\u8d44\u6e90\u8f83\u5c11\u8bed\u8a00\u5f00\u53d1\u53c2\u6570\u9ad8\u6548\u3001\u9ad8\u6027\u80fd\u6a21\u578b\u5efa\u7acb\u4e86\u65b0\u57fa\u51c6\uff0c\u652f\u6301\u591a\u79cd\u91cf\u5316\u9009\u9879\u4ee5\u9002\u5e94\u4e0d\u540c\u786c\u4ef6\u914d\u7f6e\u3002"}}
{"id": "2601.13227", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13227", "abs": "https://arxiv.org/abs/2601.13227", "authors": ["Laura Dietz", "Bryan Li", "Eugene Yang", "Dawn Lawrie", "William Walden", "James Mayfield"], "title": "Insider Knowledge: How Much Can RAG Systems Gain from Evaluation Secrets?", "comment": null, "summary": "RAG systems are increasingly evaluated and optimized using LLM judges, an approach that is rapidly becoming the dominant paradigm for system assessment. Nugget-based approaches in particular are now embedded not only in evaluation frameworks but also in the architectures of RAG systems themselves. While this integration can lead to genuine improvements, it also creates a risk of faulty measurements due to circularity. In this paper, we investigate this risk through comparative experiments with nugget-based RAG systems, including Ginger and Crucible, against strong baselines such as GPT-Researcher. By deliberately modifying Crucible to generate outputs optimized for an LLM judge, we show that near-perfect evaluation scores can be achieved when elements of the evaluation - such as prompt templates or gold nuggets - are leaked or can be predicted. Our results highlight the importance of blind evaluation settings and methodological diversity to guard against mistaking metric overfitting for genuine system progress.", "AI": {"tldr": "\u8bba\u6587\u6307\u51faRAG\u7cfb\u7edf\u4e2d\u57fa\u4e8enugget\u7684LLM\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5faa\u73af\u98ce\u9669\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5f53\u8bc4\u4f30\u5143\u7d20\u6cc4\u9732\u65f6\uff0c\u7cfb\u7edf\u53ef\u4ee5\u8f7b\u6613\u83b7\u5f97\u63a5\u8fd1\u5b8c\u7f8e\u7684\u8bc4\u5206\uff0c\u5f3a\u8c03\u9700\u8981\u76f2\u8bc4\u4f30\u548c\u65b9\u6cd5\u591a\u6837\u6027\u6765\u907f\u514d\u6307\u6807\u8fc7\u62df\u5408", "motivation": "RAG\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u4f7f\u7528LLM\u8bc4\u4f30\u5668\u8fdb\u884c\u4f18\u5316\u548c\u8bc4\u4f30\uff0c\u8fd9\u79cd\u57fa\u4e8enugget\u7684\u65b9\u6cd5\u4e0d\u4ec5\u7528\u4e8e\u8bc4\u4f30\u6846\u67b6\uff0c\u8fd8\u96c6\u6210\u5230RAG\u7cfb\u7edf\u67b6\u6784\u4e2d\u3002\u867d\u7136\u8fd9\u79cd\u96c6\u6210\u53ef\u80fd\u5e26\u6765\u771f\u6b63\u6539\u8fdb\uff0c\u4f46\u4e5f\u5b58\u5728\u5faa\u73af\u6027\u5bfc\u81f4\u9519\u8bef\u6d4b\u91cf\u7684\u98ce\u9669\u3002\u8bba\u6587\u65e8\u5728\u8c03\u67e5\u8fd9\u79cd\u98ce\u9669", "method": "\u901a\u8fc7\u6bd4\u8f83\u5b9e\u9a8c\uff0c\u7814\u7a76\u57fa\u4e8enugget\u7684RAG\u7cfb\u7edf\uff08\u5982Ginger\u548cCrucible\uff09\u4e0e\u5f3a\u57fa\u7ebf\uff08\u5982GPT-Researcher\uff09\u7684\u6027\u80fd\u3002\u6545\u610f\u4fee\u6539Crucible\u4ee5\u751f\u6210\u9488\u5bf9LLM\u8bc4\u4f30\u5668\u4f18\u5316\u7684\u8f93\u51fa\uff0c\u6d4b\u8bd5\u5f53\u8bc4\u4f30\u5143\u7d20\uff08\u5982\u63d0\u793a\u6a21\u677f\u6216\u9ec4\u91d1nuggets\uff09\u6cc4\u9732\u6216\u53ef\u9884\u6d4b\u65f6\u7684\u8868\u73b0", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5f53\u8bc4\u4f30\u5143\u7d20\u6cc4\u9732\u65f6\uff0c\u53ef\u4ee5\u8f7b\u677e\u5b9e\u73b0\u63a5\u8fd1\u5b8c\u7f8e\u7684\u8bc4\u4f30\u5206\u6570\u3002\u8fd9\u8868\u660e\u57fa\u4e8enugget\u7684\u8bc4\u4f30\u65b9\u6cd5\u5bb9\u6613\u53d7\u5230\u5faa\u73af\u6027\u5f71\u54cd\uff0c\u7cfb\u7edf\u53ef\u4ee5\u901a\u8fc7\u4f18\u5316\u7279\u5b9a\u8bc4\u4f30\u6307\u6807\u800c\u975e\u771f\u6b63\u6539\u8fdb\u6027\u80fd\u6765\u83b7\u5f97\u9ad8\u5206", "conclusion": "\u5f3a\u8c03\u76f2\u8bc4\u4f30\u8bbe\u7f6e\u548c\u65b9\u6cd5\u591a\u6837\u6027\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u9632\u6b62\u5c06\u6307\u6807\u8fc7\u62df\u5408\u8bef\u8ba4\u4e3a\u662f\u771f\u6b63\u7684\u7cfb\u7edf\u8fdb\u6b65\u3002\u9700\u8981\u66f4\u4e25\u8c28\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u786e\u4fddRAG\u7cfb\u7edf\u7684\u771f\u5b9e\u6539\u8fdb"}}
{"id": "2601.11580", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11580", "abs": "https://arxiv.org/abs/2601.11580", "authors": ["Xiaoxuan Liu", "Jiaxiang Yu", "Jongseok Park", "Ion Stoica", "Alvin Cheung"], "title": "Speculative Decoding: Performance or Illusion?", "comment": null, "summary": "Speculative decoding (SD) has become a popular technique to accelerate Large Language Model (LLM) inference, yet its real-world effectiveness remains unclear as prior evaluations rely on research prototypes and unrealistically small batch sizes. We present, to our knowledge, the first systematic study of SD on a production-grade and widely deployed inference engine (vLLM), covering multiple SD variants ($n$-gram, EAGLE/EAGLE-3, Draft-Model, Multi-Token Prediction) across diverse workloads, model scales, and batch sizes. We analyze key factors governing SD performance, and quantify a theoretical upper bound on SD speedup. Our results show that verification by the target model dominates the execution, while acceptance length varies markedly across output token positions, requests, and datasets. Comparing measured performance with theoretical bounds reveals substantial gaps between observed and theoretical upper bounds, and we leverage this observation to highlight new research opportunities that our study opens up in improving SD.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5728\u751f\u4ea7\u7ea7\u63a8\u7406\u5f15\u64ce(vLLM)\u4e0a\u7cfb\u7edf\u7814\u7a76\u63a8\u6d4b\u89e3\u7801(SD)\u7684\u5b9e\u9645\u6548\u679c\uff0c\u53d1\u73b0\u9a8c\u8bc1\u9636\u6bb5\u4e3b\u5bfc\u6267\u884c\u65f6\u95f4\uff0c\u63a5\u53d7\u957f\u5ea6\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u5dee\u5f02\u663e\u8457\uff0c\u5b9e\u6d4b\u6027\u80fd\u4e0e\u7406\u8bba\u4e0a\u9650\u5b58\u5728\u8f83\u5927\u5dee\u8ddd\u3002", "motivation": "\u63a8\u6d4b\u89e3\u7801\u5df2\u6210\u4e3a\u52a0\u901f\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u6d41\u884c\u6280\u672f\uff0c\u4f46\u5148\u524d\u8bc4\u4f30\u591a\u57fa\u4e8e\u7814\u7a76\u539f\u578b\u548c\u4e0d\u5207\u5b9e\u9645\u7684\u5c0f\u6279\u91cf\u5927\u5c0f\uff0c\u5176\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u6548\u679c\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u5728\u751f\u4ea7\u7ea7\u63a8\u7406\u5f15\u64cevLLM\u4e0a\u7cfb\u7edf\u7814\u7a76\u591a\u79cdSD\u53d8\u4f53(n-gram\u3001EAGLE/EAGLE-3\u3001Draft-Model\u3001Multi-Token Prediction)\uff0c\u8986\u76d6\u591a\u6837\u5316\u5de5\u4f5c\u8d1f\u8f7d\u3001\u6a21\u578b\u89c4\u6a21\u548c\u6279\u91cf\u5927\u5c0f\uff0c\u5206\u6790\u5f71\u54cdSD\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u5e76\u91cf\u5316\u7406\u8bba\u52a0\u901f\u4e0a\u9650\u3002", "result": "\u76ee\u6807\u6a21\u578b\u7684\u9a8c\u8bc1\u9636\u6bb5\u4e3b\u5bfc\u6267\u884c\u65f6\u95f4\uff1b\u63a5\u53d7\u957f\u5ea6\u5728\u4e0d\u540c\u8f93\u51fatoken\u4f4d\u7f6e\u3001\u8bf7\u6c42\u548c\u6570\u636e\u96c6\u95f4\u5dee\u5f02\u663e\u8457\uff1b\u5b9e\u6d4b\u6027\u80fd\u4e0e\u7406\u8bba\u4e0a\u9650\u5b58\u5728\u5b9e\u8d28\u6027\u5dee\u8ddd\uff0c\u63ed\u793a\u4e86SD\u6539\u8fdb\u7684\u65b0\u7814\u7a76\u673a\u4f1a\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u7cfb\u7edf\u8bc4\u4f30\u63a8\u6d4b\u89e3\u7801\uff0c\u63ed\u793a\u4e86\u5b9e\u9645\u6027\u80fd\u4e0e\u7406\u8bba\u9884\u671f\u7684\u5dee\u8ddd\uff0c\u4e3a\u6539\u8fdbSD\u6280\u672f\u6307\u660e\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2601.13353", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.13353", "abs": "https://arxiv.org/abs/2601.13353", "authors": ["Bahdja Boudoua", "Nadia Guiffant", "Mathieu Roche", "Maguelonne Teisseire", "Annelise Tran"], "title": "Guidelines for the Creation of an Annotated Corpus", "comment": "8 pages, 3 figures", "summary": "This document, based on feedback from UMR TETIS members and the scientific literature, provides a generic methodology for creating annotation guidelines and annotated textual datasets (corpora). It covers methodological aspects, as well as storage, sharing, and valorization of the data. It includes definitions and examples to clearly illustrate each step of the process, thus providing a comprehensive framework to support the creation and use of corpora in various research contexts.", "AI": {"tldr": "\u63d0\u4f9b\u521b\u5efa\u6587\u672c\u6807\u6ce8\u6307\u5357\u548c\u6807\u6ce8\u8bed\u6599\u5e93\u7684\u901a\u7528\u65b9\u6cd5\u8bba\u6846\u67b6", "motivation": "\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u8bba\u652f\u6301\uff0c\u4ee5\u521b\u5efa\u9ad8\u8d28\u91cf\u7684\u6807\u6ce8\u6307\u5357\u548c\u6587\u672c\u8bed\u6599\u5e93\uff0c\u89e3\u51b3\u6807\u6ce8\u8fc7\u7a0b\u4e2d\u7684\u6807\u51c6\u5316\u3001\u4e00\u81f4\u6027\u548c\u53ef\u91cd\u590d\u6027\u95ee\u9898", "method": "\u57fa\u4e8eUMR TETIS\u6210\u5458\u53cd\u9988\u548c\u79d1\u5b66\u6587\u732e\uff0c\u63d0\u51fa\u5305\u542b\u65b9\u6cd5\u8bba\u3001\u5b58\u50a8\u3001\u5171\u4eab\u548c\u589e\u503c\u5229\u7528\u7684\u5b8c\u6574\u6846\u67b6\uff0c\u901a\u8fc7\u5b9a\u4e49\u548c\u793a\u4f8b\u6e05\u6670\u8bf4\u660e\u6bcf\u4e2a\u6b65\u9aa4", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u65b9\u6cd5\u8bba\u6846\u67b6\uff0c\u6db5\u76d6\u4ece\u6807\u6ce8\u6307\u5357\u521b\u5efa\u5230\u8bed\u6599\u5e93\u5b58\u50a8\u3001\u5171\u4eab\u548c\u589e\u503c\u5229\u7528\u7684\u5168\u8fc7\u7a0b", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4e0d\u540c\u7814\u7a76\u80cc\u666f\u4e0b\u521b\u5efa\u548c\u4f7f\u7528\u8bed\u6599\u5e93\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u652f\u6301\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u6587\u672c\u6807\u6ce8\u5de5\u4f5c\u7684\u8d28\u91cf\u548c\u6548\u7387"}}
{"id": "2601.11581", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11581", "abs": "https://arxiv.org/abs/2601.11581", "authors": ["Yuefeng Wang", "ChangJae Lee"], "title": "Enhancing the QA Model through a Multi-domain Debiasing Framework", "comment": "5 pages, 7 tables", "summary": "Question-answering (QA) models have advanced significantly in machine reading comprehension but often exhibit biases that hinder their performance, particularly with complex queries in adversarial conditions. This study evaluates the ELECTRA-small model on the Stanford Question Answering Dataset (SQuAD) v1.1 and adversarial datasets AddSent and AddOneSent. By identifying errors related to lexical bias, numerical reasoning, and entity recognition, we develop a multi-domain debiasing framework incorporating knowledge distillation, debiasing techniques, and domain expansion. Our results demonstrate up to 2.6 percentage point improvements in Exact Match (EM) and F1 scores across all test sets, with gains in adversarial contexts. These findings highlight the potential of targeted bias mitigation strategies to enhance the robustness and reliability of natural language understanding systems.", "AI": {"tldr": "ELECTRA-small\u6a21\u578b\u5728SQuAD v1.1\u53ca\u5bf9\u6297\u6570\u636e\u96c6\u4e0a\u5b58\u5728\u504f\u89c1\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u9886\u57df\u53bb\u504f\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd", "motivation": "\u5c3d\u7ba1QA\u6a21\u578b\u5728\u673a\u5668\u9605\u8bfb\u7406\u89e3\u65b9\u9762\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u590d\u6742\u67e5\u8be2\u548c\u5bf9\u6297\u6761\u4ef6\u4e0b\u4ecd\u5b58\u5728\u504f\u89c1\u95ee\u9898\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u6027\u80fd\u548c\u53ef\u9760\u6027", "method": "\u8bc4\u4f30ELECTRA-small\u6a21\u578b\u5728SQuAD v1.1\u53ca\u5bf9\u6297\u6570\u636e\u96c6AddSent\u548cAddOneSent\u4e0a\u7684\u8868\u73b0\uff0c\u8bc6\u522b\u8bcd\u6c47\u504f\u89c1\u3001\u6570\u503c\u63a8\u7406\u548c\u5b9e\u4f53\u8bc6\u522b\u9519\u8bef\uff0c\u5f00\u53d1\u5305\u542b\u77e5\u8bc6\u84b8\u998f\u3001\u53bb\u504f\u6280\u672f\u548c\u9886\u57df\u6269\u5c55\u7684\u591a\u9886\u57df\u53bb\u504f\u6846\u67b6", "result": "\u5728\u6240\u6709\u6d4b\u8bd5\u96c6\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe2.6\u4e2a\u767e\u5206\u70b9\u7684Exact Match\u548cF1\u5206\u6570\u63d0\u5347\uff0c\u5728\u5bf9\u6297\u73af\u5883\u4e0b\u4e5f\u83b7\u5f97\u4e86\u663e\u8457\u589e\u76ca", "conclusion": "\u9488\u5bf9\u6027\u7684\u504f\u89c1\u7f13\u89e3\u7b56\u7565\u80fd\u591f\u6709\u6548\u63d0\u5347\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027"}}
{"id": "2601.11816", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11816", "abs": "https://arxiv.org/abs/2601.11816", "authors": ["Zahra Moslemi", "Keerthi Koneru", "Yen-Ting Lee", "Sheethal Kumar", "Ramesh Radhakrishnan"], "title": "POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation", "comment": "Workshop on Agentic AI Benchmarks and Applications for Enterprise Tasks: AAAI 2026", "summary": "Enterprise back office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type checked directed acyclic graphs (DAGs), a rubric guided reasoning module selects a single compliant plan, and execution is guarded by validator gated checks, a bounded repair loop, and compiled policy guardrails that block or route side effects before they occur. Applied to document centric finance tasks, POLARIS produces decision grade artifacts and full execution traces while reducing human intervention. Empirically, POLARIS achieves a micro F1 of 0.81 on the SROIE dataset and, on a controlled synthetic suite, achieves 0.95 to 1.00 precision for anomaly routing with preserved audit trails. These evaluations constitute an initial benchmark for governed Agentic AI. POLARIS provides a methodological and benchmark reference for policy-aligned Agentic AI. Keywords Agentic AI, Enterprise Automation, Back-Office Tasks, Benchmarks, Governance, Typed Planning, Evaluation", "AI": {"tldr": "POLARIS\u662f\u4e00\u4e2a\u9762\u5411\u4f01\u4e1a\u540e\u53f0\u5de5\u4f5c\u6d41\u7684\u6cbb\u7406\u578bLLM\u667a\u80fd\u4f53\u7f16\u6392\u6846\u67b6\uff0c\u901a\u8fc7\u7c7b\u578b\u5316\u8ba1\u5212\u5408\u6210\u548c\u9a8c\u8bc1\u6267\u884c\u5b9e\u73b0\u53ef\u5ba1\u8ba1\u3001\u7b56\u7565\u5bf9\u9f50\u4e14\u64cd\u4f5c\u53ef\u9884\u6d4b\u7684\u81ea\u52a8\u5316\u7cfb\u7edf\u3002", "motivation": "\u4f01\u4e1a\u540e\u53f0\u5de5\u4f5c\u6d41\u9700\u8981\u53ef\u5ba1\u8ba1\u3001\u7b56\u7565\u5bf9\u9f50\u4e14\u64cd\u4f5c\u53ef\u9884\u6d4b\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u800c\u901a\u7528\u7684\u591a\u667a\u80fd\u4f53\u8bbe\u7f6e\u5f80\u5f80\u65e0\u6cd5\u6ee1\u8db3\u8fd9\u4e9b\u8981\u6c42\u3002\u73b0\u6709\u7cfb\u7edf\u7f3a\u4e4f\u6709\u6548\u7684\u6cbb\u7406\u673a\u5236\uff0c\u96be\u4ee5\u4fdd\u8bc1\u5408\u89c4\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\u3002", "method": "POLARIS\u91c7\u7528\u6cbb\u7406\u578b\u7f16\u6392\u6846\u67b6\uff0c\u5c06\u81ea\u52a8\u5316\u89c6\u4e3a\u7c7b\u578b\u5316\u8ba1\u5212\u5408\u6210\u548c\u9a8c\u8bc1\u6267\u884c\u3002\u5305\u542b\uff1a1\uff09\u89c4\u5212\u5668\u751f\u6210\u7ed3\u6784\u591a\u6837\u3001\u7c7b\u578b\u68c0\u67e5\u7684\u6709\u5411\u65e0\u73af\u56fe\uff1b2\uff09\u57fa\u4e8e\u89c4\u5219\u7684\u63a8\u7406\u6a21\u5757\u9009\u62e9\u5408\u89c4\u8ba1\u5212\uff1b3\uff09\u6267\u884c\u9636\u6bb5\u901a\u8fc7\u9a8c\u8bc1\u5668\u95e8\u63a7\u68c0\u67e5\u3001\u6709\u754c\u4fee\u590d\u5faa\u73af\u548c\u7f16\u8bd1\u7684\u7b56\u7565\u62a4\u680f\u6765\u963b\u6b62\u6216\u8def\u7531\u526f\u4f5c\u7528\u3002", "result": "\u5728\u6587\u6863\u4e2d\u5fc3\u8d22\u52a1\u4efb\u52a1\u4e2d\uff0cPOLARIS\u751f\u6210\u51b3\u7b56\u7ea7\u5de5\u4ef6\u548c\u5b8c\u6574\u6267\u884c\u8f68\u8ff9\uff0c\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u3002\u5728SROIE\u6570\u636e\u96c6\u4e0a\u83b7\u5f970.81\u7684\u5faeF1\u5206\u6570\uff0c\u5728\u53d7\u63a7\u5408\u6210\u5957\u4ef6\u4e2d\u5b9e\u73b00.95-1.00\u7684\u5f02\u5e38\u8def\u7531\u7cbe\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u5ba1\u8ba1\u8f68\u8ff9\u3002", "conclusion": "POLARIS\u4e3a\u7b56\u7565\u5bf9\u9f50\u7684\u667a\u80fd\u4f53AI\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u548c\u57fa\u51c6\u53c2\u8003\uff0c\u5efa\u7acb\u4e86\u6cbb\u7406\u578b\u667a\u80fd\u4f53AI\u7684\u521d\u6b65\u57fa\u51c6\uff0c\u5c55\u793a\u4e86\u5728\u4f01\u4e1a\u81ea\u52a8\u5316\u4e2d\u5b9e\u73b0\u53ef\u5ba1\u8ba1\u3001\u5408\u89c4\u4e14\u9ad8\u6548\u5de5\u4f5c\u6d41\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2601.13505", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.13505", "abs": "https://arxiv.org/abs/2601.13505", "authors": ["Wei Yuan", "Shutong Qiao", "Tong Chen", "Quoc Viet Hung Nguyen", "Zi Huang", "Hongzhi Yin"], "title": "Integrating Vision-Centric Text Understanding for Conversational Recommender Systems", "comment": null, "summary": "Conversational Recommender Systems (CRSs) have attracted growing attention for their ability to deliver personalized recommendations through natural language interactions. To more accurately infer user preferences from multi-turn conversations, recent works increasingly expand conversational context (e.g., by incorporating diverse entity information or retrieving related dialogues). While such context enrichment can assist preference modeling, it also introduces longer and more heterogeneous inputs, leading to practical issues such as input length constraints, text style inconsistency, and irrelevant textual noise, thereby raising the demand for stronger language understanding ability. In this paper, we propose STARCRS, a Screen-Text-AwaRe Conversational Recommender System that integrates two complementary text understanding modes: (1) a screen-reading pathway that encodes auxiliary textual information as visual tokens, mimicking skim reading on a screen, and (2) an LLM-based textual pathway that focuses on a limited set of critical content for fine-grained reasoning. We design a knowledge-anchored fusion framework that combines contrastive alignment, cross-attention interaction, and adaptive gating to integrate the two modes for improved preference modeling and response generation. Extensive experiments on two widely used benchmarks demonstrate that STARCRS consistently improves both recommendation accuracy and generated response quality.", "AI": {"tldr": "STARCRS\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5c4f\u5e55\u9605\u8bfb\u548cLLM\u6587\u672c\u7406\u89e3\u7684\u53cc\u901a\u8def\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u89c6\u89c9\u5316\u7f16\u7801\u548c\u7cbe\u7ec6\u63a8\u7406\u7684\u4e92\u8865\u6a21\u5f0f\u63d0\u5347\u504f\u597d\u5efa\u6a21\u548c\u54cd\u5e94\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u4f20\u7edf\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u901a\u8fc7\u6269\u5c55\u5bf9\u8bdd\u4e0a\u4e0b\u6587\uff08\u5982\u5f15\u5165\u5b9e\u4f53\u4fe1\u606f\u6216\u76f8\u5173\u5bf9\u8bdd\uff09\u6765\u63d0\u5347\u504f\u597d\u63a8\u65ad\uff0c\u4f46\u8fd9\u5bfc\u81f4\u8f93\u5165\u66f4\u957f\u3001\u66f4\u5f02\u6784\uff0c\u5f15\u53d1\u8f93\u5165\u957f\u5ea6\u9650\u5236\u3001\u6587\u672c\u98ce\u683c\u4e0d\u4e00\u81f4\u548c\u65e0\u5173\u566a\u58f0\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u5f3a\u7684\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u3002", "method": "\u63d0\u51faSTARCRS\u7cfb\u7edf\uff0c\u5305\u542b\u4e24\u4e2a\u4e92\u8865\u7684\u6587\u672c\u7406\u89e3\u6a21\u5f0f\uff1a(1)\u5c4f\u5e55\u9605\u8bfb\u901a\u8def\uff1a\u5c06\u8f85\u52a9\u6587\u672c\u4fe1\u606f\u7f16\u7801\u4e3a\u89c6\u89c9\u6807\u8bb0\uff0c\u6a21\u62df\u5c4f\u5e55\u6d4f\u89c8\uff1b(2)\u57fa\u4e8eLLM\u7684\u6587\u672c\u901a\u8def\uff1a\u805a\u7126\u5173\u952e\u5185\u5bb9\u8fdb\u884c\u7ec6\u7c92\u5ea6\u63a8\u7406\u3002\u8bbe\u8ba1\u4e86\u77e5\u8bc6\u951a\u5b9a\u878d\u5408\u6846\u67b6\uff0c\u7ed3\u5408\u5bf9\u6bd4\u5bf9\u9f50\u3001\u4ea4\u53c9\u6ce8\u610f\u529b\u4ea4\u4e92\u548c\u81ea\u9002\u5e94\u95e8\u63a7\u6765\u6574\u5408\u4e24\u79cd\u6a21\u5f0f\u3002", "result": "\u5728\u4e24\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660eSTARCRS\u5728\u63a8\u8350\u51c6\u786e\u6027\u548c\u751f\u6210\u54cd\u5e94\u8d28\u91cf\u65b9\u9762\u5747\u53d6\u5f97\u4e00\u81f4\u63d0\u5347\u3002", "conclusion": "STARCRS\u901a\u8fc7\u6574\u5408\u5c4f\u5e55\u9605\u8bfb\u548cLLM\u6587\u672c\u7406\u89e3\u7684\u53cc\u901a\u8def\u6a21\u5f0f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u4e2d\u4e0a\u4e0b\u6587\u6269\u5c55\u5e26\u6765\u7684\u5b9e\u9645\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u504f\u597d\u5efa\u6a21\u548c\u54cd\u5e94\u751f\u6210\u6027\u80fd\u3002"}}
{"id": "2601.11825", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11825", "abs": "https://arxiv.org/abs/2601.11825", "authors": ["Arya Rahgozar", "Pouria Mortezaagha"], "title": "AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept", "comment": null, "summary": "Research waste in biomedical science is driven by redundant studies, incomplete reporting, and the limited scalability of traditional evidence synthesis workflows. We present an AI co-scientist for scalable and transparent knowledge synthesis based on explicit formalization of Population, Intervention, Comparator, Outcome, and Study design (PICOS). The platform integrates relational storage, vector-based semantic retrieval, and a Neo4j knowledge graph. Evaluation was conducted on dementia-sport and non-communicable disease corpora. Automated PICOS compliance and study design classification from titles and abstracts were performed using a Bidirectional Long Short-Term Memory baseline and a transformer-based multi-task classifier fine-tuned from PubMedBERT. Full-text synthesis employed retrieval-augmented generation with hybrid vector and graph retrieval, while BERTopic was used to identify thematic structure, redundancy, and evidence gaps. The transformer model achieved 95.7% accuracy for study design classification with strong agreement against expert annotations, while the Bi-LSTM achieved 87% accuracy for PICOS compliance detection. Retrieval-augmented generation outperformed non-retrieval generation for queries requiring structured constraints, cross-study integration, and graph-based reasoning, whereas non-retrieval approaches remained competitive for high-level summaries. Topic modeling revealed substantial thematic redundancy and identified underexplored research areas. These results demonstrate that PICOS-aware and explainable natural language processing can improve the scalability, transparency, and efficiency of evidence synthesis. The proposed architecture is domain-agnostic and offers a practical framework for reducing research waste across biomedical disciplines.", "AI": {"tldr": "AI\u8f85\u52a9\u7684PICOS\u77e5\u8bc6\u5408\u6210\u5e73\u53f0\uff0c\u901a\u8fc7\u81ea\u52a8\u5316PICOS\u5408\u89c4\u68c0\u6d4b\u3001\u7814\u7a76\u8bbe\u8ba1\u5206\u7c7b\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u4e3b\u9898\u5efa\u6a21\uff0c\u63d0\u9ad8\u751f\u7269\u533b\u5b66\u8bc1\u636e\u5408\u6210\u7684\u53ef\u6269\u5c55\u6027\u548c\u900f\u660e\u5ea6", "motivation": "\u89e3\u51b3\u751f\u7269\u533b\u5b66\u7814\u7a76\u4e2d\u56e0\u5197\u4f59\u7814\u7a76\u3001\u4e0d\u5b8c\u6574\u62a5\u544a\u548c\u4f20\u7edf\u8bc1\u636e\u5408\u6210\u5de5\u4f5c\u6d41\u7a0b\u53ef\u6269\u5c55\u6027\u6709\u9650\u5bfc\u81f4\u7684\u7814\u7a76\u6d6a\u8d39\u95ee\u9898", "method": "\u5f00\u53d1\u57fa\u4e8ePICOS\u7684AI\u534f\u540c\u79d1\u5b66\u5bb6\u5e73\u53f0\uff0c\u6574\u5408\u5173\u7cfb\u5b58\u50a8\u3001\u5411\u91cf\u8bed\u4e49\u68c0\u7d22\u548cNeo4j\u77e5\u8bc6\u56fe\u8c31\uff1b\u4f7f\u7528Bi-LSTM\u548cPubMedBERT\u5fae\u8c03\u7684transformer\u6a21\u578b\u8fdb\u884cPICOS\u5408\u89c4\u68c0\u6d4b\u548c\u7814\u7a76\u8bbe\u8ba1\u5206\u7c7b\uff1b\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7ed3\u5408\u5411\u91cf\u548c\u56fe\u68c0\u7d22\u8fdb\u884c\u5168\u6587\u5408\u6210\uff1b\u4f7f\u7528BERTopic\u8fdb\u884c\u4e3b\u9898\u5efa\u6a21", "result": "transformer\u6a21\u578b\u5728\u7814\u7a76\u8bbe\u8ba1\u5206\u7c7b\u4e0a\u8fbe\u523095.7%\u51c6\u786e\u7387\uff0cBi-LSTM\u5728PICOS\u5408\u89c4\u68c0\u6d4b\u4e0a\u8fbe\u523087%\u51c6\u786e\u7387\uff1b\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5728\u7ed3\u6784\u5316\u7ea6\u675f\u3001\u8de8\u7814\u7a76\u6574\u5408\u548c\u56fe\u63a8\u7406\u67e5\u8be2\u4e0a\u4f18\u4e8e\u975e\u68c0\u7d22\u65b9\u6cd5\uff1b\u4e3b\u9898\u5efa\u6a21\u63ed\u793a\u4e86\u5927\u91cf\u4e3b\u9898\u5197\u4f59\u5e76\u8bc6\u522b\u4e86\u672a\u5145\u5206\u63a2\u7d22\u7684\u7814\u7a76\u9886\u57df", "conclusion": "PICOS\u611f\u77e5\u548c\u53ef\u89e3\u91ca\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u80fd\u591f\u63d0\u9ad8\u8bc1\u636e\u5408\u6210\u7684\u53ef\u6269\u5c55\u6027\u3001\u900f\u660e\u5ea6\u548c\u6548\u7387\uff0c\u63d0\u51fa\u7684\u67b6\u6784\u662f\u9886\u57df\u65e0\u5173\u7684\uff0c\u4e3a\u51cf\u5c11\u751f\u7269\u533b\u5b66\u5b66\u79d1\u7684\u7814\u7a76\u6d6a\u8d39\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6"}}
{"id": "2601.13525", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.13525", "abs": "https://arxiv.org/abs/2601.13525", "authors": ["Chunsheng Zuo", "Daniel Khashabi"], "title": "More Than Efficiency: Embedding Compression Improves Domain Adaptation in Dense Retrieval", "comment": null, "summary": "Dense retrievers powered by pretrained embeddings are widely used for document retrieval but struggle in specialized domains due to the mismatches between the training and target domain distributions. Domain adaptation typically requires costly annotation and retraining of query-document pairs. In this work, we revisit an overlooked alternative: applying PCA to domain embeddings to derive lower-dimensional representations that preserve domain-relevant features while discarding non-discriminative components. Though traditionally used for efficiency, we demonstrate that this simple embedding compression can effectively improve retrieval performance. Evaluated across 9 retrievers and 14 MTEB datasets, PCA applied solely to query embeddings improves NDCG@10 in 75.4% of model-dataset pairs, offering a simple and lightweight method for domain adaptation.", "AI": {"tldr": "\u901a\u8fc7PCA\u5bf9\u67e5\u8be2\u5d4c\u5165\u8fdb\u884c\u964d\u7ef4\u538b\u7f29\uff0c\u53ef\u6709\u6548\u63d0\u5347\u4e13\u4e1a\u9886\u57df\u68c0\u7d22\u6027\u80fd\uff0c\u65e0\u9700\u6602\u8d35\u6807\u6ce8\u548c\u91cd\u65b0\u8bad\u7ec3", "motivation": "\u57fa\u4e8e\u9884\u8bad\u7ec3\u5d4c\u5165\u7684\u5bc6\u96c6\u68c0\u7d22\u5668\u5728\u4e13\u4e1a\u9886\u57df\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u8bad\u7ec3\u548c\u76ee\u6807\u9886\u57df\u5206\u5e03\u4e0d\u5339\u914d\u3002\u4f20\u7edf\u9886\u57df\u9002\u5e94\u65b9\u6cd5\u9700\u8981\u6602\u8d35\u7684\u6807\u6ce8\u548c\u91cd\u65b0\u8bad\u7ec3\u67e5\u8be2-\u6587\u6863\u5bf9\u3002", "method": "\u91cd\u65b0\u5ba1\u89c6\u88ab\u5ffd\u89c6\u7684\u66ff\u4ee3\u65b9\u6848\uff1a\u5bf9\u9886\u57df\u5d4c\u5165\u5e94\u7528PCA\uff0c\u83b7\u5f97\u4f4e\u7ef4\u8868\u793a\uff0c\u4fdd\u7559\u9886\u57df\u76f8\u5173\u7279\u5f81\u540c\u65f6\u4e22\u5f03\u975e\u5224\u522b\u6027\u6210\u5206\u3002\u867d\u7136\u4f20\u7edf\u4e0a\u7528\u4e8e\u6548\u7387\u63d0\u5347\uff0c\u4f46\u672c\u6587\u8bc1\u660e\u8fd9\u79cd\u7b80\u5355\u7684\u5d4c\u5165\u538b\u7f29\u80fd\u6709\u6548\u6539\u8fdb\u68c0\u7d22\u6027\u80fd\u3002", "result": "\u57289\u4e2a\u68c0\u7d22\u5668\u548c14\u4e2aMTEB\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4ec5\u5bf9\u67e5\u8be2\u5d4c\u5165\u5e94\u7528PCA\uff0c\u572875.4%\u7684\u6a21\u578b-\u6570\u636e\u96c6\u5bf9\u4e0a\u63d0\u9ad8\u4e86NDCG@10\uff0c\u4e3a\u9886\u57df\u9002\u5e94\u63d0\u4f9b\u4e86\u7b80\u5355\u8f7b\u91cf\u7684\u65b9\u6cd5\u3002", "conclusion": "\u5d4c\u5165\u538b\u7f29\uff08\u7279\u522b\u662fPCA\uff09\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u9886\u57df\u9002\u5e94\u65b9\u6cd5\uff0c\u65e0\u9700\u6602\u8d35\u6807\u6ce8\u6216\u91cd\u65b0\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u4e13\u4e1a\u9886\u57df\u68c0\u7d22\u6027\u80fd\u3002"}}
{"id": "2601.11658", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11658", "abs": "https://arxiv.org/abs/2601.11658", "authors": ["Indrajit Kar", "Sammy Zonunpuia", "Zonunfeli Ralte"], "title": "Towards AGI A Pragmatic Approach Towards Self Evolving Agent", "comment": null, "summary": "Large Language Model (LLM) based agents are powerful yet fundamentally static after deployment, lacking the ability to autonomously expand capabilities, generate new tools, or evolve their reasoning. This work introduces a hierarchical self-evolving multi-agent framework that integrates a Base LLM, an operational SLM agent, a Code-Generation LLM, and a Teacher-LLM to enable continuous adaptation. The workflow begins with the agent attempting a task using reasoning and existing tools; if unsuccessful, it escalates to tool synthesis through the Code-Gen LLM, and when failures persist, it triggers an evolution phase using Curriculum Learning (CL), Reward-Based Learning (RL), or Genetic Algorithm (GA) evolution. Using the TaskCraft dataset rich in hierarchical tasks, tool-use traces, and difficulty scaling we evaluate these paradigms. CL delivers fast recovery and strong generalization, RL excels on high-difficulty tasks, and GA offers high behavioral diversity. Across all settings, evolved agents outperform their originals, demonstrating robust, autonomous, self-improving agentic evolution.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u81ea\u8fdb\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5de5\u5177\u5408\u6210\u548c\u8fdb\u5316\u7b97\u6cd5\u5b9e\u73b0LLM\u667a\u80fd\u4f53\u7684\u81ea\u4e3b\u80fd\u529b\u6269\u5c55\u548c\u6301\u7eed\u9002\u5e94", "motivation": "\u4f20\u7edfLLM\u667a\u80fd\u4f53\u90e8\u7f72\u540e\u9759\u6001\u5316\uff0c\u7f3a\u4e4f\u81ea\u4e3b\u6269\u5c55\u80fd\u529b\u3001\u751f\u6210\u65b0\u5de5\u5177\u6216\u8fdb\u5316\u63a8\u7406\u7684\u80fd\u529b\uff0c\u9700\u8981\u5b9e\u73b0\u6301\u7eed\u81ea\u9002\u5e94", "method": "\u5206\u5c42\u81ea\u8fdb\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1a\u96c6\u6210\u57fa\u7840LLM\u3001\u64cd\u4f5cSLM\u667a\u80fd\u4f53\u3001\u4ee3\u7801\u751f\u6210LLM\u548c\u6559\u5e08LLM\uff1b\u91c7\u7528\u4e09\u7ea7\u5de5\u4f5c\u6d41\uff1a\u4efb\u52a1\u5c1d\u8bd5\u2192\u5de5\u5177\u5408\u6210\u2192\u8fdb\u5316\u9636\u6bb5\uff08\u8bfe\u7a0b\u5b66\u4e60\u3001\u5956\u52b1\u5b66\u4e60\u3001\u9057\u4f20\u7b97\u6cd5\uff09", "result": "\u5728TaskCraft\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff1a\u8bfe\u7a0b\u5b66\u4e60\u5b9e\u73b0\u5feb\u901f\u6062\u590d\u548c\u5f3a\u6cdb\u5316\uff0c\u5956\u52b1\u5b66\u4e60\u5728\u9ad8\u96be\u5ea6\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u9057\u4f20\u7b97\u6cd5\u63d0\u4f9b\u9ad8\u884c\u4e3a\u591a\u6837\u6027\uff1b\u6240\u6709\u8fdb\u5316\u667a\u80fd\u4f53\u5747\u4f18\u4e8e\u539f\u59cb\u7248\u672c", "conclusion": "\u5206\u5c42\u81ea\u8fdb\u5316\u6846\u67b6\u5b9e\u73b0\u4e86\u7a33\u5065\u3001\u81ea\u4e3b\u3001\u81ea\u6211\u6539\u8fdb\u7684\u667a\u80fd\u4f53\u8fdb\u5316\uff0c\u4e3aLLM\u667a\u80fd\u4f53\u7684\u6301\u7eed\u9002\u5e94\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.13609", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.13609", "abs": "https://arxiv.org/abs/2601.13609", "authors": ["Yoji Tomita", "Tomohiko Yokoyama"], "title": "Balancing Fairness and High Match Rates in Reciprocal Recommender Systems: A Nash Social Welfare Approach", "comment": "arXiv admin note: text overlap with arXiv:2409.00720", "summary": "Matching platforms, such as online dating services and job recommendations, have become increasingly prevalent. For the success of these platforms, it is crucial to design reciprocal recommender systems (RRSs) that not only increase the total number of matches but also avoid creating unfairness among users. In this paper, we investigate the fairness of RRSs on matching platforms. From the perspective of fair division, we define the users' opportunities to be recommended and establish the fairness concept of envy-freeness in the allocation of these opportunities. We first introduce the Social Welfare (SW) method, which approximately maximizes the number of matches, and show that it leads to significant unfairness in recommendation opportunities, illustrating the trade-off between fairness and match rates. To address this challenge, we propose the Nash Social Welfare (NSW) method, which alternately optimizes two NSW functions and achieves nearly envy-free recommendations. We further generalize the SW and NSW method to the $\u03b1$-SW method, which balances the trade-off between fairness and high match rates. Additionally, we develop a computationally efficient approximation algorithm for the SW/NSW/$\u03b1$-SW methods based on the Sinkhorn algorithm. Through extensive experiments on both synthetic datasets and two real-world datasets, we demonstrate the practical effectiveness of our approach.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5339\u914d\u5e73\u53f0\u4e2d\u4e92\u60e0\u63a8\u8350\u7cfb\u7edf\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u793e\u4f1a\u798f\u5229\u548c\u7eb3\u4ec0\u793e\u4f1a\u798f\u5229\u7684\u65b9\u6cd5\u6765\u5e73\u8861\u5339\u914d\u7387\u4e0e\u516c\u5e73\u6027\uff0c\u5e76\u5f00\u53d1\u4e86\u9ad8\u6548\u7684\u8fd1\u4f3c\u7b97\u6cd5\u3002", "motivation": "\u968f\u7740\u5728\u7ebf\u7ea6\u4f1a\u670d\u52a1\u548c\u804c\u4f4d\u63a8\u8350\u7b49\u5339\u914d\u5e73\u53f0\u7684\u666e\u53ca\uff0c\u8bbe\u8ba1\u65e2\u63d0\u9ad8\u5339\u914d\u603b\u6570\u53c8\u907f\u514d\u7528\u6237\u95f4\u4e0d\u516c\u5e73\u7684\u4e92\u60e0\u63a8\u8350\u7cfb\u7edf\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u8ffd\u6c42\u9ad8\u5339\u914d\u7387\u65f6\u5f80\u5f80\u5bfc\u81f4\u63a8\u8350\u673a\u4f1a\u5206\u914d\u4e0d\u516c\u5e73\uff0c\u9700\u8981\u7814\u7a76\u5982\u4f55\u5e73\u8861\u516c\u5e73\u6027\u4e0e\u5339\u914d\u6548\u7387\u3002", "method": "1. \u4ece\u516c\u5e73\u5206\u914d\u89d2\u5ea6\u5b9a\u4e49\u7528\u6237\u7684\u63a8\u8350\u673a\u4f1a\uff0c\u5efa\u7acb\u57fa\u4e8e\u5ac9\u5992\u81ea\u7531\uff08envy-freeness\uff09\u7684\u516c\u5e73\u6982\u5ff5\uff1b2. \u63d0\u51fa\u793e\u4f1a\u798f\u5229\uff08SW\uff09\u65b9\u6cd5\u8fd1\u4f3c\u6700\u5927\u5316\u5339\u914d\u6570\uff1b3. \u63d0\u51fa\u7eb3\u4ec0\u793e\u4f1a\u798f\u5229\uff08NSW\uff09\u65b9\u6cd5\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u4e24\u4e2aNSW\u51fd\u6570\u5b9e\u73b0\u8fd1\u4f3c\u5ac9\u5992\u81ea\u7531\u7684\u63a8\u8350\uff1b4. \u5c06SW\u548cNSW\u65b9\u6cd5\u63a8\u5e7f\u4e3a\u03b1-SW\u65b9\u6cd5\uff0c\u5e73\u8861\u516c\u5e73\u6027\u4e0e\u9ad8\u5339\u914d\u7387\u4e4b\u95f4\u7684\u6743\u8861\uff1b5. \u57fa\u4e8eSinkhorn\u7b97\u6cd5\u5f00\u53d1SW/NSW/\u03b1-SW\u65b9\u6cd5\u7684\u8ba1\u7b97\u9ad8\u6548\u8fd1\u4f3c\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1. SW\u65b9\u6cd5\u867d\u7136\u80fd\u8fd1\u4f3c\u6700\u5927\u5316\u5339\u914d\u6570\uff0c\u4f46\u4f1a\u5bfc\u81f4\u63a8\u8350\u673a\u4f1a\u663e\u8457\u4e0d\u516c\u5e73\uff1b2. NSW\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u8fd1\u4f3c\u5ac9\u5992\u81ea\u7531\u7684\u63a8\u8350\uff1b3. \u03b1-SW\u65b9\u6cd5\u80fd\u591f\u5728\u516c\u5e73\u6027\u4e0e\u5339\u914d\u7387\u4e4b\u95f4\u8fdb\u884c\u7075\u6d3b\u6743\u8861\uff1b4. \u63d0\u51fa\u7684\u57fa\u4e8eSinkhorn\u7684\u8fd1\u4f3c\u7b97\u6cd5\u5177\u6709\u8ba1\u7b97\u6548\u7387\uff1b5. \u5728\u5408\u6210\u6570\u636e\u96c6\u548c\u4e24\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u5b9e\u9645\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u4e3a\u5339\u914d\u5e73\u53f0\u4e2d\u7684\u4e92\u60e0\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7cfb\u7edf\u7684\u516c\u5e73\u6027\u5206\u6790\u6846\u67b6\uff0c\u63d0\u51fa\u7684NSW\u548c\u03b1-SW\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5e73\u8861\u516c\u5e73\u6027\u4e0e\u5339\u914d\u6548\u7387\uff0c\u5f00\u53d1\u7684\u8fd1\u4f3c\u7b97\u6cd5\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u4e3a\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u516c\u5e73\u6027\u6311\u6218\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2601.11722", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11722", "abs": "https://arxiv.org/abs/2601.11722", "authors": ["Ahmed Rayane Kebir", "Vincent Guigue", "Lynda Said Lhadj", "Laure Soulier"], "title": "RAC: Retrieval-Augmented Clarification for Faithful Conversational Search", "comment": "This is the author's version of the work. The definitive version is published in: Proceedings of the 48th European Conference on Information Retrieval (ECIR '26), 29 March--2 April, 2026, Delft, Netherlands", "summary": "Clarification questions help conversational search systems resolve ambiguous or underspecified user queries. While prior work has focused on fluency and alignment with user intent, especially through facet extraction, much less attention has been paid to grounding clarifications in the underlying corpus. Without such grounding, systems risk asking questions that cannot be answered from the available documents. We introduce RAC (Retrieval-Augmented Clarification), a framework for generating corpus-faithful clarification questions. After comparing several indexing strategies for retrieval, we fine-tune a large language model to make optimal use of research context and to encourage the generation of evidence-based question. We then apply contrastive preference optimization to favor questions supported by retrieved passages over ungrounded alternatives. Evaluated on four benchmarks, RAC demonstrate significant improvements over baselines. In addition to LLM-as-Judge assessments, we introduce novel metrics derived from NLI and data-to-text to assess how well questions are anchored in the context, and we demonstrate that our approach consistently enhances faithfulness.", "AI": {"tldr": "RAC\u6846\u67b6\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u57fa\u4e8e\u8bed\u6599\u5e93\u7684\u6f84\u6e05\u95ee\u9898\uff0c\u4f7f\u7528\u5bf9\u6bd4\u504f\u597d\u4f18\u5316\u786e\u4fdd\u95ee\u9898\u6709\u6587\u6863\u4f9d\u636e\uff0c\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "motivation": "\u73b0\u6709\u5bf9\u8bdd\u641c\u7d22\u7cfb\u7edf\u7684\u6f84\u6e05\u95ee\u9898\u751f\u6210\u4e3b\u8981\u5173\u6ce8\u6d41\u7545\u6027\u548c\u7528\u6237\u610f\u56fe\u5bf9\u9f50\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5e95\u5c42\u8bed\u6599\u5e93\u7684\u951a\u5b9a\uff0c\u5bfc\u81f4\u53ef\u80fd\u751f\u6210\u65e0\u6cd5\u4ece\u53ef\u7528\u6587\u6863\u4e2d\u56de\u7b54\u7684\u95ee\u9898", "method": "1) \u6bd4\u8f83\u591a\u79cd\u68c0\u7d22\u7d22\u5f15\u7b56\u7565\uff1b2) \u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u4ee5\u5145\u5206\u5229\u7528\u68c0\u7d22\u4e0a\u4e0b\u6587\u5e76\u9f13\u52b1\u751f\u6210\u57fa\u4e8e\u8bc1\u636e\u7684\u95ee\u9898\uff1b3) \u5e94\u7528\u5bf9\u6bd4\u504f\u597d\u4f18\u5316\uff0c\u4f7f\u6709\u68c0\u7d22\u6bb5\u843d\u652f\u6301\u7684\u95ee\u9898\u4f18\u4e8e\u65e0\u4f9d\u636e\u7684\u66ff\u4ee3\u65b9\u6848", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRAC\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u8868\u73b0\u51fa\u663e\u8457\u6539\u8fdb\u3002\u9664\u4e86LLM-as-Judge\u8bc4\u4f30\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u57fa\u4e8eNLI\u548c\u6570\u636e\u5230\u6587\u672c\u7684\u65b0\u6307\u6807\u6765\u8bc4\u4f30\u95ee\u9898\u4e0e\u4e0a\u4e0b\u6587\u7684\u951a\u5b9a\u7a0b\u5ea6\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u6301\u7eed\u63d0\u5347\u5fe0\u5b9e\u6027", "conclusion": "RAC\u6846\u67b6\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u548c\u5bf9\u6bd4\u504f\u597d\u4f18\u5316\uff0c\u6210\u529f\u751f\u6210\u4e86\u57fa\u4e8e\u8bed\u6599\u5e93\u7684\u5fe0\u5b9e\u6f84\u6e05\u95ee\u9898\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u6587\u6863\u4f9d\u636e\u7684\u95ee\u9898\uff0c\u4e3a\u5bf9\u8bdd\u641c\u7d22\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u6f84\u6e05\u673a\u5236"}}
{"id": "2601.11850", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11850", "abs": "https://arxiv.org/abs/2601.11850", "authors": ["Matthew Nyaaba", "Min SungEun", "Mary Abiswin Apam", "Kwame Owoahene Acheampong", "Emmanuel Dwamena", "Xiaoming Zhai"], "title": "Human-AI Collaborative Inductive Thematic Analysis: AI Guided Analysis and Human Interpretive Authority", "comment": null, "summary": "The increasing use of generative artificial intelligence (GenAI) in qualitative research raises important questions about analytic practice and interpretive authority. This study examines how researchers interact with an Inductive Thematic Analysis GPT (ITA-GPT), a purpose-built AI tool designed to support inductive thematic analysis through structured, semi-automated prompts aligned with reflexive thematic analysis and verbatim coding principles. Guided by a Human-Artificial Intelligence Collaborative Inductive Thematic Analysis (HACITA) framework, the study focuses on analytic process rather than substantive findings. Three experienced qualitative researchers conducted ITA-GPT assisted analyses of interview transcripts from education research in the Ghanaian teacher education context. The tool supported familiarization, verbatim in vivo coding, gerund-based descriptive coding, and theme development, while enforcing trace to text integrity, coverage checks, and auditability. Data sources included interaction logs, AI-generated tables, researcher revisions, deletions, insertions, comments, and reflexive memos. Findings show that ITA-GPT functioned as a procedural scaffold that structured analytic workflow and enhanced transparency. However, interpretive authority remained with human researchers, who exercised judgment through recurrent analytic actions including modification, deletion, rejection, insertion, and commenting. The study demonstrates how inductive thematic analysis is enacted through responsible human AI collaboration.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u751f\u6210\u5f0fAI\u5728\u8d28\u6027\u7814\u7a76\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662fITA-GPT\u5de5\u5177\u5982\u4f55\u652f\u6301\u5f52\u7eb3\u4e3b\u9898\u5206\u6790\uff0c\u5e76\u8003\u5bdf\u4e86\u4eba\u673a\u534f\u4f5c\u4e2d\u89e3\u91ca\u6743\u5a01\u7684\u5f52\u5c5e\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u5728\u8d28\u6027\u7814\u7a76\u4e2d\u7684\u4f7f\u7528\u589e\u52a0\uff0c\u9700\u8981\u63a2\u8ba8\u5176\u5bf9\u5206\u6790\u5b9e\u8df5\u548c\u89e3\u91ca\u6743\u5a01\u7684\u5f71\u54cd\u3002\u7814\u7a76\u65e8\u5728\u7406\u89e3\u7814\u7a76\u4eba\u5458\u5982\u4f55\u4e0e\u4e13\u95e8\u8bbe\u8ba1\u7684AI\u5de5\u5177\u4e92\u52a8\uff0c\u4ee5\u53ca\u4eba\u673a\u534f\u4f5c\u5982\u4f55\u5f71\u54cd\u5f52\u7eb3\u4e3b\u9898\u5206\u6790\u8fc7\u7a0b\u3002", "method": "\u91c7\u7528HACITA\u6846\u67b6\uff0c\u4e09\u4f4d\u7ecf\u9a8c\u4e30\u5bcc\u7684\u8d28\u6027\u7814\u7a76\u4eba\u5458\u4f7f\u7528ITA-GPT\u5de5\u5177\u5206\u6790\u52a0\u7eb3\u6559\u5e08\u6559\u80b2\u80cc\u666f\u4e0b\u7684\u8bbf\u8c08\u8f6c\u5f55\u6587\u672c\u3002ITA-GPT\u652f\u6301\u719f\u6089\u5316\u3001\u9010\u5b57\u7f16\u7801\u3001\u52a8\u540d\u8bcd\u63cf\u8ff0\u6027\u7f16\u7801\u548c\u4e3b\u9898\u5f00\u53d1\uff0c\u540c\u65f6\u786e\u4fdd\u6587\u672c\u5b8c\u6574\u6027\u3001\u8986\u76d6\u68c0\u67e5\u548c\u53ef\u5ba1\u8ba1\u6027\u3002\u6570\u636e\u6765\u6e90\u5305\u62ec\u4ea4\u4e92\u65e5\u5fd7\u3001AI\u751f\u6210\u8868\u683c\u3001\u7814\u7a76\u4eba\u5458\u4fee\u8ba2\u3001\u5220\u9664\u3001\u63d2\u5165\u3001\u8bc4\u8bba\u548c\u53cd\u601d\u5907\u5fd8\u5f55\u3002", "result": "ITA-GPT\u4f5c\u4e3a\u7a0b\u5e8f\u6027\u652f\u67b6\uff0c\u7ed3\u6784\u5316\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\u5e76\u589e\u5f3a\u900f\u660e\u5ea6\u3002\u7136\u800c\uff0c\u89e3\u91ca\u6743\u5a01\u4ecd\u5c5e\u4e8e\u4eba\u7c7b\u7814\u7a76\u4eba\u5458\uff0c\u4ed6\u4eec\u901a\u8fc7\u4fee\u6539\u3001\u5220\u9664\u3001\u62d2\u7edd\u3001\u63d2\u5165\u548c\u8bc4\u8bba\u7b49\u53cd\u590d\u5206\u6790\u884c\u52a8\u884c\u4f7f\u5224\u65ad\u529b\u3002\u7814\u7a76\u5c55\u793a\u4e86\u5f52\u7eb3\u4e3b\u9898\u5206\u6790\u5982\u4f55\u901a\u8fc7\u8d1f\u8d23\u4efb\u7684\u4eba\u673a\u534f\u4f5c\u5f97\u4ee5\u5b9e\u65bd\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u5f52\u7eb3\u4e3b\u9898\u5206\u6790\u4e2d\uff0cAI\u5de5\u5177\u53ef\u4ee5\u4f5c\u4e3a\u7a0b\u5e8f\u6027\u652f\u67b6\u652f\u6301\u5206\u6790\u8fc7\u7a0b\uff0c\u4f46\u6700\u7ec8\u7684\u89e3\u91ca\u6743\u5a01\u548c\u5224\u65ad\u4ecd\u7531\u4eba\u7c7b\u7814\u7a76\u4eba\u5458\u638c\u63e1\u3002\u8fd9\u4e3a\u4eba\u673a\u534f\u4f5c\u7684\u8d28\u6027\u7814\u7a76\u5b9e\u8df5\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\u3002"}}
{"id": "2601.13856", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.13856", "abs": "https://arxiv.org/abs/2601.13856", "authors": ["Wei Ye", "Yixin Su", "Yueguo Chen", "Longxiang Gao", "Jianjun Li", "Ruixuan Li", "Rui Zhang"], "title": "QKVQA: Question-Focused Filtering for Knowledge-based VQA", "comment": null, "summary": "Knowledge-based Visual Question Answering (KB-VQA) aims to answer questions by integrating images with external knowledge. Effective knowledge filtering is crucial for improving accuracy. Typical filtering methods use similarity metrics to locate relevant article sections from one article, leading to information selection errors at the article and intra-article levels. Although recent explorations of Multimodal Large Language Model (MLLM)-based filtering methods demonstrate superior semantic understanding and cross-article filtering capabilities, their high computational cost limits practical application. To address these issues, this paper proposes a question-focused filtering method. This approach can perform question-focused, cross-article filtering, efficiently obtaining high-quality filtered knowledge while keeping computational costs comparable to typical methods. Specifically, we design a trainable Question-Focused Filter (QFF) and a Chunk-based Dynamic Multi-Article Selection (CDA) module, which collectively alleviate information selection errors at both the article and intra-article levels. Experiments show that our method outperforms current state-of-the-art models by 4.9% on E-VQA and 3.8% on InfoSeek, validating its effectiveness. The code is publicly available at: https://github.com/leaffeall/QKVQA.", "code_url": "https://github.com/leaffeall/QKVQA", "code_stars": 0, "code_last_update": "2026-01-19", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9762\u5411\u95ee\u9898\u7684\u77e5\u8bc6\u8fc7\u6ee4\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u8bad\u7ec3\u7684\u95ee\u9898\u805a\u7126\u8fc7\u6ee4\u5668\u548c\u5206\u5757\u52a8\u6001\u591a\u6587\u7ae0\u9009\u62e9\u6a21\u5757\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6210\u672c\u4e0e\u5178\u578b\u65b9\u6cd5\u76f8\u5f53\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u8de8\u6587\u7ae0\u7684\u9ad8\u8d28\u91cf\u77e5\u8bc6\u8fc7\u6ee4\uff0c\u663e\u8457\u63d0\u5347KB-VQA\u6027\u80fd\u3002", "motivation": "KB-VQA\u9700\u8981\u6709\u6548\u6574\u5408\u56fe\u50cf\u4e0e\u5916\u90e8\u77e5\u8bc6\uff0c\u77e5\u8bc6\u8fc7\u6ee4\u662f\u5173\u952e\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u6587\u7ae0\u7ea7\u548c\u6587\u7ae0\u5185\u4fe1\u606f\u9009\u62e9\u9519\u8bef\uff0c\u800cMLLM\u65b9\u6cd5\u867d\u80fd\u8de8\u6587\u7ae0\u8fc7\u6ee4\u4f46\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u95ee\u9898\u805a\u7126\u8fc7\u6ee4\u65b9\u6cd5\uff0c\u5305\u542b\u53ef\u8bad\u7ec3\u7684\u95ee\u9898\u805a\u7126\u8fc7\u6ee4\u5668\uff08QFF\uff09\u548c\u5206\u5757\u52a8\u6001\u591a\u6587\u7ae0\u9009\u62e9\uff08CDA\uff09\u6a21\u5757\u3002QFF\u5b9e\u73b0\u9762\u5411\u95ee\u9898\u7684\u77e5\u8bc6\u8fc7\u6ee4\uff0cCDA\u901a\u8fc7\u5206\u5757\u7b56\u7565\u52a8\u6001\u9009\u62e9\u591a\u7bc7\u6587\u7ae0\uff0c\u5171\u540c\u89e3\u51b3\u6587\u7ae0\u7ea7\u548c\u6587\u7ae0\u5185\u7684\u4fe1\u606f\u9009\u62e9\u9519\u8bef\u3002", "result": "\u5728E-VQA\u6570\u636e\u96c6\u4e0a\u6bd4\u5f53\u524d\u6700\u4f18\u6a21\u578b\u63d0\u53474.9%\uff0c\u5728InfoSeek\u6570\u636e\u96c6\u4e0a\u63d0\u53473.8%\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u8ba1\u7b97\u6210\u672c\u4e0e\u5178\u578b\u65b9\u6cd5\u76f8\u5f53\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u77e5\u8bc6\u8fc7\u6ee4\u3002", "conclusion": "\u63d0\u51fa\u7684\u95ee\u9898\u805a\u7126\u8fc7\u6ee4\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u8fdb\u884c\u8de8\u6587\u7ae0\u77e5\u8bc6\u8fc7\u6ee4\uff0c\u5728\u4fdd\u6301\u5408\u7406\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347KB-VQA\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u77e5\u8bc6\u8fc7\u6ee4\u4e2d\u7684\u4fe1\u606f\u9009\u62e9\u9519\u8bef\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2601.11739", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11739", "abs": "https://arxiv.org/abs/2601.11739", "authors": ["Xinyu Pi", "Qisen Yang", "Chuong Nguyen", "Hua Shen"], "title": "Bridging Human Interpretation and Machine Representation: A Landscape of Qualitative Data Analysis in the LLM Era", "comment": null, "summary": "LLMs are increasingly used to support qualitative research, yet existing systems produce outputs that vary widely--from trace-faithful summaries to theory-mediated explanations and system models. To make these differences explicit, we introduce a 4$\\times$4 landscape crossing four levels of meaning-making (descriptive, categorical, interpretive, theoretical) with four levels of modeling (static structure, stages/timelines, causal pathways, feedback dynamics). Applying the landscape to prior LLM-based automation highlights a strong skew toward low-level meaning and low-commitment representations, with few reliable attempts at interpretive/theoretical inference or dynamical modeling. Based on the revealed gap, we outline an agenda for applying and building LLM-systems that make their interpretive and modeling commitments explicit, selectable, and governable.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a4\u00d74\u6846\u67b6\u6765\u5206\u7c7bLLM\u5728\u8d28\u6027\u7814\u7a76\u4e2d\u7684\u8f93\u51fa\u7c7b\u578b\uff0c\u63ed\u793a\u73b0\u6709\u7cfb\u7edf\u504f\u5411\u4f4e\u5c42\u6b21\u610f\u4e49\u548c\u4f4e\u627f\u8bfa\u8868\u793a\uff0c\u5e76\u89c4\u5212\u4e86\u63d0\u5347\u89e3\u91ca\u6027\u548c\u5efa\u6a21\u80fd\u529b\u7684\u8def\u7ebf\u56fe\u3002", "motivation": "\u5f53\u524dLLM\u5728\u8d28\u6027\u7814\u7a76\u652f\u6301\u4e2d\u4ea7\u751f\u7684\u8f93\u51fa\u5dee\u5f02\u5f88\u5927\uff0c\u4ece\u5fe0\u5b9e\u8ffd\u8e2a\u7684\u6458\u8981\u5230\u7406\u8bba\u4e2d\u4ecb\u7684\u89e3\u91ca\u548c\u7cfb\u7edf\u6a21\u578b\u90fd\u6709\u3002\u4e3a\u4e86\u660e\u786e\u8fd9\u4e9b\u5dee\u5f02\uff0c\u9700\u8981\u4e00\u4e2a\u7cfb\u7edf\u6027\u7684\u5206\u7c7b\u6846\u67b6\u6765\u7406\u89e3LLM\u5728\u8d28\u6027\u7814\u7a76\u4e2d\u7684\u4e0d\u540c\u5e94\u7528\u5c42\u6b21\u548c\u5efa\u6a21\u627f\u8bfa\u3002", "method": "\u5f15\u5165\u4e00\u4e2a4\u00d74\u7684\u666f\u89c2\u6846\u67b6\uff0c\u6a2a\u8de8\u56db\u4e2a\u610f\u4e49\u5efa\u6784\u5c42\u6b21\uff08\u63cf\u8ff0\u6027\u3001\u5206\u7c7b\u6027\u3001\u89e3\u91ca\u6027\u3001\u7406\u8bba\u6027\uff09\u548c\u56db\u4e2a\u5efa\u6a21\u5c42\u6b21\uff08\u9759\u6001\u7ed3\u6784\u3001\u9636\u6bb5/\u65f6\u95f4\u7ebf\u3001\u56e0\u679c\u8def\u5f84\u3001\u53cd\u9988\u52a8\u6001\uff09\u3002\u5c06\u8be5\u6846\u67b6\u5e94\u7528\u4e8e\u73b0\u6709\u7684LLM\u81ea\u52a8\u5316\u7cfb\u7edf\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5e94\u7528\u8be5\u6846\u67b6\u5206\u6790\u53d1\u73b0\uff0c\u73b0\u6709LLM\u7cfb\u7edf\u5b58\u5728\u660e\u663e\u504f\u5411\uff1a\u4e3b\u8981\u96c6\u4e2d\u5728\u4f4e\u5c42\u6b21\u610f\u4e49\u5efa\u6784\uff08\u63cf\u8ff0\u6027\u3001\u5206\u7c7b\u6027\uff09\u548c\u4f4e\u627f\u8bfa\u8868\u793a\uff08\u9759\u6001\u7ed3\u6784\u3001\u9636\u6bb5/\u65f6\u95f4\u7ebf\uff09\uff0c\u800c\u7f3a\u4e4f\u53ef\u9760\u7684\u9ad8\u5c42\u6b21\u89e3\u91ca\u6027/\u7406\u8bba\u6027\u63a8\u7406\u548c\u52a8\u6001\u5efa\u6a21\u80fd\u529b\u3002", "conclusion": "\u57fa\u4e8e\u63ed\u793a\u7684\u5dee\u8ddd\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7814\u7a76\u8bae\u7a0b\uff1a\u5f00\u53d1\u80fd\u591f\u660e\u786e\u3001\u53ef\u9009\u62e9\u4e14\u53ef\u7ba1\u7406\u7684\u89e3\u91ca\u6027\u548c\u5efa\u6a21\u627f\u8bfa\u7684LLM\u7cfb\u7edf\uff0c\u63d0\u5347LLM\u5728\u8d28\u6027\u7814\u7a76\u4e2d\u7684\u9ad8\u7ea7\u63a8\u7406\u548c\u52a8\u6001\u5efa\u6a21\u80fd\u529b\u3002"}}
{"id": "2601.11885", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11885", "abs": "https://arxiv.org/abs/2601.11885", "authors": ["Zhifei Li", "Ziyue Qin", "Xiangyu Luo", "Xiaoju Hou", "Yue Zhao", "Miao Zhang", "Zhifang Huang", "Kui Xiao", "Bing Yang"], "title": "MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment", "comment": "Accepted by AAAI 2026", "summary": "Multi-modal entity alignment aims to identify equivalent entities between two multi-modal Knowledge graphs by integrating multi-modal data, such as images and text, to enrich the semantic representations of entities. However, existing methods may overlook the structural contextual information within each modality, making them vulnerable to interference from shallow features. To address these challenges, we propose MyGram, a modality-aware graph transformer with global distribution for multi-modal entity alignment. Specifically, we develop a modality diffusion learning module to capture deep structural contextual information within modalities and enable fine-grained multi-modal fusion. In addition, we introduce a Gram Loss that acts as a regularization constraint by minimizing the volume of a 4-dimensional parallelotope formed by multi-modal features, thereby achieving global distribution consistency across modalities. We conduct experiments on five public datasets. Results show that MyGram outperforms baseline models, achieving a maximum improvement of 4.8% in Hits@1 on FBDB15K, 9.9% on FBYG15K, and 4.3% on DBP15K.", "AI": {"tldr": "MyGram\uff1a\u4e00\u79cd\u7528\u4e8e\u591a\u6a21\u6001\u5b9e\u4f53\u5bf9\u9f50\u7684\u6a21\u6001\u611f\u77e5\u56fe\u53d8\u6362\u5668\uff0c\u901a\u8fc7\u6a21\u6001\u6269\u6563\u5b66\u4e60\u548cGram\u635f\u5931\u5b9e\u73b0\u8de8\u6a21\u6001\u5168\u5c40\u5206\u5e03\u4e00\u81f4\u6027", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5b9e\u4f53\u5bf9\u9f50\u65b9\u6cd5\u53ef\u80fd\u5ffd\u7565\u5404\u6a21\u6001\u5185\u7684\u7ed3\u6784\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5bb9\u6613\u53d7\u5230\u6d45\u5c42\u7279\u5f81\u7684\u5e72\u6270\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u591a\u6a21\u6001\u878d\u5408\u548c\u5168\u5c40\u5206\u5e03\u4e00\u81f4\u6027\u65b9\u6cd5", "method": "\u63d0\u51faMyGram\u6846\u67b6\uff1a1\uff09\u6a21\u6001\u6269\u6563\u5b66\u4e60\u6a21\u5757\u6355\u83b7\u6a21\u6001\u5185\u6df1\u5c42\u7ed3\u6784\u4e0a\u4e0b\u6587\u4fe1\u606f\u5e76\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u591a\u6a21\u6001\u878d\u5408\uff1b2\uff09Gram\u635f\u5931\u4f5c\u4e3a\u6b63\u5219\u5316\u7ea6\u675f\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u591a\u6a21\u6001\u7279\u5f81\u5f62\u6210\u76844\u7ef4\u5e73\u884c\u516d\u9762\u4f53\u4f53\u79ef\u5b9e\u73b0\u8de8\u6a21\u6001\u5168\u5c40\u5206\u5e03\u4e00\u81f4\u6027", "result": "\u5728\u4e94\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cMyGram\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff1aFBDB15K\u4e0aHits@1\u6700\u5927\u63d0\u53474.8%\uff0cFBYG15K\u4e0a\u63d0\u53479.9%\uff0cDBP15K\u4e0a\u63d0\u53474.3%", "conclusion": "MyGram\u901a\u8fc7\u6a21\u6001\u6269\u6563\u5b66\u4e60\u548cGram\u635f\u5931\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5b9e\u4f53\u5bf9\u9f50\u4e2d\u7684\u7ed3\u6784\u4fe1\u606f\u6355\u83b7\u548c\u8de8\u6a21\u6001\u5206\u5e03\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u9f50\u6027\u80fd"}}
{"id": "2601.13938", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13938", "abs": "https://arxiv.org/abs/2601.13938", "authors": ["Heyang Zhou", "JiaJia Chen", "Xiaolu Chen", "Jie Bao", "Zhen Chen", "Yong Liao"], "title": "IF-GEO: Conflict-Aware Instruction Fusion for Multi-Query Generative Engine Optimization", "comment": "9 pages, 3 figures. Submitted to ACL 2026. Corresponding author: Zhen Chen", "summary": "As Generative Engines revolutionize information retrieval by synthesizing direct answers from retrieved sources, ensuring source visibility becomes a significant challenge. Improving it through targeted content revisions is a practical strategy termed Generative Engine Optimization (GEO). However, optimizing a document for diverse queries presents a constrained optimization challenge where heterogeneous queries often impose conflicting and competing revision requirements under a limited content budget. To address this challenge, we propose IF-GEO, a \"diverge-then-converge\" framework comprising two phases: (i) mining distinct optimization preferences from representative latent queries; (ii) synthesizing a Global Revision Blueprint for guided editing by coordinating preferences via conflict-aware instruction fusion. To explicitly quantify IF-GEO's objective of cross-query stability, we introduce risk-aware stability metrics. Experiments on multi-query benchmarks demonstrate that IF-GEO achieves substantial performance gains while maintaining robustness across diverse retrieval scenarios.", "AI": {"tldr": "IF-GEO\u662f\u4e00\u4e2a\u9488\u5bf9\u751f\u6210\u5f0f\u5f15\u64ce\u4f18\u5316\u7684\"\u53d1\u6563-\u6536\u655b\"\u6846\u67b6\uff0c\u901a\u8fc7\u6316\u6398\u4e0d\u540c\u67e5\u8be2\u7684\u4f18\u5316\u504f\u597d\u5e76\u534f\u8c03\u51b2\u7a81\uff0c\u751f\u6210\u5168\u5c40\u4fee\u8ba2\u84dd\u56fe\uff0c\u4ee5\u5728\u5185\u5bb9\u9884\u7b97\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u591a\u67e5\u8be2\u573a\u666f\u4e0b\u7684\u6e90\u6587\u6863\u53ef\u89c1\u6027\u3002", "motivation": "\u751f\u6210\u5f0f\u5f15\u64ce\u901a\u8fc7\u4ece\u68c0\u7d22\u6e90\u5408\u6210\u76f4\u63a5\u7b54\u6848\u6765\u9769\u65b0\u4fe1\u606f\u68c0\u7d22\uff0c\u4f46\u8fd9\u4e5f\u5e26\u6765\u4e86\u6e90\u6587\u6863\u53ef\u89c1\u6027\u7684\u6311\u6218\u3002\u751f\u6210\u5f0f\u5f15\u64ce\u4f18\u5316(GEO)\u901a\u8fc7\u9488\u5bf9\u6027\u5185\u5bb9\u4fee\u8ba2\u6765\u6539\u5584\u53ef\u89c1\u6027\uff0c\u4f46\u4e3a\u591a\u6837\u5316\u67e5\u8be2\u4f18\u5316\u6587\u6863\u9762\u4e34\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff1a\u5f02\u8d28\u67e5\u8be2\u5e38\u4ea7\u751f\u51b2\u7a81\u7684\u4fee\u8ba2\u9700\u6c42\uff0c\u4e14\u5185\u5bb9\u9884\u7b97\u6709\u9650\u3002", "method": "\u63d0\u51faIF-GEO\u6846\u67b6\uff0c\u91c7\u7528\"\u53d1\u6563-\u6536\u655b\"\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u4ece\u4ee3\u8868\u6027\u6f5c\u5728\u67e5\u8be2\u4e2d\u6316\u6398\u4e0d\u540c\u7684\u4f18\u5316\u504f\u597d\uff1b2) \u901a\u8fc7\u51b2\u7a81\u611f\u77e5\u7684\u6307\u4ee4\u878d\u5408\u534f\u8c03\u8fd9\u4e9b\u504f\u597d\uff0c\u5408\u6210\u5168\u5c40\u4fee\u8ba2\u84dd\u56fe\u4ee5\u6307\u5bfc\u7f16\u8f91\u3002\u540c\u65f6\u5f15\u5165\u98ce\u9669\u611f\u77e5\u7684\u7a33\u5b9a\u6027\u6307\u6807\u6765\u91cf\u5316\u8de8\u67e5\u8be2\u7a33\u5b9a\u6027\u76ee\u6807\u3002", "result": "\u5728\u591a\u67e5\u8be2\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cIF-GEO\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u5728\u591a\u6837\u5316\u68c0\u7d22\u573a\u666f\u4e2d\u4fdd\u6301\u4e86\u9c81\u68d2\u6027\u3002", "conclusion": "IF-GEO\u6709\u6548\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u5f15\u64ce\u4f18\u5316\u4e2d\u7684\u591a\u67e5\u8be2\u51b2\u7a81\u95ee\u9898\uff0c\u901a\u8fc7\u534f\u8c03\u4e0d\u540c\u67e5\u8be2\u7684\u4f18\u5316\u504f\u597d\u751f\u6210\u5168\u5c40\u4fee\u8ba2\u84dd\u56fe\uff0c\u5728\u6709\u9650\u5185\u5bb9\u9884\u7b97\u4e0b\u5b9e\u73b0\u4e86\u8de8\u67e5\u8be2\u7684\u7a33\u5b9a\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2601.11903", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11903", "abs": "https://arxiv.org/abs/2601.11903", "authors": ["YenTing Lee", "Keerthi Koneru", "Zahra Moslemi", "Sheethal Kumar", "Ramesh Radhakrishnan"], "title": "AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems", "comment": "Workshop on W51: How Can We Trust and Control Agentic AI? Toward Alignment, Robustness, and Verifiability in Autonomous LLM Agents at AAAI 2026", "summary": "Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.\n  Keywords Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight", "AI": {"tldr": "AEMA\u662f\u4e00\u4e2a\u9762\u5411\u4f01\u4e1a\u7ea7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6b65\u9aa4\u3001\u53ef\u5ba1\u8ba1\u7684\u6d41\u7a0b\u5b9e\u73b0\u7a33\u5b9a\u3001\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\uff0c\u76f8\u6bd4\u5355\u4e00LLM\u8bc4\u4f30\u5177\u6709\u66f4\u597d\u7684\u7a33\u5b9a\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bc4\u4f30\u9762\u4e34\u6311\u6218\uff1a\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\u4e8e\u5355\u54cd\u5e94\u8bc4\u5206\u6216\u72ed\u7a84\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5728\u4f01\u4e1a\u7ea7\u591a\u667a\u80fd\u4f53\u89c4\u6a21\u4e0b\u7f3a\u4e4f\u7a33\u5b9a\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u81ea\u52a8\u5316\u80fd\u529b\uff0c\u9700\u8981\u53ef\u9760\u534f\u8c03\u3001\u900f\u660e\u51b3\u7b56\u548c\u53ef\u9a8c\u8bc1\u6027\u80fd\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51faAEMA\uff08\u81ea\u9002\u5e94\u8bc4\u4f30\u591a\u667a\u80fd\u4f53\uff09\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u6d41\u7a0b\u611f\u77e5\u4e14\u53ef\u5ba1\u8ba1\u7684\u8bc4\u4f30\u7cfb\u7edf\u3002\u5b83\u80fd\u591f\u5728\u4eba\u7c7b\u76d1\u7763\u4e0b\u89c4\u5212\u3001\u6267\u884c\u548c\u805a\u5408\u5f02\u6784\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u591a\u6b65\u9aa4\u8bc4\u4f30\uff0c\u652f\u6301\u53ef\u8ffd\u6eaf\u7684\u8bb0\u5f55\u548c\u8d1f\u8d23\u4efb\u7684\u81ea\u52a8\u5316\u3002", "result": "\u5728\u57fa\u4e8e\u73b0\u5b9e\u4e1a\u52a1\u573a\u666f\u6a21\u62df\u7684\u4f01\u4e1a\u98ce\u683c\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u4e0a\u6d4b\u8bd5\uff0cAEMA\u76f8\u6bd4\u5355\u4e00LLM-as-a-Judge\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\u3001\u66f4\u597d\u7684\u4eba\u7c7b\u5bf9\u9f50\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u8ffd\u6eaf\u7684\u8bb0\u5f55\uff0c\u652f\u6301\u8d1f\u8d23\u4efb\u7684\u81ea\u52a8\u5316\u3002", "conclusion": "AEMA\u4e3a\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u900f\u660e\u3001\u53ef\u590d\u73b0\u7684\u8d1f\u8d23\u4efb\u8bc4\u4f30\u8def\u5f84\uff0c\u89e3\u51b3\u4e86\u4f01\u4e1a\u73af\u5883\u4e2d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bc4\u4f30\u7684\u7a33\u5b9a\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u53ef\u5ba1\u8ba1\u6027\u9700\u6c42\u3002"}}
{"id": "2601.14001", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14001", "abs": "https://arxiv.org/abs/2601.14001", "authors": ["Niall McGuire", "Yashar Moshfeghi"], "title": "Auditory Brain Passage Retrieval: Cross-Sensory EEG Training for Neural Information Retrieval", "comment": "Accepted At ECIR 2026", "summary": "Query formulation from internal information needs remains fundamentally challenging across all Information Retrieval paradigms due to cognitive complexity and physical impairments. Brain Passage Retrieval (BPR) addresses this by directly mapping EEG signals to passage representations without intermediate text translation. However, existing BPR research exclusively uses visual stimuli, leaving critical questions unanswered: Can auditory EEG enable effective retrieval for voice-based interfaces and visually impaired users? Can training on combined EEG datasets from different sensory modalities improve performance despite severe data scarcity? We present the first systematic investigation of auditory EEG for BPR and evaluate cross-sensory training benefits. Using dual encoder architectures with four pooling strategies (CLS, mean, max, multi-vector), we conduct controlled experiments comparing auditory-only, visual-only, and combined training on the Alice (auditory) and Nieuwland (visual) datasets. Results demonstrate that auditory EEG consistently outperforms visual EEG, and cross-sensory training with CLS pooling achieves substantial improvements over individual training: 31% in MRR (0.474), 43% in Hit@1 (0.314), and 28% in Hit@10 (0.858). Critically, combined auditory EEG models surpass BM25 text baselines (MRR: 0.474 vs 0.428), establishing neural queries as competitive with traditional retrieval whilst enabling accessible interfaces. These findings validate auditory neural interfaces for IR tasks and demonstrate that cross-sensory training addresses data scarcity whilst outperforming single-modality approaches Code: https://github.com/NiallMcguire/Audio_BPR", "code_url": "https://github.com/NiallMcguire/Audio_BPR", "code_stars": 0, "code_last_update": "2026-01-08", "AI": {"tldr": "\u9996\u4e2a\u7cfb\u7edf\u7814\u7a76\u542c\u89c9\u8111\u7535\u56fe\u7528\u4e8e\u8111\u901a\u9053\u68c0\u7d22\uff0c\u53d1\u73b0\u542c\u89c9EEG\u4f18\u4e8e\u89c6\u89c9EEG\uff0c\u8de8\u611f\u5b98\u8bad\u7ec3\u663e\u8457\u63d0\u5347\u68c0\u7d22\u6027\u80fd\uff0c\u751a\u81f3\u8d85\u8d8aBM25\u6587\u672c\u57fa\u7ebf", "motivation": "\u4f20\u7edf\u67e5\u8be2\u6784\u5efa\u56e0\u8ba4\u77e5\u590d\u6742\u6027\u548c\u8eab\u4f53\u969c\u788d\u800c\u56f0\u96be\uff0c\u73b0\u6709\u8111\u901a\u9053\u68c0\u7d22\u7814\u7a76\u4ec5\u4f7f\u7528\u89c6\u89c9\u523a\u6fc0\uff0c\u672a\u63a2\u7d22\u542c\u89c9EEG\u5728\u8bed\u97f3\u754c\u9762\u548c\u89c6\u969c\u7528\u6237\u4e2d\u7684\u6f5c\u529b\uff0c\u4e5f\u672a\u7814\u7a76\u8de8\u611f\u5b98\u8bad\u7ec3\u80fd\u5426\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898", "method": "\u4f7f\u7528\u53cc\u7f16\u7801\u5668\u67b6\u6784\u548c\u56db\u79cd\u6c60\u5316\u7b56\u7565\uff08CLS\u3001\u5747\u503c\u3001\u6700\u5927\u503c\u3001\u591a\u5411\u91cf\uff09\uff0c\u5728Alice\uff08\u542c\u89c9\uff09\u548cNieuwland\uff08\u89c6\u89c9\uff09\u6570\u636e\u96c6\u4e0a\u5bf9\u6bd4\u542c\u89c9\u5355\u72ec\u8bad\u7ec3\u3001\u89c6\u89c9\u5355\u72ec\u8bad\u7ec3\u548c\u8de8\u611f\u5b98\u7ec4\u5408\u8bad\u7ec3", "result": "\u542c\u89c9EEG\u6301\u7eed\u4f18\u4e8e\u89c6\u89c9EEG\uff1b\u8de8\u611f\u5b98\u8bad\u7ec3\u914d\u5408CLS\u6c60\u5316\u663e\u8457\u63d0\u5347\u6027\u80fd\uff1aMRR\u63d0\u534731%\uff080.474\uff09\u3001Hit@1\u63d0\u534743%\uff080.314\uff09\u3001Hit@10\u63d0\u534728%\uff080.858\uff09\uff1b\u7ec4\u5408\u542c\u89c9EEG\u6a21\u578b\u8d85\u8d8aBM25\u6587\u672c\u57fa\u7ebf\uff08MRR: 0.474 vs 0.428\uff09", "conclusion": "\u9a8c\u8bc1\u4e86\u542c\u89c9\u795e\u7ecf\u754c\u9762\u5728\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u8de8\u611f\u5b98\u8bad\u7ec3\u65e2\u80fd\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u53c8\u80fd\u8d85\u8d8a\u5355\u6a21\u6001\u65b9\u6cd5\uff0c\u4f7f\u795e\u7ecf\u67e5\u8be2\u4e0e\u4f20\u7edf\u68c0\u7d22\u7ade\u4e89\uff0c\u540c\u65f6\u652f\u6301\u65e0\u969c\u788d\u754c\u9762"}}
{"id": "2601.11758", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11758", "abs": "https://arxiv.org/abs/2601.11758", "authors": ["Arnab Das Utsa"], "title": "Early Linguistic Pattern of Anxiety from Social Media Using Interpretable Linguistic Features: A Multi-Faceted Validation Study with Author-Disjoint Evaluation", "comment": "9 figures, more than 1o pages", "summary": "Anxiety affects hundreds of millions of individuals globally, yet large-scale screening remains limited. Social media language provides an opportunity for scalable detection, but current models often lack interpretability, keyword-robustness validation, and rigorous user-level data integrity. This work presents a transparent approach to social media-based anxiety detection through linguistically interpretable feature-grounded modeling and cross-domain validation. Using a substantial dataset of Reddit posts, we trained a logistic regression classifier on carefully curated subreddits for training, validation, and test splits. Comprehensive evaluation included feature ablation, keyword masking experiments, and varying-density difference analyses comparing anxious and control groups, along with external validation using clinically interviewed participants with diagnosed anxiety disorders. The model achieved strong performance while maintaining high accuracy even after sentiment removal or keyword masking. Early detection using minimal post history significantly outperformed random classification, and cross-domain analysis demonstrated strong consistency with clinical interview data. Results indicate that transparent linguistic features can support reliable, generalizable, and keyword-robust anxiety detection. The proposed framework provides a reproducible baseline for interpretable mental health screening across diverse online contexts.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u793e\u4ea4\u5a92\u4f53\u8bed\u8a00\u7684\u900f\u660e\u7126\u8651\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bed\u8a00\u53ef\u89e3\u91ca\u7279\u5f81\u5efa\u6a21\u548c\u8de8\u57df\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u53ef\u9760\u3001\u53ef\u6cdb\u5316\u4e14\u5bf9\u5173\u952e\u8bcd\u9c81\u68d2\u7684\u7126\u8651\u68c0\u6d4b", "motivation": "\u5168\u7403\u6570\u4ebf\u4eba\u53d7\u7126\u8651\u5f71\u54cd\uff0c\u4f46\u5927\u89c4\u6a21\u7b5b\u67e5\u6709\u9650\u3002\u793e\u4ea4\u5a92\u4f53\u8bed\u8a00\u63d0\u4f9b\u53ef\u6269\u5c55\u68c0\u6d4b\u673a\u4f1a\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3001\u5173\u952e\u8bcd\u9c81\u68d2\u6027\u9a8c\u8bc1\u548c\u4e25\u683c\u7528\u6237\u7ea7\u6570\u636e\u5b8c\u6574\u6027", "method": "\u4f7f\u7528Reddit\u5e16\u5b50\u6570\u636e\u96c6\uff0c\u5728\u7cbe\u5fc3\u7b56\u5212\u7684\u5b50\u7248\u5757\u4e0a\u8bad\u7ec3\u903b\u8f91\u56de\u5f52\u5206\u7c7b\u5668\uff0c\u8fdb\u884c\u7279\u5f81\u6d88\u878d\u3001\u5173\u952e\u8bcd\u63a9\u7801\u5b9e\u9a8c\u3001\u7126\u8651\u7ec4\u4e0e\u5bf9\u7167\u7ec4\u5bc6\u5ea6\u5dee\u5f02\u5206\u6790\uff0c\u5e76\u4f7f\u7528\u4e34\u5e8a\u8bbf\u8c08\u53c2\u4e0e\u8005\u8fdb\u884c\u5916\u90e8\u9a8c\u8bc1", "result": "\u6a21\u578b\u5728\u79fb\u9664\u60c5\u611f\u6216\u63a9\u7801\u5173\u952e\u8bcd\u540e\u4ecd\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\uff1b\u4f7f\u7528\u6700\u5c11\u53d1\u5e16\u5386\u53f2\u7684\u65e9\u671f\u68c0\u6d4b\u663e\u8457\u4f18\u4e8e\u968f\u673a\u5206\u7c7b\uff1b\u8de8\u57df\u5206\u6790\u4e0e\u4e34\u5e8a\u8bbf\u8c08\u6570\u636e\u9ad8\u5ea6\u4e00\u81f4", "conclusion": "\u900f\u660e\u8bed\u8a00\u7279\u5f81\u53ef\u652f\u6301\u53ef\u9760\u3001\u53ef\u6cdb\u5316\u4e14\u5bf9\u5173\u952e\u8bcd\u9c81\u68d2\u7684\u7126\u8651\u68c0\u6d4b\uff1b\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u8de8\u4e0d\u540c\u5728\u7ebf\u573a\u666f\u7684\u53ef\u89e3\u91ca\u5fc3\u7406\u5065\u5eb7\u7b5b\u67e5\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u57fa\u7ebf"}}
{"id": "2601.11905", "categories": ["cs.AI", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.11905", "abs": "https://arxiv.org/abs/2601.11905", "authors": ["Junyu Cao", "Ruijiang Gao", "Esmaeil Keyvanshokooh", "Jianhao Ma"], "title": "LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning", "comment": "50 pages. Previous version with human-AI collaboration: arXiv:2410.14640", "summary": "We introduce a unified framework that seamlessly integrates algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings such as personalized medicine. We first introduce the recourse bandit problem, where a decision-maker must select both a treatment action and a feasible, minimal modification to mutable patient features. To address this problem, we develop the Generalized Linear Recourse Bandit (GLRB) algorithm. Building on this foundation, we propose LIBRA, a Language Model-Informed Bandit Recourse Algorithm that strategically combines domain knowledge from LLMs with the statistical rigor of bandit learning. LIBRA offers three key guarantees: (i) a warm-start guarantee, showing that LIBRA significantly reduces initial regret when LLM recommendations are near-optimal; (ii) an LLM-effort guarantee, proving that the algorithm consults the LLM only $O(\\log^2 T)$ times, where $T$ is the time horizon, ensuring long-term autonomy; and (iii) a robustness guarantee, showing that LIBRA never performs worse than a pure bandit algorithm even when the LLM is unreliable. We further establish matching lower bounds that characterize the fundamental difficulty of the recourse bandit problem and demonstrate the near-optimality of our algorithms. Experiments on synthetic environments and a real hypertension-management case study confirm that GLRB and LIBRA improve regret, treatment quality, and sample efficiency compared with standard contextual bandits and LLM-only benchmarks. Our results highlight the promise of recourse-aware, LLM-assisted bandit algorithms for trustworthy LLM-bandits collaboration in personalized high-stakes decision-making.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u5c06\u7b97\u6cd5\u8ffd\u7d22\u3001\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96c6\u6210\uff0c\u7528\u4e8e\u9ad8\u98ce\u9669\u987a\u5e8f\u51b3\u7b56\uff08\u5982\u4e2a\u6027\u5316\u533b\u7597\uff09\u3002\u63d0\u51fa\u4e86\u8ffd\u7d22\u8001\u864e\u673a\u95ee\u9898\u548cGLRB\u7b97\u6cd5\uff0c\u4ee5\u53ca\u7ed3\u5408LLM\u9886\u57df\u77e5\u8bc6\u7684LIBRA\u7b97\u6cd5\uff0c\u63d0\u4f9b\u4e09\u4e2a\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u987a\u5e8f\u51b3\u7b56\u573a\u666f\uff08\u5982\u4e2a\u6027\u5316\u533b\u7597\uff09\u4e2d\uff0c\u9700\u8981\u540c\u65f6\u9009\u62e9\u6cbb\u7597\u884c\u52a8\u548c\u53ef\u884c\u7684\u60a3\u8005\u7279\u5f81\u4fee\u6539\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5c06\u7b97\u6cd5\u8ffd\u7d22\u3001\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u548cLLM\u77e5\u8bc6\u6709\u6548\u7ed3\u5408\u7684\u6846\u67b6\uff0c\u65e0\u6cd5\u5e73\u8861\u7edf\u8ba1\u4e25\u8c28\u6027\u548c\u9886\u57df\u77e5\u8bc6\u3002", "method": "1. \u63d0\u51fa\u8ffd\u7d22\u8001\u864e\u673a\u95ee\u9898\uff0c\u51b3\u7b56\u8005\u9700\u540c\u65f6\u9009\u62e9\u6cbb\u7597\u884c\u52a8\u548c\u53ef\u53d8\u7684\u60a3\u8005\u7279\u5f81\u4fee\u6539\u30022. \u5f00\u53d1GLRB\u7b97\u6cd5\u89e3\u51b3\u8be5\u95ee\u9898\u30023. \u63d0\u51faLIBRA\u7b97\u6cd5\uff0c\u7b56\u7565\u6027\u5730\u7ed3\u5408LLM\u9886\u57df\u77e5\u8bc6\u548c\u8001\u864e\u673a\u5b66\u4e60\u7684\u7edf\u8ba1\u4e25\u8c28\u6027\uff0c\u63d0\u4f9b\u4e09\u4e2a\u7406\u8bba\u4fdd\u8bc1\uff1a\u70ed\u542f\u52a8\u4fdd\u8bc1\u3001LLM\u52aa\u529b\u4fdd\u8bc1\u548c\u9c81\u68d2\u6027\u4fdd\u8bc1\u3002", "result": "\u5efa\u7acb\u4e86\u5339\u914d\u7684\u4e0b\u754c\uff0c\u523b\u753b\u4e86\u8ffd\u7d22\u8001\u864e\u673a\u95ee\u9898\u7684\u57fa\u672c\u96be\u5ea6\uff0c\u8bc1\u660e\u4e86\u7b97\u6cd5\u7684\u8fd1\u6700\u4f18\u6027\u3002\u5728\u5408\u6210\u73af\u5883\u548c\u771f\u5b9e\u9ad8\u8840\u538b\u7ba1\u7406\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cGLRB\u548cLIBRA\u76f8\u6bd4\u6807\u51c6\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u548c\u7eafLLM\u57fa\u51c6\uff0c\u5728\u9057\u61be\u3001\u6cbb\u7597\u8d28\u91cf\u548c\u6837\u672c\u6548\u7387\u65b9\u9762\u5747\u6709\u6539\u8fdb\u3002", "conclusion": "\u8ffd\u7d22\u611f\u77e5\u7684\u3001LLM\u8f85\u52a9\u7684\u8001\u864e\u673a\u7b97\u6cd5\u5728\u4e2a\u6027\u5316\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u5177\u6709\u524d\u666f\uff0c\u80fd\u591f\u5b9e\u73b0\u53ef\u4fe1\u7684LLM-\u8001\u864e\u673a\u534f\u4f5c\uff0c\u5e73\u8861\u9886\u57df\u77e5\u8bc6\u548c\u7edf\u8ba1\u5b66\u4e60\uff0c\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2601.11762", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11762", "abs": "https://arxiv.org/abs/2601.11762", "authors": ["Sae Young Moon", "Myeongjun Erik Jang", "Haoyan Luo", "Chunyang Xiao", "Antonios Georgiadis", "Fran Silavong"], "title": "Industry-Aligned Granular Topic Modeling", "comment": null, "summary": "Topic modeling has extensive applications in text mining and data analysis across various industrial sectors. Although the concept of granularity holds significant value for business applications by providing deeper insights, the capability of topic modeling methods to produce granular topics has not been thoroughly explored. In this context, this paper introduces a framework called TIDE, which primarily provides a novel granular topic modeling method based on large language models (LLMs) as a core feature, along with other useful functionalities for business applications, such as summarizing long documents, topic parenting, and distillation. Through extensive experiments on a variety of public and real-world business datasets, we demonstrate that TIDE's topic modeling approach outperforms modern topic modeling methods, and our auxiliary components provide valuable support for dealing with industrial business scenarios. The TIDE framework is currently undergoing the process of being open sourced.", "AI": {"tldr": "TIDE\u6846\u67b6\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7c92\u5ea6\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\uff0c\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u6587\u6863\u6458\u8981\u3001\u4e3b\u9898\u5206\u5c42\u7b49\u8f85\u52a9\u529f\u80fd", "motivation": "\u4e3b\u9898\u5efa\u6a21\u5728\u6587\u672c\u6316\u6398\u548c\u6570\u636e\u5206\u6790\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u751f\u6210\u7c92\u5ea6\u4e3b\u9898\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u800c\u7c92\u5ea6\u5bf9\u5546\u4e1a\u5e94\u7528\u5177\u6709\u91cd\u8981\u4ef7\u503c", "method": "\u63d0\u51faTIDE\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u578b\u7c92\u5ea6\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\uff0c\u540c\u65f6\u63d0\u4f9b\u6587\u6863\u6458\u8981\u3001\u4e3b\u9898\u5206\u5c42\uff08topic parenting\uff09\u548c\u84b8\u998f\u7b49\u8f85\u52a9\u529f\u80fd", "result": "\u5728\u591a\u79cd\u516c\u5f00\u548c\u771f\u5b9e\u5546\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTIDE\u7684\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\u4f18\u4e8e\u73b0\u4ee3\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\uff0c\u8f85\u52a9\u7ec4\u4ef6\u4e3a\u5de5\u4e1a\u5546\u4e1a\u573a\u666f\u63d0\u4f9b\u6709\u4ef7\u503c\u652f\u6301", "conclusion": "TIDE\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7c92\u5ea6\u4e3b\u9898\u5efa\u6a21\u89e3\u51b3\u65b9\u6848\uff0c\u76ee\u524d\u6b63\u5728\u5f00\u6e90\u8fc7\u7a0b\u4e2d\uff0c\u4e3a\u5546\u4e1a\u5e94\u7528\u63d0\u4f9b\u6df1\u5ea6\u6d1e\u5bdf"}}
{"id": "2601.11940", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11940", "abs": "https://arxiv.org/abs/2601.11940", "authors": ["Kang Chen", "Fan Yu", "Junjie Nian", "Shihan Zhao", "Zhuoka Feng", "Zijun Yao", "Heng Wang", "Minshen Yu", "Yixin Cao"], "title": "Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart", "comment": null, "summary": "Scaling test-time compute via Long Chain-of-Thought (Long-CoT) significantly enhances reasoning capabilities, yet extended generation does not guarantee correctness: after an early wrong commitment, models may keep elaborating a self-consistent but incorrect prefix. Through fine-grained trajectory analysis, we identify Thinking Traps, prefix-dominant deadlocks where later reflection, alternative attempts, or verification fails to revise the root error. On a curated subset of DAPO-MATH, 89\\% of failures exhibit such traps. To solve this problem, we introduce TAAR (Trap-Aware Adaptive Restart), a test-time control framework that trains a diagnostic policy to predict two signals from partial trajectories: a trap index for where to truncate and an escape probability for whether and how strongly to intervene. At inference time, TAAR truncates the trajectory before the predicted trap segment and adaptively restarts decoding; for severely trapped cases, it applies stronger perturbations, including higher-temperature resampling and an optional structured reboot suffix. Experiments on challenging mathematical and scientific reasoning benchmarks (AIME24, AIME25, GPQA-Diamond, HMMT25, BRUMO25) show that TAAR improves reasoning performance without fine-tuning base model parameters.", "AI": {"tldr": "TAAR\u6846\u67b6\u901a\u8fc7\u8bad\u7ec3\u8bca\u65ad\u7b56\u7565\u68c0\u6d4b\u601d\u7ef4\u9677\u9631\uff0c\u5728\u63a8\u7406\u65f6\u622a\u65ad\u9519\u8bef\u8f68\u8ff9\u5e76\u81ea\u9002\u5e94\u91cd\u542f\u89e3\u7801\uff0c\u63d0\u5347\u6570\u5b66\u548c\u79d1\u5b66\u63a8\u7406\u6027\u80fd", "motivation": "Long-CoT\u901a\u8fc7\u6269\u5c55\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u663e\u8457\u589e\u5f3a\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u957f\u751f\u6210\u4e0d\u4fdd\u8bc1\u6b63\u786e\u6027\uff1a\u65e9\u671f\u9519\u8bef\u627f\u8bfa\u540e\uff0c\u6a21\u578b\u53ef\u80fd\u7ee7\u7eed\u9610\u8ff0\u81ea\u6d3d\u4f46\u9519\u8bef\u7684\u63a8\u7406\u524d\u7f00\uff0c\u5f62\u6210\u601d\u7ef4\u9677\u9631", "method": "\u63d0\u51faTAAR\uff08Trap-Aware Adaptive Restart\uff09\u6846\u67b6\uff1a\u8bad\u7ec3\u8bca\u65ad\u7b56\u7565\u4ece\u90e8\u5206\u8f68\u8ff9\u9884\u6d4b\u4e24\u4e2a\u4fe1\u53f7\uff1a\u9677\u9631\u622a\u65ad\u4f4d\u7f6e\u548c\u9003\u8131\u6982\u7387\uff1b\u63a8\u7406\u65f6\u622a\u65ad\u9884\u6d4b\u7684\u9677\u9631\u6bb5\u5e76\u81ea\u9002\u5e94\u91cd\u542f\u89e3\u7801\uff0c\u4e25\u91cd\u9677\u9631\u65f6\u5e94\u7528\u66f4\u5f3a\u6270\u52a8\uff08\u9ad8\u6e29\u91cd\u91c7\u6837\u548c\u53ef\u9009\u7ed3\u6784\u5316\u91cd\u542f\u540e\u7f00\uff09", "result": "\u5728DAPO-MATH\u5b50\u96c6\u4e0a\uff0c89%\u7684\u5931\u8d25\u6848\u4f8b\u8868\u73b0\u51fa\u601d\u7ef4\u9677\u9631\uff1b\u5728AIME24\u3001AIME25\u3001GPQA-Diamond\u3001HMMT25\u3001BRUMO25\u7b49\u6570\u5b66\u548c\u79d1\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\uff0cTAAR\u5728\u4e0d\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u4e86\u63a8\u7406\u6027\u80fd", "conclusion": "TAAR\u901a\u8fc7\u68c0\u6d4b\u548c\u89c4\u907f\u601d\u7ef4\u9677\u9631\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u957f\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u4e2d\u7684\u9519\u8bef\u7d2f\u79ef\u95ee\u9898\uff0c\u4e3a\u6d4b\u8bd5\u65f6\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u6846\u67b6"}}
{"id": "2601.11776", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11776", "abs": "https://arxiv.org/abs/2601.11776", "authors": ["Kaituo Zhang", "Zhimeng Jiang", "Na Zou"], "title": "Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework for Large Language Models", "comment": null, "summary": "Recent breakthroughs in Large Language Models (LLMs) have revealed remarkable generative capabilities and emerging self-regulatory mechanisms, including self-correction and self-rewarding. However, current detoxification techniques rarely exploit these built-in abilities; instead, they rely on external modules, labor-intensive data annotation, or human intervention --factors that hinder scalability and consistency. In this paper, we introduce a fully self-reflective detoxification framework that harnesses the inherent capacities of LLMs to detect, correct toxic content, and refine LLMs without external modules and data annotation. Specifically, we propose a Toxic Signal Detector --an internal self-identification mechanism, coupled with a systematic intervention process to transform toxic text into its non-toxic counterpart. This iterative procedure yields a contrastive detoxification dataset used to fine-tune the model, enhancing its ability for safe and coherent text generation. Experiments on benchmark datasets such as DetoxLLM and ParaDetox show that our method achieves better detoxification performance than state-of-the-art methods while preserving semantic fidelity. By obviating the need for human intervention or external components, this paper reveals the intrinsic self-detoxification ability of LLMs, offering a consistent and effective approach for mitigating harmful content generation. Ultimately, our findings underscore the potential for truly self-regulated language models, paving the way for more responsible and ethically guided text generation systems.", "AI": {"tldr": "\u63d0\u51fa\u5b8c\u5168\u81ea\u53cd\u5c04\u7684\u53bb\u6bd2\u6846\u67b6\uff0c\u5229\u7528LLMs\u5185\u5728\u80fd\u529b\u8fdb\u884c\u6bd2\u6027\u68c0\u6d4b\u3001\u4fee\u6b63\u548c\u6a21\u578b\u7cbe\u70bc\uff0c\u65e0\u9700\u5916\u90e8\u6a21\u5757\u6216\u6570\u636e\u6807\u6ce8\uff0c\u5b9e\u73b0\u66f4\u597d\u7684\u53bb\u6bd2\u6548\u679c\u548c\u8bed\u4e49\u4fdd\u771f\u5ea6\u3002", "motivation": "\u5f53\u524d\u53bb\u6bd2\u6280\u672f\u5f88\u5c11\u5229\u7528LLMs\u5185\u5728\u7684\u81ea\u6821\u6b63\u548c\u81ea\u5956\u52b1\u80fd\u529b\uff0c\u800c\u662f\u4f9d\u8d56\u5916\u90e8\u6a21\u5757\u3001\u4eba\u5de5\u6570\u636e\u6807\u6ce8\u6216\u4eba\u5de5\u5e72\u9884\uff0c\u8fd9\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u4e00\u81f4\u6027\u3002\u9700\u8981\u5f00\u53d1\u80fd\u5145\u5206\u5229\u7528LLMs\u5185\u7f6e\u80fd\u529b\u7684\u81ea\u53bb\u6bd2\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5b8c\u5168\u81ea\u53cd\u5c04\u53bb\u6bd2\u6846\u67b6\uff1a1) \u6bd2\u6027\u4fe1\u53f7\u68c0\u6d4b\u5668\u2014\u2014\u5185\u90e8\u81ea\u8bc6\u522b\u673a\u5236\uff1b2) \u7cfb\u7edf\u6027\u5e72\u9884\u8fc7\u7a0b\u5c06\u6bd2\u6027\u6587\u672c\u8f6c\u5316\u4e3a\u975e\u6bd2\u6027\u5bf9\u5e94\u6587\u672c\uff1b3) \u8fed\u4ee3\u8fc7\u7a0b\u751f\u6210\u5bf9\u6bd4\u53bb\u6bd2\u6570\u636e\u96c6\u7528\u4e8e\u5fae\u8c03\u6a21\u578b\uff0c\u589e\u5f3a\u5b89\u5168\u8fde\u8d2f\u6587\u672c\u751f\u6210\u80fd\u529b\u3002", "result": "\u5728DetoxLLM\u548cParaDetox\u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u53bb\u6bd2\u6027\u80fd\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u8bed\u4e49\u4fdd\u771f\u5ea6\u3002\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u6216\u5916\u90e8\u7ec4\u4ef6\uff0c\u5c55\u73b0\u4e86LLMs\u5185\u5728\u7684\u81ea\u53bb\u6bd2\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63ed\u793a\u4e86LLMs\u5185\u5728\u7684\u81ea\u53bb\u6bd2\u80fd\u529b\uff0c\u4e3a\u51cf\u8f7b\u6709\u5bb3\u5185\u5bb9\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u81f4\u6709\u6548\u7684\u9014\u5f84\u3002\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u771f\u6b63\u81ea\u8c03\u8282\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u529b\uff0c\u4e3a\u66f4\u8d1f\u8d23\u4efb\u548c\u4f26\u7406\u6307\u5bfc\u7684\u6587\u672c\u751f\u6210\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2601.11979", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11979", "abs": "https://arxiv.org/abs/2601.11979", "authors": ["Ang Gao", "Changshuo Zhang", "Xiao Zhang", "Deyang Li", "Minjun Zhao", "Fangchao Liu", "Xinyu Zhang"], "title": "Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion", "comment": null, "summary": "In-context learning (ICL) has proven highly effective across diverse large language model (LLM) tasks. However, its potential for enhancing tasks that demand step-by-step logical deduction, such as mathematical reasoning, remains underexplored. A core limitation of existing ICL approaches is their static use of demonstrations: examples are pre-selected before inference and remain fixed, failing to adapt to the dynamic confusion points that often arise during multi-step reasoning such as ambiguous calculations or logical gaps. These unresolved confusion points can lead to cascading errors that degrade final accuracy. To tackle this issue, we propose Process In-Context Learning (PICL), a dynamic demonstration integration framework designed to boost mathematical reasoning by responding to real-time inference needs. PICL operates in two stages: 1)~it identifies potential confusion points by analyzing semantics and entropy in the reasoning process and summarizes their core characteristics; 2)~upon encountering these points, it retrieves relevant demonstrations from the demonstration pool that match the confusion context and inserts them directly into the ongoing reasoning process to guide subsequent steps. Experiments show that PICL outperforms baseline methods by mitigating mid-inference confusion, highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.", "AI": {"tldr": "PICL\uff08\u8fc7\u7a0b\u4e0a\u4e0b\u6587\u5b66\u4e60\uff09\u662f\u4e00\u79cd\u52a8\u6001\u6f14\u793a\u96c6\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u65f6\u8bc6\u522b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u6df7\u6dc6\u70b9\u5e76\u63d2\u5165\u76f8\u5173\u6f14\u793a\u6765\u589e\u5f3a\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709ICL\u65b9\u6cd5\u5728\u6570\u5b66\u63a8\u7406\u7b49\u9700\u8981\u9010\u6b65\u903b\u8f91\u63a8\u5bfc\u7684\u4efb\u52a1\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u56e0\u4e3a\u5176\u6f14\u793a\u662f\u9759\u6001\u9884\u9009\u7684\uff0c\u65e0\u6cd5\u9002\u5e94\u63a8\u7406\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u7684\u52a8\u6001\u6df7\u6dc6\u70b9\uff08\u5982\u6a21\u7cca\u8ba1\u7b97\u6216\u903b\u8f91\u6f0f\u6d1e\uff09\uff0c\u8fd9\u4e9b\u672a\u89e3\u51b3\u7684\u6df7\u6dc6\u70b9\u4f1a\u5bfc\u81f4\u7ea7\u8054\u9519\u8bef\u5e76\u964d\u4f4e\u6700\u7ec8\u51c6\u786e\u6027\u3002", "method": "PICL\u91c7\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u5206\u6790\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u8bed\u4e49\u548c\u71b5\u6765\u8bc6\u522b\u6f5c\u5728\u6df7\u6dc6\u70b9\u5e76\u603b\u7ed3\u5176\u6838\u5fc3\u7279\u5f81\uff1b2\uff09\u5728\u9047\u5230\u8fd9\u4e9b\u6df7\u6dc6\u70b9\u65f6\uff0c\u4ece\u6f14\u793a\u6c60\u4e2d\u68c0\u7d22\u4e0e\u6df7\u6dc6\u4e0a\u4e0b\u6587\u5339\u914d\u7684\u76f8\u5173\u6f14\u793a\uff0c\u5e76\u5c06\u5176\u76f4\u63a5\u63d2\u5165\u5230\u6b63\u5728\u8fdb\u884c\u7684\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4ee5\u6307\u5bfc\u540e\u7eed\u6b65\u9aa4\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cPICL\u901a\u8fc7\u7f13\u89e3\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u6df7\u6dc6\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7a81\u663e\u4e86\u81ea\u9002\u5e94\u6f14\u793a\u63d2\u5165\u5728\u590d\u6742\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u4ef7\u503c\u3002", "conclusion": "PICL\u8bc1\u660e\u4e86\u52a8\u6001\u6f14\u793a\u96c6\u6210\u6846\u67b6\u5728\u589e\u5f3a\u6570\u5b66\u63a8\u7406\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u901a\u8fc7\u5b9e\u65f6\u54cd\u5e94\u63a8\u7406\u9700\u6c42\u6765\u9002\u5e94\u52a8\u6001\u6df7\u6dc6\u70b9\uff0c\u4e3a\u9700\u8981\u9010\u6b65\u903b\u8f91\u63a8\u5bfc\u7684\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684ICL\u65b9\u6cd5\u3002"}}
{"id": "2601.11791", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11791", "abs": "https://arxiv.org/abs/2601.11791", "authors": ["Laya Iyer", "Pranav Somani", "Alice Guo", "Dan Jurafsky", "Chen Shani"], "title": "Beyond Tokens: Concept-Level Training Objectives for LLMs", "comment": null, "summary": "The next-token prediction (NTP) objective has been foundational in the development of modern large language models (LLMs), driving advances in fluency and generalization. However, NTP operates at the \\textit{token} level, treating deviations from a single reference continuation as errors even when alternative continuations are equally plausible or semantically equivalent (e.g., ``mom'' vs. ``mother''). As a result, token-level loss can penalize valid abstractions, paraphrases, or conceptually correct reasoning paths, biasing models toward surface form rather than underlying meaning. This mismatch between the training signal and semantic correctness motivates learning objectives that operate over higher-level representations. We propose a shift from token-level to concept-level prediction, where concepts group multiple surface forms of the same idea (e.g., ``mom,'' ``mommy,'' ``mother'' $\\rightarrow$ \\textit{MOTHER}). We introduce various methods for integrating conceptual supervision into LLM training and show that concept-aware models achieve lower perplexity, improved robustness under domain shift, and stronger performance than NTP-based models on diverse NLP benchmarks. This suggests \\textit{concept-level supervision} as an improved training signal that better aligns LLMs with human semantic abstractions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4ece\u4f20\u7edf\u7684\u4e0b\u4e00\u8bcd\u9884\u6d4b\u76ee\u6807\u8f6c\u5411\u6982\u5ff5\u7ea7\u9884\u6d4b\uff0c\u901a\u8fc7\u5c06\u540c\u4e00\u6982\u5ff5\u7684\u4e0d\u540c\u8868\u9762\u5f62\u5f0f\uff08\u5982\"mom\"\u3001\"mother\"\uff09\u5206\u7ec4\uff0c\u8ba9\u8bed\u8a00\u6a21\u578b\u5b66\u4e60\u66f4\u9ad8\u5c42\u6b21\u7684\u8bed\u4e49\u62bd\u8c61\uff0c\u4ece\u800c\u6539\u5584\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u4e0b\u4e00\u8bcd\u9884\u6d4b\u76ee\u6807\u5728\u8bcd\u7ea7\u522b\u64cd\u4f5c\uff0c\u4f1a\u5c06\u8bed\u4e49\u7b49\u4ef7\u4f46\u8868\u9762\u5f62\u5f0f\u4e0d\u540c\u7684\u5ef6\u7eed\uff08\u5982\"mom\" vs \"mother\"\uff09\u89c6\u4e3a\u9519\u8bef\uff0c\u4ece\u800c\u60e9\u7f5a\u6709\u6548\u7684\u62bd\u8c61\u3001\u91ca\u4e49\u6216\u6982\u5ff5\u6b63\u786e\u7684\u63a8\u7406\u8def\u5f84\u3002\u8fd9\u79cd\u8bad\u7ec3\u4fe1\u53f7\u4e0e\u8bed\u4e49\u6b63\u786e\u6027\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u4fc3\u4f7f\u9700\u8981\u66f4\u9ad8\u5c42\u6b21\u8868\u793a\u7684\u5b66\u4e60\u76ee\u6807\u3002", "method": "\u63d0\u51fa\u4ece\u8bcd\u7ea7\u9884\u6d4b\u8f6c\u5411\u6982\u5ff5\u7ea7\u9884\u6d4b\uff0c\u5176\u4e2d\u6982\u5ff5\u5c06\u540c\u4e00\u60f3\u6cd5\u7684\u591a\u4e2a\u8868\u9762\u5f62\u5f0f\u5206\u7ec4\u3002\u4ecb\u7ecd\u4e86\u5c06\u6982\u5ff5\u76d1\u7763\u6574\u5408\u5230LLM\u8bad\u7ec3\u4e2d\u7684\u5404\u79cd\u65b9\u6cd5\u3002", "result": "\u6982\u5ff5\u611f\u77e5\u6a21\u578b\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u56f0\u60d1\u5ea6\uff0c\u5728\u9886\u57df\u8f6c\u79fb\u4e0b\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u4e14\u5728\u591a\u6837\u5316\u7684NLP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6bd4\u57fa\u4e8eNTP\u7684\u6a21\u578b\u8868\u73b0\u66f4\u5f3a\u3002", "conclusion": "\u6982\u5ff5\u7ea7\u76d1\u7763\u4f5c\u4e3a\u4e00\u79cd\u6539\u8fdb\u7684\u8bad\u7ec3\u4fe1\u53f7\uff0c\u80fd\u66f4\u597d\u5730\u5c06LLM\u4e0e\u4eba\u7c7b\u8bed\u4e49\u62bd\u8c61\u5bf9\u9f50\uff0c\u662f\u6bd4\u4f20\u7edf\u4e0b\u4e00\u8bcd\u9884\u6d4b\u66f4\u4f18\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002"}}
{"id": "2601.12034", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.12034", "abs": "https://arxiv.org/abs/2601.12034", "authors": ["Ziyi Zhao", "Chongming Gao", "Yang Zhang", "Haoyan Liu", "Weinan Gan", "Huifeng Guo", "Yong Liu", "Fuli Feng"], "title": "Don't Start Over: A Cost-Effective Framework for Migrating Personalized Prompts Between LLMs", "comment": "Accepted to AAAI 2026 (Oral). 9 pages, 5 figures", "summary": "Personalization in Large Language Models (LLMs) often relies on user-specific soft prompts. However, these prompts become obsolete when the foundation model is upgraded, necessitating costly, full-scale retraining. To overcome this limitation, we propose the Prompt-level User Migration Adapter (PUMA), a lightweight framework to efficiently migrate personalized prompts across incompatible models. PUMA utilizes a parameter-efficient adapter to bridge the semantic gap, combined with a group-based user selection strategy to significantly reduce training costs. Experiments on three large-scale datasets show our method matches or even surpasses the performance of retraining from scratch, reducing computational cost by up to 98%. The framework demonstrates strong generalization across diverse model architectures and robustness in advanced scenarios like chained and aggregated migrations, offering a practical path for the sustainable evolution of personalized AI by decoupling user assets from the underlying models.", "AI": {"tldr": "PUMA\u6846\u67b6\u901a\u8fc7\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u8fc1\u79fb\u4e2a\u6027\u5316\u63d0\u793a\uff0c\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5347\u7ea7\u65f6\u7528\u6237\u8f6f\u63d0\u793a\u5931\u6548\u95ee\u9898\uff0c\u51cf\u5c1198%\u8ba1\u7b97\u6210\u672c", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4e2a\u6027\u5316\u901a\u5e38\u4f9d\u8d56\u7528\u6237\u7279\u5b9a\u7684\u8f6f\u63d0\u793a\uff0c\u4f46\u5f53\u57fa\u7840\u6a21\u578b\u5347\u7ea7\u65f6\uff0c\u8fd9\u4e9b\u63d0\u793a\u4f1a\u5931\u6548\uff0c\u9700\u8981\u6602\u8d35\u7684\u5168\u91cf\u91cd\u65b0\u8bad\u7ec3\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u9ad8\u6548\u8fc1\u79fb\u4e2a\u6027\u5316\u63d0\u793a\u5230\u4e0d\u517c\u5bb9\u6a21\u578b\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faPrompt-level User Migration Adapter (PUMA)\u6846\u67b6\uff1a1) \u4f7f\u7528\u53c2\u6570\u9ad8\u6548\u7684\u9002\u914d\u5668\u6865\u63a5\u8bed\u4e49\u9e3f\u6c9f\uff1b2) \u91c7\u7528\u57fa\u4e8e\u7ec4\u7684\u7528\u6237\u9009\u62e9\u7b56\u7565\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\uff1b3) \u652f\u6301\u94fe\u5f0f\u548c\u805a\u5408\u8fc1\u79fb\u7b49\u9ad8\u7ea7\u573a\u666f\u3002", "result": "\u5728\u4e09\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff1a1) \u6027\u80fd\u5339\u914d\u751a\u81f3\u8d85\u8fc7\u4ece\u5934\u8bad\u7ec3\uff1b2) \u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe98%\uff1b3) \u5728\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u4e0a\u5177\u6709\u5f3a\u6cdb\u5316\u80fd\u529b\uff1b4) \u5728\u94fe\u5f0f\u548c\u805a\u5408\u8fc1\u79fb\u573a\u666f\u4e2d\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "PUMA\u901a\u8fc7\u5c06\u7528\u6237\u8d44\u4ea7\u4e0e\u5e95\u5c42\u6a21\u578b\u89e3\u8026\uff0c\u4e3a\u4e2a\u6027\u5316AI\u7684\u53ef\u6301\u7eed\u6f14\u8fdb\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u7684\u4e2a\u6027\u5316\u63d0\u793a\u8fc1\u79fb\uff0c\u652f\u6301\u6a21\u578b\u5347\u7ea7\u65f6\u7684\u7528\u6237\u8d44\u4ea7\u4fdd\u7559\u3002"}}
{"id": "2601.11819", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11819", "abs": "https://arxiv.org/abs/2601.11819", "authors": ["Shirlene Rose Bandela", "Sanjeev Parthasarathy", "Vaibhav Garg"], "title": "TWeddit : A Dataset of Triggering Stories Predominantly Shared by Women on Reddit", "comment": "11 pages, 12 figures, 7 tables", "summary": "Warning: This paper may contain examples and topics that may be disturbing to some readers, especially survivors of miscarriage and sexual violence. People affected by abortion, miscarriage, or sexual violence often share their experiences on social media to express emotions and seek support. On public platforms like Reddit, where users can post long, detailed narratives (up to 40,000 characters), readers may be exposed to distressing content. Although Reddit allows manual trigger warnings, many users omit them due to limited awareness or uncertainty about which categories apply. There is scarcity of datasets on Reddit stories labeled for triggering experiences. We propose a curated Reddit dataset, TWeddit, covering triggering experiences related to issues majorly faced by women. Our linguistic analyses show that annotated stories in TWeddit express distinct topics and moral foundations, making the dataset useful for a wide range of future research.", "AI": {"tldr": "TWeddit\u6570\u636e\u96c6\uff1a\u4e00\u4e2a\u6807\u6ce8Reddit\u4e2d\u5973\u6027\u4e3b\u8981\u9762\u4e34\u7684\u89e6\u53d1\u7ecf\u5386\uff08\u5982\u6d41\u4ea7\u3001\u6027\u66b4\u529b\uff09\u7684\u8bed\u6599\u5e93\uff0c\u7528\u4e8e\u7814\u7a76\u521b\u4f24\u5185\u5bb9\u68c0\u6d4b\u548c\u7528\u6237\u652f\u6301", "motivation": "Reddit\u7b49\u5e73\u53f0\u7528\u6237\u5e38\u5206\u4eab\u6d41\u4ea7\u3001\u6027\u66b4\u529b\u7b49\u521b\u4f24\u7ecf\u5386\uff0c\u4f46\u7f3a\u4e4f\u624b\u52a8\u89e6\u53d1\u8b66\u544a\uff0c\u73b0\u6709\u6807\u6ce8\u6570\u636e\u96c6\u7a00\u7f3a\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u8d44\u6e90\u6765\u7814\u7a76\u8fd9\u4e9b\u654f\u611f\u5185\u5bb9", "method": "\u6784\u5efaTWeddit\u6570\u636e\u96c6\uff0c\u6536\u96c6Reddit\u4e0a\u8be6\u7ec6\u53d9\u4e8b\uff08\u6700\u957f40,000\u5b57\u7b26\uff09\uff0c\u6807\u6ce8\u89e6\u53d1\u7ecf\u5386\u7c7b\u522b\uff0c\u8fdb\u884c\u8bed\u8a00\u5206\u6790\u548c\u4e3b\u9898\u5efa\u6a21\uff0c\u6bd4\u8f83\u9053\u5fb7\u57fa\u7840\u8868\u8fbe", "result": "TWeddit\u6570\u636e\u96c6\u663e\u793a\u6807\u6ce8\u6545\u4e8b\u8868\u8fbe\u72ec\u7279\u4e3b\u9898\u548c\u9053\u5fb7\u57fa\u7840\uff0c\u4e0e\u672a\u6807\u6ce8\u5185\u5bb9\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u6709\u4ef7\u503c\u8d44\u6e90", "conclusion": "TWeddit\u586b\u8865\u4e86Reddit\u89e6\u53d1\u7ecf\u5386\u6807\u6ce8\u6570\u636e\u96c6\u7684\u7a7a\u767d\uff0c\u5176\u8bed\u8a00\u7279\u5f81\u5206\u6790\u8868\u660e\u8be5\u6570\u636e\u96c6\u9002\u7528\u4e8e\u5e7f\u6cdb\u7814\u7a76\uff0c\u5305\u62ec\u521b\u4f24\u5185\u5bb9\u68c0\u6d4b\u548c\u7528\u6237\u652f\u6301\u7cfb\u7edf\u5f00\u53d1"}}
{"id": "2601.11846", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.11846", "abs": "https://arxiv.org/abs/2601.11846", "authors": ["Natalia Tomashenko", "Xiaoxiao Miao", "Pierre Champion", "Sarina Meyer", "Michele Panariello", "Xin Wang", "Nicholas Evans", "Emmanuel Vincent", "Junichi Yamagishi", "Massimiliano Todisco"], "title": "The Third VoicePrivacy Challenge: Preserving Emotional Expressiveness and Linguistic Content in Voice Anonymization", "comment": "under review", "summary": "We present results and analyses from the third VoicePrivacy Challenge held in 2024, which focuses on advancing voice anonymization technologies. The task was to develop a voice anonymization system for speech data that conceals a speaker's voice identity while preserving linguistic content and emotional state. We provide a systematic overview of the challenge framework, including detailed descriptions of the anonymization task and datasets used for both system development and evaluation. We outline the attack model and objective evaluation metrics for assessing privacy protection (concealing speaker voice identity) and utility (content and emotional state preservation). We describe six baseline anonymization systems and summarize the innovative approaches developed by challenge participants. Finally, we provide key insights and observations to guide the design of future VoicePrivacy challenges and identify promising directions for voice anonymization research.", "AI": {"tldr": "2024\u5e74\u7b2c\u4e09\u5c4aVoicePrivacy\u6311\u6218\u8d5b\u603b\u7ed3\uff0c\u805a\u7126\u8bed\u97f3\u533f\u540d\u5316\u6280\u672f\uff0c\u65e8\u5728\u9690\u85cf\u8bf4\u8bdd\u4eba\u8eab\u4efd\u540c\u65f6\u4fdd\u7559\u8bed\u8a00\u5185\u5bb9\u548c\u60c5\u611f\u72b6\u6001", "motivation": "\u63a8\u52a8\u8bed\u97f3\u533f\u540d\u5316\u6280\u672f\u53d1\u5c55\uff0c\u89e3\u51b3\u5728\u4fdd\u62a4\u8bf4\u8bdd\u4eba\u8eab\u4efd\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u8bed\u97f3\u5185\u5bb9\uff08\u8bed\u8a00\u4fe1\u606f\u548c\u60c5\u611f\u72b6\u6001\uff09\u53ef\u7528\u6027\u7684\u6311\u6218", "method": "\u7cfb\u7edf\u6982\u8ff0\u6311\u6218\u6846\u67b6\uff0c\u5305\u62ec\u533f\u540d\u5316\u4efb\u52a1\u5b9a\u4e49\u3001\u6570\u636e\u96c6\uff08\u5f00\u53d1\u4e0e\u8bc4\u4f30\uff09\u3001\u653b\u51fb\u6a21\u578b\u3001\u5ba2\u89c2\u8bc4\u4f30\u6307\u6807\uff08\u9690\u79c1\u4fdd\u62a4\u548c\u5b9e\u7528\u6027\uff09\uff0c\u63cf\u8ff0\u516d\u4e2a\u57fa\u7ebf\u533f\u540d\u5316\u7cfb\u7edf\u5e76\u603b\u7ed3\u53c2\u8d5b\u8005\u7684\u521b\u65b0\u65b9\u6cd5", "result": "\u63d0\u4f9b\u4e86\u7b2c\u4e09\u5c4aVoicePrivacy\u6311\u6218\u8d5b\u7684\u5168\u9762\u5206\u6790\uff0c\u5305\u62ec\u6846\u67b6\u8bbe\u8ba1\u3001\u57fa\u7ebf\u7cfb\u7edf\u63cf\u8ff0\u3001\u53c2\u4e0e\u8005\u521b\u65b0\u65b9\u6cd5\u603b\u7ed3\uff0c\u4ee5\u53ca\u8bc4\u4f30\u7ed3\u679c\u5206\u6790", "conclusion": "\u63d0\u51fa\u5173\u952e\u89c1\u89e3\u548c\u89c2\u5bdf\uff0c\u4e3a\u672a\u6765VoicePrivacy\u6311\u6218\u8d5b\u8bbe\u8ba1\u63d0\u4f9b\u6307\u5bfc\uff0c\u5e76\u8bc6\u522b\u8bed\u97f3\u533f\u540d\u5316\u7814\u7a76\u7684\u6709\u524d\u666f\u65b9\u5411"}}
{"id": "2601.12024", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12024", "abs": "https://arxiv.org/abs/2601.12024", "authors": ["Kartikey Singh Bhandari", "Tanish Jain", "Archit Agrawal", "Dhruv Kumar", "Praveen Kumar", "Pratik Narang"], "title": "A Multi-Agent System for Generating Actionable Business Advice", "comment": null, "summary": "Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. While large language models (LLMs) can generate free-form suggestions, their outputs often lack accuracy and depth of reasoning. In this paper, we present a multi-agent, LLM-based framework for prescriptive decision support, which transforms large scale review corpora into actionable business advice. The framework integrates four components: clustering to select representative reviews, generation of advices, iterative evaluation, and feasibility based ranking. This design couples corpus distillation with feedback driven advice refinement to produce outputs that are specific, actionable, and practical. Experiments across three service domains and multiple model families show that our framework consistently outperform single model baselines on actionability, specificity, and non-redundancy, with medium sized models approaching the performance of large model frameworks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u5927\u89c4\u6a21\u5ba2\u6237\u8bc4\u8bba\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u5546\u4e1a\u5efa\u8bae\uff0c\u901a\u8fc7\u805a\u7c7b\u3001\u751f\u6210\u3001\u8fed\u4ee3\u8bc4\u4f30\u548c\u53ef\u884c\u6027\u6392\u5e8f\u63d0\u5347\u5efa\u8bae\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u5206\u6790\u65b9\u6cd5\uff08\u5982\u60c5\u611f\u5206\u6790\u3001\u65b9\u9762\u63d0\u53d6\uff09\u505c\u7559\u5728\u63cf\u8ff0\u6027\u4efb\u52a1\u5c42\u9762\uff0c\u65e0\u6cd5\u63d0\u4f9b\u6df1\u5ea6\u51b3\u7b56\u652f\u6301\uff1bLLM\u751f\u6210\u7684\u5efa\u8bae\u867d\u7136\u81ea\u7531\u5ea6\u9ad8\uff0c\u4f46\u7f3a\u4e4f\u51c6\u786e\u6027\u548c\u6df1\u5ea6\u63a8\u7406\u3002", "method": "\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\u5305\u542b\u56db\u4e2a\u7ec4\u4ef6\uff1a1\uff09\u805a\u7c7b\u9009\u62e9\u4ee3\u8868\u6027\u8bc4\u8bba\uff1b2\uff09\u751f\u6210\u5efa\u8bae\uff1b3\uff09\u8fed\u4ee3\u8bc4\u4f30\uff1b4\uff09\u57fa\u4e8e\u53ef\u884c\u6027\u7684\u6392\u5e8f\u3002\u8be5\u8bbe\u8ba1\u5c06\u8bed\u6599\u5e93\u84b8\u998f\u4e0e\u53cd\u9988\u9a71\u52a8\u7684\u5efa\u8bae\u7cbe\u70bc\u76f8\u7ed3\u5408\u3002", "result": "\u5728\u4e09\u4e2a\u670d\u52a1\u9886\u57df\u548c\u591a\u4e2a\u6a21\u578b\u5bb6\u65cf\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u53ef\u64cd\u4f5c\u6027\u3001\u7279\u5f02\u6027\u548c\u975e\u5197\u4f59\u6027\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u5355\u6a21\u578b\u57fa\u7ebf\uff0c\u4e2d\u7b49\u89c4\u6a21\u6a21\u578b\u63a5\u8fd1\u5927\u578b\u6a21\u578b\u6846\u67b6\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5c06\u5927\u89c4\u6a21\u8bc4\u8bba\u8bed\u6599\u8f6c\u5316\u4e3a\u5177\u4f53\u3001\u53ef\u64cd\u4f5c\u4e14\u5b9e\u7528\u7684\u5546\u4e1a\u5efa\u8bae\uff0c\u4e3a\u57fa\u4e8e\u5ba2\u6237\u53cd\u9988\u7684\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12632", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.12632", "abs": "https://arxiv.org/abs/2601.12632", "authors": ["Kriti Bhattarai", "Vipina K. Keloth", "Donald Wright", "Andrew Loza", "Yang Ren", "Hua Xu"], "title": "BioPulse-QA: A Dynamic Biomedical Question-Answering Benchmark for Evaluating Factuality, Robustness, and Bias in Large Language Models", "comment": null, "summary": "Objective: Large language models (LLMs) are increasingly applied in biomedical settings, and existing benchmark datasets have played an important role in supporting model development and evaluation. However, these benchmarks often have limitations. Many rely on static or outdated datasets that fail to capture the dynamic, context-rich, and high-stakes nature of biomedical knowledge. They also carry increasing risk of data leakage due to overlap with model pretraining corpora and often overlook critical dimensions such as robustness to linguistic variation and potential demographic biases.\n  Materials and Methods: To address these gaps, we introduce BioPulse-QA, a benchmark that evaluates LLMs on answering questions from newly published biomedical documents including drug labels, trial protocols, and clinical guidelines. BioPulse-QA includes 2,280 expert-verified question answering (QA) pairs and perturbed variants, covering both extractive and abstractive formats. We evaluate four LLMs - GPT-4o, GPT-o1, Gemini-2.0-Flash, and LLaMA-3.1 8B Instruct - released prior to the publication dates of the benchmark documents.\n  Results: GPT-o1 achieves the highest relaxed F1 score (0.92), followed by Gemini-2.0-Flash (0.90) on drug labels. Clinical trials are the most challenging source, with extractive F1 scores as low as 0.36.\n  Discussion and Conclusion: Performance differences are larger for paraphrasing than for typographical errors, while bias testing shows negligible differences. BioPulse-QA provides a scalable and clinically relevant framework for evaluating biomedical LLMs.", "AI": {"tldr": "BioPulse-QA\u662f\u4e00\u4e2a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u7269\u533b\u5b66\u9886\u57df\u8868\u73b0\u7684\u65b0\u57fa\u51c6\uff0c\u5305\u542b2280\u4e2a\u4e13\u5bb6\u9a8c\u8bc1\u7684\u95ee\u7b54\u5bf9\uff0c\u8986\u76d6\u836f\u7269\u6807\u7b7e\u3001\u8bd5\u9a8c\u65b9\u6848\u548c\u4e34\u5e8a\u6307\u5357\u7b49\u65b0\u53d1\u5e03\u6587\u6863\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u57fa\u51c6\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u751f\u7269\u533b\u5b66\u57fa\u51c6\u5b58\u5728\u591a\u4e2a\u5c40\u9650\u6027\uff1a\u4f9d\u8d56\u9759\u6001\u6216\u8fc7\u65f6\u6570\u636e\u96c6\uff0c\u65e0\u6cd5\u6355\u6349\u52a8\u6001\u3001\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u751f\u7269\u533b\u5b66\u77e5\u8bc6\uff1b\u5b58\u5728\u6570\u636e\u6cc4\u9732\u98ce\u9669\uff08\u4e0e\u6a21\u578b\u9884\u8bad\u7ec3\u8bed\u6599\u91cd\u53e0\uff09\uff1b\u5ffd\u89c6\u5173\u952e\u7ef4\u5ea6\u5982\u8bed\u8a00\u53d8\u5f02\u7684\u9c81\u68d2\u6027\u548c\u4eba\u53e3\u7edf\u8ba1\u5b66\u504f\u89c1\u3002\u9700\u8981\u66f4\u5168\u9762\u3001\u52a8\u6001\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u5f00\u53d1BioPulse-QA\u57fa\u51c6\uff0c\u5305\u542b2280\u4e2a\u4e13\u5bb6\u9a8c\u8bc1\u7684\u95ee\u7b54\u5bf9\uff0c\u8986\u76d6\u65b0\u53d1\u5e03\u7684\u751f\u7269\u533b\u5b66\u6587\u6863\uff08\u836f\u7269\u6807\u7b7e\u3001\u8bd5\u9a8c\u65b9\u6848\u3001\u4e34\u5e8a\u6307\u5357\uff09\u3002\u5305\u542b\u63d0\u53d6\u5f0f\u548c\u62bd\u8c61\u5f0f\u95ee\u7b54\u683c\u5f0f\uff0c\u5e76\u5f15\u5165\u6270\u52a8\u53d8\u4f53\uff08\u5982\u91ca\u4e49\u3001\u62fc\u5199\u9519\u8bef\uff09\u3002\u8bc4\u4f30GPT-4o\u3001GPT-o1\u3001Gemini-2.0-Flash\u548cLLaMA-3.1 8B Instruct\u56db\u4e2a\u5728\u57fa\u51c6\u6587\u6863\u53d1\u5e03\u65e5\u671f\u524d\u53d1\u5e03\u7684LLM\u3002", "result": "GPT-o1\u5728\u836f\u7269\u6807\u7b7e\u4e0a\u83b7\u5f97\u6700\u9ad8\u653e\u677eF1\u5206\u6570\uff080.92\uff09\uff0cGemini-2.0-Flash\u6b21\u4e4b\uff080.90\uff09\u3002\u4e34\u5e8a\u8bd5\u9a8c\u662f\u6700\u5177\u6311\u6218\u6027\u7684\u6765\u6e90\uff0c\u63d0\u53d6\u5f0fF1\u5206\u6570\u4f4e\u81f30.36\u3002\u6a21\u578b\u5728\u91ca\u4e49\u6270\u52a8\u4e0a\u7684\u6027\u80fd\u5dee\u5f02\u5927\u4e8e\u62fc\u5199\u9519\u8bef\uff0c\u504f\u89c1\u6d4b\u8bd5\u663e\u793a\u5dee\u5f02\u53ef\u5ffd\u7565\u3002", "conclusion": "BioPulse-QA\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u4e34\u5e8a\u76f8\u5173\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u751f\u7269\u533b\u5b66LLM\u3002\u57fa\u51c6\u63ed\u793a\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u6587\u6863\u7c7b\u578b\u4e0a\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u7279\u522b\u662f\u5728\u4e34\u5e8a\u8bd5\u9a8c\u9886\u57df\u7684\u6311\u6218\u3002\u8be5\u6846\u67b6\u6709\u52a9\u4e8e\u66f4\u5168\u9762\u5730\u8bc4\u4f30LLM\u5728\u52a8\u6001\u3001\u9ad8\u98ce\u9669\u751f\u7269\u533b\u5b66\u73af\u5883\u4e2d\u7684\u80fd\u529b\u3002"}}
{"id": "2601.11854", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.11854", "abs": "https://arxiv.org/abs/2601.11854", "authors": ["Yifei Zhang", "Hooshang Nayyeri", "Rinat Khaziev", "Emine Yilmaz", "Gokhan Tur", "Dilek Hakkani-T\u00fcr", "Hari Thadakamalla"], "title": "ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System", "comment": null, "summary": "Recent advances in task-oriented dialogue (TOD) systems, driven by large language models (LLMs) with extensive API and tool integration, have enabled conversational agents to coordinate interleaved goals, maintain long-horizon context, and act proactively through asynchronous execution. These capabilities extend beyond traditional TOD systems, yet existing benchmarks lack systematic support for evaluating such agentic behaviors. To address this gap, we introduce ATOD, a benchmark and synthetic dialogue generation pipeline that produces richly annotated conversations requiring long-term reasoning. ATOD captures key characteristics of advanced TOD, including multi-goal coordination, dependency management, memory, adaptability, and proactivity. Building on ATOD, we propose ATOD-Eval, a holistic evaluation framework that translates these dimensions into fine-grained metrics and supports reproducible offline and online evaluation. We further present a strong agentic memory-based evaluator for benchmarking on ATOD. Experiments show that ATOD-Eval enables comprehensive assessment across task completion, agentic capability, and response quality, and that the proposed evaluator offers a better accuracy-efficiency tradeoff compared to existing memory- and LLM-based approaches under this evaluation setting.", "AI": {"tldr": "ATOD\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u5bf9\u8bdd\u751f\u6210\u6846\u67b6\uff0c\u5305\u542bATOD-Eval\u8bc4\u4f30\u6846\u67b6\u548c\u57fa\u4e8e\u8bb0\u5fc6\u7684\u8bc4\u4f30\u5668", "motivation": "\u73b0\u6709\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u7cfb\u7edf\u57fa\u51c6\u7f3a\u4e4f\u5bf9LLM\u9a71\u52a8\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u652f\u6301\uff0c\u5982\u591a\u76ee\u6807\u534f\u8c03\u3001\u957f\u671f\u63a8\u7406\u3001\u5f02\u6b65\u6267\u884c\u7b49\u80fd\u529b", "method": "\u63d0\u51faATOD\u57fa\u51c6\u548c\u5408\u6210\u5bf9\u8bdd\u751f\u6210\u7ba1\u9053\uff0c\u521b\u5efa\u9700\u8981\u957f\u671f\u63a8\u7406\u7684\u4e30\u5bcc\u6ce8\u91ca\u5bf9\u8bdd\uff1b\u6784\u5efaATOD-Eval\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u4f53\u7ef4\u5ea6\u8f6c\u5316\u4e3a\u7ec6\u7c92\u5ea6\u6307\u6807\uff1b\u5f00\u53d1\u57fa\u4e8e\u8bb0\u5fc6\u7684\u667a\u80fd\u4f53\u8bc4\u4f30\u5668", "result": "ATOD-Eval\u80fd\u591f\u5168\u9762\u8bc4\u4f30\u4efb\u52a1\u5b8c\u6210\u5ea6\u3001\u667a\u80fd\u4f53\u80fd\u529b\u548c\u54cd\u5e94\u8d28\u91cf\uff1b\u63d0\u51fa\u7684\u8bc4\u4f30\u5668\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e4b\u95f4\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u6743\u8861", "conclusion": "ATOD\u586b\u8865\u4e86\u9ad8\u7ea7\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u4e3a\u667a\u80fd\u4f53\u884c\u4e3a\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u8bc4\u4f30\u6846\u67b6"}}
{"id": "2601.12030", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12030", "abs": "https://arxiv.org/abs/2601.12030", "authors": ["Yilun Yao", "Shan Huang", "Elsie Dai", "Zhewen Tan", "Zhenyu Duan", "Shousheng Jia", "Yanbing Jiang", "Tong Yang"], "title": "ARC: Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents", "comment": "15 pages, 5 figures", "summary": "Large language models are increasingly deployed as research agents for deep search and long-horizon information seeking, yet their performance often degrades as interaction histories grow. This degradation, known as context rot, reflects a failure to maintain coherent and task-relevant internal states over extended reasoning horizons. Existing approaches primarily manage context through raw accumulation or passive summarization, treating it as a static artifact and allowing early errors or misplaced emphasis to persist. Motivated by this perspective, we propose ARC, which is the first framework to systematically formulate context management as an active, reflection-driven process that treats context as a dynamic internal reasoning state during execution. ARC operationalizes this view through reflection-driven monitoring and revision, allowing agents to actively reorganize their working context when misalignment or degradation is detected. Experiments on challenging long-horizon information-seeking benchmarks show that ARC consistently outperforms passive context compression methods, achieving up to an 11% absolute improvement in accuracy on BrowseComp-ZH with Qwen2.5-32B-Instruct.", "AI": {"tldr": "ARC\u6846\u67b6\u5c06\u4e0a\u4e0b\u6587\u7ba1\u7406\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4e3b\u52a8\u7684\u3001\u53cd\u601d\u9a71\u52a8\u7684\u52a8\u6001\u63a8\u7406\u72b6\u6001\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u65f6\u7a0b\u4fe1\u606f\u641c\u7d22\u4efb\u52a1\u4e2d\u7684\u6027\u80fd", "motivation": "\u73b0\u6709\u4e0a\u4e0b\u6587\u7ba1\u7406\u65b9\u6cd5\uff08\u539f\u59cb\u79ef\u7d2f\u6216\u88ab\u52a8\u6458\u8981\uff09\u5c06\u4e0a\u4e0b\u6587\u89c6\u4e3a\u9759\u6001\u4ea7\u7269\uff0c\u5bfc\u81f4\u65e9\u671f\u9519\u8bef\u6216\u4e0d\u5f53\u5f3a\u8c03\u6301\u7eed\u5b58\u5728\uff0c\u968f\u7740\u4ea4\u4e92\u5386\u53f2\u589e\u957f\u51fa\u73b0\u6027\u80fd\u9000\u5316\uff08\u4e0a\u4e0b\u6587\u8150\u5316\uff09", "method": "\u63d0\u51faARC\u6846\u67b6\uff0c\u5c06\u4e0a\u4e0b\u6587\u7ba1\u7406\u7cfb\u7edf\u5316\u4e3a\u4e3b\u52a8\u7684\u3001\u53cd\u601d\u9a71\u52a8\u7684\u52a8\u6001\u63a8\u7406\u72b6\u6001\u8fc7\u7a0b\uff0c\u901a\u8fc7\u53cd\u601d\u9a71\u52a8\u7684\u76d1\u63a7\u548c\u4fee\u8ba2\u673a\u5236\uff0c\u5728\u68c0\u6d4b\u5230\u9519\u4f4d\u6216\u9000\u5316\u65f6\u4e3b\u52a8\u91cd\u7ec4\u5de5\u4f5c\u4e0a\u4e0b\u6587", "result": "\u5728\u6311\u6218\u6027\u957f\u65f6\u7a0b\u4fe1\u606f\u641c\u7d22\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cARC\u6301\u7eed\u4f18\u4e8e\u88ab\u52a8\u4e0a\u4e0b\u6587\u538b\u7f29\u65b9\u6cd5\uff0c\u5728BrowseComp-ZH\u57fa\u51c6\u4e0a\u4f7f\u7528Qwen2.5-32B-Instruct\u6a21\u578b\u5b9e\u73b0\u9ad8\u8fbe11%\u7684\u7edd\u5bf9\u51c6\u786e\u7387\u63d0\u5347", "conclusion": "\u5c06\u4e0a\u4e0b\u6587\u7ba1\u7406\u91cd\u65b0\u6982\u5ff5\u5316\u4e3a\u4e3b\u52a8\u7684\u3001\u53cd\u601d\u9a71\u52a8\u7684\u52a8\u6001\u8fc7\u7a0b\uff0c\u800c\u975e\u9759\u6001\u4ea7\u7269\uff0c\u662f\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u4e0a\u4e0b\u6587\u8150\u5316\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5"}}
{"id": "2601.13111", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.13111", "abs": "https://arxiv.org/abs/2601.13111", "authors": ["Hassan Soliman", "Vivek Gupta", "Dan Roth", "Iryna Gurevych"], "title": "CORE-T: COherent REtrieval of Tables for Text-to-SQL", "comment": "Preprint under review. Code and data available at: https://github.com/UKPLab/arxiv2026-core-t", "summary": "Realistic text-to-SQL workflows often require joining multiple tables. As a result, accurately retrieving the relevant set of tables becomes a key bottleneck for end-to-end performance. We study an open-book setting where queries must be answered over large, heterogeneous table collections pooled from many sources, without clean scoping signals such as database identifiers. Here, dense retrieval (DR) achieves high recall but returns many distractors, while join-aware alternatives often rely on extra assumptions and/or incur high inference overhead. We propose CORE-T, a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. At inference time, DR returns top-K candidates; a single LLM call selects a coherent, joinable subset, and a simple additive adjustment step restores strongly compatible tables. Across Bird, Spider, and MMQA, CORE-T improves table-selection F1 by up to 22.7 points while retrieving up to 42% fewer tables, improving multi-table execution accuracy by up to 5.0 points on Bird and 6.9 points on MMQA, and using 4-5x fewer tokens than LLM-intensive baselines.", "AI": {"tldr": "CORE-T\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u8868\u6587\u672c\u5230SQL\u7684\u514d\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7LLM\u751f\u6210\u8868\u76ee\u7684\u5143\u6570\u636e\u548c\u9884\u8ba1\u7b97\u8868\u517c\u5bb9\u6027\u7f13\u5b58\uff0c\u63d0\u9ad8\u76f8\u5173\u8868\u68c0\u7d22\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u5b9e\u4e2d\u7684\u6587\u672c\u5230SQL\u5de5\u4f5c\u6d41\u901a\u5e38\u9700\u8981\u8fde\u63a5\u591a\u4e2a\u8868\uff0c\u4f46\u5728\u5927\u89c4\u6a21\u5f02\u6784\u8868\u96c6\u5408\u4e2d\u51c6\u786e\u68c0\u7d22\u76f8\u5173\u8868\u6210\u4e3a\u7aef\u5230\u7aef\u6027\u80fd\u7684\u5173\u952e\u74f6\u9888\u3002\u73b0\u6709\u65b9\u6cd5\u4e2d\uff0c\u5bc6\u96c6\u68c0\u7d22\u53ec\u56de\u7387\u9ad8\u4f46\u5305\u542b\u5927\u91cf\u5e72\u6270\u9879\uff0c\u800c\u8fde\u63a5\u611f\u77e5\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u989d\u5916\u5047\u8bbe\u6216\u63a8\u7406\u5f00\u9500\u9ad8\u3002", "method": "CORE-T\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u4f7f\u7528LLM\u4e3a\u6bcf\u4e2a\u8868\u751f\u6210\u76ee\u7684\u5143\u6570\u636e\uff1b2) \u9884\u8ba1\u7b97\u8f7b\u91cf\u7ea7\u7684\u8868\u517c\u5bb9\u6027\u7f13\u5b58\uff1b3) \u63a8\u7406\u65f6\u5148\u7528\u5bc6\u96c6\u68c0\u7d22\u83b7\u53d6top-K\u5019\u9009\u8868\uff0c\u518d\u7528\u5355\u6b21LLM\u8c03\u7528\u9009\u62e9\u8fde\u8d2f\u53ef\u8fde\u63a5\u7684\u8868\u5b50\u96c6\uff0c\u6700\u540e\u901a\u8fc7\u7b80\u5355\u7684\u52a0\u6cd5\u8c03\u6574\u6b65\u9aa4\u6062\u590d\u5f3a\u517c\u5bb9\u8868\u3002", "result": "\u5728Bird\u3001Spider\u548cMMQA\u6570\u636e\u96c6\u4e0a\uff0cCORE-T\u5c06\u8868\u9009\u62e9F1\u5206\u6570\u63d0\u9ad8\u4e86\u6700\u591a22.7\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u68c0\u7d22\u7684\u8868\u6570\u91cf\u51cf\u5c11\u4e86\u6700\u591a42%\u3002\u5728\u591a\u8868\u6267\u884c\u51c6\u786e\u7387\u65b9\u9762\uff0c\u5728Bird\u4e0a\u63d0\u9ad8\u4e86\u6700\u591a5.0\u4e2a\u767e\u5206\u70b9\uff0c\u5728MMQA\u4e0a\u63d0\u9ad8\u4e86\u6700\u591a6.9\u4e2a\u767e\u5206\u70b9\uff0c\u4e14\u6bd4LLM\u5bc6\u96c6\u578b\u57fa\u7ebf\u4f7f\u7528\u7684token\u6570\u91cf\u51cf\u5c11\u4e864-5\u500d\u3002", "conclusion": "CORE-T\u901a\u8fc7\u7ed3\u5408\u5bc6\u96c6\u68c0\u7d22\u7684\u9ad8\u53ec\u56de\u7387\u548cLLM\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u5728\u65e0\u9700\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u8868\u6587\u672c\u5230SQL\u4e2d\u76f8\u5173\u8868\u68c0\u7d22\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2601.11865", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11865", "abs": "https://arxiv.org/abs/2601.11865", "authors": ["Truong Nguyen", "Phi Van Dat", "Ngan Nguyen", "Linh Ngo Van", "Trung Le", "Thanh Hong Nguyen"], "title": "CTPD: Cross Tokenizer Preference Distillation", "comment": "AAAI 2026", "summary": "While knowledge distillation has seen widespread use in pre-training and instruction tuning, its application to aligning language models with human preferences remains underexplored, particularly in the more realistic cross-tokenizer setting. The incompatibility of tokenization schemes between teacher and student models has largely prevented fine-grained, white-box distillation of preference information. To address this gap, we propose Cross-Tokenizer Preference Distillation (CTPD), the first unified framework for transferring human-aligned behavior between models with heterogeneous tokenizers. CTPD introduces three key innovations: (1) Aligned Span Projection, which maps teacher and student tokens to shared character-level spans for precise supervision transfer; (2) a cross-tokenizer adaptation of Token-level Importance Sampling (TIS-DPO) for improved credit assignment; and (3) a Teacher-Anchored Reference, allowing the student to directly leverage the teacher's preferences in a DPO-style objective. Our theoretical analysis grounds CTPD in importance sampling, and experiments across multiple benchmarks confirm its effectiveness, with significant performance gains over existing methods. These results establish CTPD as a practical and general solution for preference distillation across diverse tokenization schemes, opening the door to more accessible and efficient alignment of language models.", "AI": {"tldr": "CTPD\u662f\u9996\u4e2a\u5728\u5f02\u6784\u5206\u8bcd\u5668\u6a21\u578b\u95f4\u8fdb\u884c\u504f\u597d\u84b8\u998f\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u56e0\u5206\u8bcd\u65b9\u6848\u4e0d\u517c\u5bb9\u800c\u65e0\u6cd5\u8fdb\u884c\u7ec6\u7c92\u5ea6\u767d\u76d2\u84b8\u998f\u7684\u95ee\u9898\u3002", "motivation": "\u77e5\u8bc6\u84b8\u998f\u5728\u9884\u8bad\u7ec3\u548c\u6307\u4ee4\u8c03\u4f18\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5728\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u65b9\u9762\u7684\u5e94\u7528\u4ecd\u5f85\u63a2\u7d22\uff0c\u7279\u522b\u662f\u5728\u66f4\u73b0\u5b9e\u7684\u8de8\u5206\u8bcd\u5668\u573a\u666f\u4e2d\u3002\u6559\u5e08\u548c\u5b66\u751f\u6a21\u578b\u5206\u8bcd\u65b9\u6848\u7684\u4e0d\u517c\u5bb9\u6027\u963b\u788d\u4e86\u504f\u597d\u4fe1\u606f\u7684\u7ec6\u7c92\u5ea6\u767d\u76d2\u84b8\u998f\u3002", "method": "\u63d0\u51fa\u4e86\u8de8\u5206\u8bcd\u5668\u504f\u597d\u84b8\u998f(CTPD)\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a1)\u5bf9\u9f50\u8de8\u5ea6\u6295\u5f71\uff0c\u5c06\u6559\u5e08\u548c\u5b66\u751ftoken\u6620\u5c04\u5230\u5171\u4eab\u5b57\u7b26\u7ea7\u8de8\u5ea6\u4ee5\u5b9e\u73b0\u7cbe\u786e\u76d1\u7763\u4f20\u9012\uff1b2)\u8de8\u5206\u8bcd\u5668\u9002\u914d\u7684token\u7ea7\u91cd\u8981\u6027\u91c7\u6837(TIS-DPO)\u6539\u8fdb\u4fe1\u7528\u5206\u914d\uff1b3)\u6559\u5e08\u951a\u5b9a\u53c2\u8003\uff0c\u5141\u8bb8\u5b66\u751f\u5728DPO\u98ce\u683c\u76ee\u6807\u4e2d\u76f4\u63a5\u5229\u7528\u6559\u5e08\u7684\u504f\u597d\u3002", "result": "\u7406\u8bba\u5206\u6790\u5c06CTPD\u5efa\u7acb\u5728\u91cd\u8981\u6027\u91c7\u6837\u57fa\u7840\u4e0a\uff0c\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u5176\u6709\u6548\u6027\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "CTPD\u4e3a\u4e0d\u540c\u5206\u8bcd\u65b9\u6848\u95f4\u7684\u504f\u597d\u84b8\u998f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u66f4\u6613\u8bbf\u95ee\u548c\u9ad8\u6548\u7684\u5bf9\u9f50\u6253\u5f00\u4e86\u5927\u95e8\u3002"}}
{"id": "2601.12038", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12038", "abs": "https://arxiv.org/abs/2601.12038", "authors": ["Beishui Liao"], "title": "Abstract Argumentation with Subargument Relations", "comment": "11 pages", "summary": "Dung's abstract argumentation framework characterises argument acceptability solely via an attack relation, deliberately abstracting from the internal structure of arguments. While this level of abstraction has enabled a rich body of results, it limits the ability to represent structural dependencies that are central in many structured argumentation formalisms, in particular subargument relations. Existing extensions, including bipolar argumentation frameworks, introduce support relations, but these do not capture the asymmetric and constitutive nature of subarguments or their interaction with attacks. In this paper, we study abstract argumentation frameworks enriched with an explicit subargument relation, treated alongside attack as a basic relation. We analyse how subargument relations interact with attacks and examine their impact on fundamental semantic properties. This framework provides a principled abstraction of structural information and clarifies the role of subarguments in abstract acceptability reasoning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5728Dung\u7684\u62bd\u8c61\u8bba\u8fa9\u6846\u67b6\u4e2d\u5f15\u5165\u660e\u786e\u7684\u5b50\u8bba\u70b9\u5173\u7cfb\uff0c\u4f5c\u4e3a\u4e0e\u653b\u51fb\u5173\u7cfb\u5e76\u5217\u7684\u57fa\u672c\u5173\u7cfb\uff0c\u4ee5\u6355\u6349\u7ed3\u6784\u5316\u8bba\u8fa9\u4e2d\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "motivation": "Dung\u7684\u62bd\u8c61\u8bba\u8fa9\u6846\u67b6\u4ec5\u901a\u8fc7\u653b\u51fb\u5173\u7cfb\u6765\u523b\u753b\u8bba\u70b9\u53ef\u63a5\u53d7\u6027\uff0c\u8fd9\u79cd\u62bd\u8c61\u5c42\u6b21\u867d\u7136\u4ea7\u751f\u4e86\u4e30\u5bcc\u7684\u7ed3\u679c\uff0c\u4f46\u9650\u5236\u4e86\u8868\u793a\u7ed3\u6784\u5316\u8bba\u8fa9\u5f62\u5f0f\u4e2d\u6838\u5fc3\u7684\u7ed3\u6784\u4f9d\u8d56\u5173\u7cfb\uff08\u7279\u522b\u662f\u5b50\u8bba\u70b9\u5173\u7cfb\uff09\u7684\u80fd\u529b\u3002\u73b0\u6709\u6269\u5c55\uff08\u5982\u53cc\u6781\u8bba\u8fa9\u6846\u67b6\uff09\u5f15\u5165\u4e86\u652f\u6301\u5173\u7cfb\uff0c\u4f46\u672a\u80fd\u6355\u6349\u5b50\u8bba\u70b9\u7684\u975e\u5bf9\u79f0\u6027\u548c\u6784\u6210\u6027\u672c\u8d28\uff0c\u4e5f\u672a\u5904\u7406\u5b50\u8bba\u70b9\u4e0e\u653b\u51fb\u4e4b\u95f4\u7684\u4ea4\u4e92\u3002", "method": "\u7814\u7a76\u5728\u62bd\u8c61\u8bba\u8fa9\u6846\u67b6\u4e2d\u4e30\u5bcc\u660e\u786e\u7684\u5b50\u8bba\u70b9\u5173\u7cfb\uff0c\u5c06\u5176\u4e0e\u653b\u51fb\u5173\u7cfb\u4e00\u8d77\u4f5c\u4e3a\u57fa\u672c\u5173\u7cfb\u5904\u7406\u3002\u5206\u6790\u5b50\u8bba\u70b9\u5173\u7cfb\u5982\u4f55\u4e0e\u653b\u51fb\u4ea4\u4e92\uff0c\u5e76\u8003\u5bdf\u5b83\u4eec\u5bf9\u57fa\u672c\u8bed\u4e49\u6027\u8d28\u7684\u5f71\u54cd\u3002", "result": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u7ed3\u6784\u4fe1\u606f\u7684\u539f\u7406\u6027\u62bd\u8c61\uff0c\u5e76\u6f84\u6e05\u4e86\u5b50\u8bba\u70b9\u5728\u62bd\u8c61\u53ef\u63a5\u53d7\u6027\u63a8\u7406\u4e2d\u7684\u4f5c\u7528\u3002\u901a\u8fc7\u5c06\u5b50\u8bba\u70b9\u5173\u7cfb\u4f5c\u4e3a\u57fa\u672c\u5173\u7cfb\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u7ed3\u6784\u5316\u8bba\u8fa9\u4e2d\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u660e\u786e\u7684\u5b50\u8bba\u70b9\u5173\u7cfb\u4f5c\u4e3a\u4e0e\u653b\u51fb\u5173\u7cfb\u5e76\u5217\u7684\u57fa\u672c\u5173\u7cfb\uff0c\u53ef\u4ee5\u589e\u5f3a\u62bd\u8c61\u8bba\u8fa9\u6846\u67b6\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u591f\u66f4\u597d\u5730\u8868\u793a\u7ed3\u6784\u5316\u8bba\u8fa9\u4e2d\u7684\u5173\u952e\u4f9d\u8d56\u5173\u7cfb\uff0c\u540c\u65f6\u4fdd\u6301\u62bd\u8c61\u6846\u67b6\u7684\u7406\u8bba\u4f18\u52bf\u3002"}}
{"id": "2601.11866", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11866", "abs": "https://arxiv.org/abs/2601.11866", "authors": ["Kie Shidara", "Preethi Prem", "Jonathan Kim", "Anna Podlasek", "Feng Liu", "Ahmed Alaa", "Danilo Bernardo"], "title": "Advances in LLM Reasoning Enable Flexibility in Clinical Problem-Solving", "comment": "10 pages, 6 figures", "summary": "Large Language Models (LLMs) have achieved high accuracy on medical question-answer (QA) benchmarks, yet their capacity for flexible clinical reasoning has been debated. Here, we asked whether advances in reasoning LLMs improve their cognitive flexibility in clinical reasoning. We assessed reasoning models from the OpenAI, Grok, Gemini, Claude, and DeepSeek families on the medicine abstraction and reasoning corpus (mARC), an adversarial medical QA benchmark which utilizes the Einstellung effect to induce inflexible overreliance on learned heuristic patterns in contexts where they become suboptimal. We found that strong reasoning models avoided Einstellung-based traps more often than weaker reasoning models, achieving human-level performance on mARC. On questions most commonly missed by physicians, the top 5 performing models answered 55% to 70% correctly with high confidence, indicating that these models may be less susceptible than humans to Einstellung effects. Our results indicate that strong reasoning models demonstrate improved flexibility in medical reasoning, achieving performance on par with humans on mARC.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66QA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u4e34\u5e8a\u63a8\u7406\u7684\u7075\u6d3b\u6027\u5b58\u5728\u4e89\u8bae\u3002\u7814\u7a76\u901a\u8fc7mARC\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u591a\u4e2a\u63a8\u7406\u6a21\u578b\uff0c\u53d1\u73b0\u5f3a\u63a8\u7406\u6a21\u578b\u80fd\u66f4\u597d\u5730\u907f\u514dEinstellung\u6548\u5e94\u9677\u9631\uff0c\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u8868\u73b0\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u533b\u5b66QA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u9ad8\u51c6\u786e\u7387\uff0c\u4f46\u5176\u4e34\u5e8a\u63a8\u7406\u7684\u7075\u6d3b\u6027\u4e00\u76f4\u5b58\u5728\u4e89\u8bae\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u5148\u8fdb\u7684\u63a8\u7406LLMs\u662f\u5426\u5728\u4e34\u5e8a\u63a8\u7406\u4e2d\u5c55\u73b0\u51fa\u66f4\u597d\u7684\u8ba4\u77e5\u7075\u6d3b\u6027\uff0c\u7279\u522b\u662f\u80fd\u5426\u907f\u514dEinstellung\u6548\u5e94\u5bfc\u81f4\u7684\u601d\u7ef4\u50f5\u5316\u3002", "method": "\u4f7f\u7528\u533b\u5b66\u62bd\u8c61\u4e0e\u63a8\u7406\u8bed\u6599\u5e93(mARC)\u4f5c\u4e3a\u8bc4\u4f30\u57fa\u51c6\uff0c\u8fd9\u662f\u4e00\u4e2a\u5229\u7528Einstellung\u6548\u5e94\u8bbe\u8ba1\u7684\u5bf9\u6297\u6027\u533b\u5b66QA\u57fa\u51c6\u3002\u8bc4\u4f30\u4e86\u6765\u81eaOpenAI\u3001Grok\u3001Gemini\u3001Claude\u548cDeepSeek\u5bb6\u65cf\u7684\u63a8\u7406\u6a21\u578b\uff0c\u6d4b\u8bd5\u5b83\u4eec\u5728\u4e0d\u540c\u60c5\u5883\u4e0b\u907f\u514d\u8fc7\u5ea6\u4f9d\u8d56\u5b66\u4e60\u5230\u7684\u542f\u53d1\u5f0f\u6a21\u5f0f\u7684\u80fd\u529b\u3002", "result": "\u5f3a\u63a8\u7406\u6a21\u578b\u6bd4\u5f31\u63a8\u7406\u6a21\u578b\u66f4\u9891\u7e41\u5730\u907f\u514d\u4e86\u57fa\u4e8eEinstellung\u7684\u9677\u9631\uff0c\u5728mARC\u4e0a\u8fbe\u5230\u4e86\u4eba\u7c7b\u6c34\u5e73\u7684\u6027\u80fd\u3002\u5728\u533b\u751f\u6700\u5e38\u51fa\u9519\u7684\u95ee\u9898\u4e0a\uff0c\u524d5\u540d\u6a21\u578b\u4ee5\u9ad8\u7f6e\u4fe1\u5ea6\u6b63\u786e\u56de\u7b54\u4e8655%\u523070%\u7684\u95ee\u9898\uff0c\u8868\u660e\u8fd9\u4e9b\u6a21\u578b\u53ef\u80fd\u6bd4\u4eba\u7c7b\u66f4\u4e0d\u5bb9\u6613\u53d7\u5230Einstellung\u6548\u5e94\u7684\u5f71\u54cd\u3002", "conclusion": "\u5f3a\u63a8\u7406\u6a21\u578b\u5728\u533b\u5b66\u63a8\u7406\u4e2d\u5c55\u73b0\u51fa\u6539\u8fdb\u7684\u7075\u6d3b\u6027\uff0c\u5728mARC\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fbe\u5230\u4e86\u4e0e\u4eba\u7c7b\u76f8\u5f53\u7684\u6027\u80fd\u6c34\u5e73\u3002\u8fd9\u8868\u660e\u5148\u8fdb\u7684\u63a8\u7406LLMs\u80fd\u591f\u6709\u6548\u907f\u514d\u4e34\u5e8a\u63a8\u7406\u4e2d\u7684\u8ba4\u77e5\u504f\u89c1\uff0c\u5177\u5907\u8d85\u8d8a\u4f20\u7edf\u533b\u5b66QA\u57fa\u51c6\u6d4b\u8bd5\u6240\u8861\u91cf\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2601.11872", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11872", "abs": "https://arxiv.org/abs/2601.11872", "authors": ["Nguyen Tien Phat", "Ngo Vu Minh", "Linh Van Ngo", "Nguyen Thi Ngoc Diep", "Thien Huu Nguyen"], "title": "GloCTM: Cross-Lingual Topic Modeling via a Global Context Space", "comment": "AAAI 2026", "summary": "Cross-lingual topic modeling seeks to uncover coherent and semantically aligned topics across languages - a task central to multilingual understanding. Yet most existing models learn topics in disjoint, language-specific spaces and rely on alignment mechanisms (e.g., bilingual dictionaries) that often fail to capture deep cross-lingual semantics, resulting in loosely connected topic spaces. Moreover, these approaches often overlook the rich semantic signals embedded in multilingual pretrained representations, further limiting their ability to capture fine-grained alignment. We introduce GloCTM (Global Context Space for Cross-Lingual Topic Model), a novel framework that enforces cross-lingual topic alignment through a unified semantic space spanning the entire model pipeline. GloCTM constructs enriched input representations by expanding bag-of-words with cross-lingual lexical neighborhoods, and infers topic proportions using both local and global encoders, with their latent representations aligned through internal regularization. At the output level, the global topic-word distribution, defined over the combined vocabulary, structurally synchronizes topic meanings across languages. To further ground topics in deep semantic space, GloCTM incorporates a Centered Kernel Alignment (CKA) loss that aligns the latent topic space with multilingual contextual embeddings. Experiments across multiple benchmarks demonstrate that GloCTM significantly improves topic coherence and cross-lingual alignment, outperforming strong baselines.", "AI": {"tldr": "GloCTM\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u8de8\u8bed\u8a00\u4e3b\u9898\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u8bed\u4e49\u7a7a\u95f4\u5f3a\u5236\u8de8\u8bed\u8a00\u4e3b\u9898\u5bf9\u9f50\uff0c\u5229\u7528\u591a\u8bed\u8a00\u9884\u8bad\u7ec3\u8868\u793a\u548c\u8bcd\u6c47\u90bb\u57df\u6269\u5c55\uff0c\u663e\u8457\u63d0\u5347\u4e3b\u9898\u8fde\u8d2f\u6027\u548c\u8de8\u8bed\u8a00\u5bf9\u9f50\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u8de8\u8bed\u8a00\u4e3b\u9898\u6a21\u578b\u901a\u5e38\u5728\u5206\u79bb\u7684\u8bed\u8a00\u7279\u5b9a\u7a7a\u95f4\u4e2d\u5b66\u4e60\u4e3b\u9898\uff0c\u4f9d\u8d56\u53cc\u8bed\u8bcd\u5178\u7b49\u5bf9\u9f50\u673a\u5236\uff0c\u8fd9\u4e9b\u673a\u5236\u5f80\u5f80\u65e0\u6cd5\u6355\u6349\u6df1\u5c42\u7684\u8de8\u8bed\u8a00\u8bed\u4e49\uff0c\u5bfc\u81f4\u4e3b\u9898\u7a7a\u95f4\u677e\u6563\u8fde\u63a5\u3002\u540c\u65f6\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5ffd\u89c6\u4e86\u591a\u8bed\u8a00\u9884\u8bad\u7ec3\u8868\u793a\u4e2d\u4e30\u5bcc\u7684\u8bed\u4e49\u4fe1\u53f7\uff0c\u9650\u5236\u4e86\u7ec6\u7c92\u5ea6\u5bf9\u9f50\u80fd\u529b\u3002", "method": "GloCTM\u901a\u8fc7\u5728\u6574\u4e2a\u6a21\u578b\u6d41\u7a0b\u4e2d\u6784\u5efa\u7edf\u4e00\u7684\u8bed\u4e49\u7a7a\u95f4\u6765\u5f3a\u5236\u8de8\u8bed\u8a00\u4e3b\u9898\u5bf9\u9f50\u3002\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u901a\u8fc7\u8de8\u8bed\u8a00\u8bcd\u6c47\u90bb\u57df\u6269\u5c55\u8bcd\u888b\u8868\u793a\uff1b2\uff09\u4f7f\u7528\u5c40\u90e8\u548c\u5168\u5c40\u7f16\u7801\u5668\u63a8\u65ad\u4e3b\u9898\u6bd4\u4f8b\uff0c\u5e76\u901a\u8fc7\u5185\u90e8\u6b63\u5219\u5316\u5bf9\u9f50\u5176\u6f5c\u5728\u8868\u793a\uff1b3\uff09\u5728\u8f93\u51fa\u5c42\u5b9a\u4e49\u5728\u7ec4\u5408\u8bcd\u6c47\u4e0a\u7684\u5168\u5c40\u4e3b\u9898-\u8bcd\u5206\u5e03\uff0c\u7ed3\u6784\u4e0a\u540c\u6b65\u8de8\u8bed\u8a00\u4e3b\u9898\u542b\u4e49\uff1b4\uff09\u5f15\u5165\u4e2d\u5fc3\u6838\u5bf9\u9f50\u635f\u5931\uff0c\u5c06\u6f5c\u5728\u4e3b\u9898\u7a7a\u95f4\u4e0e\u591a\u8bed\u8a00\u4e0a\u4e0b\u6587\u5d4c\u5165\u5bf9\u9f50\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGloCTM\u663e\u8457\u63d0\u9ad8\u4e86\u4e3b\u9898\u8fde\u8d2f\u6027\u548c\u8de8\u8bed\u8a00\u5bf9\u9f50\u6548\u679c\uff0c\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "GloCTM\u901a\u8fc7\u7edf\u4e00\u7684\u8bed\u4e49\u7a7a\u95f4\u548c\u6df1\u5ea6\u8bed\u4e49\u5bf9\u9f50\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u8bed\u8a00\u4e3b\u9898\u5efa\u6a21\u4e2d\u7684\u5bf9\u9f50\u95ee\u9898\uff0c\u4e3a\u591a\u8bed\u8a00\u7406\u89e3\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u6846\u67b6\u3002"}}
{"id": "2601.12126", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12126", "abs": "https://arxiv.org/abs/2601.12126", "authors": ["Guocun Wang", "Kenkun Liu", "Jing Lin", "Guorui Song", "Jian Li", "Xiaoguang Han"], "title": "UniMo: Unified Motion Generation and Understanding with Chain of Thought", "comment": null, "summary": "Existing 3D human motion generation and understanding methods often exhibit limited interpretability, restricting effective mutual enhancement between these inherently related tasks. While current unified frameworks based on large language models (LLMs) leverage linguistic priors, they frequently encounter challenges in semantic alignment and task coherence. Moreover, the next-token prediction paradigm in LLMs is ill-suited for motion sequences, causing cumulative prediction errors. To address these limitations, we propose UniMo, a novel framework that integrates motion-language information and interpretable chain of thought (CoT) reasoning into the LLM via supervised fine-tuning (SFT). We further introduce reinforcement learning with Group Relative Policy Optimization (GRPO) as a post-training strategy that optimizes over groups of tokens to enforce structural correctness and semantic alignment, mitigating cumulative errors in motion token prediction. Extensive experiments demonstrate that UniMo significantly outperforms existing unified and task-specific models, achieving state-of-the-art performance in both motion generation and understanding.", "AI": {"tldr": "UniMo\u6846\u67b6\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u6574\u5408\u8fd0\u52a8-\u8bed\u8a00\u4fe1\u606f\u4e0e\u53ef\u89e3\u91ca\u601d\u7ef4\u94fe\uff0c\u89e3\u51b3\u73b0\u67093D\u4eba\u4f53\u8fd0\u52a8\u751f\u6210\u4e0e\u7406\u89e3\u65b9\u6cd5\u5728\u8bed\u4e49\u5bf9\u9f50\u3001\u4efb\u52a1\u4e00\u81f4\u6027\u548c\u7d2f\u79ef\u9884\u6d4b\u8bef\u5dee\u65b9\u9762\u7684\u9650\u5236\uff0c\u5728\u4e24\u9879\u4efb\u52a1\u4e0a\u5747\u53d6\u5f97SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u67093D\u4eba\u4f53\u8fd0\u52a8\u751f\u6210\u4e0e\u7406\u89e3\u65b9\u6cd5\u53ef\u89e3\u91ca\u6027\u6709\u9650\uff0c\u9650\u5236\u4e86\u8fd9\u4e24\u4e2a\u5185\u5728\u76f8\u5173\u4efb\u52a1\u4e4b\u95f4\u7684\u6709\u6548\u76f8\u4e92\u589e\u5f3a\u3002\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7edf\u4e00\u6846\u67b6\u867d\u7136\u5229\u7528\u4e86\u8bed\u8a00\u5148\u9a8c\uff0c\u4f46\u7ecf\u5e38\u9762\u4e34\u8bed\u4e49\u5bf9\u9f50\u548c\u4efb\u52a1\u4e00\u81f4\u6027\u7684\u6311\u6218\u3002\u6b64\u5916\uff0cLLM\u4e2d\u7684\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\u8303\u5f0f\u4e0d\u9002\u5408\u8fd0\u52a8\u5e8f\u5217\uff0c\u4f1a\u5bfc\u81f4\u7d2f\u79ef\u9884\u6d4b\u8bef\u5dee\u3002", "method": "\u63d0\u51faUniMo\u6846\u67b6\uff1a1) \u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u5c06\u8fd0\u52a8-\u8bed\u8a00\u4fe1\u606f\u548c\u53ef\u89e3\u91ca\u601d\u7ef4\u94fe\u63a8\u7406\u6574\u5408\u5230LLM\u4e2d\uff1b2) \u5f15\u5165\u5f3a\u5316\u5b66\u4e60\u4e0e\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u4f5c\u4e3a\u540e\u8bad\u7ec3\u7b56\u7565\uff0c\u901a\u8fc7\u4f18\u5316token\u7ec4\u6765\u5f3a\u5236\u7ed3\u6784\u6b63\u786e\u6027\u548c\u8bed\u4e49\u5bf9\u9f50\uff0c\u51cf\u8f7b\u8fd0\u52a8token\u9884\u6d4b\u4e2d\u7684\u7d2f\u79ef\u8bef\u5dee\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cUniMo\u5728\u8fd0\u52a8\u751f\u6210\u548c\u7406\u89e3\u4e24\u65b9\u9762\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u7edf\u4e00\u6846\u67b6\u548c\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "UniMo\u901a\u8fc7\u6574\u5408\u8fd0\u52a8-\u8bed\u8a00\u4fe1\u606f\u3001\u53ef\u89e3\u91ca\u601d\u7ef4\u94fe\u63a8\u7406\u4ee5\u53ca\u521b\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e863D\u4eba\u4f53\u8fd0\u52a8\u751f\u6210\u4e0e\u7406\u89e3\u4e2d\u7684\u8bed\u4e49\u5bf9\u9f50\u3001\u4efb\u52a1\u4e00\u81f4\u6027\u548c\u7d2f\u79ef\u8bef\u5dee\u95ee\u9898\uff0c\u4e3a\u8fd9\u4e24\u4e2a\u76f8\u5173\u4efb\u52a1\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u589e\u5f3a\u6846\u67b6\u3002"}}
{"id": "2601.14123", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.14123", "abs": "https://arxiv.org/abs/2601.14123", "authors": ["Sofia Bennani", "Charles Moslonka"], "title": "A Systematic Analysis of Chunking Strategies for Reliable Question Answering", "comment": "3 pages, 2 figures, 1 table, pre-print", "summary": "We study how document chunking choices impact the reliability of Retrieval-Augmented Generation (RAG) systems in industry. While practice often relies on heuristics, our end-to-end evaluation on Natural Questions systematically varies chunking method (token, sentence, semantic, code), chunk size, overlap, and context length. We use a standard industrial setup: SPLADE retrieval and a Mistral-8B generator. We derive actionable lessons for cost-efficient deployment: (i) overlap provides no measurable benefit and increases indexing cost; (ii) sentence chunking is the most cost-effective method, matching semantic chunking up to ~5k tokens; (iii) a \"context cliff\" reduces quality beyond ~2.5k tokens; and (iv) optimal context depends on the goal (semantic quality peaks at small contexts; exact match at larger ones).", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u6587\u6863\u5206\u5757\u7b56\u7565\u5bf9RAG\u7cfb\u7edf\u53ef\u9760\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u53e5\u5b50\u5206\u5757\u662f\u6700\u5177\u6210\u672c\u6548\u76ca\u7684\u65b9\u6cd5\uff0c\u91cd\u53e0\u5206\u5757\u65e0\u663e\u8457\u76ca\u5904\uff0c\u4e14\u5b58\u5728\"\u4e0a\u4e0b\u6587\u60ac\u5d16\"\u73b0\u8c61", "motivation": "\u5de5\u4e1a\u5b9e\u8df5\u4e2dRAG\u7cfb\u7edf\u901a\u5e38\u4f9d\u8d56\u542f\u53d1\u5f0f\u65b9\u6cd5\u8fdb\u884c\u6587\u6863\u5206\u5757\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5206\u5757\u9009\u62e9\u5982\u4f55\u5f71\u54cd\u7cfb\u7edf\u53ef\u9760\u6027\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u6210\u672c\u9ad8\u6548\u7684\u90e8\u7f72\u63d0\u4f9b\u5b9e\u8bc1\u6307\u5bfc\u3002", "method": "\u5728Natural Questions\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7aef\u5230\u7aef\u8bc4\u4f30\uff0c\u7cfb\u7edf\u6027\u5730\u53d8\u5316\u5206\u5757\u65b9\u6cd5\uff08token\u3001\u53e5\u5b50\u3001\u8bed\u4e49\u3001\u4ee3\u7801\uff09\u3001\u5206\u5757\u5927\u5c0f\u3001\u91cd\u53e0\u548c\u4e0a\u4e0b\u6587\u957f\u5ea6\u3002\u91c7\u7528\u6807\u51c6\u5de5\u4e1a\u8bbe\u7f6e\uff1aSPLADE\u68c0\u7d22\u548cMistral-8B\u751f\u6210\u5668\u3002", "result": "\u53d1\u73b0\u56db\u4e2a\u5173\u952e\u7ed3\u8bba\uff1a(1) \u91cd\u53e0\u5206\u5757\u65e0\u663e\u8457\u76ca\u5904\u4e14\u589e\u52a0\u7d22\u5f15\u6210\u672c\uff1b(2) \u53e5\u5b50\u5206\u5757\u662f\u6700\u5177\u6210\u672c\u6548\u76ca\u7684\u65b9\u6cd5\uff0c\u5728~5k tokens\u5185\u4e0e\u8bed\u4e49\u5206\u5757\u6548\u679c\u76f8\u5f53\uff1b(3) \u5b58\u5728\"\u4e0a\u4e0b\u6587\u60ac\u5d16\"\u73b0\u8c61\uff0c\u8d85\u8fc7~2.5k tokens\u540e\u8d28\u91cf\u4e0b\u964d\uff1b(4) \u6700\u4f18\u4e0a\u4e0b\u6587\u957f\u5ea6\u53d6\u51b3\u4e8e\u76ee\u6807\uff1a\u8bed\u4e49\u8d28\u91cf\u5728\u5c0f\u4e0a\u4e0b\u6587\u4e2d\u8fbe\u5230\u5cf0\u503c\uff0c\u7cbe\u786e\u5339\u914d\u9700\u8981\u66f4\u5927\u7684\u4e0a\u4e0b\u6587\u3002", "conclusion": "\u4e3aRAG\u7cfb\u7edf\u7684\u6210\u672c\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\uff1a\u63a8\u8350\u4f7f\u7528\u53e5\u5b50\u5206\u5757\u800c\u975e\u91cd\u53e0\u5206\u5757\uff0c\u6ce8\u610f\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\"\u60ac\u5d16\u6548\u5e94\"\uff0c\u5e76\u6839\u636e\u5177\u4f53\u76ee\u6807\uff08\u8bed\u4e49\u8d28\u91cfvs\u7cbe\u786e\u5339\u914d\uff09\u9009\u62e9\u9002\u5f53\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u3002"}}
{"id": "2601.11886", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11886", "abs": "https://arxiv.org/abs/2601.11886", "authors": ["Kaijie Mo", "Siddhartha Venkatayogi", "Chantal Shaib", "Ramez Kouzy", "Wei Xu", "Byron C. Wallace", "Junyi Jessy Li"], "title": "Faithfulness vs. Safety: Evaluating LLM Behavior Under Counterfactual Medical Evidence", "comment": "26 pages", "summary": "In high-stakes domains like medicine, it may be generally desirable for models to faithfully adhere to the context provided. But what happens if the context does not align with model priors or safety protocols? In this paper, we investigate how LLMs behave and reason when presented with counterfactual or even adversarial medical evidence. We first construct MedCounterFact, a counterfactual medical QA dataset that requires the models to answer clinical comparison questions (i.e., judge the efficacy of certain treatments, with evidence consisting of randomized controlled trials provided as context). In MedCounterFact, real-world medical interventions within the questions and evidence are systematically replaced with four types of counterfactual stimuli, ranging from unknown words to toxic substances. Our evaluation across multiple frontier LLMs on MedCounterFact reveals that in the presence of counterfactual evidence, existing models overwhelmingly accept such \"evidence\" at face value even when it is dangerous or implausible, and provide confident and uncaveated answers. While it may be prudent to draw a boundary between faithfulness and safety, our findings reveal that there exists no such boundary yet.", "AI": {"tldr": "\u7814\u7a76\u6784\u5efa\u4e86MedCounterFact\u53cd\u4e8b\u5b9e\u533b\u5b66QA\u6570\u636e\u96c6\uff0c\u8bc4\u4f30LLMs\u5728\u9762\u5bf9\u53cd\u4e8b\u5b9e\u533b\u5b66\u8bc1\u636e\u65f6\u7684\u884c\u4e3a\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u503e\u5411\u4e8e\u4e0d\u52a0\u6279\u5224\u5730\u63a5\u53d7\u5371\u9669\u6216\u4e0d\u5408\u7406\u7684\u8bc1\u636e\u3002", "motivation": "\u5728\u533b\u5b66\u7b49\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u6a21\u578b\u5e94\u5fe0\u5b9e\u9075\u5faa\u4e0a\u4e0b\u6587\uff0c\u4f46\u5f53\u4e0a\u4e0b\u6587\u4e0e\u6a21\u578b\u5148\u9a8c\u6216\u5b89\u5168\u534f\u8bae\u4e0d\u4e00\u81f4\u65f6\uff0c\u9700\u8981\u7814\u7a76LLMs\u7684\u884c\u4e3a\u548c\u63a8\u7406\u65b9\u5f0f\uff0c\u7279\u522b\u662f\u5728\u9762\u5bf9\u53cd\u4e8b\u5b9e\u6216\u5bf9\u6297\u6027\u533b\u5b66\u8bc1\u636e\u65f6\u3002", "method": "\u6784\u5efaMedCounterFact\u53cd\u4e8b\u5b9e\u533b\u5b66QA\u6570\u636e\u96c6\uff0c\u5305\u542b\u4e34\u5e8a\u6bd4\u8f83\u95ee\u9898\uff08\u8bc4\u4f30\u6cbb\u7597\u6548\u679c\uff09\uff0c\u5c06\u771f\u5b9e\u533b\u5b66\u5e72\u9884\u7cfb\u7edf\u6027\u5730\u66ff\u6362\u4e3a\u56db\u79cd\u53cd\u4e8b\u5b9e\u523a\u6fc0\uff08\u4ece\u672a\u77e5\u8bcd\u6c47\u5230\u6709\u6bd2\u7269\u8d28\uff09\uff0c\u5e76\u5728\u591a\u4e2a\u524d\u6cbfLLMs\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u9762\u5bf9\u53cd\u4e8b\u5b9e\u8bc1\u636e\u65f6\uff0c\u73b0\u6709\u6a21\u578b\u503e\u5411\u4e8e\u4e0d\u52a0\u6279\u5224\u5730\u63a5\u53d7\u8fd9\u4e9b\u8bc1\u636e\uff08\u5373\u4f7f\u5371\u9669\u6216\u4e0d\u5408\u7406\uff09\uff0c\u5e76\u63d0\u4f9b\u81ea\u4fe1\u4e14\u65e0\u4fdd\u7559\u7684\u7b54\u6848\uff0c\u8868\u660e\u76ee\u524d\u6a21\u578b\u5728\u5fe0\u5b9e\u6027\u4e0e\u5b89\u5168\u6027\u4e4b\u95f4\u7f3a\u4e4f\u660e\u786e\u8fb9\u754c\u3002", "conclusion": "\u867d\u7136\u7406\u8bba\u4e0a\u5e94\u5728\u5fe0\u5b9e\u6027\u4e0e\u5b89\u5168\u6027\u4e4b\u95f4\u5212\u5b9a\u754c\u9650\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5c1a\u672a\u5efa\u7acb\u8fd9\u6837\u7684\u8fb9\u754c\uff0c\u8fd9\u5bf9\u9ad8\u98ce\u9669\u9886\u57df\u5e94\u7528\u63d0\u51fa\u4e86\u91cd\u8981\u8b66\u793a\u3002"}}
{"id": "2601.12138", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12138", "abs": "https://arxiv.org/abs/2601.12138", "authors": ["Abhishek Kumar", "Riya Tapwal", "Carsten Maple"], "title": "DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants", "comment": null, "summary": "Large Language Models (LLMs) are increasingly integrated into vehicle-based digital assistants, where unsafe, ambiguous, or legally incorrect responses can lead to serious safety, ethical, and regulatory consequences. Despite growing interest in LLM safety, existing taxonomies and evaluation frameworks remain largely general-purpose and fail to capture the domain-specific risks inherent to real-world driving scenarios. In this paper, we introduce DriveSafe, a hierarchical, four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants. The taxonomy comprises 129 fine-grained atomic risk categories spanning technical, legal, societal, and ethical dimensions, grounded in real-world driving regulations and safety principles and reviewed by domain experts. To validate the safety relevance and realism of the constructed prompts, we evaluate their refusal behavior across six widely deployed LLMs. Our analysis shows that the evaluated models often fail to appropriately refuse unsafe or non-compliant driving-related queries, underscoring the limitations of general-purpose safety alignment in driving contexts.", "AI": {"tldr": "DriveSafe\uff1a\u9488\u5bf9LLM\u9a7e\u9a76\u52a9\u624b\u7684\u56db\u5c42\u6b21\u98ce\u9669\u5206\u7c7b\u6cd5\uff0c\u5305\u542b129\u4e2a\u7ec6\u7c92\u5ea6\u98ce\u9669\u7c7b\u522b\uff0c\u8bc4\u4f30\u663e\u793a\u73b0\u6709\u6a21\u578b\u5728\u9a7e\u9a76\u573a\u666f\u4e2d\u5b89\u5168\u62d2\u7edd\u80fd\u529b\u4e0d\u8db3", "motivation": "LLM\u8d8a\u6765\u8d8a\u591a\u5730\u96c6\u6210\u5230\u8f66\u8f7d\u6570\u5b57\u52a9\u624b\u4e2d\uff0c\u4f46\u4e0d\u5b89\u5168\u3001\u6a21\u7cca\u6216\u6cd5\u5f8b\u9519\u8bef\u7684\u54cd\u5e94\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u7684\u5b89\u5168\u3001\u4f26\u7406\u548c\u76d1\u7ba1\u540e\u679c\u3002\u73b0\u6709\u98ce\u9669\u8bc4\u4f30\u5206\u7c7b\u6cd5\u591a\u4e3a\u901a\u7528\u578b\uff0c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u9a7e\u9a76\u573a\u666f\u4e2d\u7684\u9886\u57df\u7279\u5b9a\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86DriveSafe\u2014\u2014\u4e00\u4e2a\u5206\u5c42\u7684\u56db\u5c42\u6b21\u98ce\u9669\u5206\u7c7b\u6cd5\uff0c\u5305\u542b129\u4e2a\u7ec6\u7c92\u5ea6\u539f\u5b50\u98ce\u9669\u7c7b\u522b\uff0c\u6db5\u76d6\u6280\u672f\u3001\u6cd5\u5f8b\u3001\u793e\u4f1a\u548c\u4f26\u7406\u7ef4\u5ea6\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u771f\u5b9e\u9a7e\u9a76\u6cd5\u89c4\u548c\u5b89\u5168\u539f\u5219\u6784\u5efa\uff0c\u5e76\u7531\u9886\u57df\u4e13\u5bb6\u8bc4\u5ba1\u3002\u901a\u8fc7\u8bc4\u4f30\u516d\u4e2a\u5e7f\u6cdb\u90e8\u7f72\u7684LLM\u5728\u6784\u5efa\u63d0\u793a\u4e0a\u7684\u62d2\u7edd\u884c\u4e3a\u6765\u9a8c\u8bc1\u5b89\u5168\u76f8\u5173\u6027\u548c\u771f\u5b9e\u6027\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u88ab\u6d4b\u8bd5\u7684\u6a21\u578b\u7ecf\u5e38\u65e0\u6cd5\u9002\u5f53\u62d2\u7edd\u4e0d\u5b89\u5168\u6216\u4e0d\u5408\u89c4\u7684\u9a7e\u9a76\u76f8\u5173\u67e5\u8be2\uff0c\u7a81\u663e\u4e86\u901a\u7528\u5b89\u5168\u5bf9\u9f50\u5728\u9a7e\u9a76\u4e0a\u4e0b\u6587\u4e2d\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u9700\u8981\u9488\u5bf9\u9a7e\u9a76\u9886\u57df\u7684\u7279\u5b9a\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\uff0c\u73b0\u6709LLM\u5b89\u5168\u5bf9\u9f50\u5728\u9a7e\u9a76\u573a\u666f\u4e2d\u4e0d\u8db3\uff0cDriveSafe\u5206\u7c7b\u6cd5\u4e3a\u7cfb\u7edf\u8bc4\u4f30LLM\u9a7e\u9a76\u52a9\u624b\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.11908", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11908", "abs": "https://arxiv.org/abs/2601.11908", "authors": ["Byeongjin Kim", "Gyuwan Kim", "Seo Yeon Park"], "title": "PPA-Plan: Proactive Pitfall Avoidance for Reliable Planning in Long-Context LLM Reasoning", "comment": "23 pages, 6 figures", "summary": "Large language models (LLMs) struggle with reasoning over long contexts where relevant information is sparsely distributed. Although plan-and-execute frameworks mitigate this by decomposing tasks into planning and execution, their effectiveness is often limited by unreliable plan generation due to dependence on surface-level cues. Consequently, plans may be based on incorrect assumptions, and once a plan is formed, identifying what went wrong and revising it reliably becomes difficult, limiting the effectiveness of reactive refinement. To address this limitation, we propose PPA-Plan, a proactive planning strategy for long-context reasoning that focuses on preventing such failures before plan generation. PPA-Plan identifies potential logical pitfalls and false assumptions, formulates them as negative constraints, and conditions plan generation on explicitly avoiding these constraints. Experiments on long-context QA benchmarks show that executing plans generated by PPA-Plan consistently outperforms existing plan-and-execute methods and direct prompting.", "AI": {"tldr": "PPA-Plan\u662f\u4e00\u79cd\u9488\u5bf9\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u7684\u4e3b\u52a8\u89c4\u5212\u7b56\u7565\uff0c\u901a\u8fc7\u8bc6\u522b\u6f5c\u5728\u903b\u8f91\u9677\u9631\u548c\u9519\u8bef\u5047\u8bbe\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u8d1f\u9762\u7ea6\u675f\uff0c\u5e76\u5728\u89c4\u5212\u751f\u6210\u65f6\u660e\u786e\u907f\u514d\u8fd9\u4e9b\u7ea6\u675f\uff0c\u4ece\u800c\u9884\u9632\u89c4\u5212\u5931\u8d25\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u5b58\u5728\u56f0\u96be\uff0c\u7279\u522b\u662f\u5f53\u76f8\u5173\u4fe1\u606f\u7a00\u758f\u5206\u5e03\u65f6\u3002\u73b0\u6709\u7684\u89c4\u5212-\u6267\u884c\u6846\u67b6\u56e0\u4f9d\u8d56\u8868\u5c42\u7ebf\u7d22\u800c\u5bfc\u81f4\u89c4\u5212\u751f\u6210\u4e0d\u53ef\u9760\uff0c\u89c4\u5212\u53ef\u80fd\u57fa\u4e8e\u9519\u8bef\u5047\u8bbe\uff0c\u4e14\u4e00\u65e6\u5f62\u6210\u89c4\u5212\u540e\u96be\u4ee5\u8bc6\u522b\u95ee\u9898\u5e76\u8fdb\u884c\u53ef\u9760\u4fee\u8ba2\u3002", "method": "PPA-Plan\u91c7\u7528\u4e3b\u52a8\u89c4\u5212\u7b56\u7565\uff1a1) \u8bc6\u522b\u6f5c\u5728\u903b\u8f91\u9677\u9631\u548c\u9519\u8bef\u5047\u8bbe\uff1b2) \u5c06\u5176\u8868\u8ff0\u4e3a\u8d1f\u9762\u7ea6\u675f\uff1b3) \u5728\u89c4\u5212\u751f\u6210\u65f6\u660e\u786e\u907f\u514d\u8fd9\u4e9b\u7ea6\u675f\u3002\u8fd9\u79cd\u65b9\u6cd5\u5728\u89c4\u5212\u751f\u6210\u524d\u9884\u9632\u5931\u8d25\uff0c\u800c\u975e\u4e8b\u540e\u53cd\u5e94\u6027\u4fee\u6b63\u3002", "result": "\u5728\u957f\u4e0a\u4e0b\u6587QA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6267\u884cPPA-Plan\u751f\u6210\u7684\u89c4\u5212\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u7684\u89c4\u5212-\u6267\u884c\u65b9\u6cd5\u548c\u76f4\u63a5\u63d0\u793a\u65b9\u6cd5\u3002", "conclusion": "PPA-Plan\u901a\u8fc7\u4e3b\u52a8\u8bc6\u522b\u548c\u907f\u514d\u6f5c\u5728\u903b\u8f91\u9677\u9631\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u89c4\u5212-\u6267\u884c\u6846\u67b6\u7684\u53ef\u9760\u6027\u548c\u6709\u6548\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u89c4\u5212\u751f\u6210\u4e0d\u53ef\u9760\u548c\u4fee\u8ba2\u56f0\u96be\u7684\u95ee\u9898\u3002"}}
{"id": "2601.12141", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12141", "abs": "https://arxiv.org/abs/2601.12141", "authors": ["Yuliia Suprun", "Khen Elimelech", "Lydia E. Kavraki", "Moshe Y. Vardi"], "title": "TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals", "comment": null, "summary": "Task planning with temporally extended goals (TEGs) is a critical challenge in AI and robotics, enabling agents to achieve complex sequences of objectives over time rather than addressing isolated, immediate tasks. Linear Temporal Logic on finite traces (LTLf ) provides a robust formalism for encoding these temporal goals. Traditional LTLf task planning approaches often transform the temporal planning problem into a classical planning problem with reachability goals, which are then solved using off-the-shelf planners. However, these methods often lack informed heuristics to provide a guided search for temporal goals. We introduce TIDE (Trace-Informed Depth-first Exploration), a novel approach that addresses this limitation by decomposing a temporal problem into a sequence of smaller, manageable reach-avoid sub-problems, each solvable using an off-the-shelf planner. TIDE identifies and prioritizes promising automaton traces within the domain graph, using cost-driven heuristics to guide exploration. Its adaptive backtracking mechanism systematically recovers from failed plans by recalculating costs and penalizing infeasible transitions, ensuring completeness and efficiency. Experimental results demonstrate that TIDE achieves promising performance and is a valuable addition to the portfolio of planning methods for temporally extended goals.", "AI": {"tldr": "TIDE\u662f\u4e00\u79cd\u7528\u4e8e\u65f6\u5e8f\u6269\u5c55\u76ee\u6807\u89c4\u5212\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u65f6\u5e8f\u95ee\u9898\u5206\u89e3\u4e3a\u53ef\u7ba1\u7406\u7684\u5b50\u95ee\u9898\uff0c\u5229\u7528\u6210\u672c\u9a71\u52a8\u542f\u53d1\u5f0f\u548c\u81ea\u9002\u5e94\u56de\u6eaf\u673a\u5236\u63d0\u9ad8\u89c4\u5212\u6548\u7387\u3002", "motivation": "\u4f20\u7edfLTLf\u4efb\u52a1\u89c4\u5212\u65b9\u6cd5\u5c06\u65f6\u5e8f\u89c4\u5212\u95ee\u9898\u8f6c\u5316\u4e3a\u7ecf\u5178\u89c4\u5212\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u65f6\u5e8f\u76ee\u6807\u7684\u542f\u53d1\u5f0f\u5f15\u5bfc\u641c\u7d22\uff0c\u5bfc\u81f4\u6548\u7387\u53d7\u9650\u3002", "method": "TIDE\u5c06\u65f6\u5e8f\u95ee\u9898\u5206\u89e3\u4e3a\u4e00\u7cfb\u5217\u53ef\u8fbe-\u89c4\u907f\u5b50\u95ee\u9898\uff0c\u5229\u7528\u6210\u672c\u9a71\u52a8\u542f\u53d1\u5f0f\u8bc6\u522b\u548c\u4f18\u5148\u5904\u7406\u6709\u524d\u666f\u7684\u81ea\u52a8\u673a\u8f68\u8ff9\uff0c\u5e76\u91c7\u7528\u81ea\u9002\u5e94\u56de\u6eaf\u673a\u5236\u4ece\u5931\u8d25\u8ba1\u5212\u4e2d\u6062\u590d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eTIDE\u5b9e\u73b0\u4e86\u6709\u524d\u666f\u7684\u6027\u80fd\uff0c\u662f\u65f6\u5e8f\u6269\u5c55\u76ee\u6807\u89c4\u5212\u65b9\u6cd5\u7ec4\u5408\u4e2d\u7684\u6709\u4ef7\u503c\u8865\u5145\u3002", "conclusion": "TIDE\u901a\u8fc7\u5206\u89e3\u7b56\u7565\u3001\u542f\u53d1\u5f0f\u5f15\u5bfc\u548c\u81ea\u9002\u5e94\u56de\u6eaf\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfLTLf\u89c4\u5212\u4e2d\u7f3a\u4e4f\u65f6\u5e8f\u76ee\u6807\u542f\u53d1\u5f0f\u5f15\u5bfc\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u89c4\u5212\u6548\u7387\u548c\u5b8c\u5907\u6027\u3002"}}
{"id": "2601.11913", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11913", "abs": "https://arxiv.org/abs/2601.11913", "authors": ["Yichen Jiang", "Peng Ye", "Jiakang Yuan", "Chongjun Tu", "Lei Bai", "Tao Chen"], "title": "LSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent System for Long-Context Understanding", "comment": "12 pages, 5 figures", "summary": "Effectively processing long contexts remains a fundamental yet unsolved challenge for large language models (LLMs). Existing single-LLM-based methods primarily reduce the context window or optimize the attention mechanism, but they often encounter additional computational costs or constrained expanded context length. While multi-agent-based frameworks can mitigate these limitations, they remain susceptible to the accumulation of errors and the propagation of hallucinations. In this work, we draw inspiration from the Long Short-Term Memory (LSTM) architecture to design a Multi-Agent System called LSTM-MAS, emulating LSTM's hierarchical information flow and gated memory mechanisms for long-context understanding. Specifically, LSTM-MAS organizes agents in a chained architecture, where each node comprises a worker agent for segment-level comprehension, a filter agent for redundancy reduction, a judge agent for continuous error detection, and a manager agent for globally regulates information propagation and retention, analogous to LSTM and its input gate, forget gate, constant error carousel unit, and output gate. These novel designs enable controlled information transfer and selective long-term dependency modeling across textual segments, which can effectively avoid error accumulation and hallucination propagation. We conducted an extensive evaluation of our method. Compared with the previous best multi-agent approach, CoA, our model achieves improvements of 40.93%, 43.70%,121.57% and 33.12%, on NarrativeQA, Qasper, HotpotQA, and MuSiQue, respectively.", "AI": {"tldr": "\u63d0\u51faLSTM-MAS\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u6a21\u62dfLSTM\u67b6\u6784\u7684\u5c42\u6b21\u4fe1\u606f\u6d41\u548c\u95e8\u63a7\u8bb0\u5fc6\u673a\u5236\u6765\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u7684\u95ee\u9898\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6027\u80fd", "motivation": "\u73b0\u6709\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u7684\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u5355LLM\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u51cf\u5c11\u4e0a\u4e0b\u6587\u7a97\u53e3\u6216\u4f18\u5316\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5bfc\u81f4\u989d\u5916\u8ba1\u7b97\u6210\u672c\u6216\u53d7\u9650\u7684\u6269\u5c55\u4e0a\u4e0b\u6587\u957f\u5ea6\uff1b\u591a\u667a\u80fd\u4f53\u6846\u67b6\u867d\u7136\u80fd\u7f13\u89e3\u8fd9\u4e9b\u9650\u5236\uff0c\u4f46\u4ecd\u6613\u53d7\u9519\u8bef\u7d2f\u79ef\u548c\u5e7b\u89c9\u4f20\u64ad\u7684\u5f71\u54cd", "method": "\u8bbe\u8ba1LSTM-MAS\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u6a21\u62dfLSTM\u67b6\u6784\u7684\u5c42\u6b21\u4fe1\u606f\u6d41\u548c\u95e8\u63a7\u8bb0\u5fc6\u673a\u5236\u3002\u7cfb\u7edf\u91c7\u7528\u94fe\u5f0f\u67b6\u6784\u7ec4\u7ec7\u667a\u80fd\u4f53\uff0c\u6bcf\u4e2a\u8282\u70b9\u5305\u542b\uff1a\u5de5\u4f5c\u667a\u80fd\u4f53\uff08\u7528\u4e8e\u7247\u6bb5\u7ea7\u7406\u89e3\uff09\u3001\u8fc7\u6ee4\u667a\u80fd\u4f53\uff08\u7528\u4e8e\u5197\u4f59\u51cf\u5c11\uff09\u3001\u5224\u65ad\u667a\u80fd\u4f53\uff08\u7528\u4e8e\u6301\u7eed\u9519\u8bef\u68c0\u6d4b\uff09\u548c\u7ba1\u7406\u667a\u80fd\u4f53\uff08\u7528\u4e8e\u5168\u5c40\u8c03\u8282\u4fe1\u606f\u4f20\u64ad\u548c\u4fdd\u7559\uff09\uff0c\u5206\u522b\u5bf9\u5e94LSTM\u7684\u8f93\u5165\u95e8\u3001\u9057\u5fd8\u95e8\u3001\u6052\u5b9a\u8bef\u5dee\u5faa\u73af\u5355\u5143\u548c\u8f93\u51fa\u95e8", "result": "\u76f8\u6bd4\u4e4b\u524d\u6700\u4f73\u7684\u591a\u667a\u80fd\u4f53\u65b9\u6cd5CoA\uff0c\u5728NarrativeQA\u4e0a\u63d0\u534740.93%\uff0cQasper\u4e0a\u63d0\u534743.70%\uff0cHotpotQA\u4e0a\u63d0\u5347121.57%\uff0cMuSiQue\u4e0a\u63d0\u534733.12%", "conclusion": "LSTM-MAS\u901a\u8fc7\u53d7\u63a7\u4fe1\u606f\u4f20\u9012\u548c\u9009\u62e9\u6027\u957f\u7a0b\u4f9d\u8d56\u5efa\u6a21\uff0c\u80fd\u6709\u6548\u907f\u514d\u9519\u8bef\u7d2f\u79ef\u548c\u5e7b\u89c9\u4f20\u64ad\uff0c\u4e3a\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u591a\u667a\u80fd\u4f53\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.11920", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11920", "abs": "https://arxiv.org/abs/2601.11920", "authors": ["Zhen Xu", "Vedant Khatri", "Yijun Dai", "Xiner Liu", "Siyan Li", "Xuanming Zhang", "Renzhe Yu"], "title": "Enhancing LLM-Based Data Annotation with Error Decomposition", "comment": null, "summary": "Large language models offer a scalable alternative to human coding for data annotation tasks, enabling the scale-up of research across data-intensive domains. While LLMs are already achieving near-human accuracy on objective annotation tasks, their performance on subjective annotation tasks, such as those involving psychological constructs, is less consistent and more prone to errors. Standard evaluation practices typically collapse all annotation errors into a single alignment metric, but this simplified approach may obscure different kinds of errors that affect final analytical conclusions in different ways. Here, we propose a diagnostic evaluation paradigm that incorporates a human-in-the-loop step to separate task-inherent ambiguity from model-driven inaccuracies and assess annotation quality in terms of their potential downstream impacts. We refine this paradigm on ordinal annotation tasks, which are common in subjective annotation. The refined paradigm includes: (1) a diagnostic taxonomy that categorizes LLM annotation errors along two dimensions: source (model-specific vs. task-inherent) and type (boundary ambiguity vs. conceptual misidentification); (2) a lightweight human annotation test to estimate task-inherent ambiguity from LLM annotations; and (3) a computational method to decompose observed LLM annotation errors following our taxonomy. We validate this paradigm on four educational annotation tasks, demonstrating both its conceptual validity and practical utility. Theoretically, our work provides empirical evidence for why excessively high alignment is unrealistic in specific annotation tasks and why single alignment metrics inadequately reflect the quality of LLM annotations. In practice, our paradigm can be a low-cost diagnostic tool that assesses the suitability of a given task for LLM annotation and provides actionable insights for further technical optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bca\u65ad\u6027\u8bc4\u4f30\u8303\u5f0f\uff0c\u7528\u4e8e\u5206\u6790LLM\u5728\u4e3b\u89c2\u6807\u6ce8\u4efb\u52a1\u4e2d\u7684\u9519\u8bef\u7c7b\u578b\uff0c\u533a\u5206\u6a21\u578b\u7279\u5b9a\u9519\u8bef\u4e0e\u4efb\u52a1\u56fa\u6709\u6a21\u7cca\u6027\uff0c\u5e76\u8bc4\u4f30\u5176\u5bf9\u4e0b\u6e38\u5206\u6790\u7684\u5f71\u54cd\u3002", "motivation": "LLM\u5728\u5ba2\u89c2\u6807\u6ce8\u4efb\u52a1\u4e0a\u5df2\u8fbe\u5230\u63a5\u8fd1\u4eba\u7c7b\u7684\u51c6\u786e\u7387\uff0c\u4f46\u5728\u6d89\u53ca\u5fc3\u7406\u6784\u5ff5\u7b49\u4e3b\u89c2\u6807\u6ce8\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u7a33\u5b9a\u4e14\u6613\u51fa\u9519\u3002\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5c06\u6240\u6709\u9519\u8bef\u5408\u5e76\u4e3a\u5355\u4e00\u5bf9\u9f50\u6307\u6807\uff0c\u8fd9\u79cd\u7b80\u5316\u65b9\u6cd5\u63a9\u76d6\u4e86\u4e0d\u540c\u7c7b\u578b\u9519\u8bef\u5bf9\u6700\u7ec8\u5206\u6790\u7ed3\u8bba\u7684\u4e0d\u540c\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bca\u65ad\u6027\u8bc4\u4f30\u8303\u5f0f\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u4e8c\u7ef4\u8bca\u65ad\u5206\u7c7b\u6cd5\uff0c\u6309\u6765\u6e90\uff08\u6a21\u578b\u7279\u5b9avs\u4efb\u52a1\u56fa\u6709\uff09\u548c\u7c7b\u578b\uff08\u8fb9\u754c\u6a21\u7ccavs\u6982\u5ff5\u8bef\u8bc6\u522b\uff09\u5206\u7c7bLLM\u6807\u6ce8\u9519\u8bef\uff1b2) \u8f7b\u91cf\u7ea7\u4eba\u5de5\u6807\u6ce8\u6d4b\u8bd5\uff0c\u4eceLLM\u6807\u6ce8\u4e2d\u4f30\u8ba1\u4efb\u52a1\u56fa\u6709\u6a21\u7cca\u6027\uff1b3) \u8ba1\u7b97\u65b9\u6cd5\uff0c\u6309\u5206\u7c7b\u6cd5\u5206\u89e3\u89c2\u5bdf\u5230\u7684LLM\u6807\u6ce8\u9519\u8bef\u3002\u8be5\u8303\u5f0f\u5728\u56db\u4e2a\u6559\u80b2\u6807\u6ce8\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "result": "\u9a8c\u8bc1\u4e86\u8be5\u8303\u5f0f\u7684\u6982\u5ff5\u6709\u6548\u6027\u548c\u5b9e\u9645\u6548\u7528\u3002\u7406\u8bba\u4e0a\uff0c\u4e3a\u7279\u5b9a\u6807\u6ce8\u4efb\u52a1\u4e2d\u8fc7\u9ad8\u5bf9\u9f50\u4e0d\u73b0\u5b9e\u4ee5\u53ca\u5355\u4e00\u5bf9\u9f50\u6307\u6807\u4e0d\u8db3\u4ee5\u53cd\u6620LLM\u6807\u6ce8\u8d28\u91cf\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u8bc1\u636e\u3002\u5b9e\u8df5\u4e0a\uff0c\u8be5\u8303\u5f0f\u53ef\u4f5c\u4e3a\u4f4e\u6210\u672c\u8bca\u65ad\u5de5\u5177\uff0c\u8bc4\u4f30\u7279\u5b9a\u4efb\u52a1\u662f\u5426\u9002\u5408LLM\u6807\u6ce8\uff0c\u5e76\u4e3a\u8fdb\u4e00\u6b65\u6280\u672f\u4f18\u5316\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002", "conclusion": "\u63d0\u51fa\u7684\u8bca\u65ad\u8bc4\u4f30\u8303\u5f0f\u80fd\u591f\u6709\u6548\u533a\u5206LLM\u6807\u6ce8\u9519\u8bef\u7684\u4e0d\u540c\u7c7b\u578b\uff0c\u4e3a\u7406\u89e3LLM\u5728\u4e3b\u89c2\u6807\u6ce8\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u66f4\u7cbe\u7ec6\u7684\u5206\u6790\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u8bc4\u4f30LLM\u6807\u6ce8\u7684\u9002\u7528\u6027\u548c\u8d28\u91cf\u3002"}}
{"id": "2601.12256", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12256", "abs": "https://arxiv.org/abs/2601.12256", "authors": ["Jinyoung Park", "Minseong Bae", "Jeehye Na", "Hyunwoo J. Kim"], "title": "Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration", "comment": null, "summary": "Large language models (LLMs) have demonstrated their instruction-following capabilities and achieved powerful performance on various tasks. Inspired by their success, recent works in the molecular domain have led to the development of large molecular language models (LMLMs) that integrate 1D molecular strings or 2D molecular graphs into the language models. However, existing LMLMs often suffer from hallucination and limited robustness, largely due to inadequate integration of diverse molecular modalities such as 1D sequences, 2D molecular graphs, and 3D conformations. To address these limitations, we propose CoLLaMo, a large language model-based molecular assistant equipped with a multi-level molecular modality-collaborative projector. The relation-aware modality-collaborative attention mechanism in the projector facilitates fine-grained and relation-guided information exchange between atoms by incorporating 2D structural and 3D spatial relations. Furthermore, we present a molecule-centric new automatic measurement, including a hallucination assessment metric and GPT-based caption quality evaluation to address the limitations of token-based generic evaluation metrics (i.e., BLEU) widely used in assessing molecular comprehension of LMLMs. Our extensive experiments demonstrate that our CoLLaMo enhances the molecular modality generalization capabilities of LMLMs, achieving the best performance on multiple tasks, including molecule captioning, computed property QA, descriptive property QA, motif counting, and IUPAC name prediction.", "AI": {"tldr": "CoLLaMo\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5206\u5b50\u52a9\u624b\uff0c\u901a\u8fc7\u591a\u7ea7\u5206\u5b50\u6a21\u6001\u534f\u4f5c\u6295\u5f71\u5668\u6574\u54081D\u5e8f\u5217\u30012D\u5206\u5b50\u56fe\u548c3D\u6784\u8c61\u4fe1\u606f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5927\u5206\u5b50\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u548c\u9c81\u68d2\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u5206\u5b50\u8bed\u8a00\u6a21\u578b\uff08LMLMs\uff09\u901a\u5e38\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\u548c\u6709\u9650\u7684\u9c81\u68d2\u6027\uff0c\u8fd9\u4e3b\u8981\u662f\u7531\u4e8e\u672a\u80fd\u5145\u5206\u6574\u54081D\u5e8f\u5217\u30012D\u5206\u5b50\u56fe\u548c3D\u6784\u8c61\u7b49\u591a\u79cd\u5206\u5b50\u6a21\u6001\u4fe1\u606f\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6709\u6548\u6574\u5408\u591a\u6a21\u6001\u5206\u5b50\u4fe1\u606f\u7684\u6a21\u578b\u6765\u63d0\u5347\u5206\u5b50\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\u3002", "method": "\u63d0\u51faCoLLaMo\u6a21\u578b\uff0c\u5305\u542b\uff1a1\uff09\u591a\u7ea7\u5206\u5b50\u6a21\u6001\u534f\u4f5c\u6295\u5f71\u5668\uff0c\u901a\u8fc7\u5173\u7cfb\u611f\u77e5\u7684\u6a21\u6001\u534f\u4f5c\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\u539f\u5b50\u95f4\u7684\u7ec6\u7c92\u5ea6\u4fe1\u606f\u4ea4\u6362\uff1b2\uff09\u5f15\u51652D\u7ed3\u6784\u5173\u7cfb\u548c3D\u7a7a\u95f4\u5173\u7cfb\u6307\u5bfc\u4fe1\u606f\u4f20\u9012\uff1b3\uff09\u63d0\u51fa\u65b0\u7684\u5206\u5b50\u4e2d\u5fc3\u81ea\u52a8\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5305\u62ec\u5e7b\u89c9\u8bc4\u4f30\u6307\u6807\u548c\u57fa\u4e8eGPT\u7684\u6807\u9898\u8d28\u91cf\u8bc4\u4f30\uff0c\u4ee5\u66ff\u4ee3\u4f20\u7edf\u7684\u57fa\u4e8etoken\u7684\u901a\u7528\u8bc4\u4f30\u6307\u6807\uff08\u5982BLEU\uff09\u3002", "result": "CoLLaMo\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\uff0c\u5305\u62ec\u5206\u5b50\u6807\u9898\u751f\u6210\u3001\u8ba1\u7b97\u6027\u8d28\u95ee\u7b54\u3001\u63cf\u8ff0\u6027\u8d28\u95ee\u7b54\u3001\u57fa\u5e8f\u8ba1\u6570\u548cIUPAC\u540d\u79f0\u9884\u6d4b\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u6a21\u578b\u589e\u5f3a\u4e86LMLMs\u7684\u5206\u5b50\u6a21\u6001\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u591a\u7ea7\u5206\u5b50\u6a21\u6001\u4fe1\u606f\u5e76\u91c7\u7528\u5173\u7cfb\u611f\u77e5\u7684\u534f\u4f5c\u6ce8\u610f\u529b\u673a\u5236\uff0cCoLLaMo\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u5927\u5206\u5b50\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u548c\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u5728\u591a\u79cd\u5206\u5b50\u7406\u89e3\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002\u540c\u65f6\u63d0\u51fa\u7684\u5206\u5b50\u4e2d\u5fc3\u8bc4\u4f30\u65b9\u6cd5\u4e3a\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u5206\u5b50\u7406\u89e3\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.11923", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11923", "abs": "https://arxiv.org/abs/2601.11923", "authors": ["P. Bilha Githinji", "Aikaterini Melliou", "Xi Yuan", "Dayan Zhang", "Lian Zhang", "Zhenglin Chen", "Jiansong Ji", "Chengying Lv", "Jinhao Xu", "Peiwu Qin", "Dongmei Yu"], "title": "Mapping the maturation of TCM as an adjuvant to radiotherapy", "comment": null, "summary": "The integration of complementary medicine into oncology represents a paradigm shift that has seen to increasing adoption of Traditional Chinese Medicine (TCM) as an adjuvant to radiotherapy. About twenty-five years since the formal institutionalization of integrated oncology, it is opportune to synthesize the trajectory of evidence for TCM as an adjuvant to radiotherapy. Here we conduct a large-scale analysis of 69,745 publications (2000 - 2025), emerging a cyclical evolution defined by coordinated expansion and contraction in publication output, international collaboration, and funding commitments that mirrors a define-ideate-test pattern. Using a theme modeling workflow designed to determine a stable thematic structure of the field, we identify five dominant thematic axes - cancer types, supportive care, clinical endpoints, mechanisms, and methodology - that signal a focus on patient well-being, scientific rigor and mechanistic exploration. Cross-theme integration of TCM is patient-centered and systems-oriented. Together with the emergent cycles of evolution, the thematic structure demonstrates progressive specialization and potential defragmentation of the field or saturation of existing research agenda. The analysis points to a field that has matured its current research agenda and is likely at the cusp of something new. Additionally, the field exhibits positive reporting of findings that is homogeneous across publication types, thematic areas, and the cycles of evolution suggesting a system-wide positive reporting bias agnostic to structural drivers.", "AI": {"tldr": "\u5bf92000-2025\u5e7469,745\u7bc7\u6587\u732e\u7684\u5927\u89c4\u6a21\u5206\u6790\u663e\u793a\uff0c\u4e2d\u533b\u836f\u4f5c\u4e3a\u653e\u7597\u8f85\u52a9\u7684\u6574\u5408\u80bf\u7624\u5b66\u9886\u57df\u7ecf\u5386\u4e86\u5468\u671f\u6027\u6f14\u53d8\uff0c\u5f62\u6210\u4e86\u4e94\u4e2a\u4e3b\u5bfc\u4e3b\u9898\u8f74\uff0c\u8868\u660e\u8be5\u9886\u57df\u5df2\u6210\u719f\u5e76\u53ef\u80fd\u9762\u4e34\u65b0\u7684\u8f6c\u6298\u70b9\uff0c\u540c\u65f6\u5b58\u5728\u7cfb\u7edf\u6027\u9633\u6027\u62a5\u544a\u504f\u501a\u3002", "motivation": "\u6574\u5408\u80bf\u7624\u5b66\u4f5c\u4e3a\u8303\u5f0f\u8f6c\u53d8\u5df2\u53d1\u5c55\u7ea625\u5e74\uff0c\u4e2d\u533b\u836f\u4f5c\u4e3a\u653e\u7597\u8f85\u52a9\u7684\u8bc1\u636e\u8f68\u8ff9\u9700\u8981\u7cfb\u7edf\u68b3\u7406\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5927\u89c4\u6a21\u6587\u732e\u5206\u6790\uff0c\u63ed\u793a\u8be5\u9886\u57df\u7684\u6f14\u53d8\u6a21\u5f0f\u3001\u4e3b\u9898\u7ed3\u6784\u548c\u6f5c\u5728\u504f\u501a\uff0c\u4e3a\u672a\u6765\u53d1\u5c55\u63d0\u4f9b\u89c1\u89e3\u3002", "method": "\u5bf92000-2025\u5e74\u95f469,745\u7bc7\u51fa\u7248\u7269\u8fdb\u884c\u5927\u89c4\u6a21\u5206\u6790\uff0c\u91c7\u7528\u4e3b\u9898\u5efa\u6a21\u5de5\u4f5c\u6d41\u7a0b\u786e\u5b9a\u7a33\u5b9a\u7684\u4e3b\u9898\u7ed3\u6784\uff0c\u8bc6\u522b\u5468\u671f\u6027\u6f14\u53d8\u6a21\u5f0f\uff0c\u5e76\u8bc4\u4f30\u8de8\u51fa\u7248\u7269\u7c7b\u578b\u3001\u4e3b\u9898\u9886\u57df\u548c\u6f14\u53d8\u5468\u671f\u7684\u62a5\u544a\u504f\u501a\u3002", "result": "\u8bc6\u522b\u51fa\u4e94\u4e2a\u4e3b\u5bfc\u4e3b\u9898\u8f74\uff1a\u764c\u75c7\u7c7b\u578b\u3001\u652f\u6301\u6027\u62a4\u7406\u3001\u4e34\u5e8a\u7ec8\u70b9\u3001\u673a\u5236\u548c\u65b9\u6cd5\u5b66\uff1b\u53d1\u73b0\u8be5\u9886\u57df\u5448\u73b0\u5b9a\u4e49-\u6784\u601d-\u6d4b\u8bd5\u6a21\u5f0f\u7684\u5468\u671f\u6027\u6f14\u53d8\uff1b\u89c2\u5bdf\u5230\u7cfb\u7edf\u6027\u9633\u6027\u62a5\u544a\u504f\u501a\uff0c\u4e14\u8fd9\u79cd\u504f\u501a\u5728\u4e0d\u540c\u7ed3\u6784\u9a71\u52a8\u56e0\u7d20\u4e2d\u5177\u6709\u540c\u8d28\u6027\u3002", "conclusion": "\u4e2d\u533b\u836f\u4f5c\u4e3a\u653e\u7597\u8f85\u52a9\u7684\u6574\u5408\u80bf\u7624\u5b66\u9886\u57df\u5df2\u6210\u719f\u5f53\u524d\u7814\u7a76\u8bae\u7a0b\uff0c\u6b63\u5904\u4e8e\u65b0\u7a81\u7834\u7684\u8fb9\u7f18\u3002\u8be5\u9886\u57df\u5448\u73b0\u6e10\u8fdb\u4e13\u4e1a\u5316\u548c\u6f5c\u5728\u788e\u7247\u5316\uff0c\u540c\u65f6\u5b58\u5728\u5168\u7cfb\u7edf\u8303\u56f4\u7684\u9633\u6027\u62a5\u544a\u504f\u501a\uff0c\u9700\u8981\u66f4\u6279\u5224\u6027\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2601.11932", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11932", "abs": "https://arxiv.org/abs/2601.11932", "authors": ["Abdullah Al Monsur", "Nitesh Vamshi Bommisetty", "Gene Louis Kim"], "title": "Event Detection with a Context-Aware Encoder and LoRA for Improved Performance on Long-Tailed Classes", "comment": null, "summary": "The current state of event detection research has two notable re-occurring limitations that we investigate in this study. First, the unidirectional nature of decoder-only LLMs presents a fundamental architectural bottleneck for natural language understanding tasks that depend on rich, bidirectional context. Second, we confront the conventional reliance on Micro-F1 scores in event detection literature, which systematically inflates performance by favoring majority classes. Instead, we focus on Macro-F1 as a more representative measure of a model's ability across the long-tail of event types. Our experiments demonstrate that models enhanced with sentence context achieve superior performance over canonical decoder-only baselines. Using Low-Rank Adaptation (LoRA) during finetuning provides a substantial boost in Macro-F1 scores in particular, especially for the decoder-only models, showing that LoRA can be an effective tool to enhance LLMs' performance on long-tailed event classes.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e8b\u4ef6\u68c0\u6d4b\u4e2dLLM\u5355\u5411\u89e3\u7801\u5668\u67b6\u6784\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4f7f\u7528\u53cc\u5411\u4e0a\u4e0b\u6587\u548cMacro-F1\u8bc4\u4f30\u6307\u6807\uff0c\u901a\u8fc7LoRA\u5fae\u8c03\u63d0\u5347\u957f\u5c3e\u4e8b\u4ef6\u7c7b\u522b\u7684\u6027\u80fd", "motivation": "\u5f53\u524d\u4e8b\u4ef6\u68c0\u6d4b\u7814\u7a76\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u5c40\u9650\uff1a1\uff09\u4ec5\u89e3\u7801\u5668LLM\u7684\u5355\u5411\u67b6\u6784\u5728\u5904\u7406\u9700\u8981\u53cc\u5411\u4e0a\u4e0b\u6587\u7406\u89e3\u7684\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4efb\u52a1\u65f6\u5b58\u5728\u74f6\u9888\uff1b2\uff09\u4f20\u7edf\u4f9d\u8d56Micro-F1\u8bc4\u5206\u4f1a\u56e0\u504f\u5411\u591a\u6570\u7c7b\u522b\u800c\u7cfb\u7edf\u6027\u9ad8\u4f30\u6027\u80fd\uff0c\u9700\u8981\u66f4\u5173\u6ce8\u6a21\u578b\u5728\u957f\u5c3e\u4e8b\u4ef6\u7c7b\u578b\u4e0a\u7684\u8868\u73b0", "method": "\u91c7\u7528\u53e5\u5b50\u4e0a\u4e0b\u6587\u589e\u5f3a\u6a21\u578b\u6027\u80fd\uff0c\u4f7f\u7528\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u8fdb\u884c\u5fae\u8c03\uff0c\u7279\u522b\u5173\u6ce8Macro-F1\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\uff0c\u5bf9\u6bd4\u589e\u5f3a\u6a21\u578b\u4e0e\u6807\u51c6\u4ec5\u89e3\u7801\u5668\u57fa\u7ebf\u6a21\u578b\u7684\u6027\u80fd", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1\uff09\u53e5\u5b50\u4e0a\u4e0b\u6587\u589e\u5f3a\u7684\u6a21\u578b\u6027\u80fd\u4f18\u4e8e\u6807\u51c6\u4ec5\u89e3\u7801\u5668\u57fa\u7ebf\uff1b2\uff09LoRA\u5fae\u8c03\u663e\u8457\u63d0\u5347Macro-F1\u5206\u6570\uff0c\u7279\u522b\u662f\u5bf9\u4ec5\u89e3\u7801\u5668\u6a21\u578b\uff0c\u8bc1\u660eLoRA\u80fd\u6709\u6548\u589e\u5f3aLLM\u5728\u957f\u5c3e\u4e8b\u4ef6\u7c7b\u522b\u4e0a\u7684\u8868\u73b0", "conclusion": "\u4e8b\u4ef6\u68c0\u6d4b\u7814\u7a76\u9700\u8981\u8d85\u8d8a\u5355\u5411LLM\u67b6\u6784\u7684\u9650\u5236\uff0c\u91c7\u7528\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6307\u6807\uff08\u5982Macro-F1\uff09\uff0cLoRA\u5fae\u8c03\u662f\u63d0\u5347\u6a21\u578b\u5728\u957f\u5c3e\u4e8b\u4ef6\u7c7b\u522b\u6027\u80fd\u7684\u6709\u6548\u5de5\u5177"}}
{"id": "2601.12294", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12294", "abs": "https://arxiv.org/abs/2601.12294", "authors": ["Dawei Li", "Yuguang Yao", "Zhen Tan", "Huan Liu", "Ruocheng Guo"], "title": "ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents", "comment": "under review", "summary": "Reward-guided search methods have demonstrated strong potential in enhancing tool-using agents by effectively guiding sampling and exploration over complex action spaces. As a core design, those search methods utilize process reward models (PRMs) to provide step-level rewards, enabling more fine-grained monitoring. However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings. In this paper, we introduce ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents. ToolPRMBench is built on top of several representative tool-using benchmarks and converts agent trajectories into step-level test cases. Each case contains the interaction history, a correct action, a plausible but incorrect alternative, and relevant tool metadata. We respectively utilize offline sampling to isolate local single-step errors and online sampling to capture realistic multi-step failures from full agent rollouts. A multi-LLM verification pipeline is proposed to reduce label noise and ensure data quality. We conduct extensive experiments across large language models, general PRMs, and tool-specialized PRMs on ToolPRMBench. The results reveal clear differences in PRM effectiveness and highlight the potential of specialized PRMs for tool-using. Code and data will be released at https://github.com/David-Li0406/ToolPRMBench.", "code_url": "https://github.com/David-Li0406/ToolPRMBench", "code_stars": 1, "code_last_update": "2026-01-21", "AI": {"tldr": "ToolPRMBench\uff1a\u9996\u4e2a\u4e13\u95e8\u8bc4\u4f30\u5de5\u5177\u4f7f\u7528\u667a\u80fd\u4f53\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRMs\uff09\u7684\u5927\u89c4\u6a21\u57fa\u51c6\uff0c\u901a\u8fc7\u79bb\u7ebf/\u5728\u7ebf\u91c7\u6837\u548c\u591aLLM\u9a8c\u8bc1\u6784\u5efa\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u96c6", "motivation": "\u73b0\u6709\u5956\u52b1\u5f15\u5bfc\u641c\u7d22\u65b9\u6cd5\u5728\u5de5\u5177\u4f7f\u7528\u667a\u80fd\u4f53\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u53ef\u9760\u7684PRM\u8bc4\u4f30\u57fa\u51c6\uff0c\u963b\u788d\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55", "method": "\u57fa\u4e8e\u591a\u4e2a\u4ee3\u8868\u6027\u5de5\u5177\u4f7f\u7528\u57fa\u51c6\u6784\u5efaToolPRMBench\uff0c\u5c06\u667a\u80fd\u4f53\u8f68\u8ff9\u8f6c\u6362\u4e3a\u6b65\u9aa4\u7ea7\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5305\u542b\u4ea4\u4e92\u5386\u53f2\u3001\u6b63\u786e\u52a8\u4f5c\u3001\u5408\u7406\u4f46\u4e0d\u6b63\u786e\u7684\u66ff\u4ee3\u65b9\u6848\u548c\u5de5\u5177\u5143\u6570\u636e\uff1b\u91c7\u7528\u79bb\u7ebf\u91c7\u6837\u9694\u79bb\u5355\u6b65\u9519\u8bef\u548c\u5728\u7ebf\u91c7\u6837\u6355\u83b7\u591a\u6b65\u5931\u8d25\uff1b\u8bbe\u8ba1\u591aLLM\u9a8c\u8bc1\u6d41\u7a0b\u964d\u4f4e\u6807\u7b7e\u566a\u58f0", "result": "\u5b9e\u9a8c\u6db5\u76d6\u5927\u8bed\u8a00\u6a21\u578b\u3001\u901a\u7528PRMs\u548c\u5de5\u5177\u4e13\u7528PRMs\uff0c\u7ed3\u679c\u663e\u793aPRM\u6709\u6548\u6027\u5b58\u5728\u660e\u663e\u5dee\u5f02\uff0c\u5de5\u5177\u4e13\u7528PRMs\u5c55\u73b0\u51fa\u663e\u8457\u6f5c\u529b", "conclusion": "ToolPRMBench\u586b\u8865\u4e86\u5de5\u5177\u4f7f\u7528PRM\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u9760\u57fa\u51c6\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90"}}
{"id": "2601.11969", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11969", "abs": "https://arxiv.org/abs/2601.11969", "authors": ["Zecheng Tang", "Baibei Ji", "Ruoxi Sun", "Haitian Wang", "WangJie You", "Zhang Yijun", "Wenpeng Zhu", "Ji Qi", "Juntao Li", "Min Zhang"], "title": "$\\texttt{MemoryRewardBench}$: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models", "comment": null, "summary": "Existing works increasingly adopt memory-centric mechanisms to process long contexts in a segment manner, and effective memory management is one of the key capabilities that enables large language models to effectively propagate information across the entire sequence. Therefore, leveraging reward models (RMs) to automatically and reliably evaluate memory quality is critical. In this work, we introduce $\\texttt{MemoryRewardBench}$, the first benchmark to systematically study the ability of RMs to evaluate long-term memory management processes. $\\texttt{MemoryRewardBench}$ covers both long-context comprehension and long-form generation tasks, featuring 10 distinct settings with different memory management patterns, with context length ranging from 8K to 128K tokens. Evaluations on 13 cutting-edge RMs indicate a diminishing performance gap between open-source and proprietary models, with newer-generation models consistently outperforming their predecessors regardless of parameter count. We further expose the capabilities and fundamental limitations of current RMs in evaluating LLM memory management across diverse settings.", "AI": {"tldr": "MemoryRewardBench\uff1a\u9996\u4e2a\u7cfb\u7edf\u7814\u7a76\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\u957f\u65f6\u8bb0\u5fc6\u7ba1\u7406\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u8986\u76d6\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u548c\u957f\u6587\u672c\u751f\u6210\u4efb\u52a1\uff0c\u5305\u542b10\u79cd\u4e0d\u540c\u8bb0\u5fc6\u7ba1\u7406\u6a21\u5f0f\u7684\u8bbe\u7f6e\uff0c\u4e0a\u4e0b\u6587\u957f\u5ea6\u4ece8K\u5230128K token\u3002", "motivation": "\u968f\u7740\u5de5\u4f5c\u8d8a\u6765\u8d8a\u591a\u5730\u91c7\u7528\u4ee5\u5185\u5b58\u4e3a\u4e2d\u5fc3\u7684\u673a\u5236\u4ee5\u5206\u6bb5\u65b9\u5f0f\u5904\u7406\u957f\u4e0a\u4e0b\u6587\uff0c\u6709\u6548\u7684\u5185\u5b58\u7ba1\u7406\u662f\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u6574\u4e2a\u5e8f\u5217\u4e2d\u6709\u6548\u4f20\u64ad\u4fe1\u606f\u7684\u5173\u952e\u80fd\u529b\u4e4b\u4e00\u3002\u56e0\u6b64\uff0c\u5229\u7528\u5956\u52b1\u6a21\u578b\u81ea\u52a8\u53ef\u9760\u5730\u8bc4\u4f30\u5185\u5b58\u8d28\u91cf\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f15\u5165MemoryRewardBench\u57fa\u51c6\uff0c\u7cfb\u7edf\u7814\u7a76\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\u957f\u65f6\u8bb0\u5fc6\u7ba1\u7406\u8fc7\u7a0b\u7684\u80fd\u529b\u3002\u8be5\u57fa\u51c6\u8986\u76d6\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u548c\u957f\u6587\u672c\u751f\u6210\u4efb\u52a1\uff0c\u5305\u542b10\u79cd\u4e0d\u540c\u8bb0\u5fc6\u7ba1\u7406\u6a21\u5f0f\u7684\u8bbe\u7f6e\uff0c\u4e0a\u4e0b\u6587\u957f\u5ea6\u4ece8K\u5230128K token\u3002\u572813\u4e2a\u524d\u6cbf\u5956\u52b1\u6a21\u578b\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u8868\u660e\u5f00\u6e90\u6a21\u578b\u4e0e\u4e13\u6709\u6a21\u578b\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u6b63\u5728\u7f29\u5c0f\uff0c\u65b0\u4e00\u4ee3\u6a21\u578b\u65e0\u8bba\u53c2\u6570\u6570\u91cf\u5982\u4f55\u90fd\u6301\u7eed\u4f18\u4e8e\u524d\u4ee3\u6a21\u578b\u3002\u8fdb\u4e00\u6b65\u63ed\u793a\u4e86\u5f53\u524d\u5956\u52b1\u6a21\u578b\u5728\u8bc4\u4f30LLM\u5185\u5b58\u7ba1\u7406\u65b9\u9762\u7684\u80fd\u529b\u548c\u57fa\u672c\u5c40\u9650\u6027\u3002", "conclusion": "MemoryRewardBench\u4e3a\u7cfb\u7edf\u8bc4\u4f30\u5956\u52b1\u6a21\u578b\u5728\u957f\u65f6\u8bb0\u5fc6\u7ba1\u7406\u65b9\u9762\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u9996\u4e2a\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u7684\u8fdb\u5c55\u548c\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u6539\u8fdb\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2601.12318", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12318", "abs": "https://arxiv.org/abs/2601.12318", "authors": ["Dehao Ying", "Fengchang Yu", "Haihua Chen", "Changjiang Jiang", "Yurong Li", "Wei Lu"], "title": "Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence", "comment": null, "summary": "The advancement of Document Intelligence (DI) demands large-scale, high-quality training data, yet manual annotation remains a critical bottleneck. While data generation methods are evolving rapidly, existing surveys are constrained by fragmented focuses on single modalities or specific tasks, lacking a unified perspective aligned with real-world workflows. To fill this gap, this survey establishes the first comprehensive technical map for data generation in DI. Data generation is redefined as supervisory signal production, and a novel taxonomy is introduced based on the \"availability of data and labels.\" This framework organizes methodologies into four resource-centric paradigms: Data Augmentation, Data Generation from Scratch, Automated Data Annotation, and Self-Supervised Signal Construction. Furthermore, a multi-level evaluation framework is established to integrate intrinsic quality and extrinsic utility, compiling performance gains across diverse DI benchmarks. Guided by this unified structure, the methodological landscape is dissected to reveal critical challenges such as fidelity gaps and frontiers including co-evolutionary ecosystems. Ultimately, by systematizing this fragmented field, data generation is positioned as the central engine for next-generation DI.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5efa\u7acb\u4e86\u6587\u6863\u667a\u80fd\u6570\u636e\u751f\u6210\u7684\u7efc\u5408\u6280\u672f\u56fe\u8c31\uff0c\u91cd\u65b0\u5b9a\u4e49\u6570\u636e\u751f\u6210\u4e3a\u76d1\u7763\u4fe1\u53f7\u751f\u4ea7\uff0c\u57fa\u4e8e\"\u6570\u636e\u548c\u6807\u7b7e\u53ef\u7528\u6027\"\u63d0\u51fa\u65b0\u5206\u7c7b\u6cd5\uff0c\u6db5\u76d6\u6570\u636e\u589e\u5f3a\u3001\u4ece\u96f6\u751f\u6210\u3001\u81ea\u52a8\u6807\u6ce8\u548c\u81ea\u76d1\u7763\u4fe1\u53f7\u6784\u5efa\u56db\u5927\u8303\u5f0f\uff0c\u5e76\u5efa\u7acb\u591a\u7ea7\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u6587\u6863\u667a\u80fd\u53d1\u5c55\u9700\u8981\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u4f46\u4eba\u5de5\u6807\u6ce8\u6210\u4e3a\u5173\u952e\u74f6\u9888\u3002\u73b0\u6709\u6570\u636e\u751f\u6210\u65b9\u6cd5\u8c03\u67e5\u5c40\u9650\u4e8e\u5355\u4e00\u6a21\u6001\u6216\u7279\u5b9a\u4efb\u52a1\uff0c\u7f3a\u4e4f\u4e0e\u73b0\u5b9e\u5de5\u4f5c\u6d41\u7a0b\u7edf\u4e00\u89c6\u89d2\uff0c\u9700\u8981\u5efa\u7acb\u5168\u9762\u6280\u672f\u6846\u67b6\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5c06\u6570\u636e\u751f\u6210\u91cd\u65b0\u5b9a\u4e49\u4e3a\u76d1\u7763\u4fe1\u53f7\u751f\u4ea7\uff0c\u57fa\u4e8e\"\u6570\u636e\u548c\u6807\u7b7e\u53ef\u7528\u6027\"\u5f15\u5165\u65b0\u5206\u7c7b\u6cd5\uff0c\u7ec4\u7ec7\u4e3a\u56db\u5927\u8d44\u6e90\u4e2d\u5fc3\u8303\u5f0f\uff1a\u6570\u636e\u589e\u5f3a\u3001\u4ece\u96f6\u751f\u6210\u3001\u81ea\u52a8\u6807\u6ce8\u548c\u81ea\u76d1\u7763\u4fe1\u53f7\u6784\u5efa\u3002\u5efa\u7acb\u591a\u7ea7\u8bc4\u4f30\u6846\u67b6\u6574\u5408\u5185\u5728\u8d28\u91cf\u548c\u5916\u5728\u6548\u7528\uff0c\u7f16\u8bd1\u591a\u6837\u5316DI\u57fa\u51c6\u6027\u80fd\u589e\u76ca\u3002", "result": "\u521b\u5efa\u4e86\u9996\u4e2a\u6587\u6863\u667a\u80fd\u6570\u636e\u751f\u6210\u7efc\u5408\u6280\u672f\u56fe\u8c31\uff0c\u7cfb\u7edf\u5316\u6574\u7406\u4e86\u788e\u7247\u5316\u9886\u57df\uff0c\u63ed\u793a\u4e86\u4fdd\u771f\u5ea6\u5dee\u8ddd\u7b49\u5173\u952e\u6311\u6218\u548c\u534f\u540c\u8fdb\u5316\u751f\u6001\u7cfb\u7edf\u7b49\u524d\u6cbf\u65b9\u5411\uff0c\u5c55\u793a\u4e86\u6570\u636e\u751f\u6210\u65b9\u6cd5\u5728\u591a\u6837\u5316DI\u57fa\u51c6\u4e0a\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u5316\u788e\u7247\u5316\u9886\u57df\uff0c\u5c06\u6570\u636e\u751f\u6210\u5b9a\u4f4d\u4e3a\u4e0b\u4e00\u4ee3\u6587\u6863\u667a\u80fd\u7684\u6838\u5fc3\u5f15\u64ce\uff0c\u4e3a\u9886\u57df\u53d1\u5c55\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2601.12019", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12019", "abs": "https://arxiv.org/abs/2601.12019", "authors": ["Chaowei Zhang", "Xiansheng Luo", "Zewei Zhang", "Yi Zhu", "Jipeng Qiang", "Longwei Wang"], "title": "Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning", "comment": null, "summary": "The widespread proliferation of online content has intensified concerns about clickbait, deceptive or exaggerated headlines designed to attract attention. While Large Language Models (LLMs) offer a promising avenue for addressing this issue, their effectiveness is often hindered by Sycophancy, a tendency to produce reasoning that matches users' beliefs over truthful ones, which deviates from instruction-following principles. Rather than treating sycophancy as a flaw to be eliminated, this work proposes a novel approach that initially harnesses this behavior to generate contrastive reasoning from opposing perspectives. Specifically, we design a Self-renewal Opposing-stance Reasoning Generation (SORG) framework that prompts LLMs to produce high-quality agree and disagree reasoning pairs for a given news title without requiring ground-truth labels. To utilize the generated reasoning, we develop a local Opposing Reasoning-based Clickbait Detection (ORCD) model that integrates three BERT encoders to represent the title and its associated reasoning. The model leverages contrastive learning, guided by soft labels derived from LLM-generated credibility scores, to enhance detection robustness. Experimental evaluations on three benchmark datasets demonstrate that our method consistently outperforms LLM prompting, fine-tuned smaller language models, and state-of-the-art clickbait detection baselines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faSORG\u6846\u67b6\uff0c\u5229\u7528LLM\u7684\u5949\u627f\u503e\u5411\u751f\u6210\u5bf9\u7acb\u63a8\u7406\u5bf9\uff0c\u5e76\u5f00\u53d1ORCD\u6a21\u578b\u8fdb\u884c\u70b9\u51fb\u8bf1\u9975\u68c0\u6d4b\uff0c\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5728\u7ebf\u5185\u5bb9\u7684\u5e7f\u6cdb\u4f20\u64ad\u52a0\u5267\u4e86\u5bf9\u70b9\u51fb\u8bf1\u9975\u7684\u62c5\u5fe7\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e3a\u89e3\u51b3\u6b64\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\uff0c\u4f46\u5176\u6548\u679c\u5e38\u53d7\u5949\u627f\u503e\u5411\uff08Sycophancy\uff09\u7684\u963b\u788d\uff0c\u5373\u503e\u5411\u4e8e\u751f\u6210\u7b26\u5408\u7528\u6237\u4fe1\u5ff5\u800c\u975e\u771f\u5b9e\u60c5\u51b5\u7684\u63a8\u7406\uff0c\u8fd9\u504f\u79bb\u4e86\u6307\u4ee4\u9075\u5faa\u539f\u5219\u3002", "method": "\u63d0\u51faSORG\u6846\u67b6\uff0c\u5229\u7528LLM\u7684\u5949\u627f\u503e\u5411\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u5bf9\u7acb\u63a8\u7406\u5bf9\uff08\u540c\u610f\u548c\u4e0d\u540c\u610f\u63a8\u7406\uff09\uff0c\u65e0\u9700\u771f\u5b9e\u6807\u7b7e\u3002\u5f00\u53d1ORCD\u6a21\u578b\uff0c\u4f7f\u7528\u4e09\u4e2aBERT\u7f16\u7801\u5668\u5206\u522b\u8868\u793a\u65b0\u95fb\u6807\u9898\u53ca\u5176\u76f8\u5173\u63a8\u7406\uff0c\u901a\u8fc7\u57fa\u4e8eLLM\u751f\u6210\u53ef\u4fe1\u5ea6\u5206\u6570\u7684\u8f6f\u6807\u7b7e\u6307\u5bfc\u7684\u5bf9\u6bd4\u5b66\u4e60\u6765\u589e\u5f3a\u68c0\u6d4b\u9c81\u68d2\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u70b9\u51fb\u8bf1\u9975\u68c0\u6d4b\u4efb\u52a1\u4e0a\u6301\u7eed\u4f18\u4e8eLLM\u63d0\u793a\u3001\u5fae\u8c03\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4ee5\u53ca\u6700\u5148\u8fdb\u7684\u70b9\u51fb\u8bf1\u9975\u68c0\u6d4b\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u65b9\u6cd5\uff0c\u5c06LLM\u7684\u5949\u627f\u503e\u5411\u4ece\u9700\u8981\u6d88\u9664\u7684\u7f3a\u9677\u8f6c\u53d8\u4e3a\u53ef\u5229\u7528\u7684\u8d44\u6e90\uff0c\u901a\u8fc7\u751f\u6210\u5bf9\u7acb\u63a8\u7406\u5bf9\u5e76\u6784\u5efa\u4e13\u95e8\u7684\u68c0\u6d4b\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u70b9\u51fb\u8bf1\u9975\u68c0\u6d4b\u7684\u6027\u80fd\u3002"}}
{"id": "2601.12323", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12323", "abs": "https://arxiv.org/abs/2601.12323", "authors": ["Yin Cai", "Zhouhong Gu", "Juntao Zhang", "Ping Chen"], "title": "MARO: Learning Stronger Reasoning from Social Interaction", "comment": null, "summary": "Humans face countless scenarios that require reasoning and judgment in daily life. However, existing large language model training methods primarily allow models to learn from existing textual content or solve predetermined problems, lacking experience in real scenarios involving interaction, negotiation, and competition with others. To address this, this paper proposes Multi-Agent Reward Optimization (MARO), a method that enables large language models (LLMs) to acquire stronger reasoning abilities by learning and practicing in multi-agent social environments. Specifically, MARO first addresses the sparse learning signal problem by decomposing final success or failure outcomes into each specific behavior during the interaction process; second, it handles the uneven role distribution problem by balancing the training sample weights of different roles; finally, it addresses environmental instability issues by directly evaluating the utility of each behavior. Experimental results demonstrate that MARO not only achieves significant improvements in social reasoning capabilities, but also that the abilities acquired through social simulation learning can effectively transfer to other tasks such as mathematical reasoning and instruction following. This reveals the tremendous potential of multi-agent social learning in enhancing the general reasoning capabilities of LLMs.", "AI": {"tldr": "MARO\u662f\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u5956\u52b1\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u591a\u667a\u80fd\u4f53\u793e\u4ea4\u73af\u5883\u4e2d\u5b66\u4e60\u548c\u5b9e\u8df5\u6765\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u7a00\u758f\u5b66\u4e60\u4fe1\u53f7\u3001\u89d2\u8272\u5206\u5e03\u4e0d\u5747\u548c\u73af\u5883\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5\u4e3b\u8981\u8ba9\u6a21\u578b\u4ece\u73b0\u6709\u6587\u672c\u5185\u5bb9\u5b66\u4e60\u6216\u89e3\u51b3\u9884\u5b9a\u95ee\u9898\uff0c\u7f3a\u4e4f\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u4e0e\u4ed6\u4eba\u4e92\u52a8\u3001\u534f\u5546\u548c\u7ade\u4e89\u7684\u7ecf\u9a8c\uff0c\u65e0\u6cd5\u5e94\u5bf9\u9700\u8981\u590d\u6742\u793e\u4f1a\u63a8\u7406\u7684\u65e5\u5e38\u573a\u666f\u3002", "method": "\u63d0\u51faMulti-Agent Reward Optimization (MARO)\u65b9\u6cd5\uff1a1) \u5c06\u6700\u7ec8\u6210\u8d25\u7ed3\u679c\u5206\u89e3\u4e3a\u4ea4\u4e92\u8fc7\u7a0b\u4e2d\u7684\u5177\u4f53\u884c\u4e3a\uff0c\u89e3\u51b3\u7a00\u758f\u5b66\u4e60\u4fe1\u53f7\u95ee\u9898\uff1b2) \u901a\u8fc7\u5e73\u8861\u4e0d\u540c\u89d2\u8272\u7684\u8bad\u7ec3\u6837\u672c\u6743\u91cd\uff0c\u5904\u7406\u89d2\u8272\u5206\u5e03\u4e0d\u5747\u95ee\u9898\uff1b3) \u76f4\u63a5\u8bc4\u4f30\u6bcf\u4e2a\u884c\u4e3a\u7684\u6548\u7528\uff0c\u89e3\u51b3\u73af\u5883\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMARO\u4e0d\u4ec5\u5728\u793e\u4f1a\u63a8\u7406\u80fd\u529b\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u800c\u4e14\u901a\u8fc7\u793e\u4ea4\u6a21\u62df\u5b66\u4e60\u83b7\u5f97\u7684\u80fd\u529b\u80fd\u591f\u6709\u6548\u8fc1\u79fb\u5230\u6570\u5b66\u63a8\u7406\u548c\u6307\u4ee4\u8ddf\u968f\u7b49\u5176\u4ed6\u4efb\u52a1\u4e2d\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u793e\u4ea4\u5b66\u4e60\u5728\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u901a\u7528\u63a8\u7406\u80fd\u529b\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0cMARO\u65b9\u6cd5\u4e3a\u89e3\u51b3\u6a21\u578b\u5728\u590d\u6742\u793e\u4f1a\u73af\u5883\u4e2d\u5b66\u4e60\u7684\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2601.12033", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12033", "abs": "https://arxiv.org/abs/2601.12033", "authors": ["Muhammad Alif Al Hakim", "Alfan Farizki Wicaksono", "Fajri Koto"], "title": "Preserving Fairness and Safety in Quantized LLMs Through Critical Weight Protection", "comment": null, "summary": "Quantization is widely adopted to reduce the computational cost of large language models (LLMs); however, its implications for fairness and safety, particularly in dynamic quantization and multilingual contexts, remain underexplored. In this work, we conduct a systematic study of how static and dynamic quantization methods impact fairness and safety across benchmarks measuring intrinsic and extrinsic bias and safety alignment. For fairness, we evaluate English, French, Dutch, Spanish, and Turkish; for safety, we focus on English, Korean, and Arabic. Our findings reveal that quantization consistently degrades fairness and safety, with dynamic methods demonstrating greater stability than static ones. Moreover, fairness degradation varies across languages, while safety deterioration is especially pronounced in non-English settings. To address these risks, we introduce Critical Weight Protection, a novel technique that identifies and preserves fairness- and safety-critical weights during quantization. This approach effectively mitigates bias and safety deterioration without costly retraining or alignment, maintaining trustworthiness while retaining efficiency.", "AI": {"tldr": "\u91cf\u5316\u4f1a\u964d\u4f4eLLM\u7684\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\uff0c\u52a8\u6001\u91cf\u5316\u6bd4\u9759\u6001\u91cf\u5316\u66f4\u7a33\u5b9a\uff0c\u975e\u82f1\u8bed\u8bed\u8a00\u7684\u5b89\u5168\u6027\u95ee\u9898\u66f4\u4e25\u91cd\uff0c\u4f5c\u8005\u63d0\u51faCritical Weight Protection\u6280\u672f\u6765\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898", "motivation": "\u91cf\u5316\u88ab\u5e7f\u6cdb\u7528\u4e8e\u964d\u4f4e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u4f46\u5176\u5bf9\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u52a8\u6001\u91cf\u5316\u548c\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u7684\u5f71\u54cd\uff0c\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u91cf\u5316\u65b9\u6cd5\u5982\u4f55\u5f71\u54cd\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\uff0c\u5e76\u5f00\u53d1\u7f13\u89e3\u7b56\u7565\u3002", "method": "1. \u7cfb\u7edf\u7814\u7a76\u9759\u6001\u548c\u52a8\u6001\u91cf\u5316\u65b9\u6cd5\u5bf9\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\u7684\u5f71\u54cd\uff1b2. \u5728\u82f1\u8bed\u3001\u6cd5\u8bed\u3001\u8377\u5170\u8bed\u3001\u897f\u73ed\u7259\u8bed\u3001\u571f\u8033\u5176\u8bed\u4e2d\u8bc4\u4f30\u516c\u5e73\u6027\uff1b3. \u5728\u82f1\u8bed\u3001\u97e9\u8bed\u3001\u963f\u62c9\u4f2f\u8bed\u4e2d\u8bc4\u4f30\u5b89\u5168\u6027\uff1b4. \u63d0\u51faCritical Weight Protection\u6280\u672f\uff0c\u8bc6\u522b\u548c\u4fdd\u62a4\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\u5173\u952e\u6743\u91cd\u3002", "result": "1. \u91cf\u5316\u4e00\u81f4\u6027\u5730\u964d\u4f4e\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\uff1b2. \u52a8\u6001\u91cf\u5316\u65b9\u6cd5\u6bd4\u9759\u6001\u91cf\u5316\u66f4\u7a33\u5b9a\uff1b3. \u516c\u5e73\u6027\u9000\u5316\u5728\u4e0d\u540c\u8bed\u8a00\u95f4\u5b58\u5728\u5dee\u5f02\uff1b4. \u5b89\u5168\u6027\u9000\u5316\u5728\u975e\u82f1\u8bed\u73af\u5883\u4e2d\u5c24\u4e3a\u663e\u8457\uff1b5. Critical Weight Protection\u80fd\u6709\u6548\u7f13\u89e3\u504f\u89c1\u548c\u5b89\u5168\u6027\u9000\u5316\uff0c\u65e0\u9700\u6602\u8d35\u7684\u91cd\u65b0\u8bad\u7ec3\u6216\u5bf9\u9f50\u3002", "conclusion": "\u91cf\u5316\u5bf9LLM\u7684\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\u6709\u8d1f\u9762\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u3002Critical Weight Protection\u6280\u672f\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7f13\u89e3\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u6548\u7387\u7684\u540c\u65f6\u7ef4\u62a4\u6a21\u578b\u7684\u53ef\u9760\u6027\uff0c\u4e3a\u91cf\u5316\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12338", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12338", "abs": "https://arxiv.org/abs/2601.12338", "authors": ["Kartikey Singh Bhandari", "Manav Ganesh", "Yashwant Viswanathan", "Archit Agrawal", "Dhruv Kumar", "Pratik Narang"], "title": "Actionable Advice from Reviews via Mixture of LoRA Experts: A Two-LLM Pipeline for Issue Extraction and Business Recommendations", "comment": null, "summary": "Customer reviews contain detailed, domain specific signals about service failures and user expectations, but converting this unstructured feedback into actionable business decisions remains difficult. We study review-to-action generation: producing concrete, implementable recommendations grounded in review text. We propose a modular two-LLM framework in which an Issue model extracts salient issues and assigns coarse themes, and an Advice model generates targeted operational fixes conditioned on the extracted issue representation. To enable specialization without expensive full fine-tuning, we adapt the Advice model using a mixture of LoRA experts strategy: multiple low-rank adapters are trained and a lightweight gating mechanism performs token-level expert mixing at inference, combining complementary expertise across issue types. We construct synthetic review-issue-advice triples from Yelp reviews (airlines and restaurants) to supervise training, and evaluate recommendations using an eight dimension operational rubric spanning actionability, specificity, feasibility, expected impact, novelty, non-redundancy, bias, and clarity. Across both domains, our approach consistently outperforms prompting-only and single-adapter baselines, yielding higher actionability and specificity while retaining favorable efficiency-quality trade-offs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4e24\u9636\u6bb5LLM\u6846\u67b6\uff0c\u901a\u8fc7\u95ee\u9898\u63d0\u53d6\u548c\u4e13\u5bb6\u6df7\u5408\u9002\u914d\u5668\u751f\u6210\u53ef\u64cd\u4f5c\u7684\u4e1a\u52a1\u5efa\u8bae\uff0c\u5728Yelp\u8bc4\u8bba\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u5ba2\u6237\u8bc4\u8bba\u5305\u542b\u4e30\u5bcc\u7684\u670d\u52a1\u5931\u8d25\u548c\u7528\u6237\u671f\u671b\u4fe1\u53f7\uff0c\u4f46\u5c06\u975e\u7ed3\u6784\u5316\u53cd\u9988\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u4e1a\u52a1\u51b3\u7b56\u4ecd\u7136\u56f0\u96be\uff0c\u9700\u8981\u81ea\u52a8\u5316\u751f\u6210\u5177\u4f53\u53ef\u884c\u7684\u5efa\u8bae\u3002", "method": "\u63d0\u51fa\u6a21\u5757\u5316\u4e24\u9636\u6bb5LLM\u6846\u67b6\uff1a1) \u95ee\u9898\u6a21\u578b\u63d0\u53d6\u5173\u952e\u95ee\u9898\u5e76\u5206\u914d\u7c97\u7c92\u5ea6\u4e3b\u9898\uff1b2) \u5efa\u8bae\u6a21\u578b\u57fa\u4e8e\u95ee\u9898\u8868\u793a\u751f\u6210\u9488\u5bf9\u6027\u64cd\u4f5c\u65b9\u6848\u3002\u91c7\u7528LoRA\u4e13\u5bb6\u6df7\u5408\u7b56\u7565\uff0c\u8bad\u7ec3\u591a\u4e2a\u4f4e\u79e9\u9002\u914d\u5668\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7\u95e8\u63a7\u673a\u5236\u5728\u63a8\u7406\u65f6\u8fdb\u884ctoken\u7ea7\u4e13\u5bb6\u6df7\u5408\u3002", "result": "\u5728Yelp\u8bc4\u8bba\uff08\u822a\u7a7a\u548c\u9910\u5385\u9886\u57df\uff09\u6784\u5efa\u7684\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4f7f\u7528\u5305\u542b8\u4e2a\u7ef4\u5ea6\u7684\u64cd\u4f5c\u8bc4\u4f30\u6807\u51c6\u3002\u8be5\u65b9\u6cd5\u5728\u884c\u52a8\u6027\u3001\u7279\u5f02\u6027\u7b49\u5173\u952e\u6307\u6807\u4e0a\u6301\u7eed\u4f18\u4e8e\u4ec5\u63d0\u793a\u548c\u5355\u9002\u914d\u5668\u57fa\u7ebf\uff0c\u540c\u65f6\u4fdd\u6301\u6548\u7387\u4e0e\u8d28\u91cf\u7684\u826f\u597d\u5e73\u8861\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e24\u9636\u6bb5\u6846\u67b6\u7ed3\u5408\u4e13\u5bb6\u6df7\u5408\u9002\u914d\u5668\u7b56\u7565\uff0c\u80fd\u591f\u6709\u6548\u4ece\u5ba2\u6237\u8bc4\u8bba\u751f\u6210\u5177\u4f53\u53ef\u64cd\u4f5c\u7684\u5efa\u8bae\uff0c\u4e3a\u4e1a\u52a1\u51b3\u7b56\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\uff0c\u5728\u591a\u4e2a\u9886\u57df\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2601.12392", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12392", "abs": "https://arxiv.org/abs/2601.12392", "authors": ["Zhentao Xia", "Yongqi Fan", "Yuxiang Chu", "Yichao Yin", "Liangliang Chen", "Tong Ruan", "Weiyan Zhang"], "title": "Psych\u0113Chat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling", "comment": null, "summary": "Large language models (LLMs) have demonstrated notable advancements in psychological counseling. However, existing models generally do not explicitly model seekers' emotion shifts across counseling sessions, a core focus in classical psychological schools. Moreover, how to align counselor models' responses with these emotion shifts while proactively mitigating safety risks remains underexplored. To bridge these gaps, we propose Psych\u0113Chat, which explicitly integrates emotion shift tracking and safety risk analysis for psychological counseling. Specifically, we employ interactive role-playing to synthesize counselor--seeker dialogues, incorporating two modules: Emotion Management Module, to capture seekers' current emotions and emotion shifts; and Risk Control Module, to anticipate seekers' subsequent reactions and identify potential risks. Furthermore, we introduce two modeling paradigms. The Agent Mode structures emotion management, risk control, and counselor responses into a collaborative multi-agent pipeline. The LLM Mode integrates these stages into a unified chain-of-thought for end-to-end inference, balancing efficiency and performance. Extensive experiments, including interactive scoring, dialogue-level evaluation, and human assessment, demonstrate that Psych\u0113Chat outperforms existing methods for emotional insight and safety control.", "AI": {"tldr": "Psych\u0113Chat\u662f\u4e00\u4e2a\u7528\u4e8e\u5fc3\u7406\u54a8\u8be2\u7684LLM\u7cfb\u7edf\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u6765\u8bbf\u8005\u60c5\u7eea\u53d8\u5316\u548c\u5b89\u5168\u6027\u98ce\u9669\u5206\u6790\u6765\u63d0\u5347\u5fc3\u7406\u54a8\u8be2\u8d28\u91cf\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u5efa\u6a21\u8303\u5f0f\uff1a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684Agent Mode\u548c\u7aef\u5230\u7aef\u63a8\u7406\u7684LLM Mode\u3002", "motivation": "\u73b0\u6709\u5fc3\u7406\u54a8\u8be2\u6a21\u578b\u901a\u5e38\u4e0d\u663e\u5f0f\u5efa\u6a21\u6765\u8bbf\u8005\u5728\u54a8\u8be2\u8fc7\u7a0b\u4e2d\u7684\u60c5\u7eea\u53d8\u5316\uff0c\u8fd9\u662f\u7ecf\u5178\u5fc3\u7406\u5b66\u6d41\u6d3e\u7684\u6838\u5fc3\u5173\u6ce8\u70b9\u3002\u540c\u65f6\uff0c\u5982\u4f55\u4f7f\u54a8\u8be2\u5e08\u6a21\u578b\u7684\u56de\u5e94\u4e0e\u8fd9\u4e9b\u60c5\u7eea\u53d8\u5316\u5bf9\u9f50\uff0c\u5e76\u4e3b\u52a8\u7f13\u89e3\u5b89\u5168\u98ce\u9669\uff0c\u8fd9\u4e9b\u95ee\u9898\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51faPsych\u0113Chat\u7cfb\u7edf\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u89d2\u8272\u626e\u6f14\u5408\u6210\u54a8\u8be2\u5e08-\u6765\u8bbf\u8005\u5bf9\u8bdd\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\u60c5\u7eea\u7ba1\u7406\u6a21\u5757\uff08\u6355\u6349\u6765\u8bbf\u8005\u5f53\u524d\u60c5\u7eea\u548c\u60c5\u7eea\u53d8\u5316\uff09\u548c\u98ce\u9669\u63a7\u5236\u6a21\u5757\uff08\u9884\u6d4b\u6765\u8bbf\u8005\u540e\u7eed\u53cd\u5e94\u5e76\u8bc6\u522b\u6f5c\u5728\u98ce\u9669\uff09\u3002\u5f15\u5165\u4e24\u79cd\u5efa\u6a21\u8303\u5f0f\uff1aAgent Mode\uff08\u5c06\u60c5\u7eea\u7ba1\u7406\u3001\u98ce\u9669\u63a7\u5236\u548c\u54a8\u8be2\u5e08\u56de\u5e94\u6784\u5efa\u4e3a\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u7ba1\u9053\uff09\u548cLLM Mode\uff08\u5c06\u8fd9\u4e9b\u9636\u6bb5\u6574\u5408\u5230\u7edf\u4e00\u7684\u601d\u7ef4\u94fe\u4e2d\u8fdb\u884c\u7aef\u5230\u7aef\u63a8\u7406\uff09\u3002", "result": "\u901a\u8fc7\u4ea4\u4e92\u5f0f\u8bc4\u5206\u3001\u5bf9\u8bdd\u7ea7\u8bc4\u4f30\u548c\u4eba\u5de5\u8bc4\u4f30\u7b49\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cPsych\u0113Chat\u5728\u60c5\u611f\u6d1e\u5bdf\u548c\u5b89\u5168\u6027\u63a7\u5236\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Psych\u0113Chat\u901a\u8fc7\u663e\u5f0f\u6574\u5408\u60c5\u7eea\u53d8\u5316\u8ffd\u8e2a\u548c\u5b89\u5168\u6027\u98ce\u9669\u5206\u6790\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5fc3\u7406\u54a8\u8be2\u6a21\u578b\u7684\u60c5\u611f\u6d1e\u5bdf\u80fd\u529b\u548c\u5b89\u5168\u6027\u63a7\u5236\uff0c\u4e3a\u5fc3\u7406\u54a8\u8be2AI\u7cfb\u7edf\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.12061", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12061", "abs": "https://arxiv.org/abs/2601.12061", "authors": ["Jinsook Lee", "Kirk Vanacore", "Zhuqian Zhou", "Jeanine Grutter", "Rene F. Kizilcec"], "title": "Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs Annotation: LLM-Assisted and Gold-Label-Free Evaluation", "comment": "Under Review for ACL 2026", "summary": "Dialogue Act (DA) annotation typically treats communicative or pedagogical intent as localized to individual utterances or turns. This leads annotators to agree on the underlying action while disagreeing on segment boundaries, reducing apparent reliability. We propose codebook-injected segmentation, which conditions boundary decisions on downstream annotation criteria, and evaluate LLM-based segmenters against standard and retrieval-augmented baselines. To assess these without gold labels, we introduce evaluation metrics for span consistency, distinctiveness, and human-AI distributional agreement. We found DA-awareness produces segments that are internally more consistent than text-only baselines. While LLMs excel at creating construct-consistent spans, coherence-based baselines remain superior at detecting global shifts in dialogue flow. Across two datasets, no single segmenter dominates. Improvements in within-segment coherence frequently trade off against boundary distinctiveness and human-AI distributional agreement. These results highlight segmentation as a consequential design choice that should be optimized for downstream objectives rather than a single performance score.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4ee3\u7801\u672c\u6ce8\u5165\u5206\u5272\u65b9\u6cd5\uff0c\u5c06\u8fb9\u754c\u51b3\u7b56\u4e0e\u4e0b\u6e38\u6807\u6ce8\u6807\u51c6\u7ed3\u5408\uff0c\u8bc4\u4f30LLM\u5206\u5272\u5668\u5728\u5bf9\u8bdd\u884c\u4e3a\u6807\u6ce8\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u4e0d\u540c\u5206\u5272\u5668\u5404\u6709\u4f18\u52a3\uff0c\u9700\u6839\u636e\u4e0b\u6e38\u76ee\u6807\u4f18\u5316\u9009\u62e9\u3002", "motivation": "\u4f20\u7edf\u5bf9\u8bdd\u884c\u4e3a\u6807\u6ce8\u5c06\u4ea4\u9645\u6216\u6559\u5b66\u610f\u56fe\u5c40\u9650\u4e8e\u5355\u4e2a\u8bdd\u8bed\u6216\u8f6e\u6b21\uff0c\u5bfc\u81f4\u6807\u6ce8\u8005\u5728\u5e95\u5c42\u52a8\u4f5c\u4e0a\u4e00\u81f4\u4f46\u5728\u7247\u6bb5\u8fb9\u754c\u4e0a\u5b58\u5728\u5206\u6b67\uff0c\u964d\u4f4e\u4e86\u8868\u9762\u53ef\u9760\u6027\u3002\u9700\u8981\u6539\u8fdb\u5206\u5272\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u6807\u6ce8\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51fa\u4ee3\u7801\u672c\u6ce8\u5165\u5206\u5272\u65b9\u6cd5\uff0c\u5c06\u8fb9\u754c\u51b3\u7b56\u6761\u4ef6\u5316\u4e8e\u4e0b\u6e38\u6807\u6ce8\u6807\u51c6\uff1b\u8bc4\u4f30LLM\u5206\u5272\u5668\u4e0e\u6807\u51c6\u548c\u68c0\u7d22\u589e\u5f3a\u57fa\u7ebf\u7684\u5bf9\u6bd4\uff1b\u5f15\u5165\u65e0\u91d1\u6807\u51c6\u8bc4\u4f30\u6307\u6807\uff1a\u8de8\u5ea6\u4e00\u81f4\u6027\u3001\u533a\u5206\u6027\u548c\u4eba\u673a\u5206\u5e03\u4e00\u81f4\u6027\u3002", "result": "DA\u611f\u77e5\u5206\u5272\u5668\u4ea7\u751f\u7684\u7247\u6bb5\u5185\u90e8\u4e00\u81f4\u6027\u4f18\u4e8e\u7eaf\u6587\u672c\u57fa\u7ebf\uff1bLLM\u64c5\u957f\u521b\u5efa\u7ed3\u6784\u4e00\u81f4\u7684\u8de8\u5ea6\uff0c\u4f46\u57fa\u4e8e\u8fde\u8d2f\u6027\u7684\u57fa\u7ebf\u5728\u68c0\u6d4b\u5bf9\u8bdd\u6d41\u5168\u5c40\u8f6c\u53d8\u65b9\u9762\u66f4\u4f18\uff1b\u4e24\u4e2a\u6570\u636e\u96c6\u4e2d\u6ca1\u6709\u5355\u4e00\u5206\u5272\u5668\u5360\u4e3b\u5bfc\uff1b\u7247\u6bb5\u5185\u8fde\u8d2f\u6027\u7684\u63d0\u5347\u5e38\u4ee5\u8fb9\u754c\u533a\u5206\u6027\u548c\u4eba\u673a\u5206\u5e03\u4e00\u81f4\u6027\u4e3a\u4ee3\u4ef7\u3002", "conclusion": "\u5206\u5272\u662f\u91cd\u8981\u7684\u8bbe\u8ba1\u9009\u62e9\uff0c\u5e94\u6839\u636e\u4e0b\u6e38\u76ee\u6807\u4f18\u5316\u800c\u975e\u5355\u4e00\u6027\u80fd\u5206\u6570\uff1b\u4e0d\u540c\u5206\u5272\u65b9\u6cd5\u5404\u6709\u4f18\u52bf\uff0c\u9700\u8981\u6743\u8861\u7247\u6bb5\u5185\u8fde\u8d2f\u6027\u3001\u8fb9\u754c\u533a\u5206\u6027\u548c\u5206\u5e03\u4e00\u81f4\u6027\u7b49\u6307\u6807\u3002"}}
{"id": "2601.12410", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12410", "abs": "https://arxiv.org/abs/2601.12410", "authors": ["Dingyi Yang", "Junqi Zhao", "Xue Li", "Ce Li", "Boyang Li"], "title": "Are LLMs Smarter Than Chimpanzees? An Evaluation on Perspective Taking and Knowledge State Estimation", "comment": "23 pages, 11 figures", "summary": "Cognitive anthropology suggests that the distinction of human intelligence lies in the ability to infer other individuals' knowledge states and understand their intentions. In comparison, our closest animal relative, chimpanzees, lack the capacity to do so. With this paper, we aim to evaluate LLM performance in the area of knowledge state tracking and estimation. We design two tasks to test (1) if LLMs can detect when story characters, through their actions, demonstrate knowledge they should not possess, and (2) if LLMs can predict story characters' next actions based on their own knowledge vs. objective truths they do not know. Results reveal that most current state-of-the-art LLMs achieve near-random performance on both tasks, and are substantially inferior to humans. We argue future LLM research should place more weight on the abilities of knowledge estimation and intention understanding.", "AI": {"tldr": "LLMs\u5728\u77e5\u8bc6\u72b6\u6001\u8ffd\u8e2a\u548c\u4f30\u8ba1\u4efb\u52a1\u4e2d\u8868\u73b0\u63a5\u8fd1\u968f\u673a\u6c34\u5e73\uff0c\u663e\u8457\u4f4e\u4e8e\u4eba\u7c7b\u8868\u73b0\uff0c\u672a\u6765\u7814\u7a76\u5e94\u66f4\u91cd\u89c6\u77e5\u8bc6\u4f30\u8ba1\u548c\u610f\u56fe\u7406\u89e3\u80fd\u529b", "motivation": "\u8ba4\u77e5\u4eba\u7c7b\u5b66\u8ba4\u4e3a\u4eba\u7c7b\u667a\u80fd\u7684\u5173\u952e\u5728\u4e8e\u63a8\u65ad\u4ed6\u4eba\u77e5\u8bc6\u72b6\u6001\u548c\u7406\u89e3\u610f\u56fe\u7684\u80fd\u529b\uff0c\u800c\u9ed1\u7329\u7329\u7b49\u52a8\u7269\u7f3a\u4e4f\u8fd9\u79cd\u80fd\u529b\u3002\u672c\u6587\u65e8\u5728\u8bc4\u4f30LLM\u5728\u77e5\u8bc6\u72b6\u6001\u8ffd\u8e2a\u548c\u4f30\u8ba1\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u8bbe\u8ba1\u4e24\u4e2a\u4efb\u52a1\u6d4b\u8bd5LLM\uff1a(1)\u68c0\u6d4b\u6545\u4e8b\u89d2\u8272\u662f\u5426\u901a\u8fc7\u884c\u52a8\u8868\u73b0\u51fa\u672c\u4e0d\u5e94\u62e5\u6709\u7684\u77e5\u8bc6\uff1b(2)\u57fa\u4e8e\u89d2\u8272\u81ea\u8eab\u77e5\u8bc6vs\u5ba2\u89c2\u4e8b\u5b9e\u9884\u6d4b\u89d2\u8272\u4e0b\u4e00\u6b65\u884c\u52a8\u3002", "result": "\u5927\u591a\u6570\u5f53\u524d\u6700\u5148\u8fdb\u7684LLM\u5728\u4e24\u4e2a\u4efb\u52a1\u4e0a\u90fd\u8fbe\u5230\u63a5\u8fd1\u968f\u673a\u7684\u6027\u80fd\u6c34\u5e73\uff0c\u663e\u8457\u4f4e\u4e8e\u4eba\u7c7b\u8868\u73b0\u3002", "conclusion": "\u672a\u6765LLM\u7814\u7a76\u5e94\u66f4\u91cd\u89c6\u77e5\u8bc6\u4f30\u8ba1\u548c\u610f\u56fe\u7406\u89e3\u80fd\u529b\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.12068", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12068", "abs": "https://arxiv.org/abs/2601.12068", "authors": ["Rowzatul Zannat", "Abdullah Al Shafi", "Abdul Muntakim"], "title": "Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset", "comment": null, "summary": "Increased access to reliable health information is essential for non-English-speaking populations, yet resources in Bangla for disease prediction remain limited. This study addresses this gap by developing a comprehensive Bangla symptoms-disease dataset containing 758 unique symptom-disease relationships spanning 85 diseases. To ensure transparency and reproducibility, we also make our dataset publicly available. The dataset enables the prediction of diseases based on Bangla symptom inputs, supporting healthcare accessibility for Bengali-speaking populations. Using this dataset, we evaluated multiple machine learning models to predict diseases based on symptoms provided in Bangla and analyzed their performance on our dataset. Both soft and hard voting ensemble approaches combining top-performing models achieved 98\\% accuracy, demonstrating superior robustness and generalization. Our work establishes a foundational resource for disease prediction in Bangla, paving the way for future advancements in localized health informatics and diagnostic tools. This contribution aims to enhance equitable access to health information for Bangla-speaking communities, particularly for early disease detection and healthcare interventions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u521b\u5efa\u4e86\u9996\u4e2a\u5168\u9762\u7684\u5b5f\u52a0\u62c9\u8bed\u75c7\u72b6-\u75be\u75c5\u6570\u636e\u96c6\uff08\u5305\u542b758\u4e2a\u75c7\u72b6-\u75be\u75c5\u5173\u7cfb\uff0c\u6db5\u76d685\u79cd\u75be\u75c5\uff09\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u75c7\u72b6\u7684\u75be\u75c5\u9884\u6d4b\u6a21\u578b\uff0c\u96c6\u6210\u65b9\u6cd5\u8fbe\u523098%\u51c6\u786e\u7387\u3002", "motivation": "\u9488\u5bf9\u5b5f\u52a0\u62c9\u8bed\u4eba\u7fa4\u5065\u5eb7\u4fe1\u606f\u83b7\u53d6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u7f3a\u4e4f\u5b5f\u52a0\u62c9\u8bed\u75be\u75c5\u9884\u6d4b\u8d44\u6e90\uff0c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u9ad8\u5b5f\u52a0\u62c9\u8bed\u793e\u533a\u7684\u533b\u7597\u53ef\u53ca\u6027\u3002", "method": "1. \u6784\u5efa\u5305\u542b758\u4e2a\u72ec\u7279\u75c7\u72b6-\u75be\u75c5\u5173\u7cfb\u3001\u6db5\u76d685\u79cd\u75be\u75c5\u7684\u5b5f\u52a0\u62c9\u8bed\u6570\u636e\u96c6\uff1b2. \u516c\u5f00\u6570\u636e\u96c6\u4ee5\u786e\u4fdd\u900f\u660e\u5ea6\u548c\u53ef\u590d\u73b0\u6027\uff1b3. \u8bc4\u4f30\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u5b5f\u52a0\u62c9\u8bed\u75c7\u72b6\u8f93\u5165\u4e0b\u7684\u75be\u75c5\u9884\u6d4b\u6027\u80fd\uff1b4. \u91c7\u7528\u8f6f\u6295\u7968\u548c\u786c\u6295\u7968\u96c6\u6210\u65b9\u6cd5\u7ed3\u5408\u8868\u73b0\u6700\u4f73\u7684\u6a21\u578b\u3002", "result": "\u8f6f\u6295\u7968\u548c\u786c\u6295\u7968\u96c6\u6210\u65b9\u6cd5\u5747\u8fbe\u523098%\u7684\u51c6\u786e\u7387\uff0c\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u5b5f\u52a0\u62c9\u8bed\u75be\u75c5\u9884\u6d4b\u5efa\u7acb\u4e86\u57fa\u51c6\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5b5f\u52a0\u62c9\u8bed\u75be\u75c5\u9884\u6d4b\u63d0\u4f9b\u4e86\u57fa\u7840\u8d44\u6e90\uff0c\u63a8\u52a8\u4e86\u672c\u5730\u5316\u5065\u5eb7\u4fe1\u606f\u5b66\u548c\u8bca\u65ad\u5de5\u5177\u7684\u53d1\u5c55\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u5b5f\u52a0\u62c9\u8bed\u793e\u533a\u5728\u65e9\u671f\u75be\u75c5\u68c0\u6d4b\u548c\u533b\u7597\u5e72\u9884\u65b9\u9762\u7684\u516c\u5e73\u83b7\u53d6\u3002"}}
{"id": "2601.12444", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.12444", "abs": "https://arxiv.org/abs/2601.12444", "authors": ["Hui Yang", "Jiaoyan Chen", "Uli Sattler"], "title": "Large Language Model for OWL Proofs", "comment": null, "summary": "The ability of Large Language Models (LLMs) to perform reasoning tasks such as deduction has been widely investigated in recent years. Yet, their capacity to generate proofs-faithful, human-readable explanations of why conclusions follow-remains largely under explored. In this work, we study proof generation in the context of OWL ontologies, which are widely adopted for representing and reasoning over complex knowledge, by developing an automated dataset construction and evaluation framework. Our evaluation encompassing three sequential tasks for complete proving: Extraction, Simplification, and Explanation, as well as an additional task of assessing Logic Completeness of the premise. Through extensive experiments on widely used reasoning LLMs, we achieve important findings including: (1) Some models achieve overall strong results but remain limited on complex cases; (2) Logical complexity, rather than representation format (formal logic language versus natural language), is the dominant factor shaping LLM performance; and (3) Noise and incompleteness in input data substantially diminish LLMs' performance. Together, these results underscore both the promise of LLMs for explanation with rigorous logics and the gap of supporting resilient reasoning under complex or imperfect conditions. Code and data are available at https://github.com/HuiYang1997/LLMOwlR.", "code_url": "https://github.com/HuiYang1997/LLMOwlR", "code_stars": 1, "code_last_update": "2025-10-01", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728OWL\u672c\u4f53\u8bba\u4e2d\u751f\u6210\u5fe0\u5b9e\u3001\u53ef\u8bfb\u8bc1\u660e\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u590d\u6742\u6848\u4f8b\u4e2d\u4ecd\u6709\u5c40\u9650\uff0c\u903b\u8f91\u590d\u6742\u6027\u662f\u4e3b\u8981\u5f71\u54cd\u56e0\u7d20\uff0c\u6570\u636e\u566a\u58f0\u4f1a\u663e\u8457\u964d\u4f4e\u6027\u80fd\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5b83\u4eec\u5728\u751f\u6210\u5fe0\u5b9e\u3001\u4eba\u7c7b\u53ef\u8bfb\u7684\u8bc1\u660e\uff08\u89e3\u91ca\u7ed3\u8bba\u4e3a\u4f55\u6210\u7acb\uff09\u65b9\u9762\u7684\u80fd\u529b\u4ecd\u672a\u5145\u5206\u63a2\u7d22\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30LLMs\u5728OWL\u672c\u4f53\u8bba\u8fd9\u4e00\u5e7f\u6cdb\u7528\u4e8e\u8868\u793a\u548c\u63a8\u7406\u590d\u6742\u77e5\u8bc6\u7684\u8bed\u5883\u4e0b\u7684\u8bc1\u660e\u751f\u6210\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u4e86\u81ea\u52a8\u5316\u6570\u636e\u96c6\u6784\u5efa\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u8bc4\u4f30\u4e09\u4e2a\u987a\u5e8f\u4efb\u52a1\uff1a\u63d0\u53d6\u3001\u7b80\u5316\u548c\u89e3\u91ca\uff0c\u4ee5\u53ca\u4e00\u4e2a\u989d\u5916\u4efb\u52a1\uff1a\u8bc4\u4f30\u524d\u63d0\u7684\u903b\u8f91\u5b8c\u5907\u6027\u3002\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u63a8\u7406LLMs\u4e0a\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u9a8c\u3002", "result": "1. \u67d0\u4e9b\u6a21\u578b\u603b\u4f53\u8868\u73b0\u5f3a\u52b2\uff0c\u4f46\u5728\u590d\u6742\u6848\u4f8b\u4e2d\u4ecd\u6709\u5c40\u9650\uff1b2. \u903b\u8f91\u590d\u6742\u6027\uff08\u800c\u975e\u8868\u793a\u683c\u5f0f\uff1a\u5f62\u5f0f\u903b\u8f91\u8bed\u8a00vs\u81ea\u7136\u8bed\u8a00\uff09\u662f\u5f71\u54cdLLM\u6027\u80fd\u7684\u4e3b\u5bfc\u56e0\u7d20\uff1b3. \u8f93\u5165\u6570\u636e\u4e2d\u7684\u566a\u58f0\u548c\u4e0d\u5b8c\u6574\u6027\u4f1a\u663e\u8457\u964d\u4f4eLLMs\u7684\u6027\u80fd\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u65e2\u663e\u793a\u4e86LLMs\u5728\u4e25\u683c\u903b\u8f91\u89e3\u91ca\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e5f\u63ed\u793a\u4e86\u5728\u590d\u6742\u6216\u4e0d\u5b8c\u7f8e\u6761\u4ef6\u4e0b\u652f\u6301\u5f39\u6027\u63a8\u7406\u7684\u5dee\u8ddd\u3002\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.12075", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12075", "abs": "https://arxiv.org/abs/2601.12075", "authors": ["Mehrdad Farahani", "Franziska Penzkofer", "Richard Johansson"], "title": "To Copy or Not to Copy: Copying Is Easier to Induce Than Recall", "comment": null, "summary": "Language models used in retrieval-augmented settings must arbitrate between parametric knowledge stored in their weights and contextual information in the prompt. This work presents a mechanistic study of that choice by extracting an \\emph{arbitration vector} from model activations on a curated dataset designed to disentangle (i) irrelevant contexts that elicit parametric recall and (ii) relevant but false contexts that elicit copying. The vector is computed as the residual-stream centroid difference between these regimes across 27 relations, and is injected as an additive intervention at selected layers and token spans to steer behavior in two directions: Copy$\\rightarrow$Recall (suppressing context use) and Recall$\\rightarrow$Copy (inducing the model to copy any token from the context). Experiments on two architectures (decoder-only and encoder/decoder) and two open-domain QA benchmarks show consistent behavior shifts under moderate scaling while monitoring accuracy and fluency. Mechanistic analyses of attention routing, MLP contributions, and layer-wise probability trajectories reveal an asymmetry: inducing copying is an easy ``reactivation'' process that can be triggered at different locations in the input, while restoring recall is a ``suppression'' process that is more fragile and strongly tied to object-token interventions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u63d0\u53d6\"\u4ef2\u88c1\u5411\u91cf\"\u6765\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u7d22\u589e\u5f3a\u8bbe\u7f6e\u4e2d\u5982\u4f55\u6743\u8861\u53c2\u6570\u77e5\u8bc6\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u53d1\u73b0\u8bf1\u5bfc\u590d\u5236\u6bd4\u6062\u590d\u53ec\u56de\u66f4\u5bb9\u6613\u5b9e\u73b0", "motivation": "\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u7d22\u589e\u5f3a\u8bbe\u7f6e\u4e2d\u5982\u4f55\u4ef2\u88c1\u5b58\u50a8\u5728\u6743\u91cd\u4e2d\u7684\u53c2\u6570\u77e5\u8bc6\u4e0e\u63d0\u793a\u4e2d\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u7406\u89e3\u6a21\u578b\u5728\u8fd9\u4e24\u79cd\u77e5\u8bc6\u6e90\u4e4b\u95f4\u7684\u9009\u62e9\u673a\u5236", "method": "\u4ece\u6a21\u578b\u6fc0\u6d3b\u4e2d\u63d0\u53d6\u4ef2\u88c1\u5411\u91cf\uff1a\u5728\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6570\u636e\u96c6\u4e0a\u8ba1\u7b97\u6b8b\u5dee\u6d41\u8d28\u5fc3\u5dee\u5f02\uff0c\u533a\u5206\u65e0\u5173\u4e0a\u4e0b\u6587\uff08\u5f15\u53d1\u53c2\u6570\u53ec\u56de\uff09\u548c\u76f8\u5173\u4f46\u9519\u8bef\u4e0a\u4e0b\u6587\uff08\u5f15\u53d1\u590d\u5236\uff09\u3002\u5c06\u8be5\u5411\u91cf\u4f5c\u4e3a\u52a0\u6027\u5e72\u9884\u6ce8\u5165\u9009\u5b9a\u5c42\u548c\u6807\u8bb0\u8de8\u5ea6\uff0c\u4ee5\u5f15\u5bfc\u884c\u4e3a\u5728\u4e24\u4e2a\u65b9\u5411\u8f6c\u53d8\uff1a\u590d\u5236\u2192\u53ec\u56de\uff08\u6291\u5236\u4e0a\u4e0b\u6587\u4f7f\u7528\uff09\u548c\u53ec\u56de\u2192\u590d\u5236\uff08\u8bf1\u5bfc\u6a21\u578b\u590d\u5236\u4e0a\u4e0b\u6587\u4e2d\u7684\u4efb\u4f55\u6807\u8bb0\uff09", "result": "\u5728\u4e24\u4e2a\u67b6\u6784\uff08\u4ec5\u89e3\u7801\u5668\u548c\u7f16\u7801\u5668/\u89e3\u7801\u5668\uff09\u548c\u4e24\u4e2a\u5f00\u653e\u57dfQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728\u9002\u5ea6\u6269\u5c55\u4e0b\u89c2\u5bdf\u5230\u4e00\u81f4\u7684\u884c\u4e3a\u8f6c\u53d8\uff0c\u540c\u65f6\u76d1\u63a7\u51c6\u786e\u6027\u548c\u6d41\u7545\u6027\u3002\u673a\u5236\u5206\u6790\u663e\u793a\u4e0d\u5bf9\u79f0\u6027\uff1a\u8bf1\u5bfc\u590d\u5236\u662f\u5bb9\u6613\u7684\"\u518d\u6fc0\u6d3b\"\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u5728\u8f93\u5165\u7684\u4e0d\u540c\u4f4d\u7f6e\u89e6\u53d1\uff1b\u800c\u6062\u590d\u53ec\u56de\u662f\u66f4\u8106\u5f31\u7684\"\u6291\u5236\"\u8fc7\u7a0b\uff0c\u4e0e\u5bf9\u8c61\u6807\u8bb0\u5e72\u9884\u7d27\u5bc6\u76f8\u5173", "conclusion": "\u8bed\u8a00\u6a21\u578b\u5728\u53c2\u6570\u77e5\u8bc6\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u4e4b\u95f4\u7684\u4ef2\u88c1\u673a\u5236\u5b58\u5728\u4e0d\u5bf9\u79f0\u6027\uff0c\u8bf1\u5bfc\u590d\u5236\u76f8\u5bf9\u5bb9\u6613\u5b9e\u73b0\uff0c\u800c\u6291\u5236\u4e0a\u4e0b\u6587\u4f7f\u7528\u4ee5\u6062\u590d\u53c2\u6570\u53ec\u56de\u5219\u66f4\u4e3a\u8106\u5f31\uff0c\u8fd9\u4e3a\u7406\u89e3\u6a21\u578b\u5728\u68c0\u7d22\u589e\u5f3a\u8bbe\u7f6e\u4e2d\u7684\u884c\u4e3a\u63d0\u4f9b\u4e86\u673a\u5236\u6027\u89c1\u89e3"}}
{"id": "2601.12499", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12499", "abs": "https://arxiv.org/abs/2601.12499", "authors": ["Meiru Zhang", "Zaiqiao Meng", "Nigel Collier"], "title": "Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck", "comment": "preprint", "summary": "Despite scaling to massive context windows, Large Language Models (LLMs) struggle with multi-hop reasoning due to inherent position bias, which causes them to overlook information at certain positions. Whether these failures stem from an inability to locate evidence (recognition failure) or integrate it (synthesis failure) is unclear. We introduce Multi-Focus Attention Instruction (MFAI), a semantic probe to disentangle these mechanisms by explicitly steering attention towards selected positions. Across 5 LLMs on two multi-hop QA tasks (MuSiQue and NeoQA), we establish the \"Weakest Link Law\": multi-hop reasoning performance collapses to the performance level of the least visible evidence. Crucially, this failure is governed by absolute position rather than the linear distance between facts (performance variance $<3%$). We further identify a duality in attention steering: while matched MFAI resolves recognition bottlenecks, improving accuracy by up to 11.5% in low-visibility positions, misleading MFAI triggers confusion in real-world tasks but is successfully filtered in synthetic tasks. Finally, we demonstrate that \"thinking\" models that utilize System-2 reasoning, effectively locate and integrate the required information, matching gold-only baselines even in noisy, long-context settings.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMFAI\u65b9\u6cd5\u63a2\u7a76LLMs\u591a\u8df3\u63a8\u7406\u5931\u8d25\u539f\u56e0\uff0c\u53d1\u73b0\"\u6700\u5f31\u73af\u8282\u5b9a\u5f8b\"\uff1a\u591a\u8df3\u63a8\u7406\u6027\u80fd\u53d7\u9650\u4e8e\u6700\u4e0d\u663e\u8457\u8bc1\u636e\u7684\u53ef\u89c1\u6027\uff0c\u4e14\u5931\u8d25\u7531\u7edd\u5bf9\u4f4d\u7f6e\u800c\u975e\u4e8b\u5b9e\u95f4\u8ddd\u79bb\u51b3\u5b9a\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5177\u6709\u5927\u89c4\u6a21\u4e0a\u4e0b\u6587\u7a97\u53e3\uff0c\u4f46\u5728\u591a\u8df3\u63a8\u7406\u4e2d\u5b58\u5728\u4f4d\u7f6e\u504f\u89c1\u95ee\u9898\uff0c\u5bfc\u81f4\u5ffd\u7565\u67d0\u4e9b\u4f4d\u7f6e\u7684\u4fe1\u606f\u3002\u9700\u8981\u533a\u5206\u8fd9\u79cd\u5931\u8d25\u662f\u7531\u4e8e\u65e0\u6cd5\u5b9a\u4f4d\u8bc1\u636e\uff08\u8bc6\u522b\u5931\u8d25\uff09\u8fd8\u662f\u65e0\u6cd5\u6574\u5408\u8bc1\u636e\uff08\u5408\u6210\u5931\u8d25\uff09\u3002", "method": "\u5f15\u5165\u591a\u7126\u70b9\u6ce8\u610f\u529b\u6307\u4ee4\uff08MFAI\uff09\u4f5c\u4e3a\u8bed\u4e49\u63a2\u9488\uff0c\u901a\u8fc7\u663e\u5f0f\u5f15\u5bfc\u6ce8\u610f\u529b\u5230\u9009\u5b9a\u4f4d\u7f6e\u6765\u89e3\u8026\u8bc6\u522b\u548c\u5408\u6210\u673a\u5236\u3002\u57285\u4e2aLLMs\u4e0a\u6d4b\u8bd5\u4e24\u4e2a\u591a\u8df3QA\u4efb\u52a1\uff08MuSiQue\u548cNeoQA\uff09\u3002", "result": "1. \u786e\u7acb\"\u6700\u5f31\u73af\u8282\u5b9a\u5f8b\"\uff1a\u591a\u8df3\u63a8\u7406\u6027\u80fd\u5d29\u6e83\u5230\u6700\u4e0d\u663e\u8457\u8bc1\u636e\u7684\u6027\u80fd\u6c34\u5e73\uff1b2. \u5931\u8d25\u7531\u7edd\u5bf9\u4f4d\u7f6e\u800c\u975e\u4e8b\u5b9e\u95f4\u7ebf\u6027\u8ddd\u79bb\u51b3\u5b9a\uff08\u6027\u80fd\u65b9\u5dee<3%\uff09\uff1b3. MFAI\u5339\u914d\u65f6\u53ef\u89e3\u51b3\u8bc6\u522b\u74f6\u9888\uff0c\u5728\u4f4e\u53ef\u89c1\u6027\u4f4d\u7f6e\u63d0\u5347\u51c6\u786e\u7387\u8fbe11.5%\uff1b4. \u8bef\u5bfc\u6027MFAI\u5728\u771f\u5b9e\u4efb\u52a1\u4e2d\u5f15\u53d1\u6df7\u6dc6\u4f46\u5728\u5408\u6210\u4efb\u52a1\u4e2d\u88ab\u6210\u529f\u8fc7\u6ee4\uff1b5. \u4f7f\u7528\u7cfb\u7edf2\u63a8\u7406\u7684\"\u601d\u8003\"\u6a21\u578b\u80fd\u6709\u6548\u5b9a\u4f4d\u548c\u6574\u5408\u4fe1\u606f\uff0c\u5728\u566a\u58f0\u957f\u4e0a\u4e0b\u6587\u8bbe\u7f6e\u4e2d\u5339\u914d\u9ec4\u91d1\u57fa\u7ebf\u3002", "conclusion": "LLMs\u7684\u591a\u8df3\u63a8\u7406\u5931\u8d25\u4e3b\u8981\u7531\u8bc6\u522b\u74f6\u9888\u800c\u975e\u5408\u6210\u5931\u8d25\u9a71\u52a8\uff0c\u4f4d\u7f6e\u504f\u89c1\u662f\u5173\u952e\u56e0\u7d20\u3002MFAI\u80fd\u6709\u6548\u8bca\u65ad\u548c\u7f13\u89e3\u8bc6\u522b\u95ee\u9898\uff0c\u800c\u7cfb\u7edf2\u63a8\u7406\u6a21\u578b\u80fd\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u5b9e\u73b0\u7a33\u5065\u7684\u591a\u8df3\u63a8\u7406\u3002"}}
{"id": "2601.12538", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12538", "abs": "https://arxiv.org/abs/2601.12538", "authors": ["Tianxin Wei", "Ting-Wei Li", "Zhining Liu", "Xuying Ning", "Ze Yang", "Jiaru Zou", "Zhichen Zeng", "Ruizhong Qiu", "Xiao Lin", "Dongqi Fu", "Zihao Li", "Mengting Ai", "Duo Zhou", "Wenxuan Bao", "Yunzhe Li", "Gaotang Li", "Cheng Qian", "Yu Wang", "Xiangru Tang", "Yin Xiao", "Liri Fang", "Hui Liu", "Xianfeng Tang", "Yuji Zhang", "Chi Wang", "Jiaxuan You", "Heng Ji", "Hanghang Tong", "Jingrui He"], "title": "Agentic Reasoning for Large Language Models", "comment": "Project: https://github.com/weitianxin/Awesome-Agentic-Reasoning", "summary": "Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, they struggle in open-ended and dynamic environments. Agentic reasoning marks a paradigm shift by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. In this survey, we organize agentic reasoning along three complementary dimensions. First, we characterize environmental dynamics through three layers: foundational agentic reasoning, which establishes core single-agent capabilities including planning, tool use, and search in stable environments; self-evolving agentic reasoning, which studies how agents refine these capabilities through feedback, memory, and adaptation; and collective multi-agent reasoning, which extends intelligence to collaborative settings involving coordination, knowledge sharing, and shared goals. Across these layers, we distinguish in-context reasoning, which scales test-time interaction through structured orchestration, from post-training reasoning, which optimizes behaviors via reinforcement learning and supervised fine-tuning. We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. This survey synthesizes agentic reasoning methods into a unified roadmap bridging thought and action, and outlines open challenges and future directions, including personalization, long-horizon interaction, world modeling, scalable multi-agent training, and governance for real-world deployment.", "AI": {"tldr": "\u8be5\u7efc\u8ff0\u5c06\u667a\u80fd\u4f53\u63a8\u7406\u7ec4\u7ec7\u4e3a\u4e09\u4e2a\u4e92\u8865\u7ef4\u5ea6\uff1a\u57fa\u7840\u667a\u80fd\u4f53\u63a8\u7406\uff08\u5355\u667a\u80fd\u4f53\u80fd\u529b\uff09\u3001\u81ea\u6f14\u5316\u667a\u80fd\u4f53\u63a8\u7406\uff08\u901a\u8fc7\u53cd\u9988\u548c\u8bb0\u5fc6\u8fdb\u884c\u9002\u5e94\uff09\u548c\u96c6\u4f53\u591a\u667a\u80fd\u4f53\u63a8\u7406\uff08\u534f\u4f5c\u73af\u5883\uff09\uff0c\u5e76\u533a\u5206\u4e0a\u4e0b\u6587\u63a8\u7406\u4e0e\u540e\u8bad\u7ec3\u63a8\u7406\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5c01\u95ed\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5728\u5f00\u653e\u548c\u52a8\u6001\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002\u667a\u80fd\u4f53\u63a8\u7406\u901a\u8fc7\u5c06LLMs\u91cd\u6784\u4e3a\u80fd\u591f\u89c4\u5212\u3001\u884c\u52a8\u548c\u6301\u7eed\u5b66\u4e60\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\uff0c\u5b9e\u73b0\u4e86\u8303\u5f0f\u8f6c\u53d8\uff0c\u65e8\u5728\u89e3\u51b3LLMs\u5728\u5f00\u653e\u73af\u5883\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u8be5\u7efc\u8ff0\u91c7\u7528\u4e09\u7ef4\u6846\u67b6\u7ec4\u7ec7\u667a\u80fd\u4f53\u63a8\u7406\uff1a1\uff09\u57fa\u7840\u667a\u80fd\u4f53\u63a8\u7406\uff08\u5355\u667a\u80fd\u4f53\u5728\u7a33\u5b9a\u73af\u5883\u4e2d\u7684\u89c4\u5212\u3001\u5de5\u5177\u4f7f\u7528\u548c\u641c\u7d22\uff09\uff1b2\uff09\u81ea\u6f14\u5316\u667a\u80fd\u4f53\u63a8\u7406\uff08\u901a\u8fc7\u53cd\u9988\u3001\u8bb0\u5fc6\u548c\u9002\u5e94\u673a\u5236\u4f18\u5316\u80fd\u529b\uff09\uff1b3\uff09\u96c6\u4f53\u591a\u667a\u80fd\u4f53\u63a8\u7406\uff08\u534f\u4f5c\u73af\u5883\u4e2d\u7684\u534f\u8c03\u3001\u77e5\u8bc6\u5171\u4eab\u548c\u5171\u540c\u76ee\u6807\uff09\u3002\u540c\u65f6\u533a\u5206\u4e0a\u4e0b\u6587\u63a8\u7406\uff08\u901a\u8fc7\u7ed3\u6784\u5316\u7f16\u6392\u6269\u5c55\u6d4b\u8bd5\u65f6\u4ea4\u4e92\uff09\u548c\u540e\u8bad\u7ec3\u63a8\u7406\uff08\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548c\u76d1\u7763\u5fae\u8c03\u4f18\u5316\u884c\u4e3a\uff09\u3002", "result": "\u7efc\u8ff0\u7cfb\u7edf\u6027\u5730\u56de\u987e\u4e86\u667a\u80fd\u4f53\u63a8\u7406\u6846\u67b6\u5728\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u4ee3\u8868\u6027\u5de5\u4f5c\uff0c\u6db5\u76d6\u79d1\u5b66\u3001\u673a\u5668\u4eba\u3001\u533b\u7597\u4fdd\u5065\u3001\u81ea\u4e3b\u7814\u7a76\u548c\u6570\u5b66\u7b49\u9886\u57df\uff0c\u5c06\u667a\u80fd\u4f53\u63a8\u7406\u65b9\u6cd5\u7efc\u5408\u6210\u4e00\u4e2a\u7edf\u4e00\u7684\u8def\u7ebf\u56fe\uff0c\u8fde\u63a5\u601d\u7ef4\u4e0e\u884c\u52a8\u3002", "conclusion": "\u667a\u80fd\u4f53\u63a8\u7406\u4ee3\u8868\u4e86\u8fde\u63a5\u601d\u7ef4\u4e0e\u884c\u52a8\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u8be5\u7efc\u8ff0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7ec4\u7ec7\u6846\u67b6\u3002\u672a\u6765\u6311\u6218\u5305\u62ec\u4e2a\u6027\u5316\u3001\u957f\u65f6\u7a0b\u4ea4\u4e92\u3001\u4e16\u754c\u5efa\u6a21\u3001\u53ef\u6269\u5c55\u7684\u591a\u667a\u80fd\u4f53\u8bad\u7ec3\u4ee5\u53ca\u73b0\u5b9e\u4e16\u754c\u90e8\u7f72\u7684\u6cbb\u7406\u95ee\u9898\u3002"}}
{"id": "2601.12099", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12099", "abs": "https://arxiv.org/abs/2601.12099", "authors": ["Leonardo S. Goodall", "Dor Shilton", "Daniel A. Mullins", "Harvey Whitehouse"], "title": "Large language models struggle with ethnographic text annotation", "comment": null, "summary": "Large language models (LLMs) have shown promise for automated text annotation, raising hopes that they might accelerate cross-cultural research by extracting structured data from ethnographic texts. We evaluated 7 state-of-the-art LLMs on their ability to annotate 121 ritual features across 567 ethnographic excerpts. Performance was limited, falling well below levels required for reliable automated annotation. Longer texts, features requiring ordinal distinctions, and ambiguous constructs proved particularly difficult. Human inter-coder reliability set an approximate ceiling on LLM accuracy: features that human coders found difficult to agree upon were also difficult for LLMs. Yet even on features where humans reliably agreed, models fell short of human performance. Our findings suggest that LLMs cannot yet substitute for human expertise in ethnographic annotation.", "AI": {"tldr": "\u8bc4\u4f307\u4e2a\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u5728567\u4e2a\u6c11\u65cf\u5fd7\u6587\u672c\u7247\u6bb5\u4e0a\u6807\u6ce8121\u4e2a\u4eea\u5f0f\u7279\u5f81\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u6027\u80fd\u6709\u9650\uff0c\u65e0\u6cd5\u66ff\u4ee3\u4eba\u7c7b\u4e13\u5bb6\u8fdb\u884c\u6c11\u65cf\u5fd7\u6807\u6ce8", "motivation": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u6587\u672c\u6807\u6ce8\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u80fd\u5426\u52a0\u901f\u8de8\u6587\u5316\u7814\u7a76\uff0c\u4ece\u6c11\u65cf\u5fd7\u6587\u672c\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u6570\u636e", "method": "\u4f7f\u75287\u4e2a\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5728567\u4e2a\u6c11\u65cf\u5fd7\u6587\u672c\u7247\u6bb5\u4e0a\u8bc4\u4f30\u5176\u5bf9121\u4e2a\u4eea\u5f0f\u7279\u5f81\u7684\u6807\u6ce8\u80fd\u529b\uff0c\u5e76\u4e0e\u4eba\u7c7b\u7f16\u7801\u8005\u7684\u53ef\u9760\u6027\u8fdb\u884c\u6bd4\u8f83", "result": "LLM\u6027\u80fd\u6709\u9650\uff0c\u8fdc\u4f4e\u4e8e\u53ef\u9760\u81ea\u52a8\u5316\u6807\u6ce8\u6240\u9700\u6c34\u5e73\uff1b\u957f\u6587\u672c\u3001\u9700\u8981\u5e8f\u6570\u533a\u5206\u7684\u7279\u5f81\u548c\u6a21\u7cca\u6982\u5ff5\u7279\u522b\u56f0\u96be\uff1b\u4eba\u7c7b\u7f16\u7801\u8005\u53ef\u9760\u6027\u8bbe\u5b9a\u4e86LLM\u51c6\u786e\u6027\u7684\u8fd1\u4f3c\u4e0a\u9650\uff1b\u5373\u4f7f\u5728\u4eba\u7c7b\u7f16\u7801\u8005\u80fd\u53ef\u9760\u8fbe\u6210\u4e00\u81f4\u7684\u7279\u5f81\u4e0a\uff0c\u6a21\u578b\u8868\u73b0\u4e5f\u4f4e\u4e8e\u4eba\u7c7b", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u76ee\u524d\u5c1a\u65e0\u6cd5\u66ff\u4ee3\u4eba\u7c7b\u4e13\u5bb6\u8fdb\u884c\u6c11\u65cf\u5fd7\u6807\u6ce8\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u624d\u80fd\u7528\u4e8e\u8de8\u6587\u5316\u7814\u7a76\u7684\u81ea\u52a8\u5316\u6587\u672c\u5206\u6790"}}
{"id": "2601.12539", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12539", "abs": "https://arxiv.org/abs/2601.12539", "authors": ["Ali Ezzat Shahroor", "Mohamed Bayan Kmainasi", "Abul Hasnat", "Dimitar Dimitrov", "Giovanni Da San Martino", "Preslav Nakov", "Firoj Alam"], "title": "MemeLens: Multilingual Multitask VLMs for Memes", "comment": "disinformation, misinformation, factuality, harmfulness, fake news, propaganda, hateful meme, multimodality, text, images", "summary": "Memes are a dominant medium for online communication and manipulation because meaning emerges from interactions between embedded text, imagery, and cultural context. Existing meme research is distributed across tasks (hate, misogyny, propaganda, sentiment, humour) and languages, which limits cross-domain generalization. To address this gap we propose MemeLens, a unified multilingual and multitask explanation-enhanced Vision Language Model (VLM) for meme understanding. We consolidate 38 public meme datasets, filter and map dataset-specific labels into a shared taxonomy of $20$ tasks spanning harm, targets, figurative/pragmatic intent, and affect. We present a comprehensive empirical analysis across modeling paradigms, task categories, and datasets. Our findings suggest that robust meme understanding requires multimodal training, exhibits substantial variation across semantic categories, and remains sensitive to over-specialization when models are fine-tuned on individual datasets rather than trained in a unified setting. We will make the experimental resources and datasets publicly available for the community.", "AI": {"tldr": "MemeLens\uff1a\u7edf\u4e00\u7684\u591a\u8bed\u8a00\u591a\u4efb\u52a1\u89e3\u91ca\u589e\u5f3a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u7528\u4e8e\u8868\u60c5\u5305\u7406\u89e3\uff0c\u6574\u5408\u4e8638\u4e2a\u516c\u5f00\u6570\u636e\u96c6\uff0c\u6620\u5c04\u523020\u4e2a\u4efb\u52a1\u7684\u5171\u4eab\u5206\u7c7b\u6cd5\u4e2d", "motivation": "\u73b0\u6709\u8868\u60c5\u5305\u7814\u7a76\u5206\u6563\u5728\u4e0d\u540c\u4efb\u52a1\uff08\u4ec7\u6068\u3001\u538c\u5973\u3001\u5ba3\u4f20\u3001\u60c5\u611f\u3001\u5e7d\u9ed8\uff09\u548c\u8bed\u8a00\u4e2d\uff0c\u9650\u5236\u4e86\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\uff0c\u9700\u8981\u7edf\u4e00\u7684\u591a\u8bed\u8a00\u591a\u4efb\u52a1\u89e3\u51b3\u65b9\u6848", "method": "\u63d0\u51faMemeLens\u6a21\u578b\uff0c\u6574\u540838\u4e2a\u516c\u5f00\u8868\u60c5\u5305\u6570\u636e\u96c6\uff0c\u5c06\u6570\u636e\u96c6\u7279\u5b9a\u6807\u7b7e\u8fc7\u6ee4\u5e76\u6620\u5c04\u5230\u5305\u542b\u5371\u5bb3\u3001\u76ee\u6807\u3001\u6bd4\u55bb/\u8bed\u7528\u610f\u56fe\u548c\u60c5\u611f\u768420\u4e2a\u4efb\u52a1\u7684\u5171\u4eab\u5206\u7c7b\u6cd5\u4e2d\uff0c\u91c7\u7528\u89e3\u91ca\u589e\u5f3a\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u67b6\u6784", "result": "\u5b9e\u8bc1\u5206\u6790\u8868\u660e\uff1a\u7a33\u5065\u7684\u8868\u60c5\u5305\u7406\u89e3\u9700\u8981\u591a\u6a21\u6001\u8bad\u7ec3\uff1b\u4e0d\u540c\u8bed\u4e49\u7c7b\u522b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1b\u5728\u5355\u4e2a\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u800c\u975e\u7edf\u4e00\u8bad\u7ec3\u65f6\u5bb9\u6613\u8fc7\u5ea6\u4e13\u4e1a\u5316", "conclusion": "MemeLens\u4e3a\u8868\u60c5\u5305\u7406\u89e3\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u591a\u8bed\u8a00\u591a\u4efb\u52a1\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u591a\u6a21\u6001\u8bad\u7ec3\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u8fc7\u5ea6\u4e13\u4e1a\u5316\u7684\u95ee\u9898\uff0c\u5c06\u516c\u5f00\u5b9e\u9a8c\u8d44\u6e90\u548c\u6570\u636e\u96c6\u4f9b\u793e\u533a\u4f7f\u7528"}}
{"id": "2601.12104", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.12104", "abs": "https://arxiv.org/abs/2601.12104", "authors": ["David Ili\u0107", "David Stanojevi\u0107", "Kostadin Cvejoski"], "title": "Powerful Training-Free Membership Inference Against Autoregressive Language Models", "comment": "9 pages, 2 figures; appendix with additional experiments and derivations", "summary": "Fine-tuned language models pose significant privacy risks, as they may memorize and expose sensitive information from their training data. Membership inference attacks (MIAs) provide a principled framework for auditing these risks, yet existing methods achieve limited detection rates, particularly at the low false-positive thresholds required for practical privacy auditing. We present EZ-MIA, a membership inference attack that exploits a key observation: memorization manifests most strongly at error positions, specifically tokens where the model predicts incorrectly yet still shows elevated probability for training examples. We introduce the Error Zone (EZ) score, which measures the directional imbalance of probability shifts at error positions relative to a pretrained reference model. This principled statistic requires only two forward passes per query and no model training of any kind. On WikiText with GPT-2, EZ-MIA achieves 3.8x higher detection than the previous state-of-the-art under identical conditions (66.3% versus 17.5% true positive rate at 1% false positive rate), with near-perfect discrimination (AUC 0.98). At the stringent 0.1% FPR threshold critical for real-world auditing, we achieve 8x higher detection than prior work (14.0% versus 1.8%), requiring no reference model training. These gains extend to larger architectures: on AG News with Llama-2-7B, we achieve 3x higher detection (46.7% versus 15.8% TPR at 1% FPR). These results establish that privacy risks of fine-tuned language models are substantially greater than previously understood, with implications for both privacy auditing and deployment decisions. Code is available at https://github.com/JetBrains-Research/ez-mia.", "code_url": "https://github.com/JetBrains-Research/ez-mia", "code_stars": 0, "code_last_update": "2026-01-16", "AI": {"tldr": "EZ-MIA\u662f\u4e00\u79cd\u57fa\u4e8e\u9519\u8bef\u533a\u57df\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u6a21\u578b\u5728\u9519\u8bef\u4f4d\u7f6e\u7684\u8bb0\u5fc6\u8868\u73b0\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u7279\u522b\u662f\u5728\u4f4e\u8bef\u62a5\u7387\u4e0b\u3002", "motivation": "\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u9690\u79c1\u98ce\u9669\uff0c\u53ef\u80fd\u8bb0\u5fc6\u5e76\u6cc4\u9732\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u654f\u611f\u4fe1\u606f\u3002\u73b0\u6709\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\u68c0\u6d4b\u7387\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u5b9e\u9645\u9690\u79c1\u5ba1\u8ba1\u6240\u9700\u7684\u4f4e\u8bef\u62a5\u7387\u9608\u503c\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faEZ-MIA\u653b\u51fb\u65b9\u6cd5\uff0c\u57fa\u4e8e\u5173\u952e\u89c2\u5bdf\uff1a\u8bb0\u5fc6\u5728\u9519\u8bef\u4f4d\u7f6e\u8868\u73b0\u6700\u5f3a\uff08\u6a21\u578b\u9884\u6d4b\u9519\u8bef\u4f46\u4ecd\u5bf9\u8bad\u7ec3\u6837\u672c\u663e\u793a\u8f83\u9ad8\u6982\u7387\uff09\u3002\u5f15\u5165\u9519\u8bef\u533a\u57df\u5206\u6570\uff0c\u6d4b\u91cf\u9519\u8bef\u4f4d\u7f6e\u76f8\u5bf9\u4e8e\u9884\u8bad\u7ec3\u53c2\u8003\u6a21\u578b\u7684\u6982\u7387\u504f\u79fb\u65b9\u5411\u6027\u4e0d\u5e73\u8861\u3002\u8be5\u65b9\u6cd5\u4ec5\u9700\u6bcf\u4e2a\u67e5\u8be2\u4e24\u6b21\u524d\u5411\u4f20\u64ad\uff0c\u65e0\u9700\u4efb\u4f55\u6a21\u578b\u8bad\u7ec3\u3002", "result": "\u5728WikiText\u4e0eGPT-2\u4e0a\uff0cEZ-MIA\u5728\u76f8\u540c\u6761\u4ef6\u4e0b\u68c0\u6d4b\u7387\u6bd4\u5148\u524d\u6700\u4f18\u65b9\u6cd5\u9ad83.8\u500d\uff081%\u8bef\u62a5\u7387\u4e0b\u771f\u9633\u6027\u738766.3% vs 17.5%\uff09\uff0cAUC\u8fbe0.98\u3002\u5728\u5173\u952e\u76840.1%\u8bef\u62a5\u7387\u4e0b\uff0c\u68c0\u6d4b\u7387\u6bd4\u5148\u524d\u5de5\u4f5c\u9ad88\u500d\uff0814.0% vs 1.8%\uff09\u3002\u5728AG News\u4e0eLlama-2-7B\u4e0a\uff0c\u68c0\u6d4b\u7387\u9ad83\u500d\uff081%\u8bef\u62a5\u7387\u4e0b46.7% vs 15.8%\uff09\u3002", "conclusion": "\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u7684\u9690\u79c1\u98ce\u9669\u6bd4\u5148\u524d\u7406\u89e3\u7684\u8981\u5927\u5f97\u591a\uff0c\u8fd9\u5bf9\u9690\u79c1\u5ba1\u8ba1\u548c\u90e8\u7f72\u51b3\u7b56\u90fd\u6709\u91cd\u8981\u5f71\u54cd\u3002EZ-MIA\u4e3a\u9690\u79c1\u98ce\u9669\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u5de5\u5177\u3002"}}
{"id": "2601.12542", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12542", "abs": "https://arxiv.org/abs/2601.12542", "authors": ["Lukas Weidener", "Marko Brki\u0107", "Mihailo Jovanovi\u0107", "Ritvik Singh", "Chiara Baccin", "Emre Ulgac", "Alex Dobrin", "Aakaash Meduri"], "title": "Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery", "comment": null, "summary": "Artificial intelligence systems for scientific discovery have demonstrated remarkable potential, yet existing approaches remain largely proprietary and operate in batch-processing modes requiring hours per research cycle, precluding real-time researcher guidance. This paper introduces Deep Research, a multi-agent system enabling interactive scientific investigation with turnaround times measured in minutes. The architecture comprises specialized agents for planning, data analysis, literature search, and novelty detection, unified through a persistent world state that maintains context across iterative research cycles. Two operational modes support different workflows: semi-autonomous mode with selective human checkpoints, and fully autonomous mode for extended investigations. Evaluation on the BixBench computational biology benchmark demonstrated state-of-the-art performance, achieving 48.8% accuracy on open response and 64.5% on multiple-choice evaluation, exceeding existing baselines by 14 to 26 percentage points. Analysis of architectural constraints, including open access literature limitations and challenges inherent to automated novelty assessment, informs practical deployment considerations for AI-assisted scientific workflows.", "AI": {"tldr": "Deep Research\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u80fd\u591f\u5728\u51e0\u5206\u949f\u5185\u5b8c\u6210\u4ea4\u4e92\u5f0f\u79d1\u5b66\u7814\u7a76\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u6279\u91cf\u5904\u7406\u6a21\u5f0f\uff0c\u652f\u6301\u534a\u81ea\u4e3b\u548c\u5168\u81ea\u4e3b\u4e24\u79cd\u5de5\u4f5c\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709AI\u79d1\u5b66\u53d1\u73b0\u7cfb\u7edf\u5927\u591a\u662f\u4e13\u6709\u7684\uff0c\u91c7\u7528\u6279\u91cf\u5904\u7406\u6a21\u5f0f\uff0c\u6bcf\u4e2a\u7814\u7a76\u5468\u671f\u9700\u8981\u6570\u5c0f\u65f6\uff0c\u65e0\u6cd5\u5b9e\u73b0\u5b9e\u65f6\u7814\u7a76\u8005\u6307\u5bfc\uff0c\u9650\u5236\u4e86AI\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5305\u542b\u89c4\u5212\u3001\u6570\u636e\u5206\u6790\u3001\u6587\u732e\u641c\u7d22\u548c\u65b0\u9896\u6027\u68c0\u6d4b\u7b49\u4e13\u95e8\u5316\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u6301\u4e45\u4e16\u754c\u72b6\u6001\u4fdd\u6301\u8de8\u8fed\u4ee3\u7814\u7a76\u5468\u671f\u7684\u4e0a\u4e0b\u6587\uff0c\u652f\u6301\u534a\u81ea\u4e3b\uff08\u9009\u62e9\u6027\u4eba\u5de5\u68c0\u67e5\u70b9\uff09\u548c\u5168\u81ea\u4e3b\u4e24\u79cd\u64cd\u4f5c\u6a21\u5f0f\u3002", "result": "\u5728BixBench\u8ba1\u7b97\u751f\u7269\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6700\u5148\u8fdb\u6027\u80fd\uff1a\u5f00\u653e\u56de\u7b54\u51c6\u786e\u738748.8%\uff0c\u591a\u9879\u9009\u62e9\u9898\u51c6\u786e\u738764.5%\uff0c\u6bd4\u73b0\u6709\u57fa\u7ebf\u63d0\u9ad814-26\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "Deep Research\u5c55\u793a\u4e86AI\u8f85\u52a9\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\u7684\u53ef\u884c\u6027\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u9700\u8981\u8003\u8651\u5f00\u653e\u83b7\u53d6\u6587\u732e\u9650\u5236\u548c\u81ea\u52a8\u65b0\u9896\u6027\u8bc4\u4f30\u7b49\u67b6\u6784\u7ea6\u675f\uff0c\u4e3a\u5b9e\u65f6\u4ea4\u4e92\u5f0f\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2601.12132", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12132", "abs": "https://arxiv.org/abs/2601.12132", "authors": ["Md Mahmudul Hoque", "Md Mehedi Hassain", "Md Hojaifa Tanvir", "Rahul Nandy"], "title": "Bengali Text Classification: An Evaluation of Large Language Model Approaches", "comment": null, "summary": "Bengali text classification is a Significant task in natural language processing (NLP), where text is categorized into predefined labels. Unlike English, Bengali faces challenges due to the lack of extensive annotated datasets and pre-trained language models. This study explores the effectiveness of large language models (LLMs) in classifying Bengali newspaper articles. The dataset used, obtained from Kaggle, consists of articles from Prothom Alo, a major Bangladeshi newspaper. Three instruction-tuned LLMs LLaMA 3.1 8B Instruct, LLaMA 3.2 3B Instruct, and Qwen 2.5 7B Instruct were evaluated for this task under the same classification framework. Among the evaluated models, Qwen 2.5 achieved the highest classification accuracy of 72%, showing particular strength in the \"Sports\" category. In comparison, LLaMA 3.1 and LLaMA 3.2 attained accuracies of 53% and 56%, respectively. The findings highlight the effectiveness of LLMs in Bengali text classification, despite the scarcity of resources for Bengali NLP. Future research will focus on exploring additional models, addressing class imbalance issues, and refining fine-tuning approaches to improve classification performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u4e09\u79cd\u6307\u4ee4\u8c03\u4f18\u5927\u8bed\u8a00\u6a21\u578b\uff08LLaMA 3.1 8B Instruct\u3001LLaMA 3.2 3B Instruct\u548cQwen 2.5 7B Instruct\uff09\u5728\u5b5f\u52a0\u62c9\u8bed\u65b0\u95fb\u6587\u7ae0\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5176\u4e2dQwen 2.5\u4ee572%\u7684\u51c6\u786e\u7387\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u5b5f\u52a0\u62c9\u8bed\u6587\u672c\u5206\u7c7b\u662fNLP\u4e2d\u7684\u91cd\u8981\u4efb\u52a1\uff0c\u4f46\u4e0e\u82f1\u8bed\u76f8\u6bd4\u9762\u4e34\u6807\u6ce8\u6570\u636e\u96c6\u548c\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u7684\u6311\u6218\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b5f\u52a0\u62c9\u8bed\u65b0\u95fb\u6587\u7ae0\u5206\u7c7b\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u4f7f\u7528\u6765\u81eaKaggle\u7684Prothom Alo\uff08\u5b5f\u52a0\u62c9\u56fd\u4e3b\u8981\u62a5\u7eb8\uff09\u65b0\u95fb\u6587\u7ae0\u6570\u636e\u96c6\uff0c\u5728\u76f8\u540c\u7684\u5206\u7c7b\u6846\u67b6\u4e0b\u8bc4\u4f30\u4e09\u79cd\u6307\u4ee4\u8c03\u4f18\u5927\u8bed\u8a00\u6a21\u578b\uff1aLLaMA 3.1 8B Instruct\u3001LLaMA 3.2 3B Instruct\u548cQwen 2.5 7B Instruct\u3002", "result": "Qwen 2.5 7B Instruct\u83b7\u5f97\u4e86\u6700\u9ad8\u7684\u5206\u7c7b\u51c6\u786e\u738772%\uff0c\u5728\"\u4f53\u80b2\"\u7c7b\u522b\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\u3002LLaMA 3.1\u548cLLaMA 3.2\u5206\u522b\u83b7\u5f9753%\u548c56%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5c3d\u7ba1\u5b5f\u52a0\u62c9\u8bedNLP\u8d44\u6e90\u7a00\u7f3a\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b5f\u52a0\u62c9\u8bed\u6587\u672c\u5206\u7c7b\u4e2d\u4ecd\u7136\u6709\u6548\u3002\u672a\u6765\u7814\u7a76\u5c06\u63a2\u7d22\u66f4\u591a\u6a21\u578b\u3001\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u5e76\u6539\u8fdb\u5fae\u8c03\u65b9\u6cd5\u4ee5\u63d0\u5347\u5206\u7c7b\u6027\u80fd\u3002"}}
{"id": "2601.12547", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12547", "abs": "https://arxiv.org/abs/2601.12547", "authors": ["Dipayan Sengupta", "Saumya Panda"], "title": "How Clinicians Think and What AI Can Learn From It", "comment": "34 pages", "summary": "Most clinical AI systems operate as prediction engines -- producing labels or risk scores -- yet real clinical reasoning is a time-bounded, sequential control problem under uncertainty. Clinicians interleave information gathering with irreversible actions, guided by regret, constraints and patient values. We argue that the dominant computational substrate of clinician reasoning is not cardinal optimization but ordinal, non-compensatory decision-making: Clinicians frequently rely on fast-and-frugal, lexicographic heuristics (e.g., fast-and-frugal trees) that stop early after checking a small, fixed sequence of cues. We provide a normative rationale for why such algorithms are not merely bounded rationality shortcuts, but can be epistemically preferred in medicine. First, many clinical trade-offs are constructed through human judgment and are only weakly measurable on absolute scales; without strong measurement axioms, only orderings are invariant, motivating an ordinal-by-default stance. Second, preference and signal elicitation are structurally crude: The mapping from truth $\\to$ perception $\\to$ inference $\\to$ recorded variables introduces layered noise, leaving a persistent uncertainty floor. When this 'crudeness' overwhelms the decision margin, plug-in expected-utility optimization becomes brittle (high flip probability under small perturbations), whereas robust dominance/filtering rules ($\u03b5$-dominance, maximin) stabilize decisions.Finally, we outline a clinician-aligned AI blueprint: Use rich models for beliefs and trajectories, but choose actions through robust ordinal rules; treat heuristics as the low-dimensional special case; and deploy AI as 'selective complexity' -- invoked mainly for tie-breaking when decisions are fragile and information has positive expected impact.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u4e34\u5e8aAI\u5e94\u4ece\u9884\u6d4b\u5f15\u64ce\u8f6c\u5411\u57fa\u4e8e\u5e8f\u6570\u3001\u975e\u8865\u507f\u6027\u51b3\u7b56\u7684\u4e34\u5e8a\u63a8\u7406\u6846\u67b6\uff0c\u91c7\u7528\u7a33\u5065\u7684\u542f\u53d1\u5f0f\u89c4\u5219\u800c\u975e\u671f\u671b\u6548\u7528\u4f18\u5316", "motivation": "\u5f53\u524d\u4e34\u5e8aAI\u7cfb\u7edf\u4e3b\u8981\u4f5c\u4e3a\u9884\u6d4b\u5f15\u64ce\uff08\u751f\u6210\u6807\u7b7e\u6216\u98ce\u9669\u8bc4\u5206\uff09\uff0c\u4f46\u771f\u5b9e\u7684\u4e34\u5e8a\u63a8\u7406\u662f\u65f6\u95f4\u53d7\u9650\u3001\u5e8f\u5217\u5316\u7684\u63a7\u5236\u95ee\u9898\uff0c\u6d89\u53ca\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u4fe1\u606f\u6536\u96c6\u4e0e\u4e0d\u53ef\u9006\u884c\u52a8\u3002\u4e34\u5e8a\u533b\u751f\u4f9d\u8d56\u5feb\u901f\u8282\u4fed\u7684\u8bcd\u5178\u5f0f\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u800c\u975e\u57fa\u6570\u4f18\u5316", "method": "\u63d0\u51fa\u4e34\u5e8a\u63a8\u7406\u7684\u8ba1\u7b97\u57fa\u7840\u5e94\u662f\u5e8f\u6570\u3001\u975e\u8865\u507f\u6027\u51b3\u7b56\uff1a1\uff09\u4e34\u5e8a\u6743\u8861\u901a\u5e38\u57fa\u4e8e\u4eba\u7c7b\u5224\u65ad\uff0c\u5728\u7edd\u5bf9\u5c3a\u5ea6\u4e0a\u96be\u4ee5\u7cbe\u786e\u6d4b\u91cf\uff0c\u53ea\u6709\u5e8f\u6570\u5173\u7cfb\u5177\u6709\u4e0d\u53d8\u6027\uff1b2\uff09\u504f\u597d\u548c\u4fe1\u53f7\u83b7\u53d6\u5b58\u5728\u7ed3\u6784\u6027\u7c97\u7cd9\u5ea6\uff0c\u5bfc\u81f4\u6301\u7eed\u4e0d\u786e\u5b9a\u6027\uff0c\u671f\u671b\u6548\u7528\u4f18\u5316\u5728\u51b3\u7b56\u8fb9\u9645\u88ab\u7c97\u7cd9\u5ea6\u6df9\u6ca1\u65f6\u53d8\u5f97\u8106\u5f31\uff1b3\uff09\u91c7\u7528\u7a33\u5065\u7684\u652f\u914d/\u8fc7\u6ee4\u89c4\u5219\uff08\u5982\u03b5-\u652f\u914d\u3001\u6781\u5927\u6781\u5c0f\uff09\u6765\u7a33\u5b9a\u51b3\u7b56", "result": "\u8bba\u8bc1\u4e86\u5feb\u901f\u8282\u4fed\u542f\u53d1\u5f0f\u65b9\u6cd5\u4e0d\u4ec5\u662f\u6709\u9650\u7406\u6027\u6377\u5f84\uff0c\u5728\u533b\u5b66\u4e2d\u5177\u6709\u8ba4\u8bc6\u8bba\u4f18\u52bf\uff1a\u5e8f\u6570\u51b3\u7b56\u5728\u6d4b\u91cf\u516c\u7406\u8584\u5f31\u65f6\u66f4\u7a33\u5065\uff1b\u5f53\u7ed3\u6784\u6027\u7c97\u7cd9\u5ea6\u8d85\u8fc7\u51b3\u7b56\u8fb9\u9645\u65f6\uff0c\u671f\u671b\u6548\u7528\u4f18\u5316\u6613\u53d7\u5c0f\u6270\u52a8\u5f71\u54cd\uff08\u9ad8\u7ffb\u8f6c\u6982\u7387\uff09\uff0c\u800c\u7a33\u5065\u89c4\u5219\u80fd\u7a33\u5b9a\u51b3\u7b56", "conclusion": "\u63d0\u51fa\u4e34\u5e8a\u5bf9\u9f50\u7684AI\u84dd\u56fe\uff1a\u4f7f\u7528\u4e30\u5bcc\u6a21\u578b\u8fdb\u884c\u4fe1\u5ff5\u548c\u8f68\u8ff9\u5efa\u6a21\uff0c\u4f46\u901a\u8fc7\u7a33\u5065\u5e8f\u6570\u89c4\u5219\u9009\u62e9\u884c\u52a8\uff1b\u5c06\u542f\u53d1\u5f0f\u89c6\u4e3a\u4f4e\u7ef4\u7279\u4f8b\uff1b\u90e8\u7f72AI\u4f5c\u4e3a\"\u9009\u62e9\u6027\u590d\u6742\u6027\"\u2014\u2014\u4e3b\u8981\u5728\u51b3\u7b56\u8106\u5f31\u4e14\u4fe1\u606f\u5177\u6709\u6b63\u671f\u671b\u5f71\u54cd\u65f6\u7528\u4e8e\u6253\u7834\u5e73\u5c40"}}
{"id": "2601.12154", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12154", "abs": "https://arxiv.org/abs/2601.12154", "authors": ["Teodor-C\u0103lin Ionescu", "Lifeng Han", "Jan Heijdra Suasnabar", "Anne Stiggelbout", "Suzan Verberne"], "title": "Analyzing Cancer Patients' Experiences with Embedding-based Topic Modeling and LLMs", "comment": "under review to CLIN journal", "summary": "This study investigates the use of neural topic modeling and LLMs to uncover meaningful themes from patient storytelling data, to offer insights that could contribute to more patient-oriented healthcare practices. We analyze a collection of transcribed interviews with cancer patients (132,722 words in 13 interviews). We first evaluate BERTopic and Top2Vec for individual interview summarization by using similar preprocessing, chunking, and clustering configurations to ensure a fair comparison on Keyword Extraction. LLMs (GPT4) are then used for the next step topic labeling. Their outputs for a single interview (I0) are rated through a small-scale human evaluation, focusing on {coherence}, {clarity}, and {relevance}. Based on the preliminary results and evaluation, BERTopic shows stronger performance and is selected for further experimentation using three {clinically oriented embedding} models. We then analyzed the full interview collection with the best model setting. Results show that domain-specific embeddings improved topic \\textit{precision} and \\textit{interpretability}, with BioClinicalBERT producing the most consistent results across transcripts. The global analysis of the full dataset of 13 interviews, using the BioClinicalBERT embedding model, reveals the most dominant topics throughout all 13 interviews, namely ``Coordination and Communication in Cancer Care Management\" and ``Patient Decision-Making in Cancer Treatment Journey''. Although the interviews are machine translations from Dutch to English, and clinical professionals are not involved in this evaluation, the findings suggest that neural topic modeling, particularly BERTopic, can help provide useful feedback to clinicians from patient interviews. This pipeline could support more efficient document navigation and strengthen the role of patients' voices in healthcare workflows.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30BERTopic\u548cTop2Vec\u5728\u764c\u75c7\u60a3\u8005\u8bbf\u8c08\u6570\u636e\u4e0a\u7684\u4e3b\u9898\u5efa\u6a21\u6027\u80fd\uff0c\u7ed3\u5408GPT-4\u8fdb\u884c\u4e3b\u9898\u6807\u6ce8\uff0c\u53d1\u73b0BERTopic\u914d\u5408BioClinicalBERT\u5d4c\u5165\u6a21\u578b\u80fd\u6709\u6548\u63d0\u53d6\u4e34\u5e8a\u76f8\u5173\u4e3b\u9898\uff0c\u4e3a\u60a3\u8005\u5bfc\u5411\u7684\u533b\u7597\u5b9e\u8df5\u63d0\u4f9b\u652f\u6301\u3002", "motivation": "\u4ece\u60a3\u8005\u53d9\u4e8b\u6570\u636e\u4e2d\u63d0\u53d6\u6709\u610f\u4e49\u7684\u4e3b\u9898\uff0c\u4e3a\u66f4\u4ee5\u60a3\u8005\u4e3a\u4e2d\u5fc3\u7684\u533b\u7597\u5b9e\u8df5\u63d0\u4f9b\u6d1e\u5bdf\u3002\u5f53\u524d\u9700\u8981\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5206\u6790\u5927\u91cf\u60a3\u8005\u8bbf\u8c08\u6587\u672c\uff0c\u4ee5\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\u548c\u533b\u7597\u6d41\u7a0b\u6539\u8fdb\u3002", "method": "\u4f7f\u7528BERTopic\u548cTop2Vec\u4e24\u79cd\u795e\u7ecf\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\u5206\u679013\u4e2a\u764c\u75c7\u60a3\u8005\u8bbf\u8c08\uff08132,722\u8bcd\uff09\u3002\u91c7\u7528\u76f8\u4f3c\u7684\u9884\u5904\u7406\u3001\u5206\u5757\u548c\u805a\u7c7b\u914d\u7f6e\u8fdb\u884c\u516c\u5e73\u6bd4\u8f83\uff0c\u7136\u540e\u4f7f\u7528GPT-4\u8fdb\u884c\u4e3b\u9898\u6807\u6ce8\u3002\u901a\u8fc7\u4eba\u5de5\u8bc4\u4f30\uff08\u5173\u6ce8\u8fde\u8d2f\u6027\u3001\u6e05\u6670\u5ea6\u548c\u76f8\u5173\u6027\uff09\u6bd4\u8f83\u6a21\u578b\u6027\u80fd\u3002\u9009\u62e9\u8868\u73b0\u66f4\u597d\u7684BERTopic\uff0c\u8fdb\u4e00\u6b65\u6d4b\u8bd5\u4e09\u79cd\u4e34\u5e8a\u5bfc\u5411\u5d4c\u5165\u6a21\u578b\uff0c\u6700\u7ec8\u4f7f\u7528\u6700\u4f73\u6a21\u578b\u8bbe\u7f6e\u5206\u6790\u5b8c\u6574\u6570\u636e\u96c6\u3002", "result": "BERTopic\u8868\u73b0\u4f18\u4e8eTop2Vec\u3002\u5728\u4e34\u5e8a\u5d4c\u5165\u6a21\u578b\u4e2d\uff0cBioClinicalBERT\u4ea7\u751f\u6700\u4e00\u81f4\u7684\u7ed3\u679c\uff0c\u63d0\u9ad8\u4e86\u4e3b\u9898\u7cbe\u786e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002\u5168\u5c40\u5206\u6790\u63ed\u793a\u4e24\u4e2a\u4e3b\u5bfc\u4e3b\u9898\uff1a\"\u764c\u75c7\u62a4\u7406\u7ba1\u7406\u4e2d\u7684\u534f\u8c03\u4e0e\u6c9f\u901a\"\u548c\"\u764c\u75c7\u6cbb\u7597\u65c5\u7a0b\u4e2d\u7684\u60a3\u8005\u51b3\u7b56\"\u3002\u5c3d\u7ba1\u6570\u636e\u662f\u673a\u5668\u7ffb\u8bd1\u4e14\u65e0\u4e34\u5e8a\u4e13\u4e1a\u4eba\u5458\u53c2\u4e0e\u8bc4\u4f30\uff0c\u4f46\u7ed3\u679c\u8868\u660e\u8be5\u6d41\u7a0b\u80fd\u4e3a\u4e34\u5e8a\u533b\u751f\u63d0\u4f9b\u6709\u7528\u53cd\u9988\u3002", "conclusion": "\u795e\u7ecf\u4e3b\u9898\u5efa\u6a21\uff08\u7279\u522b\u662fBERTopic\uff09\u80fd\u6709\u6548\u4ece\u60a3\u8005\u8bbf\u8c08\u4e2d\u63d0\u53d6\u4e34\u5e8a\u76f8\u5173\u4e3b\u9898\uff0c\u652f\u6301\u66f4\u9ad8\u6548\u7684\u6587\u6863\u5bfc\u822a\u5e76\u589e\u5f3a\u60a3\u8005\u58f0\u97f3\u5728\u533b\u7597\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u4f5c\u7528\u3002\u8be5\u6d41\u7a0b\u6709\u6f5c\u529b\u4e3a\u60a3\u8005\u5bfc\u5411\u7684\u533b\u7597\u5b9e\u8df5\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2601.12560", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.12560", "abs": "https://arxiv.org/abs/2601.12560", "authors": ["Arunkumar V", "Gangadharan G. R.", "Rajkumar Buyya"], "title": "Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents", "comment": "28 pages, 4 figures, 5 tables", "summary": "Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act. Large Language Models (LLMs) are no longer used only as passive knowledge engines but as cognitive controllers that combine memory, tool use, and feedback from their environment to pursue extended goals. This shift already supports the automation of complex workflows in software engineering, scientific discovery, and web navigation, yet the variety of emerging designs, from simple single loop agents to hierarchical multi agent systems, makes the landscape hard to navigate. In this paper, we investigate architectures and propose a unified taxonomy that breaks agents into Perception, Brain, Planning, Action, Tool Use, and Collaboration. We use this lens to describe the move from linear reasoning procedures to native inference time reasoning models, and the transition from fixed API calls to open standards like the Model Context Protocol (MCP) and Native Computer Use. We also group the environments in which these agents operate, including digital operating systems, embodied robotics, and other specialized domains, and we review current evaluation practices. Finally, we highlight open challenges, such as hallucination in action, infinite loops, and prompt injection, and outline future research directions toward more robust and reliable autonomous systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u667a\u80fd\u4f53AI\u5206\u7c7b\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u4f53\u5206\u89e3\u4e3a\u611f\u77e5\u3001\u5927\u8111\u3001\u89c4\u5212\u3001\u884c\u52a8\u3001\u5de5\u5177\u4f7f\u7528\u548c\u534f\u4f5c\u516d\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff0c\u5e76\u5206\u6790\u4e86\u4ece\u7ebf\u6027\u63a8\u7406\u5230\u539f\u751f\u63a8\u7406\u6a21\u578b\u7684\u6f14\u8fdb\u8d8b\u52bf\u3002", "motivation": "\u968f\u7740AI\u4ece\u4ec5\u751f\u6210\u6587\u672c\u7684\u6a21\u578b\u5411\u80fd\u591f\u611f\u77e5\u3001\u63a8\u7406\u3001\u89c4\u5212\u548c\u884c\u52a8\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u7cfb\u7edf\u6f14\u8fdb\uff0c\u51fa\u73b0\u4e86\u4ece\u7b80\u5355\u5355\u5faa\u73af\u667a\u80fd\u4f53\u5230\u5206\u5c42\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u591a\u6837\u5316\u8bbe\u8ba1\uff0c\u4f7f\u5f97\u8fd9\u4e00\u9886\u57df\u96be\u4ee5\u7cfb\u7edf\u5316\u7406\u89e3\u3002\u9700\u8981\u7edf\u4e00\u7684\u5206\u7c7b\u6846\u67b6\u6765\u68b3\u7406\u667a\u80fd\u4f53\u67b6\u6784\u7684\u6f14\u8fdb\u8109\u7edc\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u5206\u7c7b\u6cd5\uff0c\u5c06\u667a\u80fd\u4f53\u5206\u89e3\u4e3a\u516d\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u611f\u77e5\u3001\u5927\u8111\u3001\u89c4\u5212\u3001\u884c\u52a8\u3001\u5de5\u5177\u4f7f\u7528\u548c\u534f\u4f5c\u3002\u4f7f\u7528\u8fd9\u4e00\u6846\u67b6\u5206\u6790\u4ece\u7ebf\u6027\u63a8\u7406\u8fc7\u7a0b\u5230\u539f\u751f\u63a8\u7406\u65f6\u95f4\u63a8\u7406\u6a21\u578b\u7684\u6f14\u8fdb\uff0c\u4ee5\u53ca\u4ece\u56fa\u5b9aAPI\u8c03\u7528\u5230\u5f00\u653e\u6807\u51c6\uff08\u5982\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u548c\u539f\u751f\u8ba1\u7b97\u673a\u4f7f\u7528\uff09\u7684\u8f6c\u53d8\u3002\u540c\u65f6\u5206\u7c7b\u667a\u80fd\u4f53\u8fd0\u884c\u73af\u5883\uff0c\u5e76\u56de\u987e\u5f53\u524d\u8bc4\u4f30\u5b9e\u8df5\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u667a\u80fd\u4f53AI\u5206\u7c7b\u6846\u67b6\uff0c\u660e\u786e\u4e86\u667a\u80fd\u4f53\u67b6\u6784\u7684\u6838\u5fc3\u7ec4\u4ef6\u548c\u6f14\u8fdb\u8d8b\u52bf\u3002\u8bc6\u522b\u4e86\u667a\u80fd\u4f53\u8fd0\u884c\u7684\u4e3b\u8981\u73af\u5883\u7c7b\u578b\uff08\u6570\u5b57\u64cd\u4f5c\u7cfb\u7edf\u3001\u5177\u8eab\u673a\u5668\u4eba\u3001\u4e13\u4e1a\u9886\u57df\uff09\uff0c\u5e76\u603b\u7ed3\u4e86\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u3002\u6307\u51fa\u4e86\u5e7b\u89c9\u884c\u4e3a\u3001\u65e0\u9650\u5faa\u73af\u3001\u63d0\u793a\u6ce8\u5165\u7b49\u5f00\u653e\u6311\u6218\u3002", "conclusion": "\u667a\u80fd\u4f53AI\u6b63\u4ece\u88ab\u52a8\u77e5\u8bc6\u5f15\u64ce\u5411\u81ea\u4e3b\u8ba4\u77e5\u63a7\u5236\u5668\u6f14\u8fdb\uff0c\u7edf\u4e00\u7684\u5206\u7c7b\u6846\u67b6\u6709\u52a9\u4e8e\u7406\u89e3\u8fd9\u4e00\u590d\u6742\u9886\u57df\u3002\u672a\u6765\u7814\u7a76\u9700\u8981\u89e3\u51b3\u5e7b\u89c9\u3001\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u7b49\u5173\u952e\u6311\u6218\uff0c\u63a8\u52a8\u66f4\u7a33\u5065\u53ef\u9760\u7684\u81ea\u4e3b\u7cfb\u7edf\u53d1\u5c55\u3002"}}
{"id": "2601.12179", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12179", "abs": "https://arxiv.org/abs/2601.12179", "authors": ["Adam E. Friedman", "Stevan Harnad", "Rushen Shi"], "title": "Tolerance Principle and Small Language Model Learning", "comment": "14 pages, 6 figures. BUCLD 50 Proceedings. To be published in 2026 by Cascadilla Press", "summary": "Modern language models like GPT-3, BERT, and LLaMA require massive training data, yet with sufficient training they reliably learn to distinguish grammatical from ungrammatical sentences. Children aged as young as 14 months already have the capacity to learn abstract grammar rules from very few exemplars, even in the presence of non-rule-following exceptions. Yang's (2016) Tolerance Principle defines a precise threshold for how many exceptions a rule can tolerate and still be learnable. The present study explored the minimal amount and quality of training data necessary for rules to be generalized by a transformer-based language model to test the predictions of the Tolerance Principle. We trained BabyBERTa (Huebner et al. 2021), a transformer model optimized for small datasets, on artificial grammars. The training sets varied in size, number of unique sentence types, and proportion of rule-following versus exception exemplars. We found that, unlike human infants, BabyBERTa's learning dynamics do not align with the Tolerance Principle.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6d4b\u8bd5\u4e86BabyBERTa\u6a21\u578b\u5728\u4eba\u5de5\u8bed\u6cd5\u5b66\u4e60\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u5b66\u4e60\u52a8\u6001\u4e0e\u4eba\u7c7b\u5a74\u513f\u4e0d\u540c\uff0c\u4e0d\u9075\u5faaYang\u7684\u5bb9\u5fcd\u539f\u5219\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22Transformer\u8bed\u8a00\u6a21\u578b\u5728\u6709\u9650\u8bad\u7ec3\u6570\u636e\u4e0b\u5b66\u4e60\u62bd\u8c61\u8bed\u6cd5\u89c4\u5219\u7684\u80fd\u529b\uff0c\u5e76\u4e0e\u4eba\u7c7b\u5a74\u513f\u7684\u5feb\u901f\u8bed\u6cd5\u5b66\u4e60\u80fd\u529b\u8fdb\u884c\u6bd4\u8f83\u3002\u4eba\u7c7b\u5a74\u513f\u80fd\u4ece\u5c11\u91cf\u793a\u4f8b\u4e2d\u5b66\u4e60\u62bd\u8c61\u8bed\u6cd5\u89c4\u5219\uff0c\u5373\u4f7f\u5b58\u5728\u4f8b\u5916\u60c5\u51b5\uff0c\u800c\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u3002Yang\u7684\u5bb9\u5fcd\u539f\u5219\u4e3a\u89c4\u5219\u53ef\u5b66\u4e60\u6027\u63d0\u4f9b\u4e86\u7cbe\u786e\u9608\u503c\uff0c\u672c\u7814\u7a76\u65e8\u5728\u6d4b\u8bd5\u8bed\u8a00\u6a21\u578b\u662f\u5426\u9075\u5faa\u8fd9\u4e00\u539f\u5219\u3002", "method": "\u4f7f\u7528BabyBERTa\uff08\u4e13\u4e3a\u5c0f\u6570\u636e\u96c6\u4f18\u5316\u7684Transformer\u6a21\u578b\uff09\u5728\u4eba\u5de5\u8bed\u6cd5\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u8bad\u7ec3\u96c6\u5728\u4ee5\u4e0b\u7ef4\u5ea6\u53d8\u5316\uff1a1) \u6570\u636e\u96c6\u5927\u5c0f\uff1b2) \u72ec\u7279\u53e5\u5b50\u7c7b\u578b\u6570\u91cf\uff1b3) \u89c4\u5219\u9075\u5faa\u793a\u4f8b\u4e0e\u4f8b\u5916\u793a\u4f8b\u7684\u6bd4\u4f8b\u3002\u901a\u8fc7\u63a7\u5236\u8fd9\u4e9b\u53d8\u91cf\u6765\u6d4b\u8bd5\u6a21\u578b\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u8bed\u6cd5\u89c4\u5219\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u7814\u7a76\u53d1\u73b0BabyBERTa\u7684\u5b66\u4e60\u52a8\u6001\u4e0e\u4eba\u7c7b\u5a74\u513f\u4e0d\u540c\uff0c\u4e0d\u9075\u5faaYang\u7684\u5bb9\u5fcd\u539f\u5219\u3002\u6a21\u578b\u5728\u8bed\u6cd5\u89c4\u5219\u5b66\u4e60\u65b9\u9762\u8868\u73b0\u51fa\u4e0e\u4eba\u7c7b\u5a74\u513f\u4e0d\u540c\u7684\u6a21\u5f0f\uff0c\u672a\u80fd\u590d\u5236\u4eba\u7c7b\u5a74\u513f\u4ece\u5c11\u91cf\u793a\u4f8b\u4e2d\u5b66\u4e60\u62bd\u8c61\u8bed\u6cd5\u89c4\u5219\u7684\u80fd\u529b\u3002", "conclusion": "Transformer\u8bed\u8a00\u6a21\u578b\u5728\u6709\u9650\u6570\u636e\u4e0b\u7684\u8bed\u6cd5\u5b66\u4e60\u673a\u5236\u4e0e\u4eba\u7c7b\u5a74\u513f\u4e0d\u540c\uff0c\u4e0d\u9075\u5faa\u5bb9\u5fcd\u539f\u5219\u3002\u8fd9\u8868\u660e\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u7684\u5b66\u4e60\u673a\u5236\u4e0e\u4eba\u7c7b\u8bed\u8a00\u4e60\u5f97\u5b58\u5728\u672c\u8d28\u5dee\u5f02\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6765\u7406\u89e3\u8fd9\u4e9b\u5dee\u5f02\u5e76\u6539\u8fdb\u6a21\u578b\u7684\u5c0f\u6837\u672c\u5b66\u4e60\u80fd\u529b\u3002"}}
{"id": "2601.12641", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12641", "abs": "https://arxiv.org/abs/2601.12641", "authors": ["Xiangyu Shi", "Junyang Ding", "Xu Zhao", "Sinong Zhan", "Payal Mohapatra", "Daniel Quispe", "Kojo Welbeck", "Jian Cao", "Wei Chen", "Ping Guo", "Qi Zhu"], "title": "STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models", "comment": "Accepted to the Design, Automation & Test in Europe Conference (DATE) 2026", "summary": "Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. To enable non-experts to translate intuitive design intent into manufacturable artifacts, recent large language models-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery. However, these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ~40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search-based reserialization that linearizes cross-references while preserving locality and chain-of-thought(CoT)-style structural annotations that guide global coherence. We integrate retrieval-augmented generation to ground predictions in relevant examples for supervised fine-tuning, and refine generation quality through reinforcement learning with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strengthens overall accuracy, and the RL further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results show the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.", "AI": {"tldr": "STEP-LLM\uff1a\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210STEP\u683c\u5f0fCAD\u6a21\u578b\uff0c\u89e3\u51b3\u4f20\u7edf\u6587\u672c\u5230CAD\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u9ad8\u51e0\u4f55\u4fdd\u771f\u5ea6\u548c\u5236\u9020\u517c\u5bb9\u6027\u3002", "motivation": "\u4f20\u7edfCAD\u5efa\u6a21\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u4e14\u8017\u65f6\uff0c\u73b0\u6709\u57fa\u4e8e\u547d\u4ee4\u5e8f\u5217\u6216\u811a\u672c\u7684\u6587\u672c\u5230CAD\u65b9\u6cd5\u5b58\u5728\u5185\u6838\u4f9d\u8d56\u6027\u548c\u5236\u9020\u517c\u5bb9\u6027\u95ee\u9898\u3002STEP\u4f5c\u4e3a\u5e7f\u6cdb\u91c7\u7528\u7684\u4e2d\u6027\u8fb9\u754c\u8868\u793a\u683c\u5f0f\u76f4\u63a5\u517c\u5bb9\u5236\u9020\uff0c\u4f46\u5176\u56fe\u7ed3\u6784\u3001\u4ea4\u53c9\u5f15\u7528\u7684\u7279\u6027\u5bf9\u81ea\u56de\u5f52LLM\u6784\u6210\u6311\u6218\u3002", "method": "1. \u6784\u5efa\u7ea640K STEP-\u6587\u672c\u63cf\u8ff0\u5bf9\u6570\u636e\u96c6\uff1b2. \u9488\u5bf9STEP\u56fe\u7ed3\u6784\u683c\u5f0f\u8bbe\u8ba1\u9884\u5904\u7406\uff1a\u57fa\u4e8e\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u7684\u91cd\u65b0\u5e8f\u5217\u5316\u7ebf\u6027\u5316\u4ea4\u53c9\u5f15\u7528\u5e76\u4fdd\u6301\u5c40\u90e8\u6027\uff0c\u4ee5\u53caCoT\u98ce\u683c\u7ed3\u6784\u6ce8\u91ca\u6307\u5bfc\u5168\u5c40\u4e00\u81f4\u6027\uff1b3. \u96c6\u6210\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff1b4. \u4f7f\u7528\u57fa\u4e8eChamfer\u8ddd\u79bb\u7684\u51e0\u4f55\u5956\u52b1\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u751f\u6210\u8d28\u91cf\u3002", "result": "STEP-LLM\u5728\u51e0\u4f55\u4fdd\u771f\u5ea6\u4e0a\u6301\u7eed\u4f18\u4e8eText2CAD\u57fa\u7ebf\u3002RAG\u6a21\u5757\u663e\u8457\u63d0\u5347\u5b8c\u6574\u6027\u548c\u53ef\u6e32\u67d3\u6027\uff0cDFS\u91cd\u65b0\u5e8f\u5217\u5316\u589e\u5f3a\u6574\u4f53\u51c6\u786e\u6027\uff0cRL\u8fdb\u4e00\u6b65\u51cf\u5c11\u51e0\u4f55\u5dee\u5f02\u3002\u6307\u6807\u548c\u89c6\u89c9\u6bd4\u8f83\u5747\u8bc1\u5b9eSTEP-LLM\u751f\u6210\u5f62\u72b6\u5177\u6709\u66f4\u9ad8\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u8bc1\u660e\u4e86LLM\u9a71\u52a8\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210STEP\u6a21\u578b\u7684\u53ef\u884c\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u6c11\u4e3b\u5316\u5236\u9020CAD\u8bbe\u8ba1\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e3a\u66f4\u901a\u7528\u3001\u5236\u9020\u517c\u5bb9\u7684\u6587\u672c\u5230CAD\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.12199", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12199", "abs": "https://arxiv.org/abs/2601.12199", "authors": ["Muhammad Umar Farooq", "Oscar Saz"], "title": "CTC-DID: CTC-Based Arabic dialect identification for streaming applications", "comment": "Accepted for IEEE ICASSP 2026", "summary": "This paper proposes a Dialect Identification (DID) approach inspired by the Connectionist Temporal Classification (CTC) loss function as used in Automatic Speech Recognition (ASR). CTC-DID frames the dialect identification task as a limited-vocabulary ASR system, where dialect tags are treated as a sequence of labels for a given utterance. For training, the repetition of dialect tags in transcriptions is estimated either using a proposed Language-Agnostic Heuristic (LAH) approach or a pre-trained ASR model. The method is evaluated on the low-resource Arabic Dialect Identification (ADI) task, with experimental results demonstrating that an SSL-based CTC-DID model, trained on a limited dataset, outperforms both fine-tuned Whisper and ECAPA-TDNN models. Notably, CTC-DID also surpasses these models in zero-shot evaluation on the Casablanca dataset. The proposed approach is found to be more robust to shorter utterances and is shown to be easily adaptable for streaming, real-time applications, with minimal performance degradation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eCTC\u635f\u5931\u7684\u65b9\u8a00\u8bc6\u522b\u65b9\u6cd5\uff0c\u5c06\u65b9\u8a00\u8bc6\u522b\u4efb\u52a1\u5efa\u6a21\u4e3a\u6709\u9650\u8bcd\u6c47\u7684ASR\u7cfb\u7edf\uff0c\u5728\u4f4e\u8d44\u6e90\u963f\u62c9\u4f2f\u65b9\u8a00\u8bc6\u522b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5fae\u8c03\u7684Whisper\u548cECAPA-TDNN\u6a21\u578b", "motivation": "\u4f20\u7edf\u65b9\u8a00\u8bc6\u522b\u65b9\u6cd5\u5728\u5904\u7406\u4f4e\u8d44\u6e90\u573a\u666f\u548c\u77ed\u8bed\u97f3\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9c81\u68d2\u4e14\u9002\u7528\u4e8e\u5b9e\u65f6\u5e94\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002CTC\u635f\u5931\u5728ASR\u4e2d\u7684\u6210\u529f\u5e94\u7528\u4e3a\u65b9\u8a00\u8bc6\u522b\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002", "method": "\u63d0\u51faCTC-DID\u65b9\u6cd5\uff0c\u5c06\u65b9\u8a00\u8bc6\u522b\u4efb\u52a1\u6846\u67b6\u5316\u4e3a\u6709\u9650\u8bcd\u6c47\u7684ASR\u7cfb\u7edf\uff0c\u5c06\u65b9\u8a00\u6807\u7b7e\u89c6\u4e3a\u8bed\u97f3\u5e8f\u5217\u7684\u6807\u7b7e\u5e8f\u5217\u3002\u8bad\u7ec3\u65f6\u4f7f\u7528\u8bed\u8a00\u65e0\u5173\u542f\u53d1\u5f0f\u65b9\u6cd5\u6216\u9884\u8bad\u7ec3ASR\u6a21\u578b\u4f30\u8ba1\u65b9\u8a00\u6807\u7b7e\u5728\u8f6c\u5f55\u4e2d\u7684\u91cd\u590d\u6b21\u6570\u3002\u57fa\u4e8e\u81ea\u76d1\u7763\u5b66\u4e60\u6784\u5efa\u6a21\u578b\u3002", "result": "\u5728\u4f4e\u8d44\u6e90\u963f\u62c9\u4f2f\u65b9\u8a00\u8bc6\u522b\u4efb\u52a1\u4e2d\uff0cCTC-DID\u6a21\u578b\u5728\u6709\u9650\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u540e\uff0c\u6027\u80fd\u4f18\u4e8e\u5fae\u8c03\u7684Whisper\u548cECAPA-TDNN\u6a21\u578b\u3002\u5728Casablanca\u6570\u636e\u96c6\u4e0a\u7684\u96f6\u6837\u672c\u8bc4\u4f30\u4e2d\u4e5f\u8868\u73b0\u66f4\u4f18\uff0c\u5bf9\u77ed\u8bed\u97f3\u66f4\u9c81\u68d2\uff0c\u4e14\u6613\u4e8e\u9002\u914d\u6d41\u5f0f\u5b9e\u65f6\u5e94\u7528\u3002", "conclusion": "CTC-DID\u65b9\u6cd5\u4e3a\u65b9\u8a00\u8bc6\u522b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4f4e\u8d44\u6e90\u573a\u666f\u548c\u5b9e\u65f6\u5e94\u7528\uff0c\u5c55\u73b0\u4e86CTC\u635f\u5931\u6846\u67b6\u5728\u65b9\u8a00\u8bc6\u522b\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.12208", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12208", "abs": "https://arxiv.org/abs/2601.12208", "authors": ["Yunzhe Li", "Richie Yueqi Feng", "Tianxin Wei", "Chin-Chia Hsu"], "title": "CoReflect: Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement", "comment": null, "summary": "Evaluating conversational systems in multi-turn settings remains a fundamental challenge. Conventional pipelines typically rely on manually defined rubrics and fixed conversational context$-$a static approach that limits coverage and fails to capture the diverse, emergent behaviors of dialogue models. To address this, we introduce CoReflect (Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement), which unifies dialogue simulation and evaluation into an adaptive, iterative process. CoReflect employs a conversation planner that generates structured templates to guide a user simulator through diverse, goal-directed dialogues. Subsequently, a reflective analyzer processes these dialogues to identify systematic behavioral patterns and automatically refine the evaluation rubrics. Crucially, the insights from the conversation analysis are fed back into the planner to update conversation templates for subsequent iterations. This co-evolution loop ensures that the complexity of test cases and the diagnostic precision of rubrics improve in tandem. By minimizing human intervention, CoReflect provides a scalable and self-refining methodology that allows evaluation protocols to adapt alongside the rapidly advancing capabilities of dialogue models.", "AI": {"tldr": "CoReflect\uff1a\u901a\u8fc7\u534f\u540c\u8fdb\u5316\u6a21\u62df\u548c\u53cd\u601d\u6027\u8bc4\u4f30\u51c6\u5219\u4f18\u5316\uff0c\u5b9e\u73b0\u5bf9\u8bdd\u7cfb\u7edf\u591a\u8f6e\u8bc4\u4f30\u7684\u81ea\u9002\u5e94\u8fed\u4ee3\u65b9\u6cd5", "motivation": "\u4f20\u7edf\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u5b9a\u4e49\u7684\u8bc4\u4f30\u51c6\u5219\u548c\u56fa\u5b9a\u5bf9\u8bdd\u4e0a\u4e0b\u6587\uff0c\u8fd9\u79cd\u9759\u6001\u65b9\u6cd5\u8986\u76d6\u8303\u56f4\u6709\u9650\uff0c\u65e0\u6cd5\u6355\u6349\u5bf9\u8bdd\u6a21\u578b\u591a\u6837\u5316\u7684\u6d8c\u73b0\u884c\u4e3a\uff0c\u96be\u4ee5\u9002\u5e94\u5feb\u901f\u53d1\u5c55\u7684\u5bf9\u8bdd\u6a21\u578b\u80fd\u529b", "method": "\u63d0\u51faCoReflect\u6846\u67b6\uff0c\u5c06\u5bf9\u8bdd\u6a21\u62df\u548c\u8bc4\u4f30\u7edf\u4e00\u4e3a\u81ea\u9002\u5e94\u8fed\u4ee3\u8fc7\u7a0b\uff1a1\uff09\u5bf9\u8bdd\u89c4\u5212\u5668\u751f\u6210\u7ed3\u6784\u5316\u6a21\u677f\u6307\u5bfc\u7528\u6237\u6a21\u62df\u5668\u8fdb\u884c\u591a\u6837\u5316\u76ee\u6807\u5bfc\u5411\u5bf9\u8bdd\uff1b2\uff09\u53cd\u601d\u5206\u6790\u5668\u5904\u7406\u5bf9\u8bdd\uff0c\u8bc6\u522b\u7cfb\u7edf\u6027\u884c\u4e3a\u6a21\u5f0f\u5e76\u81ea\u52a8\u4f18\u5316\u8bc4\u4f30\u51c6\u5219\uff1b3\uff09\u901a\u8fc7\u534f\u540c\u8fdb\u5316\u5faa\u73af\u5c06\u5206\u6790\u7ed3\u679c\u53cd\u9988\u7ed9\u89c4\u5212\u5668\u66f4\u65b0\u5bf9\u8bdd\u6a21\u677f", "result": "\u8be5\u65b9\u6cd5\u6700\u5c0f\u5316\u4eba\u5de5\u5e72\u9884\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u81ea\u4f18\u5316\u65b9\u6cd5\uff0c\u4f7f\u8bc4\u4f30\u534f\u8bae\u80fd\u591f\u9002\u5e94\u5bf9\u8bdd\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u6d4b\u8bd5\u7528\u4f8b\u590d\u6742\u5ea6\u548c\u8bc4\u4f30\u51c6\u5219\u8bca\u65ad\u7cbe\u5ea6\u540c\u6b65\u63d0\u5347", "conclusion": "CoReflect\u901a\u8fc7\u534f\u540c\u8fdb\u5316\u6a21\u62df\u548c\u53cd\u601d\u6027\u8bc4\u4f30\u51c6\u5219\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u591a\u8f6e\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u4f30\u7684\u6839\u672c\u6027\u6311\u6218\uff0c\u4e3a\u5bf9\u8bdd\u6a21\u578b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u81ea\u9002\u5e94\u3001\u53ef\u6269\u5c55\u7684\u6846\u67b6"}}
{"id": "2601.12247", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12247", "abs": "https://arxiv.org/abs/2601.12247", "authors": ["Miao Li", "Hanyang Jiang", "Sikai Chen", "Hengyu Fu", "Yuhang Cai", "Baihe Huang", "Tinghan Ye", "Xuanzhou Chen", "Pascal Van Hentenryck"], "title": "Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion Language Models", "comment": null, "summary": "Diffusion Language Models (DLMs) present a promising non-sequential paradigm for text generation, distinct from standard autoregressive (AR) approaches. However, current decoding strategies often adopt a reactive stance, underutilizing the global bidirectional context to dictate global trajectories. To address this, we propose Plan-Verify-Fill (PVF), a training-free paradigm that grounds planning via quantitative validation. PVF actively constructs a hierarchical skeleton by prioritizing high-leverage semantic anchors and employs a verification protocol to operationalize pragmatic structural stopping where further deliberation yields diminishing returns. Extensive evaluations on LLaDA-8B-Instruct and Dream-7B-Instruct demonstrate that PVF reduces the Number of Function Evaluations (NFE) by up to 65% compared to confidence-based parallel decoding across benchmark datasets, unlocking superior efficiency without compromising accuracy.", "AI": {"tldr": "PVF\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u6587\u672c\u751f\u6210\u8303\u5f0f\uff0c\u901a\u8fc7\u89c4\u5212-\u9a8c\u8bc1-\u586b\u5145\u673a\u5236\uff0c\u5728\u6269\u6563\u8bed\u8a00\u6a21\u578b\u4e2d\u5b9e\u73b0\u9ad8\u6548\u5e76\u884c\u89e3\u7801\uff0c\u51cf\u5c1165%\u7684\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u3002", "motivation": "\u5f53\u524d\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u89e3\u7801\u7b56\u7565\u5f80\u5f80\u662f\u88ab\u52a8\u7684\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u5168\u5c40\u53cc\u5411\u4e0a\u4e0b\u6587\u6765\u6307\u5bfc\u751f\u6210\u8f68\u8ff9\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u4e3b\u52a8\u89c4\u5212\u5168\u5c40\u7ed3\u6784\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u89e3\u7801\u6548\u7387\u3002", "method": "\u63d0\u51faPlan-Verify-Fill\uff08PVF\uff09\u8303\u5f0f\uff1a1\uff09\u4e3b\u52a8\u6784\u5efa\u5206\u5c42\u9aa8\u67b6\uff0c\u4f18\u5148\u9009\u62e9\u9ad8\u5f71\u54cd\u529b\u7684\u8bed\u4e49\u951a\u70b9\uff1b2\uff09\u91c7\u7528\u9a8c\u8bc1\u534f\u8bae\u5b9e\u73b0\u5b9e\u7528\u7ed3\u6784\u505c\u6b62\uff0c\u5f53\u8fdb\u4e00\u6b65\u601d\u8003\u6536\u76ca\u9012\u51cf\u65f6\u505c\u6b62\uff1b3\uff09\u57fa\u4e8e\u91cf\u5316\u9a8c\u8bc1\u8fdb\u884c\u89c4\u5212\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "result": "\u5728LLaDA-8B-Instruct\u548cDream-7B-Instruct\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cPVF\u76f8\u6bd4\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u5e76\u884c\u89e3\u7801\uff0c\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u51cf\u5c11\u4e86\u9ad8\u8fbe65%\u7684\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\uff08NFE\uff09\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6548\u7387\u3002", "conclusion": "PVF\u4e3a\u6269\u6563\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u8bad\u7ec3\u65e0\u5173\u89e3\u7801\u8303\u5f0f\uff0c\u901a\u8fc7\u4e3b\u52a8\u89c4\u5212\u548c\u9a8c\u8bc1\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u6548\u7387\uff0c\u4e3aDLMs\u7684\u5b9e\u9645\u5e94\u7528\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2601.12688", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12688", "abs": "https://arxiv.org/abs/2601.12688", "authors": ["Xu Zhang", "Qinghua Wang", "Mengyang Zhao", "Fang Wang", "Cunquan Qu"], "title": "Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction", "comment": null, "summary": "Crime disrupts societal stability, making law essential for balance. In multidefendant cases, assigning responsibility is complex and challenges fairness, requiring precise role differentiation. However, judicial phrasing often obscures the roles of the defendants, hindering effective AI-driven analyses. To address this issue, we incorporate sentencing logic into a pretrained Transformer encoder framework to enhance the intelligent assistance in multidefendant cases while ensuring legal interpretability. Within this framework an oriented masking mechanism clarifies roles and a comparative data construction strategy improves the model's sensitivity to culpability distinctions between principals and accomplices. Predicted guilt labels are further incorporated into a regression model through broadcasting, consolidating crime descriptions and court views. Our proposed masked multistage inference (MMSI) framework, evaluated on the custom IMLJP dataset for intentional injury cases, achieves significant accuracy improvements, outperforming baselines in role-based culpability differentiation. This work offers a robust solution for enhancing intelligent judicial systems, with publicly code available.", "AI": {"tldr": "\u63d0\u51faMMSI\u6846\u67b6\uff0c\u5c06\u91cf\u5211\u903b\u8f91\u878d\u5165Transformer\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u5b9a\u5411\u63a9\u853d\u673a\u5236\u6f84\u6e05\u591a\u88ab\u544a\u6848\u4ef6\u4e2d\u7684\u89d2\u8272\uff0c\u63d0\u5347AI\u53f8\u6cd5\u8f85\u52a9\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027", "motivation": "\u591a\u88ab\u544a\u6848\u4ef6\u4e2d\u8d23\u4efb\u5206\u914d\u590d\u6742\uff0c\u53f8\u6cd5\u8868\u8ff0\u5e38\u6a21\u7cca\u88ab\u544a\u89d2\u8272\uff0c\u963b\u788dAI\u5206\u6790\u3002\u9700\u8981\u63d0\u5347\u667a\u80fd\u53f8\u6cd5\u7cfb\u7edf\u5728\u533a\u5206\u4e3b\u4ece\u72af\u8d23\u4efb\u65b9\u9762\u7684\u80fd\u529b\uff0c\u540c\u65f6\u786e\u4fdd\u6cd5\u5f8b\u53ef\u89e3\u91ca\u6027", "method": "\u63d0\u51faMMSI\u6846\u67b6\uff1a1) \u5c06\u91cf\u5211\u903b\u8f91\u878d\u5165\u9884\u8bad\u7ec3Transformer\u7f16\u7801\u5668\uff1b2) \u5b9a\u5411\u63a9\u853d\u673a\u5236\u6f84\u6e05\u88ab\u544a\u89d2\u8272\uff1b3) \u5bf9\u6bd4\u6570\u636e\u6784\u5efa\u7b56\u7565\u589e\u5f3a\u6a21\u578b\u5bf9\u4e3b\u4ece\u72af\u8d23\u4efb\u533a\u5206\u7684\u654f\u611f\u6027\uff1b4) \u901a\u8fc7\u5e7f\u64ad\u5c06\u9884\u6d4b\u7684\u7f6a\u540d\u6807\u7b7e\u7eb3\u5165\u56de\u5f52\u6a21\u578b\uff0c\u6574\u5408\u72af\u7f6a\u63cf\u8ff0\u548c\u6cd5\u5ead\u89c2\u70b9", "result": "\u5728\u81ea\u5b9a\u4e49\u7684IMLJP\u6545\u610f\u4f24\u5bb3\u6848\u4ef6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cMMSI\u6846\u67b6\u5728\u89d2\u8272\u8d23\u4efb\u533a\u5206\u65b9\u9762\u53d6\u5f97\u663e\u8457\u51c6\u786e\u7387\u63d0\u5347\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u589e\u5f3a\u667a\u80fd\u53f8\u6cd5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7a33\u5065\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u6709\u6548\u533a\u5206\u591a\u88ab\u544a\u6848\u4ef6\u4e2d\u7684\u8d23\u4efb\uff0c\u4ee3\u7801\u5df2\u516c\u5f00"}}
{"id": "2601.12263", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12263", "abs": "https://arxiv.org/abs/2601.12263", "authors": ["Yixuan Du", "Chenxiao Yu", "Haoyan Xu", "Ziyi Wang", "Yue Zhao", "Xiyang Hu"], "title": "Multimodal Generative Engine Optimization: Rank Manipulation for Vision-Language Model Rankers", "comment": null, "summary": "Vision-Language Models (VLMs) are rapidly replacing unimodal encoders in modern retrieval and recommendation systems. While their capabilities are well-documented, their robustness against adversarial manipulation in competitive ranking scenarios remains largely unexplored. In this paper, we uncover a critical vulnerability in VLM-based product search: multimodal ranking attacks. We present Multimodal Generative Engine Optimization (MGEO), a novel adversarial framework that enables a malicious actor to unfairly promote a target product by jointly optimizing imperceptible image perturbations and fluent textual suffixes. Unlike existing attacks that treat modalities in isolation, MGEO employs an alternating gradient-based optimization strategy to exploit the deep cross-modal coupling within the VLM. Extensive experiments on real-world datasets using state-of-the-art models demonstrate that our coordinated attack significantly outperforms text-only and image-only baselines. These findings reveal that multimodal synergy, typically a strength of VLMs, can be weaponized to compromise the integrity of search rankings without triggering conventional content filters.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u5546\u54c1\u641c\u7d22\u4e2d\u7684\u591a\u6a21\u6001\u6392\u540d\u653b\u51fb\u6f0f\u6d1e\uff0c\u63d0\u51faMGEO\u6846\u67b6\u901a\u8fc7\u8054\u5408\u4f18\u5316\u56fe\u50cf\u6270\u52a8\u548c\u6587\u672c\u540e\u7f00\u6765\u4e0d\u516c\u5e73\u5730\u63d0\u5347\u76ee\u6807\u4ea7\u54c1\u6392\u540d", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u4ee3\u68c0\u7d22\u548c\u63a8\u8350\u7cfb\u7edf\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5728\u7ade\u4e89\u6027\u6392\u540d\u573a\u666f\u4e0b\u5bf9\u6297\u64cd\u7eb5\u7684\u9c81\u68d2\u6027\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u63ed\u793aVLM\u5728\u5546\u54c1\u641c\u7d22\u4e2d\u7684\u591a\u6a21\u6001\u6392\u540d\u653b\u51fb\u6f0f\u6d1e", "method": "\u63d0\u51fa\u591a\u6a21\u6001\u751f\u6210\u5f15\u64ce\u4f18\u5316\uff08MGEO\uff09\u6846\u67b6\uff0c\u91c7\u7528\u4ea4\u66ff\u68af\u5ea6\u4f18\u5316\u7b56\u7565\uff0c\u8054\u5408\u4f18\u5316\u4e0d\u53ef\u611f\u77e5\u7684\u56fe\u50cf\u6270\u52a8\u548c\u6d41\u7545\u7684\u6587\u672c\u540e\u7f00\uff0c\u5229\u7528VLM\u5185\u90e8\u7684\u6df1\u5ea6\u8de8\u6a21\u6001\u8026\u5408", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u6700\u5148\u8fdb\u6a21\u578b\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u534f\u8c03\u653b\u51fb\u663e\u8457\u4f18\u4e8e\u4ec5\u6587\u672c\u548c\u4ec5\u56fe\u50cf\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bc1\u5b9e\u591a\u6a21\u6001\u534f\u540c\u53ef\u4ee5\u88ab\u6b66\u5668\u5316\u4ee5\u7834\u574f\u641c\u7d22\u6392\u540d\u5b8c\u6574\u6027", "conclusion": "\u591a\u6a21\u6001\u534f\u540c\u4f5c\u4e3aVLM\u7684\u4f18\u52bf\uff0c\u53ef\u80fd\u88ab\u6b66\u5668\u5316\u4ee5\u5728\u4e0d\u89e6\u53d1\u4f20\u7edf\u5185\u5bb9\u8fc7\u6ee4\u5668\u7684\u60c5\u51b5\u4e0b\u635f\u5bb3\u641c\u7d22\u6392\u540d\u7684\u5b8c\u6574\u6027\uff0c\u63ed\u793a\u4e86VLM\u5728\u5bf9\u6297\u6027\u6392\u540d\u573a\u666f\u4e2d\u7684\u5173\u952e\u6f0f\u6d1e"}}
{"id": "2601.12269", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12269", "abs": "https://arxiv.org/abs/2601.12269", "authors": ["Xucong Hu", "Jian-Qiao Zhu"], "title": "Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive Language Models", "comment": null, "summary": "Autoregressive language models are next-token predictors and have been criticized for only optimizing surface plausibility (i.e., local coherence) rather than maintaining correct latent-state representations (i.e., global coherence). Because Theory of Mind (ToM) tasks crucially depend on reasoning about latent mental states of oneself and others, such models are therefore often thought to fail at ToM. While post-training methods can improve ToM performance, we show that strong ToM capability can be recovered directly from the base model without any additional weight updates or verifications. Our approach builds on recent power-sampling methods (Karan & Du, 2025) that use Markov chain Monte Carlo (MCMC) to sample from sharpened sequence-level (rather than token-level) probability distributions of autoregressive language models. We further find that incorporating annealing, where the tempered distribution is gradually shifted from high to low temperature, substantially improves ToM performance over fixed-temperature power sampling. Together, these results suggest that sampling-based optimization provides a powerful way to extract latent capabilities from language models without retraining.", "AI": {"tldr": "\u901a\u8fc7MCMC\u91c7\u6837\u548c\u9000\u706b\u6280\u672f\uff0c\u4ece\u57fa\u7840\u8bed\u8a00\u6a21\u578b\u4e2d\u6062\u590d\u5f3a\u5927\u7684\u5fc3\u7406\u7406\u8bba\u80fd\u529b\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u6743\u91cd\u66f4\u65b0", "motivation": "\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u88ab\u8ba4\u4e3a\u662f\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\u5668\uff0c\u4e3b\u8981\u4f18\u5316\u8868\u9762\u5408\u7406\u6027\u800c\u975e\u4fdd\u6301\u6b63\u786e\u7684\u6f5c\u5728\u72b6\u6001\u8868\u793a\uff0c\u56e0\u6b64\u88ab\u8ba4\u4e3a\u5728\u5fc3\u7406\u7406\u8bba\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002\u867d\u7136\u540e\u8bad\u7ec3\u65b9\u6cd5\u53ef\u4ee5\u6539\u8fdb\u5fc3\u7406\u7406\u8bba\u6027\u80fd\uff0c\u4f46\u7814\u7a76\u65e8\u5728\u76f4\u63a5\u4ece\u57fa\u7840\u6a21\u578b\u4e2d\u6062\u590d\u8fd9\u79cd\u80fd\u529b\uff0c\u65e0\u9700\u989d\u5916\u6743\u91cd\u66f4\u65b0\u6216\u9a8c\u8bc1\u3002", "method": "\u57fa\u4e8eKaran & Du (2025)\u7684power-sampling\u65b9\u6cd5\uff0c\u4f7f\u7528\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\u4ece\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u7684\u5e8f\u5217\u7ea7\u6982\u7387\u5206\u5e03\u4e2d\u91c7\u6837\u3002\u8fdb\u4e00\u6b65\u5f15\u5165\u9000\u706b\u6280\u672f\uff0c\u5c06\u6e29\u5ea6\u5206\u5e03\u4ece\u9ad8\u6e29\u9010\u6e10\u8f6c\u79fb\u5230\u4f4e\u6e29\uff0c\u663e\u8457\u6539\u8fdb\u4e86\u56fa\u5b9a\u6e29\u5ea6power sampling\u7684\u5fc3\u7406\u7406\u8bba\u6027\u80fd\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u91c7\u6837\u4f18\u5316\u65b9\u6cd5\u53ef\u4ee5\u4ece\u8bed\u8a00\u6a21\u578b\u4e2d\u63d0\u53d6\u6f5c\u5728\u80fd\u529b\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002\u9000\u706b\u6280\u672f\u7684\u52a0\u5165\u663e\u8457\u63d0\u5347\u4e86\u5fc3\u7406\u7406\u8bba\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u8d85\u8fc7\u4e86\u56fa\u5b9a\u6e29\u5ea6\u7684power sampling\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u91c7\u6837\u7684\u4f18\u5316\u65b9\u6cd5\u4e3a\u4ece\u8bed\u8a00\u6a21\u578b\u4e2d\u63d0\u53d6\u6f5c\u5728\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u79cd\u5f3a\u5927\u9014\u5f84\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002\u8fd9\u6311\u6218\u4e86\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u5904\u7406\u5fc3\u7406\u7406\u8bba\u4efb\u52a1\u7684\u4f20\u7edf\u89c2\u70b9\uff0c\u8868\u660e\u901a\u8fc7\u9002\u5f53\u7684\u91c7\u6837\u7b56\u7565\u53ef\u4ee5\u6062\u590d\u6a21\u578b\u7684\u6df1\u5c42\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2601.12720", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12720", "abs": "https://arxiv.org/abs/2601.12720", "authors": ["Hanbin Wang", "Jingwei Song", "Jinpeng Li", "Qi Zhu", "Fei Mi", "Ganqu Cui", "Yasheng Wang", "Lifeng Shang"], "title": "Teaching Large Reasoning Models Effective Reflection", "comment": "14 pages (including appendix), 5 figures", "summary": "Large Reasoning Models (LRMs) have recently shown impressive performance on complex reasoning tasks, often by engaging in self-reflective behaviors such as self-critique and backtracking. However, not all reflections are beneficial-many are superficial, offering little to no improvement over the original answer and incurring computation overhead. In this paper, we identify and address the problem of superficial reflection in LRMs. We first propose Self-Critique Fine-Tuning (SCFT), a training framework that enhances the model's reflective reasoning ability using only self-generated critiques. SCFT prompts models to critique their own outputs, filters high-quality critiques through rejection sampling, and fine-tunes the model using a critique-based objective. Building on this strong foundation, we further introduce Reinforcement Learning with Effective Reflection Rewards (RLERR). RLERR leverages the high-quality reflections initialized by SCFT to construct reward signals, guiding the model to internalize the self-correction process via reinforcement learning. Experiments on two challenging benchmarks, AIME2024 and AIME2025, show that SCFT and RLERR significantly improve both reasoning accuracy and reflection quality, outperforming state-of-the-art baselines. All data and codes are available at https://github.com/wanghanbinpanda/SCFT.", "code_url": "https://github.com/wanghanbinpanda/SCFT", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSCFT\u548cRLERR\u65b9\u6cd5\u89e3\u51b3\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u8868\u9762\u53cd\u601d\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u6211\u6279\u5224\u5fae\u8c03\u548c\u6709\u6548\u53cd\u601d\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u63a8\u7406\u51c6\u786e\u6027\u548c\u53cd\u601d\u8d28\u91cf\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u8bb8\u591a\u53cd\u601d\u662f\u8868\u9762\u7684\uff0c\u65e0\u6cd5\u663e\u8457\u6539\u8fdb\u539f\u59cb\u7b54\u6848\u4e14\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\u3002\u672c\u6587\u65e8\u5728\u8bc6\u522b\u5e76\u89e3\u51b3LRMs\u4e2d\u7684\u8868\u9762\u53cd\u601d\u95ee\u9898\u3002", "method": "1. \u63d0\u51fa\u81ea\u6211\u6279\u5224\u5fae\u8c03\u6846\u67b6\uff1a\u8ba9\u6a21\u578b\u6279\u5224\u81ea\u8eab\u8f93\u51fa\uff0c\u901a\u8fc7\u62d2\u7edd\u91c7\u6837\u7b5b\u9009\u9ad8\u8d28\u91cf\u6279\u5224\uff0c\u4f7f\u7528\u6279\u5224\u76ee\u6807\u5fae\u8c03\u6a21\u578b\u30022. \u5f15\u5165\u6709\u6548\u53cd\u601d\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\uff1a\u5229\u7528SCFT\u521d\u59cb\u5316\u9ad8\u8d28\u91cf\u53cd\u601d\u6784\u5efa\u5956\u52b1\u4fe1\u53f7\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5185\u5316\u81ea\u6211\u4fee\u6b63\u8fc7\u7a0b\u3002", "result": "\u5728AIME2024\u548cAIME2025\u4e24\u4e2a\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSCFT\u548cRLERR\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u51c6\u786e\u6027\u548c\u53cd\u601d\u8d28\u91cf\uff0c\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "SCFT\u548cRLERR\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u8868\u9762\u53cd\u601d\u95ee\u9898\uff0c\u901a\u8fc7\u589e\u5f3a\u6a21\u578b\u7684\u53cd\u601d\u63a8\u7406\u80fd\u529b\u548c\u5185\u5316\u81ea\u6211\u4fee\u6b63\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2601.12286", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.12286", "abs": "https://arxiv.org/abs/2601.12286", "authors": ["Jonathan Pan"], "title": "Conversational Context Classification: A Representation Engineering Approach", "comment": null, "summary": "The increasing prevalence of Large Language Models (LLMs) demands effective safeguards for their operation, particularly concerning their tendency to generate out-of-context responses. A key challenge is accurately detecting when LLMs stray from expected conversational norms, manifesting as topic shifts, factual inaccuracies, or outright hallucinations. Traditional anomaly detection struggles to directly apply within contextual semantics. This paper outlines our experiment in exploring the use of Representation Engineering (RepE) and One-Class Support Vector Machine (OCSVM) to identify subspaces within the internal states of LLMs that represent a specific context. By training OCSVM on in-context examples, we establish a robust boundary within the LLM's hidden state latent space. We evaluate out study with two open source LLMs - Llama and Qwen models in specific contextual domain. Our approach entailed identifying the optimal layers within the LLM's internal state subspaces that strongly associates with the context of interest. Our evaluation results showed promising results in identifying the subspace for a specific context. Aside from being useful in detecting in or out of context conversation threads, this research work contributes to the study of better interpreting LLMs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u7d22\u4f7f\u7528\u8868\u793a\u5de5\u7a0b\u548c\u4e00\u7c7b\u652f\u6301\u5411\u91cf\u673a\u5728LLM\u5185\u90e8\u72b6\u6001\u4e2d\u8bc6\u522b\u7279\u5b9a\u4e0a\u4e0b\u6587\u5b50\u7a7a\u95f4\uff0c\u4ee5\u68c0\u6d4b\u5bf9\u8bdd\u4e2d\u7684\u79bb\u9898\u54cd\u5e94", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u666e\u53ca\uff0c\u9700\u8981\u6709\u6548\u4fdd\u969c\u5176\u64cd\u4f5c\u5b89\u5168\uff0c\u7279\u522b\u662f\u68c0\u6d4b\u5176\u751f\u6210\u79bb\u9898\u54cd\u5e94\uff08\u8bdd\u9898\u8f6c\u79fb\u3001\u4e8b\u5b9e\u9519\u8bef\u6216\u5e7b\u89c9\uff09\u7684\u80fd\u529b\u3002\u4f20\u7edf\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u76f4\u63a5\u5e94\u7528\u4e8e\u4e0a\u4e0b\u6587\u8bed\u4e49\u5206\u6790\u3002", "method": "\u91c7\u7528\u8868\u793a\u5de5\u7a0b\u548c\u4e00\u7c7b\u652f\u6301\u5411\u91cf\u673a\u65b9\u6cd5\uff0c\u5728LLM\u5185\u90e8\u72b6\u6001\u4e2d\u8bc6\u522b\u4e0e\u7279\u5b9a\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u5b50\u7a7a\u95f4\u3002\u901a\u8fc7\u8bad\u7ec3OCSVM\u5efa\u7acb\u9690\u85cf\u72b6\u6001\u6f5c\u5728\u7a7a\u95f4\u7684\u8fb9\u754c\uff0c\u5e76\u5728Llama\u548cQwen\u6a21\u578b\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u8bc6\u522b\u4e0e\u611f\u5174\u8da3\u4e0a\u4e0b\u6587\u5f3a\u5173\u8054\u7684\u6700\u4f18\u5c42\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u8bc6\u522b\u7279\u5b9a\u4e0a\u4e0b\u6587\u5b50\u7a7a\u95f4\u65b9\u9762\u8868\u73b0\u51fa\u826f\u597d\u6548\u679c\uff0c\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u5bf9\u8bdd\u7ebf\u7a0b\u662f\u5426\u5728\u7279\u5b9a\u4e0a\u4e0b\u6587\u8303\u56f4\u5185\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u53ef\u7528\u4e8e\u68c0\u6d4b\u5bf9\u8bdd\u7684\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\uff0c\u8fd8\u4e3a\u66f4\u597d\u5730\u89e3\u91ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7814\u7a76\u505a\u51fa\u4e86\u8d21\u732e\u3002"}}
{"id": "2601.12781", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12781", "abs": "https://arxiv.org/abs/2601.12781", "authors": ["Hyejin Park", "Junhyuk Kwon", "Suha Kwak", "Jungseul Ok"], "title": "VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension", "comment": null, "summary": "Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.", "AI": {"tldr": "VIRO\u6846\u67b6\u901a\u8fc7\u96c6\u6210\u8f7b\u91cf\u7ea7\u9a8c\u8bc1\u5668\u5230\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u6b65\u9aa4\u4e2d\uff0c\u89e3\u51b3REC\u4efb\u52a1\u4e2d\u56e0\u4e2d\u95f4\u6b65\u9aa4\u9519\u8bef\u5bfc\u81f4\u7684\u7ea7\u8054\u9519\u8bef\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u65e0\u76ee\u6807\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u7b26\u53f7REC\u65b9\u6cd5\u4f9d\u8d56LLM\u548cVLM\u8fdb\u884c\u7ec4\u5408\u63a8\u7406\uff0c\u4f46\u5047\u8bbe\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u51c6\u786e\uff0c\u5bfc\u81f4\u7ea7\u8054\u9519\u8bef\uff1a\u9519\u8bef\u68c0\u6d4b\u548c\u65e0\u6548\u5173\u7cfb\u5728\u63a8\u7406\u94fe\u4e2d\u4f20\u64ad\uff0c\u5373\u4f7f\u56fe\u50cf\u4e2d\u6ca1\u6709\u76ee\u6807\u4e5f\u4f1a\u4ea7\u751f\u9ad8\u7f6e\u4fe1\u5ea6\u7684\u5047\u9633\u6027\u7ed3\u679c\u3002", "method": "\u63d0\u51fa\u9a8c\u8bc1\u96c6\u6210\u63a8\u7406\u7b97\u5b50(VIRO)\u6846\u67b6\uff0c\u5728\u63a8\u7406\u6b65\u9aa4\u4e2d\u5d4c\u5165\u8f7b\u91cf\u7ea7\u7684\u7b97\u5b50\u7ea7\u9a8c\u8bc1\u5668\u3002\u6bcf\u4e2a\u7b97\u5b50\u6267\u884c\u5e76\u9a8c\u8bc1\u5176\u8f93\u51fa\uff08\u5982\u5bf9\u8c61\u5b58\u5728\u6027\u6216\u7a7a\u95f4\u5173\u7cfb\uff09\uff0c\u5f53\u9a8c\u8bc1\u6761\u4ef6\u4e0d\u6ee1\u8db3\u65f6\uff0c\u7cfb\u7edf\u80fd\u591f\u9c81\u68d2\u5730\u5904\u7406\u65e0\u76ee\u6807\u60c5\u51b5\u3002", "result": "\u5728\u76ee\u6807\u5b58\u5728\u548c\u65e0\u76ee\u6807\u8bbe\u7f6e\u4e0b\u8fbe\u523061.1%\u7684\u5e73\u8861\u51c6\u786e\u7387\uff0c\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\uff1b\u5728\u771f\u5b9e\u4e16\u754c\u81ea\u6211\u4e2d\u5fc3\u6570\u636e\u4e0a\u5c55\u793a\u6cdb\u5316\u80fd\u529b\uff1b\u8ba1\u7b97\u6548\u7387\u9ad8\uff08\u541e\u5410\u91cf\uff09\u3001\u53ef\u9760\u6027\u5f3a\uff08\u7a0b\u5e8f\u5931\u8d25\u7387\u4f4e\u4e8e0.3%\uff09\uff0c\u5e76\u901a\u8fc7\u89e3\u8026\u7a0b\u5e8f\u751f\u6210\u4e0e\u6267\u884c\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "VIRO\u6846\u67b6\u901a\u8fc7\u96c6\u6210\u9a8c\u8bc1\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u795e\u7ecf\u7b26\u53f7REC\u4e2d\u7684\u7ea7\u8054\u9519\u8bef\u95ee\u9898\uff0c\u5728\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u3001\u6548\u7387\u548c\u53ef\u9760\u6027\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u5904\u7406\u65e0\u76ee\u6807\u573a\u666f\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12374", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12374", "abs": "https://arxiv.org/abs/2601.12374", "authors": ["Akram Elbouanani", "Aboubacar Tuo", "Adrian Popescu"], "title": "A Scalable Entity-Based Framework for Auditing Bias in LLMs", "comment": null, "summary": "Existing approaches to bias evaluation in large language models (LLMs) trade ecological validity for statistical control, relying on artificial prompts that poorly reflect real-world use, or on naturalistic tasks that lack scale and rigor. We introduce a scalable bias-auditing framework using named entities as probes to measure structural disparities in model behavior. We show that synthetic data reliably reproduces bias patterns observed in natural text, enabling large-scale analysis. Using this approach, we conduct the largest bias audit to date, comprising 1.9 billion data points across multiple entity types, tasks, languages, models, and prompting strategies. Our results reveal systematic biases: models penalize right-wing politicians, favor left-wing politicians, prefer Western and wealthy nations over the Global South, favor Western companies, and penalize firms in the defense and pharmaceutical sectors. While instruction tuning reduces bias, increasing model scale amplifies it, and prompting in Chinese or Russian does not attenuate Western-aligned preferences. These results indicate that LLMs should undergo rigorous auditing before deployment in high-stakes applications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4f7f\u7528\u547d\u540d\u5b9e\u4f53\u4f5c\u4e3a\u63a2\u9488\u7684\u53ef\u6269\u5c55\u504f\u89c1\u5ba1\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u5408\u6210\u6570\u636e\u91cd\u73b0\u81ea\u7136\u6587\u672c\u4e2d\u7684\u504f\u89c1\u6a21\u5f0f\uff0c\u8fdb\u884c\u4e86\u8fc4\u4eca\u4e3a\u6b62\u6700\u5927\u7684\u504f\u89c1\u5ba1\u8ba1\uff0819\u4ebf\u6570\u636e\u70b9\uff09\uff0c\u63ed\u793a\u4e86LLMs\u4e2d\u7684\u7cfb\u7edf\u6027\u504f\u89c1\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u504f\u89c1\u8bc4\u4f30\u65b9\u6cd5\u5728\u751f\u6001\u6548\u5ea6\u548c\u7edf\u8ba1\u63a7\u5236\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff1a\u4eba\u5de5\u63d0\u793a\u4e0d\u80fd\u53cd\u6620\u771f\u5b9e\u4f7f\u7528\u573a\u666f\uff0c\u800c\u81ea\u7136\u4efb\u52a1\u7f3a\u4e4f\u89c4\u6a21\u548c\u4e25\u8c28\u6027\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u751f\u6001\u6548\u5ea6\u53c8\u80fd\u8fdb\u884c\u5927\u89c4\u6a21\u5206\u6790\u7684\u504f\u89c1\u5ba1\u8ba1\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u547d\u540d\u5b9e\u4f53\u7684\u53ef\u6269\u5c55\u504f\u89c1\u5ba1\u8ba1\u6846\u67b6\uff0c\u4f7f\u7528\u5408\u6210\u6570\u636e\u53ef\u9760\u5730\u91cd\u73b0\u81ea\u7136\u6587\u672c\u4e2d\u7684\u504f\u89c1\u6a21\u5f0f\u3002\u901a\u8fc7\u5b9e\u4f53\u4f5c\u4e3a\u63a2\u9488\uff0c\u6d4b\u91cf\u6a21\u578b\u884c\u4e3a\u4e2d\u7684\u7ed3\u6784\u6027\u5dee\u5f02\uff0c\u6db5\u76d6\u591a\u79cd\u5b9e\u4f53\u7c7b\u578b\u3001\u4efb\u52a1\u3001\u8bed\u8a00\u3001\u6a21\u578b\u548c\u63d0\u793a\u7b56\u7565\u3002", "result": "\u8fdb\u884c\u4e86\u8fc4\u4eca\u4e3a\u6b62\u6700\u5927\u7684\u504f\u89c1\u5ba1\u8ba1\uff0819\u4ebf\u6570\u636e\u70b9\uff09\uff0c\u53d1\u73b0\u7cfb\u7edf\u6027\u504f\u89c1\uff1a\u6a21\u578b\u60e9\u7f5a\u53f3\u7ffc\u653f\u5ba2\u3001\u504f\u7231\u5de6\u7ffc\u653f\u5ba2\u3001\u504f\u597d\u897f\u65b9\u548c\u5bcc\u88d5\u56fd\u5bb6\u800c\u975e\u5168\u7403\u5357\u65b9\u3001\u504f\u7231\u897f\u65b9\u516c\u53f8\u3001\u60e9\u7f5a\u56fd\u9632\u548c\u5236\u836f\u884c\u4e1a\u516c\u53f8\u3002\u6307\u4ee4\u5fae\u8c03\u51cf\u5c11\u504f\u89c1\uff0c\u4f46\u6a21\u578b\u89c4\u6a21\u589e\u5927\u4f1a\u653e\u5927\u504f\u89c1\uff0c\u4e2d\u6587\u6216\u4fc4\u6587\u63d0\u793a\u4e0d\u4f1a\u51cf\u5f31\u897f\u65b9\u504f\u597d\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u90e8\u7f72\u524d\u5e94\u8fdb\u884c\u4e25\u683c\u5ba1\u8ba1\uff0c\u56e0\u4e3a\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u4e14\u6a21\u578b\u89c4\u6a21\u589e\u5927\u4f1a\u653e\u5927\u504f\u89c1\uff0c\u8bed\u8a00\u63d0\u793a\u7b56\u7565\u4e0d\u80fd\u6709\u6548\u51cf\u8f7b\u897f\u65b9\u4e2d\u5fc3\u4e3b\u4e49\u504f\u597d\u3002"}}
{"id": "2601.12804", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12804", "abs": "https://arxiv.org/abs/2601.12804", "authors": ["Hanwei Zhang", "Luo Cheng", "Rui Wen", "Yang Zhang", "Lijun Zhang", "Holger Hermanns"], "title": "SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability", "comment": null, "summary": "Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) have emerged as a promising ante-hoc approach that provides interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. In this work, we propose SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1x1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model's internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Our ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.", "AI": {"tldr": "SL-CBM\u901a\u8fc7\u5f15\u5165\u8bed\u4e49\u5c40\u90e8\u6027\u589e\u5f3a\u6982\u5ff5\u74f6\u9888\u6a21\u578b\uff0c\u751f\u6210\u7a7a\u95f4\u4e00\u81f4\u7684\u6982\u5ff5\u548c\u7c7b\u522b\u663e\u8457\u6027\u56fe\uff0c\u63d0\u9ad8\u5c40\u90e8\u5fe0\u5b9e\u6027\u548c\u53ef\u89e3\u91ca\u6027", "motivation": "\u73b0\u6709\u6982\u5ff5\u74f6\u9888\u6a21\u578b\u7f3a\u4e4f\u5c40\u90e8\u5fe0\u5b9e\u6027\uff0c\u65e0\u6cd5\u5c06\u6982\u5ff5\u4e0e\u6709\u610f\u4e49\u7684\u56fe\u50cf\u533a\u57df\u7a7a\u95f4\u5bf9\u9f50\uff0c\u9650\u5236\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027", "method": "\u63d0\u51faSL-CBM\uff0c\u96c6\u62101x1\u5377\u79ef\u5c42\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u589e\u5f3a\u6982\u5ff5\u3001\u56fe\u50cf\u533a\u57df\u548c\u6700\u7ec8\u9884\u6d4b\u4e4b\u95f4\u7684\u5bf9\u9f50\uff0c\u751f\u6210\u7a7a\u95f4\u4e00\u81f4\u7684\u663e\u8457\u6027\u56fe", "result": "\u5728\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u5c40\u90e8\u5fe0\u5b9e\u6027\u3001\u89e3\u91ca\u8d28\u91cf\u548c\u5e72\u9884\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u5206\u7c7b\u51c6\u786e\u7387", "conclusion": "SL-CBM\u586b\u8865\u4e86\u6982\u5ff5\u63a8\u7406\u548c\u7a7a\u95f4\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u4e3a\u53ef\u89e3\u91ca\u548c\u53ef\u4fe1\u7684\u6982\u5ff5\u6a21\u578b\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6"}}
{"id": "2601.12376", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12376", "abs": "https://arxiv.org/abs/2601.12376", "authors": ["Ofek Raban", "Ethan Fetaya", "Gal Chechik"], "title": "LR-DWM: Efficient Watermarking for Diffusion Language Models", "comment": "Submitted to ACL Rolling Review (ARR). 7 pages, 4 figures", "summary": "Watermarking (WM) is a critical mechanism for detecting and attributing AI-generated content. Current WM methods for Large Language Models (LLMs) are predominantly tailored for autoregressive (AR) models: They rely on tokens being generated sequentially, and embed stable signals within the generated sequence based on the previously sampled text. Diffusion Language Models (DLMs) generate text via non-sequential iterative denoising, which requires significant modification to use WM methods designed for AR models. Recent work proposed to watermark DLMs by inverting the process when needed, but suffers significant computational or memory overhead. We introduce Left-Right Diffusion Watermarking (LR-DWM), a scheme that biases the generated token based on both left and right neighbors, when they are available. LR-DWM incurs minimal runtime and memory overhead, remaining close to the non-watermarked baseline DLM while enabling reliable statistical detection under standard evaluation settings. Our results demonstrate that DLMs can be watermarked efficiently, achieving high detectability with negligible computational and memory overhead.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLR-DWM\u7684\u6c34\u5370\u65b9\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u5229\u7528\u5de6\u53f3\u90bb\u5c45token\u6765\u5d4c\u5165\u6c34\u5370\u4fe1\u53f7\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6c34\u5370\u5d4c\u5165\u548c\u68c0\u6d4b\u3002", "motivation": "\u73b0\u6709\u6c34\u5370\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\uff0c\u4f9d\u8d56token\u7684\u987a\u5e8f\u751f\u6210\u3002\u6269\u6563\u8bed\u8a00\u6a21\u578b\u91c7\u7528\u975e\u987a\u5e8f\u8fed\u4ee3\u53bb\u566a\u751f\u6210\u6587\u672c\uff0c\u9700\u8981\u5927\u5e45\u4fee\u6539\u73b0\u6709\u6c34\u5370\u65b9\u6cd5\u3002\u6700\u8fd1\u7684\u5de5\u4f5c\u901a\u8fc7\u53cd\u8f6c\u8fc7\u7a0b\u5b9e\u73b0\u6c34\u5370\uff0c\u4f46\u5b58\u5728\u663e\u8457\u7684\u8ba1\u7b97\u6216\u5185\u5b58\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u5de6\u53f3\u6269\u6563\u6c34\u5370\u65b9\u6cd5\uff0c\u5f53\u5de6\u53f3\u90bb\u5c45token\u53ef\u7528\u65f6\uff0c\u57fa\u4e8e\u8fd9\u4e24\u4e2a\u90bb\u5c45\u6765\u504f\u7f6e\u751f\u6210\u7684token\u3002\u8be5\u65b9\u6cd5\u5728\u8fd0\u884c\u65f6\u548c\u5185\u5b58\u5f00\u9500\u4e0a\u63a5\u8fd1\u672a\u52a0\u6c34\u5370\u7684\u57fa\u7ebf\u6269\u6563\u8bed\u8a00\u6a21\u578b\u3002", "result": "LR-DWM\u5728\u6807\u51c6\u8bc4\u4f30\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u4e86\u53ef\u9760\u7684\u7edf\u8ba1\u68c0\u6d4b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63a5\u8fd1\u672a\u52a0\u6c34\u5370\u57fa\u7ebf\u6a21\u578b\u7684\u8fd0\u884c\u6548\u7387\u548c\u5185\u5b58\u4f7f\u7528\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u6269\u6563\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u9ad8\u6548\u5730\u52a0\u6c34\u5370\uff0c\u5b9e\u73b0\u9ad8\u53ef\u68c0\u6d4b\u6027\u4e14\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u53ef\u5ffd\u7565\u3002", "conclusion": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7LR-DWM\u65b9\u6cd5\u9ad8\u6548\u5730\u6dfb\u52a0\u6c34\u5370\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u5de6\u53f3\u90bb\u5c45token\u5d4c\u5165\u6c34\u5370\u4fe1\u53f7\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u53ef\u9760\u7684\u6c34\u5370\u68c0\u6d4b\u3002"}}
{"id": "2601.12389", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12389", "abs": "https://arxiv.org/abs/2601.12389", "authors": ["Lakshya Tomar", "Vinayak Abrol", "Puneet Agarwal"], "title": "NADIR: Differential Attention Flow for Non-Autoregressive Transliteration in Indic Languages", "comment": "Accepted at the AAAI Conference on Artificial Intelligence (AAAI 2026)", "summary": "In this work, we argue that not all sequence-to-sequence tasks require the strong inductive biases of autoregressive (AR) models. Tasks like multilingual transliteration, code refactoring, grammatical correction or text normalization often rely on local dependencies where the full modeling capacity of AR models can be overkill, creating a trade-off between their high accuracy and high inference latency. While non-autoregressive (NAR) models offer speed, they typically suffer from hallucinations and poor length control. To explore this trade-off, we focus on the multilingual transliteration task in Indic languages and introduce NADIR, a novel NAR architecture designed to strike a balance between speed and accuracy. NADIR integrates a Differential Transformer and a Mixture-of-Experts mechanism, enabling it to robustly model complex character mappings without sequential dependencies. NADIR achieves over a 13x speed-up compared to the state-of-the-art AR baseline. It maintains a competitive mean Character Error Rate of 15.78%, compared to 14.44% for the AR model and 21.88% for a standard NAR equivalent. Importantly, NADIR reduces Repetition errors by 49.53%, Substitution errors by 24.45%, Omission errors by 32.92%, and Insertion errors by 16.87%. This work provides a practical blueprint for building fast and reliable NAR systems, effectively bridging the gap between AR accuracy and the demands of real-time, large-scale deployment.", "AI": {"tldr": "NADIR\u662f\u4e00\u79cd\u65b0\u578b\u975e\u81ea\u56de\u5f52\u67b6\u6784\uff0c\u9488\u5bf9\u591a\u8bed\u8a00\u97f3\u8bd1\u7b49\u5c40\u90e8\u4f9d\u8d56\u4efb\u52a1\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5b9e\u73b013\u500d\u52a0\u901f\uff0c\u5e73\u8861\u4e86\u81ea\u56de\u5f52\u6a21\u578b\u7684\u9ad8\u5ef6\u8fdf\u548c\u975e\u81ea\u56de\u5f52\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u8bb8\u591a\u5e8f\u5217\u5230\u5e8f\u5217\u4efb\u52a1\uff08\u5982\u591a\u8bed\u8a00\u97f3\u8bd1\u3001\u4ee3\u7801\u91cd\u6784\u3001\u8bed\u6cd5\u4fee\u6b63\u7b49\uff09\u4e3b\u8981\u4f9d\u8d56\u5c40\u90e8\u4f9d\u8d56\u5173\u7cfb\uff0c\u81ea\u56de\u5f52\u6a21\u578b\u867d\u7136\u51c6\u786e\u4f46\u63a8\u7406\u5ef6\u8fdf\u9ad8\uff0c\u800c\u975e\u81ea\u56de\u5f52\u6a21\u578b\u901f\u5ea6\u5feb\u4f46\u5b58\u5728\u5e7b\u89c9\u548c\u957f\u5ea6\u63a7\u5236\u95ee\u9898\u3002\u9700\u8981\u5728\u51c6\u786e\u6027\u548c\u901f\u5ea6\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u3002", "method": "\u63d0\u51faNADIR\u67b6\u6784\uff0c\u7ed3\u5408\u5dee\u5206Transformer\u548c\u4e13\u5bb6\u6df7\u5408\u673a\u5236\uff0c\u80fd\u591f\u5efa\u6a21\u590d\u6742\u5b57\u7b26\u6620\u5c04\u800c\u65e0\u9700\u5e8f\u5217\u4f9d\u8d56\u3002\u8be5\u67b6\u6784\u4e13\u95e8\u9488\u5bf9\u591a\u8bed\u8a00\u97f3\u8bd1\u4efb\u52a1\u8bbe\u8ba1\uff0c\u7279\u522b\u662f\u5370\u5ea6\u8bed\u8a00\u3002", "result": "\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u81ea\u56de\u5f52\u57fa\u7ebf\uff0cNADIR\u5b9e\u73b0\u8d85\u8fc713\u500d\u52a0\u901f\u3002\u5b57\u7b26\u9519\u8bef\u7387\u4e3a15.78%\uff08\u81ea\u56de\u5f52\u6a21\u578b\u4e3a14.44%\uff0c\u6807\u51c6\u975e\u81ea\u56de\u5f52\u6a21\u578b\u4e3a21.88%\uff09\u3002\u663e\u8457\u51cf\u5c11\u5404\u7c7b\u9519\u8bef\uff1a\u91cd\u590d\u9519\u8bef\u51cf\u5c1149.53%\uff0c\u66ff\u6362\u9519\u8bef\u51cf\u5c1124.45%\uff0c\u7701\u7565\u9519\u8bef\u51cf\u5c1132.92%\uff0c\u63d2\u5165\u9519\u8bef\u51cf\u5c1116.87%\u3002", "conclusion": "NADIR\u4e3a\u6784\u5efa\u5feb\u901f\u53ef\u9760\u7684\u975e\u81ea\u56de\u5f52\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u84dd\u56fe\uff0c\u6709\u6548\u5f25\u5408\u4e86\u81ea\u56de\u5f52\u6a21\u578b\u7684\u51c6\u786e\u6027\u4e0e\u5b9e\u65f6\u5927\u89c4\u6a21\u90e8\u7f72\u9700\u6c42\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4f9d\u8d56\u5c40\u90e8\u5173\u7cfb\u7684\u5e8f\u5217\u4efb\u52a1\u3002"}}
{"id": "2601.12419", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12419", "abs": "https://arxiv.org/abs/2601.12419", "authors": ["Mahammad Namazov", "Tom\u00e1\u0161 Koref", "Ivan Habernal"], "title": "Legal experts disagree with rationale extraction techniques for explaining ECtHR case outcome classification", "comment": null, "summary": "Interpretability is critical for applications of large language models in the legal domain which requires trust and transparency. While some studies develop task-specific approaches, other use the classification model's parameters to explain the decisions. However, which technique explains the legal outcome prediction best remains an open question. To address this challenge, we propose a comparative analysis framework for model-agnostic interpretability techniques. Among these, we employ two rationale extraction methods, which justify outcomes with human-interpretable and concise text fragments (i.e., rationales) from the given input text. We conduct comparison by evaluating faithfulness-via normalized sufficiency and comprehensiveness metrics along with plausibility-by asking legal experts to evaluate extracted rationales. We further assess the feasibility of LLM-as-a-Judge using legal expert evaluation results. We show that the model's \"reasons\" for predicting a violation differ substantially from those of legal experts, despite highly promising quantitative analysis results and reasonable downstream classification performance. The source code of our experiments is publicly available at https://github.com/trusthlt/IntEval.", "code_url": "https://github.com/trusthlt/IntEval", "code_stars": 0, "code_last_update": "2026-01-20", "AI": {"tldr": "\u6bd4\u8f83\u5206\u6790\u6846\u67b6\u8bc4\u4f30\u6cd5\u5f8b\u9886\u57dfLLM\u53ef\u89e3\u91ca\u6027\u6280\u672f\uff0c\u53d1\u73b0\u6a21\u578b\u9884\u6d4b\u7406\u7531\u4e0e\u6cd5\u5f8b\u4e13\u5bb6\u5b58\u5728\u663e\u8457\u5dee\u5f02", "motivation": "\u6cd5\u5f8b\u9886\u57df\u5e94\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9700\u8981\u4fe1\u4efb\u548c\u900f\u660e\u5ea6\uff0c\u4f46\u73b0\u6709\u53ef\u89e3\u91ca\u6027\u6280\u672f\u4e2d\u54ea\u79cd\u6700\u9002\u5408\u6cd5\u5f8b\u7ed3\u679c\u9884\u6d4b\u4ecd\u4e0d\u660e\u786e", "method": "\u63d0\u51fa\u6a21\u578b\u65e0\u5173\u7684\u53ef\u89e3\u91ca\u6027\u6280\u672f\u6bd4\u8f83\u5206\u6790\u6846\u67b6\uff0c\u91c7\u7528\u4e24\u79cd\u7406\u7531\u63d0\u53d6\u65b9\u6cd5\uff0c\u901a\u8fc7\u5fe0\u5b9e\u5ea6\uff08\u6807\u51c6\u5316\u5145\u5206\u6027\u548c\u5168\u9762\u6027\u6307\u6807\uff09\u548c\u5408\u7406\u6027\uff08\u6cd5\u5f8b\u4e13\u5bb6\u8bc4\u4f30\uff09\u8fdb\u884c\u8bc4\u4f30", "result": "\u6a21\u578b\u9884\u6d4b\u8fdd\u89c4\u7684\u7406\u7531\u4e0e\u6cd5\u5f8b\u4e13\u5bb6\u7684\u7406\u7531\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5c3d\u7ba1\u5b9a\u91cf\u5206\u6790\u7ed3\u679c\u548c\u4e0b\u6e38\u5206\u7c7b\u6027\u80fd\u8868\u73b0\u826f\u597d", "conclusion": "\u9700\u8981\u66f4\u6df1\u5165\u7406\u89e3\u6cd5\u5f8b\u9886\u57dfLLM\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u6a21\u578b\u9884\u6d4b\u7406\u7531\u4e0e\u4e13\u5bb6\u5224\u65ad\u5b58\u5728\u5dee\u5f02\uff0cLLM-as-a-Judge\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u9700\u8981\u8fdb\u4e00\u6b65\u8bc4\u4f30"}}
{"id": "2601.12430", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12430", "abs": "https://arxiv.org/abs/2601.12430", "authors": ["Tsan Tsai Chan", "Varsha Suresh", "Anisha Saha", "Michael Hahn", "Vera Demberg"], "title": "System-Mediated Attention Imbalances Make Vision-Language Models Say Yes", "comment": "Under review", "summary": "Vision-language model (VLM) hallucination is commonly linked to imbalanced allocation of attention across input modalities: system, image and text. However, existing mitigation strategies tend towards an image-centric interpretation of these imbalances, often prioritising increased image attention while giving less consideration to the roles of the other modalities. In this study, we evaluate a more holistic, system-mediated account, which attributes these imbalances to functionally redundant system weights that reduce attention to image and textual inputs. We show that this framework offers a useful empirical perspective on the yes-bias, a common form of hallucination in which VLMs indiscriminately respond 'yes'. Causally redistributing attention from the system modality to image and textual inputs substantially suppresses this bias, often outperforming existing approaches. We further present evidence suggesting that system-mediated attention imbalances contribute to the yes-bias by encouraging a default reliance on coarse input representations, which are effective for some tasks but ill-suited to others. Taken together, these findings firmly establish system attention as a key factor in VLM hallucination and highlight its potential as a lever for mitigation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u7cfb\u7edf\u6ce8\u610f\u529b\u5931\u8861\u662fVLM\u5e7b\u89c9\u7684\u5173\u952e\u56e0\u7d20\uff0c\u901a\u8fc7\u56e0\u679c\u6027\u91cd\u65b0\u5206\u914d\u7cfb\u7edf\u6ce8\u610f\u529b\u5230\u56fe\u50cf\u548c\u6587\u672c\u8f93\u5165\uff0c\u6709\u6548\u6291\u5236\u4e86yes-bias\u5e7b\u89c9", "motivation": "\u73b0\u6709\u7f13\u89e3VLM\u5e7b\u89c9\u7684\u65b9\u6cd5\u901a\u5e38\u504f\u5411\u56fe\u50cf\u4e2d\u5fc3\u89e3\u91ca\uff0c\u8fc7\u5ea6\u5f3a\u8c03\u589e\u52a0\u56fe\u50cf\u6ce8\u610f\u529b\u800c\u5ffd\u89c6\u5176\u4ed6\u6a21\u6001\u7684\u4f5c\u7528\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u66f4\u5168\u9762\u7684\u7cfb\u7edf\u4ecb\u5bfc\u89e3\u91ca\uff0c\u5c06\u6ce8\u610f\u529b\u5931\u8861\u5f52\u56e0\u4e8e\u529f\u80fd\u5197\u4f59\u7684\u7cfb\u7edf\u6743\u91cd\u51cf\u5c11\u4e86\u56fe\u50cf\u548c\u6587\u672c\u8f93\u5165\u7684\u6ce8\u610f\u529b", "method": "\u91c7\u7528\u7cfb\u7edf\u4ecb\u5bfc\u7684\u89e3\u91ca\u6846\u67b6\uff0c\u901a\u8fc7\u56e0\u679c\u6027\u91cd\u65b0\u5206\u914d\u6ce8\u610f\u529b\u4ece\u7cfb\u7edf\u6a21\u6001\u5230\u56fe\u50cf\u548c\u6587\u672c\u8f93\u5165\uff0c\u8bc4\u4f30\u8fd9\u79cd\u65b9\u6cd5\u5bf9yes-bias\uff08VLM\u5e38\u89c1\u5e7b\u89c9\u5f62\u5f0f\uff09\u7684\u6291\u5236\u6548\u679c", "result": "\u56e0\u679c\u6027\u91cd\u65b0\u5206\u914d\u7cfb\u7edf\u6ce8\u610f\u529b\u5230\u56fe\u50cf\u548c\u6587\u672c\u8f93\u5165\u663e\u8457\u6291\u5236\u4e86yes-bias\uff0c\u901a\u5e38\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u8bc1\u636e\u8868\u660e\u7cfb\u7edf\u4ecb\u5bfc\u7684\u6ce8\u610f\u529b\u5931\u8861\u901a\u8fc7\u9f13\u52b1\u5bf9\u7c97\u7565\u8f93\u5165\u8868\u793a\u7684\u9ed8\u8ba4\u4f9d\u8d56\u800c\u5bfc\u81f4yes-bias", "conclusion": "\u7cfb\u7edf\u6ce8\u610f\u529b\u662fVLM\u5e7b\u89c9\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5e76\u5177\u6709\u4f5c\u4e3a\u7f13\u89e3\u6760\u6746\u7684\u6f5c\u529b\u3002\u7cfb\u7edf\u4ecb\u5bfc\u7684\u6ce8\u610f\u529b\u5931\u8861\u5bfc\u81f4\u5bf9\u7c97\u7565\u8868\u793a\u7684\u4f9d\u8d56\uff0c\u8fd9\u5728\u67d0\u4e9b\u4efb\u52a1\u4e2d\u6709\u6548\u4f46\u4e0d\u9002\u5408\u5176\u4ed6\u4efb\u52a1"}}
{"id": "2601.12912", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12912", "abs": "https://arxiv.org/abs/2601.12912", "authors": ["Andreas Br\u00e4nnstr\u00f6m", "Juan Carlos Nieves"], "title": "Human Emotion Verification by Action Languages via Answer Set Programming", "comment": "Under consideration in Theory and Practice of Logic Programming (TPLP)", "summary": "In this paper, we introduce the action language C-MT (Mind Transition Language). It is built on top of answer set programming (ASP) and transition systems to represent how human mental states evolve in response to sequences of observable actions. Drawing on well-established psychological theories, such as the Appraisal Theory of Emotion, we formalize mental states, such as emotions, as multi-dimensional configurations. With the objective to address the need for controlled agent behaviors and to restrict unwanted mental side-effects of actions, we extend the language with a novel causal rule, forbids to cause, along with expressions specialized for mental state dynamics, which enables the modeling of principles for valid transitions between mental states. These principles of mental change are translated into transition constraints, and properties of invariance, which are rigorously evaluated using transition systems in terms of so-called trajectories. This enables controlled reasoning about the dynamic evolution of human mental states. Furthermore, the framework supports the comparison of different dynamics of change by analyzing trajectories that adhere to different psychological principles. We apply the action language to design models for emotion verification. Under consideration in Theory and Practice of Logic Programming (TPLP).", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u57fa\u4e8e\u56de\u7b54\u96c6\u7f16\u7a0b\u548c\u8f6c\u79fb\u7cfb\u7edf\u7684\u52a8\u4f5c\u8bed\u8a00C-MT\uff0c\u7528\u4e8e\u5f62\u5f0f\u5316\u4eba\u7c7b\u5fc3\u7406\u72b6\u6001\u968f\u53ef\u89c2\u5bdf\u52a8\u4f5c\u5e8f\u5217\u7684\u6f14\u5316\uff0c\u7279\u522b\u5173\u6ce8\u60c5\u7eea\u7b49\u5fc3\u7406\u72b6\u6001\u7684\u591a\u7ef4\u914d\u7f6e\u5efa\u6a21\u3002", "motivation": "\u9700\u8981\u63a7\u5236\u667a\u80fd\u4f53\u884c\u4e3a\u5e76\u9650\u5236\u52a8\u4f5c\u5e26\u6765\u7684\u4e0d\u826f\u5fc3\u7406\u526f\u4f5c\u7528\uff0c\u540c\u65f6\u57fa\u4e8e\u5fc3\u7406\u5b66\u7406\u8bba\uff08\u5982\u60c5\u7eea\u8bc4\u4ef7\u7406\u8bba\uff09\u5f62\u5f0f\u5316\u5fc3\u7406\u72b6\u6001\u6f14\u5316\uff0c\u4e3a\u60c5\u7eea\u9a8c\u8bc1\u7b49\u5e94\u7528\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u5728\u56de\u7b54\u96c6\u7f16\u7a0b\u548c\u8f6c\u79fb\u7cfb\u7edf\u57fa\u7840\u4e0a\u6784\u5efaC-MT\u8bed\u8a00\uff0c\u5f15\u5165\"forbids to cause\"\u56e0\u679c\u89c4\u5219\u548c\u4e13\u95e8\u7684\u5fc3\u7406\u72b6\u6001\u52a8\u6001\u8868\u8fbe\u5f0f\uff0c\u5c06\u5fc3\u7406\u53d8\u5316\u539f\u5219\u8f6c\u5316\u4e3a\u8f6c\u79fb\u7ea6\u675f\u548c\u4e0d\u53d8\u6027\u5c5e\u6027\uff0c\u901a\u8fc7\u8f68\u8ff9\u5206\u6790\u8fdb\u884c\u4e25\u683c\u8bc4\u4f30\u3002", "result": "\u5f00\u53d1\u4e86\u80fd\u591f\u63a7\u5236\u63a8\u7406\u4eba\u7c7b\u5fc3\u7406\u72b6\u6001\u52a8\u6001\u6f14\u5316\u7684\u6846\u67b6\uff0c\u652f\u6301\u901a\u8fc7\u5206\u6790\u9075\u5faa\u4e0d\u540c\u5fc3\u7406\u5b66\u539f\u5219\u7684\u8f68\u8ff9\u6765\u6bd4\u8f83\u4e0d\u540c\u7684\u53d8\u5316\u52a8\u6001\uff0c\u5e76\u5c06\u8be5\u52a8\u4f5c\u8bed\u8a00\u5e94\u7528\u4e8e\u60c5\u7eea\u9a8c\u8bc1\u6a21\u578b\u8bbe\u8ba1\u3002", "conclusion": "C-MT\u8bed\u8a00\u4e3a\u5f62\u5f0f\u5316\u5fc3\u7406\u72b6\u6001\u6f14\u5316\u63d0\u4f9b\u4e86\u4e25\u8c28\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u80fd\u591f\u5efa\u6a21\u5fc3\u7406\u53d8\u5316\u539f\u5219\u5e76\u652f\u6301\u53d7\u63a7\u63a8\u7406\uff0c\u5728\u60c5\u7eea\u9a8c\u8bc1\u7b49\u5e94\u7528\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c\uff0c\u76ee\u524d\u6b63\u5728TPLP\u671f\u520a\u5ba1\u7a3f\u4e2d\u3002"}}
{"id": "2601.12465", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12465", "abs": "https://arxiv.org/abs/2601.12465", "authors": ["Miao Peng", "Weizhou Shen", "Nuo Chen", "Chenliang Li", "Ming Yan", "Jia Li"], "title": "Incentivizing In-depth Reasoning over Long Contexts with Process Advantage Shaping", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective in enhancing LLMs short-context reasoning, but its performance degrades in long-context scenarios that require both precise grounding and robust long-range reasoning. We identify the \"almost-there\" phenomenon in long-context reasoning, where trajectories are largely correct but fail at the final step, and attribute this failure to two factors: (1) the lack of high reasoning density in long-context QA data that push LLMs beyond mere grounding toward sophisticated multi-hop reasoning; and (2) the loss of valuable learning signals during long-context RL training due to the indiscriminate penalization of partially correct trajectories with incorrect outcomes. To overcome this bottleneck, we propose DeepReasonQA, a KG-driven synthesis framework that controllably constructs high-difficulty, multi-hop long-context QA pairs with inherent reasoning chains. Building on this, we introduce Long-context Process Advantage Shaping (LongPAS), a simple yet effective method that performs fine-grained credit assignment by evaluating reasoning steps along Validity and Relevance dimensions, which captures critical learning signals from \"almost-there\" trajectories. Experiments on three long-context reasoning benchmarks show that our approach substantially outperforms RLVR baselines and matches frontier LLMs while using far fewer parameters. Further analysis confirms the effectiveness of our methods in strengthening long-context reasoning while maintaining stable RL training.", "AI": {"tldr": "\u63d0\u51faDeepReasonQA\u6846\u67b6\u548cLongPAS\u65b9\u6cd5\uff0c\u89e3\u51b3\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2dRLVR\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u9a71\u52a8\u5408\u6210\u9ad8\u96be\u5ea6\u591a\u8df3QA\u5bf9\uff0c\u5e76\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4fe1\u7528\u5206\u914d\uff0c\u663e\u8457\u63d0\u5347\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\u3002", "motivation": "RLVR\u5728\u77ed\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u6709\u6548\uff0c\u4f46\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e2d\u6027\u80fd\u4e0b\u964d\uff0c\u5b58\u5728\"almost-there\"\u73b0\u8c61\uff08\u8f68\u8ff9\u5927\u90e8\u5206\u6b63\u786e\u4f46\u6700\u540e\u4e00\u6b65\u5931\u8d25\uff09\u3002\u8fd9\u5f52\u56e0\u4e8e\uff1a1\uff09\u957f\u4e0a\u4e0b\u6587QA\u6570\u636e\u7f3a\u4e4f\u9ad8\u63a8\u7406\u5bc6\u5ea6\uff0c\u65e0\u6cd5\u63a8\u52a8LLM\u8d85\u8d8a\u7b80\u5355\u5b9a\u4f4d\u8fdb\u884c\u590d\u6742\u591a\u8df3\u63a8\u7406\uff1b2\uff09\u957f\u4e0a\u4e0b\u6587RL\u8bad\u7ec3\u4e2d\uff0c\u5bf9\u90e8\u5206\u6b63\u786e\u4f46\u7ed3\u679c\u9519\u8bef\u7684\u8f68\u8ff9\u8fdb\u884c\u65e0\u5dee\u522b\u60e9\u7f5a\uff0c\u5bfc\u81f4\u6709\u4ef7\u503c\u5b66\u4e60\u4fe1\u53f7\u4e22\u5931\u3002", "method": "\u63d0\u51faDeepReasonQA\uff1a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u53ef\u63a7\u5408\u6210\u6846\u67b6\uff0c\u6784\u5efa\u5177\u6709\u5185\u5728\u63a8\u7406\u94fe\u7684\u9ad8\u96be\u5ea6\u591a\u8df3\u957f\u4e0a\u4e0b\u6587QA\u5bf9\u3002\u63d0\u51faLongPAS\uff08Long-context Process Advantage Shaping\uff09\uff1a\u901a\u8fc7\u6709\u6548\u6027\u548c\u76f8\u5173\u6027\u4e24\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u63a8\u7406\u6b65\u9aa4\uff0c\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4fe1\u7528\u5206\u914d\uff0c\u4ece\"almost-there\"\u8f68\u8ff9\u4e2d\u6355\u83b7\u5173\u952e\u5b66\u4e60\u4fe1\u53f7\u3002", "result": "\u5728\u4e09\u4e2a\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8eRLVR\u57fa\u7ebf\uff0c\u4e0e\u524d\u6cbfLLM\u6027\u80fd\u76f8\u5f53\u4f46\u4f7f\u7528\u66f4\u5c11\u53c2\u6570\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u8bc1\u5b9e\u4e86\u65b9\u6cd5\u5728\u589e\u5f3a\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\u7684\u540c\u65f6\u4fdd\u6301RL\u8bad\u7ec3\u7a33\u5b9a\u6027\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7DeepReasonQA\u63d0\u4f9b\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u548cLongPAS\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4fe1\u7528\u5206\u914d\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2dRLVR\u7684\u6027\u80fd\u74f6\u9888\uff0c\u5b9e\u73b0\u4e86\u5bf9\"almost-there\"\u73b0\u8c61\u7684\u6709\u6548\u5904\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u7684\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2601.12913", "categories": ["cs.AI", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.12913", "abs": "https://arxiv.org/abs/2601.12913", "authors": ["Pietro Barbiero", "Mateo Espinosa Zarlenga", "Francesco Giannini", "Alberto Termine", "Filippo Bonchi", "Mateja Jamnik", "Giuseppe Marra"], "title": "Actionable Interpretability Must Be Defined in Terms of Symmetries", "comment": null, "summary": "This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed as existing definitions of interpretability are not *actionable*: they fail to provide formal principles from which concrete modelling and inferential rules can be derived. We posit that for a definition of interpretability to be actionable, it must be given in terms of *symmetries*. We hypothesise that four symmetries suffice to (i) motivate core interpretability properties, (ii) characterize the class of interpretable models, and (iii) derive a unified formulation of interpretable inference (e.g., alignment, interventions, and counterfactuals) as a form of Bayesian inversion.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8ba4\u4e3a\u5f53\u524dAI\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u5b58\u5728\u6839\u672c\u6027\u95ee\u9898\uff0c\u56e0\u4e3a\u73b0\u6709\u5b9a\u4e49\u7f3a\u4e4f\u53ef\u64cd\u4f5c\u6027\uff0c\u65e0\u6cd5\u63d0\u4f9b\u5177\u4f53\u7684\u5efa\u6a21\u548c\u63a8\u7406\u89c4\u5219\u3002\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u53ef\u64cd\u4f5c\u6027\u5b9a\u4e49\uff0c\u5e76\u5047\u8bbe\u56db\u79cd\u5bf9\u79f0\u6027\u8db3\u4ee5\u89e3\u51b3\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u7684\u6838\u5fc3\u95ee\u9898\u3002", "motivation": "\u5f53\u524dAI\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u9762\u4e34\u6839\u672c\u6027\u6311\u6218\uff0c\u73b0\u6709\u5b9a\u4e49\u7f3a\u4e4f\u53ef\u64cd\u4f5c\u6027\uff0c\u65e0\u6cd5\u4e3a\u5177\u4f53\u5efa\u6a21\u548c\u63a8\u7406\u63d0\u4f9b\u5f62\u5f0f\u5316\u539f\u5219\u3002\u8fd9\u5bfc\u81f4\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u96be\u4ee5\u4ea7\u751f\u4e00\u81f4\u7684\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u7528\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u53ef\u64cd\u4f5c\u6027\u5b9a\u4e49\u6846\u67b6\uff0c\u5047\u8bbe\u56db\u79cd\u5bf9\u79f0\u6027\u8db3\u4ee5\uff1a1\uff09\u6fc0\u53d1\u6838\u5fc3\u53ef\u89e3\u91ca\u6027\u5c5e\u6027\uff1b2\uff09\u523b\u753b\u53ef\u89e3\u91ca\u6a21\u578b\u7c7b\u522b\uff1b3\uff09\u63a8\u5bfc\u7edf\u4e00\u7684\u53ef\u89e3\u91ca\u63a8\u7406\u5f62\u5f0f\uff08\u5982\u5bf9\u9f50\u3001\u5e72\u9884\u548c\u53cd\u4e8b\u5b9e\uff09\u4f5c\u4e3a\u8d1d\u53f6\u65af\u9006\u95ee\u9898\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u53ef\u89e3\u91ca\u6027\u5b9a\u4e49\u4e3a\u5bf9\u79f0\u6027\u5c5e\u6027\uff0c\u4e3a\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u57fa\u7840\u3002\u8be5\u6846\u67b6\u80fd\u591f\u7edf\u4e00\u5904\u7406\u5bf9\u9f50\u3001\u5e72\u9884\u548c\u53cd\u4e8b\u5b9e\u63a8\u7406\u7b49\u53ef\u89e3\u91ca\u6027\u4efb\u52a1\u3002", "conclusion": "\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u53ef\u64cd\u4f5c\u6027\u5b9a\u4e49\u4e3a\u89e3\u51b3AI\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u7684\u6839\u672c\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u6709\u671b\u5efa\u7acb\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u63a8\u52a8\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u4ece\u6982\u5ff5\u8ba8\u8bba\u8f6c\u5411\u5177\u4f53\u5efa\u6a21\u548c\u63a8\u7406\u65b9\u6cd5\u3002"}}
{"id": "2601.12471", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12471", "abs": "https://arxiv.org/abs/2601.12471", "authors": ["Sravanthi Machcha", "Sushrita Yerra", "Sahil Gupta", "Aishwarya Sahoo", "Sharmin Sultana", "Hong Yu", "Zonghai Yao"], "title": "Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty", "comment": "Equal contribution for the first two authors; To appear in proceedings of the Main Conference of the European Chapter of the Association for Computational Linguistics (EACL) 2026", "summary": "Current evaluation of large language models (LLMs) overwhelmingly prioritizes accuracy; however, in real-world and safety-critical applications, the ability to abstain when uncertain is equally vital for trustworthy deployment. We introduce MedAbstain, a unified benchmark and evaluation protocol for abstention in medical multiple-choice question answering (MCQA) -- a discrete-choice setting that generalizes to agentic action selection -- integrating conformal prediction, adversarial question perturbations, and explicit abstention options. Our systematic evaluation of both open- and closed-source LLMs reveals that even state-of-the-art, high-accuracy models often fail to abstain with uncertain. Notably, providing explicit abstention options consistently increases model uncertainty and safer abstention, far more than input perturbations, while scaling model size or advanced prompting brings little improvement. These findings highlight the central role of abstention mechanisms for trustworthy LLM deployment and offer practical guidance for improving safety in high-stakes applications.", "AI": {"tldr": "MedAbstain\uff1a\u7528\u4e8e\u533b\u5b66\u591a\u9009\u9898\u56de\u7b54\u4e2d\u5f03\u6743\u80fd\u529b\u7684\u7edf\u4e00\u57fa\u51c6\uff0c\u53d1\u73b0\u5373\u4f7f\u9ad8\u7cbe\u5ea6LLM\u4e5f\u5e38\u65e0\u6cd5\u5728\u4e0d\u786e\u5b9a\u65f6\u5f03\u6743\uff0c\u63d0\u4f9b\u663e\u5f0f\u5f03\u6743\u9009\u9879\u6bd4\u8f93\u5165\u6270\u52a8\u66f4\u6709\u6548\u63d0\u5347\u5b89\u5168\u6027\u3002", "motivation": "\u5f53\u524dLLM\u8bc4\u4f30\u8fc7\u4e8e\u5f3a\u8c03\u51c6\u786e\u6027\uff0c\u4f46\u5728\u73b0\u5b9e\u4e16\u754c\u548c\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\uff0c\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u65f6\u80fd\u591f\u5f03\u6743\u7684\u80fd\u529b\u5bf9\u4e8e\u53ef\u4fe1\u90e8\u7f72\u540c\u6837\u91cd\u8981\u3002\u533b\u5b66\u591a\u9009\u9898\u56de\u7b54\u4f5c\u4e3a\u79bb\u6563\u9009\u62e9\u573a\u666f\uff0c\u53ef\u63a8\u5e7f\u5230\u667a\u80fd\u4f53\u884c\u52a8\u9009\u62e9\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30LLM\u7684\u5f03\u6743\u80fd\u529b\u3002", "method": "\u63d0\u51faMedAbstain\u57fa\u51c6\u548c\u8bc4\u4f30\u534f\u8bae\uff0c\u6574\u5408\u4e86\u5171\u5f62\u9884\u6d4b\u3001\u5bf9\u6297\u6027\u95ee\u9898\u6270\u52a8\u548c\u663e\u5f0f\u5f03\u6743\u9009\u9879\u3002\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5f00\u6e90\u548c\u95ed\u6e90LLM\uff0c\u5206\u6790\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u65f6\u5f03\u6743\u7684\u80fd\u529b\u3002", "result": "\u5373\u4f7f\u6700\u5148\u8fdb\u7684\u9ad8\u7cbe\u5ea6LLM\u4e5f\u7ecf\u5e38\u65e0\u6cd5\u5728\u4e0d\u786e\u5b9a\u65f6\u5f03\u6743\u3002\u63d0\u4f9b\u663e\u5f0f\u5f03\u6743\u9009\u9879\u80fd\u6301\u7eed\u589e\u52a0\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u548c\u66f4\u5b89\u5168\u7684\u5f03\u6743\u884c\u4e3a\uff0c\u6548\u679c\u8fdc\u8d85\u8fc7\u8f93\u5165\u6270\u52a8\u3002\u6269\u5927\u6a21\u578b\u89c4\u6a21\u6216\u4f7f\u7528\u9ad8\u7ea7\u63d0\u793a\u6280\u672f\u5e26\u6765\u7684\u6539\u5584\u6709\u9650\u3002", "conclusion": "\u5f03\u6743\u673a\u5236\u5bf9\u4e8e\u53ef\u4fe1LLM\u90e8\u7f72\u5177\u6709\u6838\u5fc3\u4f5c\u7528\uff0c\u4e3a\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u6027\u6539\u8fdb\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u5728LLM\u8bc4\u4f30\u4e2d\u8d85\u8d8a\u51c6\u786e\u6027\u3001\u91cd\u89c6\u5f03\u6743\u80fd\u529b\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.13060", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13060", "abs": "https://arxiv.org/abs/2601.13060", "authors": ["Zecheng Li", "Zhihui Cao", "Wenke Huang", "Yudong Zhang", "Keying Qi", "Rui Wang", "Zeyu Zheng", "Jian Zhao", "Hao Zhu", "Hengxin Wu", "Yuran Wang", "Guitao Fan", "Guokun Wu", "Yicong Liu", "Zhilin Gao", "Haikun Xu", "He Yang", "Minqi Xiang", "Xingyu Liu", "Zuojian Wang"], "title": "MagicGUI-RMS: A Multi-Agent Reward Model System for Self-Evolving GUI Agents via Automated Feedback Reflux", "comment": null, "summary": "Graphical user interface (GUI) agents are rapidly progressing toward autonomous interaction and reliable task execution across diverse applications. However, two central challenges remain unresolved: automating the evaluation of agent trajectories and generating high-quality training data at scale to enable continual improvement. Existing approaches often depend on manual annotation or static rule-based verification, which restricts scalability and limits adaptability in dynamic environments. We present MagicGUI-RMS, a multi-agent reward model system that delivers adaptive trajectory evaluation, corrective feedback, and self-evolving learning capabilities. MagicGUI-RMS integrates a Domain-Specific Reward Model (DS-RM) with a General-Purpose Reward Model (GP-RM), enabling fine-grained action assessment and robust generalization across heterogeneous GUI tasks. To support reward learning at scale, we design a structured data construction pipeline that automatically produces balanced and diverse reward datasets, effectively reducing annotation costs while maintaining sample fidelity. During execution, the reward model system identifies erroneous actions, proposes refined alternatives, and continuously enhances agent behavior through an automated data-reflux mechanism. Extensive experiments demonstrate that MagicGUI-RMS yields substantial gains in task accuracy, behavioral robustness. These results establish MagicGUI-RMS as a principled and effective foundation for building self-improving GUI agents driven by reward-based adaptation.", "AI": {"tldr": "MagicGUI-RMS\uff1a\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u5956\u52b1\u6a21\u578b\u7cfb\u7edf\uff0c\u7528\u4e8eGUI\u667a\u80fd\u4f53\u7684\u81ea\u9002\u5e94\u8f68\u8ff9\u8bc4\u4f30\u3001\u7ea0\u6b63\u53cd\u9988\u548c\u81ea\u6211\u8fdb\u5316\u5b66\u4e60\uff0c\u901a\u8fc7\u9886\u57df\u7279\u5b9a\u548c\u901a\u7528\u5956\u52b1\u6a21\u578b\u7ed3\u5408\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u52a8\u4f5c\u8bc4\u4f30", "motivation": "\u5f53\u524dGUI\u667a\u80fd\u4f53\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a1) \u81ea\u52a8\u5316\u8bc4\u4f30\u667a\u80fd\u4f53\u8f68\u8ff9\u7684\u56f0\u96be\uff1b2) \u5927\u89c4\u6a21\u751f\u6210\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u4ee5\u5b9e\u73b0\u6301\u7eed\u6539\u8fdb\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u6216\u9759\u6001\u89c4\u5219\u9a8c\u8bc1\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u52a8\u6001\u73af\u5883\u9002\u5e94\u6027", "method": "\u96c6\u6210\u9886\u57df\u7279\u5b9a\u5956\u52b1\u6a21\u578b(DS-RM)\u548c\u901a\u7528\u5956\u52b1\u6a21\u578b(GP-RM)\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u52a8\u4f5c\u8bc4\u4f30\u548c\u8de8\u5f02\u6784GUI\u4efb\u52a1\u7684\u9c81\u68d2\u6cdb\u5316\u3002\u8bbe\u8ba1\u7ed3\u6784\u5316\u6570\u636e\u6784\u5efa\u7ba1\u9053\uff0c\u81ea\u52a8\u751f\u6210\u5e73\u8861\u591a\u6837\u7684\u5956\u52b1\u6570\u636e\u96c6\uff0c\u964d\u4f4e\u6807\u6ce8\u6210\u672c\u3002\u901a\u8fc7\u81ea\u52a8\u6570\u636e\u56de\u6d41\u673a\u5236\u8bc6\u522b\u9519\u8bef\u52a8\u4f5c\u3001\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\u5e76\u6301\u7eed\u589e\u5f3a\u667a\u80fd\u4f53\u884c\u4e3a", "result": "\u5b9e\u9a8c\u8868\u660eMagicGUI-RMS\u5728\u4efb\u52a1\u51c6\u786e\u6027\u548c\u884c\u4e3a\u9c81\u68d2\u6027\u65b9\u9762\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u6784\u5efa\u57fa\u4e8e\u5956\u52b1\u9002\u5e94\u7684\u81ea\u6539\u8fdbGUI\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u548c\u6709\u6548\u7684\u57fa\u7840", "conclusion": "MagicGUI-RMS\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5956\u52b1\u6a21\u578b\u7cfb\u7edf\u89e3\u51b3\u4e86GUI\u667a\u80fd\u4f53\u8bc4\u4f30\u548c\u8bad\u7ec3\u6570\u636e\u751f\u6210\u7684\u5173\u952e\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u81ea\u9002\u5e94\u8f68\u8ff9\u8bc4\u4f30\u3001\u7ea0\u6b63\u53cd\u9988\u548c\u81ea\u6211\u8fdb\u5316\u5b66\u4e60\u80fd\u529b\uff0c\u4e3a\u81ea\u6539\u8fdbGUI\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6"}}
{"id": "2601.12473", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12473", "abs": "https://arxiv.org/abs/2601.12473", "authors": ["Renlong Jie", "Chen Chu", "Zhen Wang"], "title": "Capability-Aware Early-Stage Research Idea Evaluation", "comment": null, "summary": "Predicting the outcomes of research ideas at their conceptual stage (i.e. before significant resources are committed) holds great potential for optimizing scientific resource allocation and research planning. While existing methods rely heavily on finished manuscripts or peer reviews, we propose a novel capability-aware framework that predicts paper acceptance and ratings using only author information and research ideas, without requiring full text or experimental results. Our approach integrates author information, (inferred) capability presentation, and research ideas through a three-way transformer architecture with flexible fusion mechanisms. We also introduce a two-stage architecture for learning the capability representation given the author information and idea. Experiments show that our method significantly outperform the single-way models by finetuning bert-base and bert-large, and the capability predicting significantly increase the predictive accuracy of the final model. The proposed method can be applied in both early-stage research outcome prediction and scientific resource allocation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4f5c\u8005\u4fe1\u606f\u548c\u7814\u7a76\u60f3\u6cd5\u7684\u80fd\u529b\u611f\u77e5\u6846\u67b6\uff0c\u9884\u6d4b\u8bba\u6587\u63a5\u53d7\u7387\u548c\u8bc4\u5206\uff0c\u65e0\u9700\u5b8c\u6574\u6587\u672c\u6216\u5b9e\u9a8c\u7ed3\u679c", "motivation": "\u5728\u6982\u5ff5\u9636\u6bb5\uff08\u6295\u5165\u5927\u91cf\u8d44\u6e90\u524d\uff09\u9884\u6d4b\u7814\u7a76\u60f3\u6cd5\u7684\u7ed3\u679c\uff0c\u5bf9\u4e8e\u4f18\u5316\u79d1\u5b66\u8d44\u6e90\u5206\u914d\u548c\u7814\u7a76\u89c4\u5212\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5b8c\u6574\u7a3f\u4ef6\u6216\u540c\u884c\u8bc4\u5ba1\uff0c\u800c\u672c\u7814\u7a76\u65e8\u5728\u4ec5\u4f7f\u7528\u4f5c\u8005\u4fe1\u606f\u548c\u7814\u7a76\u60f3\u6cd5\u8fdb\u884c\u9884\u6d4b", "method": "\u63d0\u51fa\u80fd\u529b\u611f\u77e5\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u8deftransformer\u67b6\u6784\u6574\u5408\u4f5c\u8005\u4fe1\u606f\u3001\uff08\u63a8\u65ad\u7684\uff09\u80fd\u529b\u5448\u73b0\u548c\u7814\u7a76\u60f3\u6cd5\uff0c\u91c7\u7528\u7075\u6d3b\u878d\u5408\u673a\u5236\u3002\u5f15\u5165\u4e24\u9636\u6bb5\u67b6\u6784\u5b66\u4e60\u7ed9\u5b9a\u4f5c\u8005\u4fe1\u606f\u548c\u60f3\u6cd5\u7684\u80fd\u529b\u8868\u793a", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u57fa\u4e8ebert-base\u548cbert-large\u5fae\u8c03\u7684\u5355\u8def\u6a21\u578b\uff0c\u80fd\u529b\u9884\u6d4b\u663e\u8457\u63d0\u9ad8\u4e86\u6700\u7ec8\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u6027", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u53ef\u5e94\u7528\u4e8e\u65e9\u671f\u7814\u7a76\u7ed3\u679c\u9884\u6d4b\u548c\u79d1\u5b66\u8d44\u6e90\u5206\u914d\uff0c\u4e3a\u7814\u7a76\u89c4\u5212\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u5de5\u5177"}}
{"id": "2601.13122", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13122", "abs": "https://arxiv.org/abs/2601.13122", "authors": ["Gourab K Patro", "Himanshi Agrawal", "Himanshu Gharat", "Supriya Panigrahi", "Nim Sherpa", "Vishal Vaddina", "Dagnachew Birru"], "title": "Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward", "comment": null, "summary": "Modern general-purpose AI systems made using large language and vision models, are capable of performing a range of tasks like writing text articles, generating and debugging codes, querying databases, and translating from one language to another, which has made them quite popular across industries. However, there are risks like hallucinations, toxicity, and stereotypes in their output that make them untrustworthy. We review various risks and vulnerabilities of modern general-purpose AI along eight widely accepted responsible AI (RAI) principles (fairness, privacy, explainability, robustness, safety, truthfulness, governance, and sustainability) and compare how they are non-existent or less severe and easily mitigable in traditional task-specific counterparts. We argue that this is due to the non-deterministically high Degree of Freedom in output (DoFo) of general-purpose AI (unlike the deterministically constant or low DoFo of traditional task-specific AI systems), and there is a need to rethink our approach to RAI for general-purpose AI. Following this, we derive C2V2 (Control, Consistency, Value, Veracity) desiderata to meet the RAI requirements for future general-purpose AI systems, and discuss how recent efforts in AI alignment, retrieval-augmented generation, reasoning enhancements, etc. fare along one or more of the desiderata. We believe that the goal of developing responsible general-purpose AI can be achieved by formally modeling application- or domain-dependent RAI requirements along C2V2 dimensions, and taking a system design approach to suitably combine various techniques to meet the desiderata.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u73b0\u4ee3\u901a\u7528AI\u7cfb\u7edf\u5728\u8d1f\u8d23\u4efbAI\u539f\u5219\u4e0b\u7684\u98ce\u9669\uff0c\u63d0\u51fa\u5176\u9ad8\u81ea\u7531\u5ea6\u8f93\u51fa\u662f\u95ee\u9898\u6839\u6e90\uff0c\u5e76\u5efa\u7acb\u4e86C2V2\u6846\u67b6\uff08\u63a7\u5236\u3001\u4e00\u81f4\u6027\u3001\u4ef7\u503c\u3001\u771f\u5b9e\u6027\uff09\u4f5c\u4e3a\u672a\u6765\u901a\u7528AI\u7cfb\u7edf\u7684\u8d1f\u8d23\u4efb\u8bbe\u8ba1\u6807\u51c6\u3002", "motivation": "\u73b0\u4ee3\u901a\u7528AI\u7cfb\u7edf\uff08\u5982\u5927\u8bed\u8a00\u548c\u89c6\u89c9\u6a21\u578b\uff09\u867d\u7136\u529f\u80fd\u5f3a\u5927\uff0c\u4f46\u5728\u8f93\u51fa\u4e2d\u5b58\u5728\u5e7b\u89c9\u3001\u6bd2\u6027\u548c\u523b\u677f\u5370\u8c61\u7b49\u98ce\u9669\uff0c\u4f7f\u5176\u4e0d\u53ef\u4fe1\u3002\u4f5c\u8005\u65e8\u5728\u5206\u6790\u8fd9\u4e9b\u7cfb\u7edf\u5728\u516b\u5927\u8d1f\u8d23\u4efbAI\u539f\u5219\u4e0b\u7684\u8106\u5f31\u6027\uff0c\u5e76\u4e0e\u4f20\u7edf\u4efb\u52a1\u7279\u5b9aAI\u7cfb\u7edf\u8fdb\u884c\u6bd4\u8f83\uff0c\u63d0\u51fa\u9700\u8981\u91cd\u65b0\u601d\u8003\u901a\u7528AI\u7684\u8d1f\u8d23\u4efbAI\u65b9\u6cd5\u3002", "method": "1. \u4ece\u516b\u5927\u8d1f\u8d23\u4efbAI\u539f\u5219\uff08\u516c\u5e73\u6027\u3001\u9690\u79c1\u6027\u3001\u53ef\u89e3\u91ca\u6027\u3001\u9c81\u68d2\u6027\u3001\u5b89\u5168\u6027\u3001\u771f\u5b9e\u6027\u3001\u6cbb\u7406\u3001\u53ef\u6301\u7eed\u6027\uff09\u89d2\u5ea6\u5ba1\u67e5\u73b0\u4ee3\u901a\u7528AI\u7684\u98ce\u9669\u548c\u8106\u5f31\u6027\uff1b2. \u4e0e\u4f20\u7edf\u4efb\u52a1\u7279\u5b9aAI\u7cfb\u7edf\u5bf9\u6bd4\uff0c\u5206\u6790\u98ce\u9669\u5dee\u5f02\uff1b3. \u63d0\u51fa\u8f93\u51fa\u81ea\u7531\u5ea6\uff08DoFo\uff09\u6982\u5ff5\u89e3\u91ca\u98ce\u9669\u6839\u6e90\uff1b4. \u63a8\u5bfc\u51faC2V2\uff08\u63a7\u5236\u3001\u4e00\u81f4\u6027\u3001\u4ef7\u503c\u3001\u771f\u5b9e\u6027\uff09\u9700\u6c42\u6846\u67b6\uff1b5. \u8bc4\u4f30\u73b0\u6709\u6280\u672f\uff08AI\u5bf9\u9f50\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3001\u63a8\u7406\u589e\u5f3a\u7b49\uff09\u5728C2V2\u7ef4\u5ea6\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u901a\u7528AI\u7cfb\u7edf\u7531\u4e8e\u8f93\u51fa\u81ea\u7531\u5ea6\uff08DoFo\uff09\u975e\u786e\u5b9a\u6027\u9ad8\uff0c\u5bfc\u81f4\u5176\u5728\u8d1f\u8d23\u4efbAI\u539f\u5219\u4e0b\u7684\u98ce\u9669\u6bd4\u4f20\u7edf\u4efb\u52a1\u7279\u5b9aAI\u66f4\u4e25\u91cd\u4e14\u96be\u4ee5\u7f13\u89e3\u3002C2V2\u6846\u67b6\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdb\u901a\u7528AI\u7684\u8d1f\u8d23\u4efb\u6027\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u6807\u51c6\u3002\u73b0\u6709\u6280\u672f\u5982AI\u5bf9\u9f50\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7b49\u53ea\u80fd\u90e8\u5206\u6ee1\u8db3C2V2\u9700\u6c42\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\u3002", "conclusion": "\u5f00\u53d1\u8d1f\u8d23\u4efb\u7684\u901a\u7528AI\u9700\u8981\uff1a1. \u6b63\u5f0f\u5efa\u6a21\u5e94\u7528\u6216\u9886\u57df\u76f8\u5173\u7684\u8d1f\u8d23\u4efbAI\u9700\u6c42\uff0c\u6cbfC2V2\u7ef4\u5ea6\uff1b2. \u91c7\u7528\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u7ed3\u5408\u591a\u79cd\u6280\u672f\u6765\u6ee1\u8db3\u8fd9\u4e9b\u9700\u6c42\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5b9e\u73b0\u8d1f\u8d23\u4efb\u7684\u901a\u7528AI\u7cfb\u7edf\u5f00\u53d1\u76ee\u6807\u3002"}}
{"id": "2601.12505", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12505", "abs": "https://arxiv.org/abs/2601.12505", "authors": ["Ashish Raj Shekhar", "Shiven Agarwal", "Priyanuj Bordoloi", "Yash Shah", "Tejas Anvekar", "Vivek Gupta"], "title": "DoPE: Decoy Oriented Perturbation Encapsulation Human-Readable, AI-Hostile Documents for Academic Integrity", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) can directly consume exam documents, threatening conventional assessments and academic integrity. We present DoPE (Decoy-Oriented Perturbation Encapsulation), a document-layer defense framework that embeds semantic decoys into PDF/HTML assessments to exploit render-parse discrepancies in MLLM pipelines. By instrumenting exams at authoring time, DoPE provides model-agnostic prevention (stop or confound automated solving) and detection (flag blind AI reliance) without relying on conventional one-shot classifiers. We formalize prevention and detection tasks, and introduce FewSoRT-Q, an LLM-guided pipeline that generates question-level semantic decoys and FewSoRT-D to encapsulate them into watermarked documents. We evaluate on Integrity-Bench, a novel benchmark of 1826 exams (PDF+HTML) derived from public QA datasets and OpenCourseWare. Against black-box MLLMs from OpenAI and Anthropic, DoPE yields strong empirical gains: a 91.4% detection rate at an 8.7% false-positive rate using an LLM-as-Judge verifier, and prevents successful completion or induces decoy-aligned failures in 96.3% of attempts. We release Integrity-Bench, our toolkit, and evaluation code to enable reproducible study of document-layer defenses for academic integrity.", "AI": {"tldr": "DoPE\u662f\u4e00\u79cd\u6587\u6863\u5c42\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u5728PDF/HTML\u8003\u8bd5\u6587\u6863\u4e2d\u5d4c\u5165\u8bed\u4e49\u8bf1\u9975\u6765\u9632\u6b62\u548c\u68c0\u6d4bMLLM\u4f5c\u5f0a\uff0c\u5229\u7528\u6e32\u67d3-\u89e3\u6790\u5dee\u5f02\u5b9e\u73b0\u6a21\u578b\u65e0\u5173\u7684\u9632\u5fa1\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b(MLLM)\u80fd\u591f\u76f4\u63a5\u5904\u7406\u8003\u8bd5\u6587\u6863\uff0c\u5a01\u80c1\u4f20\u7edf\u8bc4\u4f30\u548c\u5b66\u672f\u8bda\u4fe1\u3002\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u4f9d\u8d56\u4e00\u6b21\u6027\u5206\u7c7b\u5668\uff0c\u7f3a\u4e4f\u6709\u6548\u7684\u6587\u6863\u5c42\u9632\u5fa1\u673a\u5236\u3002", "method": "\u63d0\u51faDoPE\u6846\u67b6\uff0c\u5305\u542bFewSoRT-Q\u751f\u6210\u95ee\u9898\u7ea7\u8bed\u4e49\u8bf1\u9975\uff0cFewSoRT-D\u5c06\u5176\u5c01\u88c5\u5230\u6c34\u5370\u6587\u6863\u4e2d\u3002\u5229\u7528\u6e32\u67d3-\u89e3\u6790\u5dee\u5f02\uff0c\u5728\u4f5c\u8005\u9636\u6bb5\u5bf9\u8003\u8bd5\u6587\u6863\u8fdb\u884c\u68c0\u6d4b\u548c\u9884\u9632\u3002", "result": "\u5728Integrity-Bench\u57fa\u51c6(1826\u4e2a\u8003\u8bd5)\u4e0a\u8bc4\u4f30\uff1a\u5bf9OpenAI\u548cAnthropic\u7684\u9ed1\u76d2MLLM\uff0c\u68c0\u6d4b\u738791.4%(\u5047\u9633\u6027\u73878.7%)\uff0c96.3%\u7684\u5c1d\u8bd5\u88ab\u963b\u6b62\u6216\u8bf1\u5bfc\u8bf1\u9975\u5bf9\u9f50\u5931\u8d25\u3002", "conclusion": "DoPE\u63d0\u4f9b\u6709\u6548\u7684\u6587\u6863\u5c42\u9632\u5fa1\uff0c\u65e0\u9700\u4f9d\u8d56\u4f20\u7edf\u4e00\u6b21\u6027\u5206\u7c7b\u5668\u3002\u91ca\u653e\u57fa\u51c6\u3001\u5de5\u5177\u5305\u548c\u8bc4\u4f30\u4ee3\u7801\uff0c\u4fc3\u8fdb\u5b66\u672f\u8bda\u4fe1\u6587\u6863\u5c42\u9632\u5fa1\u7684\u53ef\u91cd\u590d\u7814\u7a76\u3002"}}
{"id": "2601.13186", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.13186", "abs": "https://arxiv.org/abs/2601.13186", "authors": ["Diego Gosmar", "Deborah A. Dahl"], "title": "Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching", "comment": "33 pages, 19 figures", "summary": "Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. Building on earlier work that introduced a four-metric Total Injection Vulnerability Score (TIVS), this paper extends the evaluation framework with semantic similarity-based caching and a fifth metric (Observability Score Ratio) to yield TIVS-O, investigating how defence effectiveness interacts with transparency in a HOPE-inspired Nested Learning architecture. The proposed system combines an agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 synthetically generated injection-focused prompts drawn from ten attack families, while a fourth agent performs comprehensive security analysis using five key performance indicators. In addition to traditional injection metrics, OSR quantifies the richness and clarity of security-relevant reasoning exposed by each agent, enabling an explicit analysis of trade-offs between strict mitigation and auditability. Experiments show that the system achieves secure responses with zero high-risk breaches, while semantic caching delivers substantial computational savings, achieving a 41.6% reduction in LLM calls and corresponding decreases in latency, energy consumption, and carbon emissions. Five TIVS-O configurations reveal optimal trade-offs between mitigation strictness and forensic transparency. These results indicate that observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.", "AI": {"tldr": "\u8bba\u6587\u6269\u5c55\u4e86TIVS\u6846\u67b6\uff0c\u589e\u52a0\u4e86\u8bed\u4e49\u76f8\u4f3c\u6027\u7f13\u5b58\u548c\u53ef\u89c2\u6d4b\u6027\u8bc4\u5206\u6bd4(OSR)\uff0c\u63d0\u51fa\u4e86TIVS-O\u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u591a\u667a\u80fd\u4f53\u5d4c\u5957\u5b66\u4e60\u67b6\u6784\u4e2d\u7814\u7a76\u9632\u5fa1\u6548\u679c\u4e0e\u900f\u660e\u5ea6\u7684\u6743\u8861\u3002", "motivation": "\u63d0\u793a\u6ce8\u5165\u4ecd\u7136\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u90e8\u7f72\u7684\u4e3b\u8981\u969c\u788d\uff0c\u7279\u522b\u662f\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\uff0c\u4e2d\u95f4\u8f93\u51fa\u53ef\u80fd\u4f20\u64ad\u6216\u653e\u5927\u6076\u610f\u6307\u4ee4\u3002\u9700\u8981\u8bc4\u4f30\u6846\u67b6\u6765\u91cf\u5316\u5b89\u5168\u6027\u548c\u53ef\u89c2\u6d4b\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u667a\u80fd\u4f53\u7ba1\u9053\u4e0e\u8fde\u7eed\u8bb0\u5fc6\u7cfb\u7edf\u7684\u67b6\u6784\uff0c\u5b9e\u73b0\u8bed\u4e49\u76f8\u4f3c\u6027\u7f13\u5b58\u3002\u4f7f\u7528301\u4e2a\u5408\u6210\u751f\u6210\u7684\u6ce8\u5165\u63d0\u793a\uff08\u6765\u81ea10\u4e2a\u653b\u51fb\u5bb6\u65cf\uff09\uff0c\u7b2c\u56db\u4e2a\u667a\u80fd\u4f53\u4f7f\u7528\u4e94\u4e2a\u5173\u952e\u6027\u80fd\u6307\u6807\u8fdb\u884c\u5b89\u5168\u5206\u6790\u3002\u5f15\u5165OSR\u6307\u6807\u91cf\u5316\u6bcf\u4e2a\u667a\u80fd\u4f53\u66b4\u9732\u7684\u5b89\u5168\u76f8\u5173\u63a8\u7406\u7684\u4e30\u5bcc\u6027\u548c\u6e05\u6670\u5ea6\u3002", "result": "\u7cfb\u7edf\u5b9e\u73b0\u96f6\u9ad8\u98ce\u9669\u6f0f\u6d1e\u7684\u5b89\u5168\u54cd\u5e94\uff0c\u8bed\u4e49\u7f13\u5b58\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\uff1aLLM\u8c03\u7528\u51cf\u5c1141.6%\uff0c\u5ef6\u8fdf\u3001\u80fd\u8017\u548c\u78b3\u6392\u653e\u76f8\u5e94\u964d\u4f4e\u3002\u4e94\u79cdTIVS-O\u914d\u7f6e\u63ed\u793a\u4e86\u7f13\u89e3\u4e25\u683c\u6027\u548c\u53d6\u8bc1\u900f\u660e\u5ea6\u4e4b\u95f4\u7684\u6700\u4f18\u6743\u8861\u3002", "conclusion": "\u53ef\u89c2\u6d4b\u6027\u611f\u77e5\u8bc4\u4f30\u80fd\u63ed\u793a\u591a\u667a\u80fd\u4f53\u7ba1\u9053\u4e2d\u7684\u975e\u5355\u8c03\u6548\u5e94\uff0c\u8bb0\u5fc6\u589e\u5f3a\u667a\u80fd\u4f53\u53ef\u540c\u65f6\u6700\u5927\u5316\u5b89\u5168\u9c81\u68d2\u6027\u3001\u5b9e\u65f6\u6027\u80fd\u3001\u8fd0\u8425\u6210\u672c\u8282\u7ea6\u548c\u73af\u5883\u53ef\u6301\u7eed\u6027\uff0c\u65e0\u9700\u4fee\u6539\u5e95\u5c42\u6a21\u578b\u6743\u91cd\uff0c\u4e3a\u5b89\u5168\u548c\u7eff\u8272LLM\u90e8\u7f72\u63d0\u4f9b\u751f\u4ea7\u5c31\u7eea\u8def\u5f84\u3002"}}
{"id": "2601.12535", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12535", "abs": "https://arxiv.org/abs/2601.12535", "authors": ["Ahmed Attia", "Alham Fikri"], "title": "Improving Low-Resource Machine Translation via Round-Trip Reinforcement Learning", "comment": null, "summary": "Low-resource machine translation (MT) has gained increasing attention as parallel data from low-resource language communities is collected, but many potential methods for improving low-resource MT remain unexplored. We investigate a self-supervised reinforcement-learning-based fine-tuning for translation in low-resource settings using round-trip bootstrapping with the No Language Left Behind (NLLB) family of models. Our approach translates English into a target low-resource language and then back into English, using a combination of chrF++ and BLEU as the reward function on the reconstructed English sentences. Using the NLLB-MD dataset, we evaluate both the 600M and 1.3B parameter NLLB models and observe consistent improvements for the following languages: Central Aymara, Friulian, Wolof and Russian. Qualitative inspection of translation outputs indicates increased fluency and semantic fidelity. We argue that our method can further benefit from scale, enabling models to increasingly leverage their pretrained knowledge and continue self-improving.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u7684\u4f4e\u8d44\u6e90\u673a\u5668\u7ffb\u8bd1\u5fae\u8c03\u65b9\u6cd5\uff0c\u4f7f\u7528NLLB\u6a21\u578b\u901a\u8fc7\u5f80\u8fd4\u7ffb\u8bd1\u8fdb\u884c\u5f15\u5bfc\uff0c\u5728\u591a\u79cd\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u53d6\u5f97\u4e86\u7ffb\u8bd1\u8d28\u91cf\u7684\u63d0\u5347\u3002", "motivation": "\u968f\u7740\u4f4e\u8d44\u6e90\u8bed\u8a00\u5e73\u884c\u6570\u636e\u7684\u6536\u96c6\uff0c\u4f4e\u8d44\u6e90\u673a\u5668\u7ffb\u8bd1\u53d7\u5230\u8d8a\u6765\u8d8a\u591a\u7684\u5173\u6ce8\uff0c\u4f46\u8bb8\u591a\u6f5c\u5728\u7684\u6539\u8fdb\u65b9\u6cd5\u4ecd\u6709\u5f85\u63a2\u7d22\u3002\u7814\u7a76\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u6709\u6548\u5229\u7528\u73b0\u6709\u9884\u8bad\u7ec3\u6a21\u578b\u77e5\u8bc6\u5e76\u6301\u7eed\u81ea\u6211\u6539\u8fdb\u7684\u4f4e\u8d44\u6e90\u7ffb\u8bd1\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u81ea\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u65b9\u6cd5\uff0c\u4f7f\u7528NLLB\u6a21\u578b\u5bb6\u65cf\u8fdb\u884c\u5f80\u8fd4\u7ffb\u8bd1\u5f15\u5bfc\uff1a\u5148\u5c06\u82f1\u8bed\u7ffb\u8bd1\u6210\u76ee\u6807\u4f4e\u8d44\u6e90\u8bed\u8a00\uff0c\u518d\u7ffb\u8bd1\u56de\u82f1\u8bed\u3002\u4f7f\u7528chrF++\u548cBLEU\u7684\u7ec4\u5408\u4f5c\u4e3a\u91cd\u5efa\u82f1\u8bed\u53e5\u5b50\u7684\u5956\u52b1\u51fd\u6570\u3002\u5728NLLB-MD\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86600M\u548c1.3B\u53c2\u6570\u7684NLLB\u6a21\u578b\u3002", "result": "\u5728Central Aymara\u3001Friulian\u3001Wolof\u548cRussian\u7b49\u8bed\u8a00\u4e0a\u89c2\u5bdf\u5230\u4e86\u4e00\u81f4\u7684\u6539\u8fdb\u3002\u5bf9\u7ffb\u8bd1\u8f93\u51fa\u7684\u5b9a\u6027\u68c0\u67e5\u8868\u660e\uff0c\u7ffb\u8bd1\u7684\u6d41\u7545\u6027\u548c\u8bed\u4e49\u4fdd\u771f\u5ea6\u90fd\u6709\u6240\u63d0\u9ad8\u3002\u8be5\u65b9\u6cd5\u663e\u793a\u51fa\u968f\u7740\u6a21\u578b\u89c4\u6a21\u589e\u5927\u800c\u8fdb\u4e00\u6b65\u83b7\u76ca\u7684\u6f5c\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u81ea\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u4f4e\u8d44\u6e90\u673a\u5668\u7ffb\u8bd1\u8d28\u91cf\uff0c\u5e76\u4e14\u8be5\u65b9\u6cd5\u53ef\u4ee5\u4ece\u6a21\u578b\u89c4\u6a21\u6269\u5c55\u4e2d\u8fdb\u4e00\u6b65\u83b7\u76ca\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u66f4\u597d\u5730\u5229\u7528\u9884\u8bad\u7ec3\u77e5\u8bc6\u5e76\u6301\u7eed\u81ea\u6211\u6539\u8fdb\u3002"}}
{"id": "2601.12549", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12549", "abs": "https://arxiv.org/abs/2601.12549", "authors": ["Ilia Badanin", "Daniil Dzenhaliou", "Imanol Schlag"], "title": "Benchmarking Concept-Spilling Across Languages in LLMs", "comment": null, "summary": "Multilingual Large Language Models (LLMs) exhibit remarkable cross-lingual abilities, yet often exhibit a systematic bias toward the representations from other languages, resulting in semantic interference when generating content in non-English languages$-$a phenomenon we define as language spilling. This paper presents a novel comparative framework for evaluating multilingual semantic robustness by systematically measuring how models handle polysemous words across languages. Our methodology provides a relative measure of model performance: when required to generate exactly five meanings, both strong and weak models may resort to meanings from dominant languages, but semantically stronger models do so later in the generation sequence, producing more true meanings from the target language before failing, while weaker models resort to dominant-language meanings earlier in the sequence. We evaluate a diverse set of open and closed multilingual LLMs using a structured meaning generation task across nine languages, employing a carefully curated benchmark of 100 high-polysemy English words. Our findings reveal significant variation in semantic robustness across both models and languages, providing a principled ranking system for model comparison without requiring definitive causal attribution of error sources. We contribute both a scalable comparative benchmark for multilingual semantic evaluation and a rigorous validation pipeline$-$critical tools for developing more linguistically balanced AI systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u8bed\u4e49\u9c81\u68d2\u6027\u7684\u6bd4\u8f83\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u6d4b\u91cf\u6a21\u578b\u5904\u7406\u8de8\u8bed\u8a00\u591a\u4e49\u8bcd\u7684\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u8bed\u8a00\u6ea2\u51fa\u73b0\u8c61\uff0c\u5e76\u5efa\u7acb\u4e86\u6a21\u578b\u6027\u80fd\u7684\u6392\u5e8f\u7cfb\u7edf\u3002", "motivation": "\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u8868\u73b0\u51fa\u663e\u8457\u7684\u8de8\u8bed\u8a00\u80fd\u529b\uff0c\u4f46\u7ecf\u5e38\u8868\u73b0\u51fa\u5bf9\u5176\u4ed6\u8bed\u8a00\u8868\u793a\u7684\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u5bfc\u81f4\u5728\u751f\u6210\u975e\u82f1\u8bed\u5185\u5bb9\u65f6\u51fa\u73b0\u8bed\u4e49\u5e72\u6270\uff0c\u8fd9\u79cd\u73b0\u8c61\u88ab\u5b9a\u4e49\u4e3a\"\u8bed\u8a00\u6ea2\u51fa\"\u3002\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u65b9\u6cd5\u6765\u8bc4\u4f30\u591a\u8bed\u8a00\u8bed\u4e49\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6bd4\u8f83\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u610f\u4e49\u751f\u6210\u4efb\u52a1\u7cfb\u7edf\u6d4b\u91cf\u6a21\u578b\u5904\u7406\u591a\u4e49\u8bcd\u7684\u80fd\u529b\u3002\u4f7f\u7528100\u4e2a\u9ad8\u591a\u4e49\u6027\u82f1\u8bed\u5355\u8bcd\u6784\u5efa\u57fa\u51c6\uff0c\u57289\u79cd\u8bed\u8a00\u4e2d\u8bc4\u4f30\u5f00\u653e\u548c\u95ed\u6e90\u591a\u8bed\u8a00LLM\u3002\u8be5\u65b9\u6cd5\u63d0\u4f9b\u76f8\u5bf9\u6027\u80fd\u5ea6\u91cf\uff1a\u5f53\u9700\u8981\u751f\u6210\u6070\u597d\u4e94\u4e2a\u610f\u4e49\u65f6\uff0c\u6a21\u578b\u4f1a\u4ece\u4e3b\u5bfc\u8bed\u8a00\u4e2d\u501f\u7528\u610f\u4e49\uff0c\u4f46\u8bed\u4e49\u66f4\u5f3a\u7684\u6a21\u578b\u5728\u751f\u6210\u5e8f\u5217\u540e\u671f\u624d\u8fd9\u6837\u505a\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u6a21\u578b\u548c\u8bed\u8a00\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u7684\u8bed\u4e49\u9c81\u68d2\u6027\u5dee\u5f02\u3002\u8bed\u4e49\u66f4\u5f3a\u7684\u6a21\u578b\u5728\u5931\u8d25\u524d\u80fd\u4ece\u76ee\u6807\u8bed\u8a00\u4ea7\u751f\u66f4\u591a\u771f\u5b9e\u610f\u4e49\uff0c\u800c\u8f83\u5f31\u7684\u6a21\u578b\u5728\u5e8f\u5217\u65e9\u671f\u5c31\u8f6c\u5411\u4e3b\u5bfc\u8bed\u8a00\u610f\u4e49\u3002\u8fd9\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65e0\u9700\u786e\u5b9a\u9519\u8bef\u6e90\u56e0\u679c\u5f52\u56e0\u7684\u539f\u5219\u6027\u6a21\u578b\u6392\u5e8f\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u591a\u8bed\u8a00\u8bed\u4e49\u8bc4\u4f30\u8d21\u732e\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6bd4\u8f83\u57fa\u51c6\u548c\u4e25\u683c\u7684\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u8fd9\u4e9b\u662f\u5f00\u53d1\u66f4\u8bed\u8a00\u5e73\u8861\u7684AI\u7cfb\u7edf\u7684\u5173\u952e\u5de5\u5177\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u7cfb\u7edf\u8bc4\u4f30\u548c\u6bd4\u8f83\u591a\u8bed\u8a00LLM\u7684\u8bed\u4e49\u9c81\u68d2\u6027\u3002"}}
{"id": "2601.12555", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12555", "abs": "https://arxiv.org/abs/2601.12555", "authors": ["Yihong Liu", "Bingyu Xiong", "Hinrich Sch\u00fctze"], "title": "Evaluating Contextually Mediated Factual Recall in Multilingual Large Language Models", "comment": "preprint", "summary": "Large language models (LLMs) can recall a wide range of factual knowledge across languages. However, existing factual recall evaluations primarily assess fact retrieval in isolation, where the queried entity is explicitly named and the fact is requested directly. In natural language use, facts are often accessed through context, where the relevant entity is introduced only indirectly. In this work, we study contextually mediated factual recall, asking whether LLMs can reliably retrieve factual knowledge when the target entity is embedded in a naturalistic context rather than queried explicitly, across languages. We construct controlled prompts that preserve the underlying fact while introducing referential mediation through contextual sentences. To disentangle contextual effects from name-specific associations, we further compare performance using synthetic names and real names across languages. Evaluating multiple model families in five languages, we find that contextual mediation consistently degrades factual recall, with substantial variation across relations. Larger models are more robust to contextual mediation, exhibiting a reduced performance gap relative to direct queries, while the effect of real names and name origin is mixed and unsystematic. These findings highlight a gap between isolated factual recall and context-dependent language understanding in multilingual LLMs.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86LLMs\u5728\u4e0a\u4e0b\u6587\u4e2d\u4ecb\u4e0b\u7684\u591a\u8bed\u8a00\u4e8b\u5b9e\u56de\u5fc6\u80fd\u529b\uff0c\u53d1\u73b0\u4e0a\u4e0b\u6587\u4e2d\u4ecb\u4f1a\u964d\u4f4e\u4e8b\u5b9e\u56de\u5fc6\u6548\u679c\uff0c\u5927\u6a21\u578b\u5bf9\u6b64\u66f4\u7a33\u5065\uff0c\u800c\u771f\u5b9e\u59d3\u540d\u7684\u5f71\u54cd\u4e0d\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709\u4e8b\u5b9e\u56de\u5fc6\u8bc4\u4f30\u4e3b\u8981\u8bc4\u4f30\u5b64\u7acb\u7684\u4e8b\u5b9e\u68c0\u7d22\uff0c\u4f46\u5728\u81ea\u7136\u8bed\u8a00\u4f7f\u7528\u4e2d\uff0c\u4e8b\u5b9e\u901a\u5e38\u901a\u8fc7\u4e0a\u4e0b\u6587\u95f4\u63a5\u8bbf\u95ee\u3002\u9700\u8981\u7814\u7a76LLMs\u5728\u76ee\u6807\u5b9e\u4f53\u5d4c\u5165\u81ea\u7136\u8bed\u5883\u800c\u975e\u663e\u5f0f\u67e5\u8be2\u65f6\u7684\u591a\u8bed\u8a00\u4e8b\u5b9e\u56de\u5fc6\u80fd\u529b\u3002", "method": "\u6784\u5efa\u53d7\u63a7\u63d0\u793a\uff0c\u5728\u4fdd\u7559\u5e95\u5c42\u4e8b\u5b9e\u7684\u540c\u65f6\u901a\u8fc7\u4e0a\u4e0b\u6587\u53e5\u5b50\u5f15\u5165\u6307\u79f0\u4e2d\u4ecb\u3002\u4f7f\u7528\u5408\u6210\u59d3\u540d\u548c\u771f\u5b9e\u59d3\u540d\u8de8\u8bed\u8a00\u6bd4\u8f83\uff0c\u4ee5\u533a\u5206\u4e0a\u4e0b\u6587\u6548\u5e94\u4e0e\u59d3\u540d\u7279\u5b9a\u5173\u8054\u3002\u5728\u4e94\u79cd\u8bed\u8a00\u4e2d\u8bc4\u4f30\u591a\u4e2a\u6a21\u578b\u5bb6\u65cf\u3002", "result": "\u4e0a\u4e0b\u6587\u4e2d\u4ecb\u6301\u7eed\u964d\u4f4e\u4e8b\u5b9e\u56de\u5fc6\u6548\u679c\uff0c\u4e0d\u540c\u5173\u7cfb\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u66f4\u5927\u6a21\u578b\u5bf9\u4e0a\u4e0b\u6587\u4e2d\u4ecb\u66f4\u7a33\u5065\uff0c\u76f8\u5bf9\u4e8e\u76f4\u63a5\u67e5\u8be2\u7684\u6027\u80fd\u5dee\u8ddd\u51cf\u5c0f\u3002\u771f\u5b9e\u59d3\u540d\u548c\u59d3\u540d\u6765\u6e90\u7684\u5f71\u54cd\u6df7\u5408\u4e14\u4e0d\u7cfb\u7edf\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u591a\u8bed\u8a00LLMs\u5728\u5b64\u7acb\u4e8b\u5b9e\u56de\u5fc6\u548c\u4e0a\u4e0b\u6587\u4f9d\u8d56\u8bed\u8a00\u7406\u89e3\u4e4b\u95f4\u5b58\u5728\u5dee\u8ddd\uff0c\u4e0a\u4e0b\u6587\u4e2d\u4ecb\u4f1a\u635f\u5bb3\u4e8b\u5b9e\u56de\u5fc6\uff0c\u5c3d\u7ba1\u5927\u6a21\u578b\u5bf9\u6b64\u66f4\u7a33\u5065\u3002"}}
{"id": "2601.13262", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13262", "abs": "https://arxiv.org/abs/2601.13262", "authors": ["Eric Onyame", "Akash Ghosh", "Subhadip Baidya", "Sriparna Saha", "Xiuying Chen", "Chirag Agarwal"], "title": "CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning", "comment": null, "summary": "While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/", "code_url": "https://cure-med.github.io", "AI": {"tldr": "CURE-MED\u6846\u67b6\u901a\u8fc7\u8bfe\u7a0b\u5f3a\u5316\u5b66\u4e60\u63d0\u5347LLMs\u7684\u591a\u8bed\u8a00\u533b\u7597\u63a8\u7406\u80fd\u529b\uff0c\u572813\u79cd\u8bed\u8a00\u4e0a\u663e\u8457\u6539\u5584\u903b\u8f91\u6b63\u786e\u6027\u548c\u8bed\u8a00\u4e00\u81f4\u6027", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5355\u8bed\u6570\u5b66\u548c\u5e38\u8bc6\u63a8\u7406\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u591a\u8bed\u8a00\u533b\u7597\u63a8\u7406\u5e94\u7528\u4e2d\u4ecd\u4e0d\u53ef\u9760\uff0c\u963b\u788d\u4e86\u5176\u5728\u591a\u8bed\u8a00\u533b\u7597\u73af\u5883\u4e2d\u7684\u90e8\u7f72", "method": "\u63d0\u51faCURE-MED\u6846\u67b6\uff0c\u5305\u542b\uff1a1) \u5f15\u5165CUREMED-BENCH\u591a\u8bed\u8a00\u533b\u7597\u63a8\u7406\u6570\u636e\u96c6\uff1b2) \u91c7\u7528\u8bfe\u7a0b\u5f3a\u5316\u5b66\u4e60\uff0c\u7ed3\u5408\u4ee3\u7801\u5207\u6362\u611f\u77e5\u7684\u76d1\u7763\u5fae\u8c03\u548c\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff0c\u5171\u540c\u63d0\u5347\u903b\u8f91\u6b63\u786e\u6027\u548c\u8bed\u8a00\u7a33\u5b9a\u6027", "result": "\u572813\u79cd\u8bed\u8a00\u4e0a\uff0c\u8be5\u65b9\u6cd5\u6301\u7eed\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u4e14\u6269\u5c55\u6709\u6548\uff1a7B\u53c2\u6570\u6a21\u578b\u8fbe\u523085.21%\u8bed\u8a00\u4e00\u81f4\u6027\u548c54.35%\u903b\u8f91\u6b63\u786e\u6027\uff1b32B\u53c2\u6570\u6a21\u578b\u8fbe\u523094.96%\u8bed\u8a00\u4e00\u81f4\u6027\u548c70.04%\u903b\u8f91\u6b63\u786e\u6027", "conclusion": "\u7814\u7a76\u7ed3\u679c\u652f\u6301LLMs\u5b9e\u73b0\u53ef\u9760\u4e14\u516c\u5e73\u7684\u591a\u8bed\u8a00\u533b\u7597\u63a8\u7406\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u5f00\u6e90"}}
{"id": "2601.13268", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13268", "abs": "https://arxiv.org/abs/2601.13268", "authors": ["Zainab Ghafoor", "Md Shafiqul Islam", "Koushik Howlader", "Md Rasel Khondokar", "Tanusree Bhattacharjee", "Sayantan Chakraborty", "Adrito Roy", "Ushashi Bhattacharjee", "Tirtho Roy"], "title": "Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops", "comment": null, "summary": "Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models - DeepSeek R1 and Med-PaLM - with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association's (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.", "AI": {"tldr": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u7cbe\u70bc\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u8fed\u4ee3\u5bf9\u9f50\u589e\u5f3a\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\uff0c\u7ed3\u5408\u751f\u6210\u6a21\u578b\u4e0e\u8bc4\u4f30\u667a\u80fd\u4f53\uff0c\u663e\u8457\u51cf\u5c11\u4f26\u7406\u8fdd\u89c4\u548c\u98ce\u9669\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u786e\u4fdd\u5176\u4f26\u7406\u5b8c\u6574\u6027\u548c\u5b89\u5168\u5408\u89c4\u6027\u4ecd\u662f\u4e34\u5e8a\u90e8\u7f72\u7684\u4e3b\u8981\u969c\u788d\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u5b89\u5168\u6cbb\u7406\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7cbe\u70bc\u6846\u67b6\uff0c\u7ed3\u5408DeepSeek R1\u548cMed-PaLM\u4e24\u4e2a\u751f\u6210\u6a21\u578b\uff0c\u4ee5\u53caLLaMA 3.1\u548cPhi-4\u4e24\u4e2a\u8bc4\u4f30\u667a\u80fd\u4f53\uff0c\u4f7f\u7528\u7f8e\u56fd\u533b\u5b66\u4f1a\u533b\u5b66\u4f26\u7406\u539f\u5219\u548c\u4e94\u7ea7\u5b89\u5168\u98ce\u9669\u8bc4\u4f30\u534f\u8bae\u8fdb\u884c\u7ed3\u6784\u5316\u8fed\u4ee3\u5bf9\u9f50\u3002", "result": "\u5728900\u4e2a\u4e34\u5e8a\u591a\u6837\u5316\u67e5\u8be2\u7684\u8bc4\u4f30\u4e2d\uff0cDeepSeek R1\u6536\u655b\u66f4\u5feb\uff08\u5e73\u57472.34 vs 2.67\u6b21\u8fed\u4ee3\uff09\uff0cMed-PaLM\u5728\u9690\u79c1\u654f\u611f\u573a\u666f\u5904\u7406\u66f4\u4f18\uff1b\u591a\u667a\u80fd\u4f53\u8fed\u4ee3\u5faa\u73af\u5b9e\u73b0\u4e8689%\u7684\u4f26\u7406\u8fdd\u89c4\u51cf\u5c11\u548c92%\u7684\u98ce\u9669\u964d\u7ea7\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u7b26\u5408\u76d1\u7ba1\u8981\u6c42\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u533b\u7597AI\u5b89\u5168\u6cbb\u7406\u8303\u5f0f\uff0c\u4e3a\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e34\u5e8a\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5b89\u5168\u589e\u5f3a\u65b9\u6cd5\u3002"}}
{"id": "2601.12618", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12618", "abs": "https://arxiv.org/abs/2601.12618", "authors": ["Elham Tajik", "Conrad Borchers", "Bahar Shahrokhian", "Sebastian Simon", "Ali Keramati", "Sonika Pal", "Sreecharan Sankaranarayanan"], "title": "Disagreement as Data: Reasoning Trace Analytics in Multi-Agent Systems", "comment": "LAK 2026 conference paper, 7 pages", "summary": "Learning analytics researchers often analyze qualitative student data such as coded annotations or interview transcripts to understand learning processes. With the rise of generative AI, fully automated and human-AI workflows have emerged as promising methods for analysis. However, methodological standards to guide such workflows remain limited. In this study, we propose that reasoning traces generated by large language model (LLM) agents, especially within multi-agent systems, constitute a novel and rich form of process data to enhance interpretive practices in qualitative coding. We apply cosine similarity to LLM reasoning traces to systematically detect, quantify, and interpret disagreements among agents, reframing disagreement as a meaningful analytic signal. Analyzing nearly 10,000 instances of agent pairs coding human tutoring dialog segments, we show that LLM agents' semantic reasoning similarity robustly differentiates consensus from disagreement and correlates with human coding reliability. Qualitative analysis guided by this metric reveals nuanced instructional sub-functions within codes and opportunities for conceptual codebook refinement. By integrating quantitative similarity metrics with qualitative review, our method has the potential to improve and accelerate establishing inter-rater reliability during coding by surfacing interpretive ambiguity, especially when LLMs collaborate with humans. We discuss how reasoning-trace disagreements represent a valuable new class of analytic signals advancing methodological rigor and interpretive depth in educational research.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u5229\u7528LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u63a8\u7406\u8f68\u8ff9\u4f5c\u4e3a\u8fc7\u7a0b\u6570\u636e\uff0c\u901a\u8fc7\u4f59\u5f26\u76f8\u4f3c\u5ea6\u91cf\u5316\u667a\u80fd\u4f53\u95f4\u7684\u5206\u6b67\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u6709\u610f\u4e49\u7684\u5206\u6790\u4fe1\u53f7\uff0c\u4ee5\u589e\u5f3a\u8d28\u6027\u7f16\u7801\u7684\u89e3\u91ca\u5b9e\u8df5\u548c\u65b9\u6cd5\u4e25\u8c28\u6027\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u7684\u53d1\u5c55\uff0c\u5168\u81ea\u52a8\u548c\u4eba\u673a\u534f\u4f5c\u7684\u5de5\u4f5c\u6d41\u7a0b\u6210\u4e3a\u5b66\u4e60\u5206\u6790\u4e2d\u8d28\u6027\u6570\u636e\u5206\u6790\u7684\u6709\u524d\u666f\u65b9\u6cd5\uff0c\u4f46\u6307\u5bfc\u6b64\u7c7b\u5de5\u4f5c\u6d41\u7a0b\u7684\u65b9\u6cd5\u5b66\u6807\u51c6\u4ecd\u7136\u6709\u9650\u3002\u7814\u7a76\u8005\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u589e\u5f3a\u8d28\u6027\u7f16\u7801\u7684\u89e3\u91ca\u5b9e\u8df5\u548c\u65b9\u6cd5\u4e25\u8c28\u6027\u3002", "method": "\u63d0\u51fa\u5c06LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\u4f5c\u4e3a\u8fc7\u7a0b\u6570\u636e\uff0c\u5e94\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u6765\u7cfb\u7edf\u68c0\u6d4b\u3001\u91cf\u5316\u548c\u89e3\u91ca\u667a\u80fd\u4f53\u95f4\u7684\u5206\u6b67\u3002\u5206\u6790\u4e86\u8fd110,000\u4e2a\u4eba\u7c7b\u8f85\u5bfc\u5bf9\u8bdd\u7247\u6bb5\u7f16\u7801\u7684\u667a\u80fd\u4f53\u5bf9\uff0c\u5c06\u5206\u6b67\u91cd\u65b0\u5b9a\u4e49\u4e3a\u6709\u610f\u4e49\u7684\u5206\u6790\u4fe1\u53f7\u3002", "result": "LLM\u667a\u80fd\u4f53\u7684\u8bed\u4e49\u63a8\u7406\u76f8\u4f3c\u5ea6\u80fd\u591f\u7a33\u5065\u5730\u533a\u5206\u5171\u8bc6\u4e0e\u5206\u6b67\uff0c\u5e76\u4e0e\u4eba\u7c7b\u7f16\u7801\u53ef\u9760\u6027\u76f8\u5173\u3002\u57fa\u4e8e\u8be5\u6307\u6807\u7684\u8d28\u6027\u5206\u6790\u63ed\u793a\u4e86\u7f16\u7801\u5185\u7684\u7ec6\u5fae\u6559\u5b66\u5b50\u529f\u80fd\u4ee5\u53ca\u6982\u5ff5\u7f16\u7801\u672c\u7ec6\u5316\u7684\u673a\u4f1a\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u91cf\u5316\u76f8\u4f3c\u5ea6\u6307\u6807\u4e0e\u8d28\u6027\u5ba1\u67e5\uff0c\u8be5\u65b9\u6cd5\u6709\u6f5c\u529b\u901a\u8fc7\u63ed\u793a\u89e3\u91ca\u6a21\u7cca\u6027\u6765\u6539\u8fdb\u548c\u52a0\u901f\u7f16\u7801\u8fc7\u7a0b\u4e2d\u8bc4\u4f30\u8005\u95f4\u4fe1\u5ea6\u7684\u5efa\u7acb\uff0c\u7279\u522b\u662f\u5728LLM\u4e0e\u4eba\u7c7b\u534f\u4f5c\u65f6\u3002\u63a8\u7406\u8f68\u8ff9\u5206\u6b67\u4ee3\u8868\u4e86\u63a8\u8fdb\u6559\u80b2\u7814\u7a76\u65b9\u6cd5\u4e25\u8c28\u6027\u548c\u89e3\u91ca\u6df1\u5ea6\u7684\u6709\u4ef7\u503c\u65b0\u578b\u5206\u6790\u4fe1\u53f7\u3002"}}
{"id": "2601.13327", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13327", "abs": "https://arxiv.org/abs/2601.13327", "authors": ["Po-Yu Liang", "Tobo Duran", "Jun Bai"], "title": "PepEDiff: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion", "comment": null, "summary": "We present PepEDiff, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Peptide binder generation is critical in therapeutic and biochemical applications, yet many existing methods rely heavily on intermediate structure prediction, adding complexity and limiting sequence diversity. Our approach departs from this paradigm by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures, thereby improving structural and sequence diversity. To encourage the model to capture binding-relevant features rather than memorizing known sequences, we perform latent-space exploration and diffusion-based sampling, enabling the generation of peptides beyond the limited distribution of known binders. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiff on TIGIT, a challenging target with a large, flat protein-protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design. The code for this research is available at GitHub: https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model", "code_url": "https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model", "code_stars": 0, "code_last_update": "2025-11-18", "AI": {"tldr": "PepEDiff\u662f\u4e00\u79cd\u65b0\u578b\u80bd\u7ed3\u5408\u5242\u751f\u6210\u5668\uff0c\u901a\u8fc7\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\u76f4\u63a5\u751f\u6210\u7ed3\u5408\u5e8f\u5217\uff0c\u65e0\u9700\u7ed3\u6784\u9884\u6d4b\uff0c\u63d0\u9ad8\u4e86\u5e8f\u5217\u591a\u6837\u6027\uff0c\u5728TIGIT\u9776\u70b9\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u80bd\u7ed3\u5408\u5242\u751f\u6210\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u4e2d\u95f4\u7ed3\u6784\u9884\u6d4b\uff0c\u589e\u52a0\u4e86\u590d\u6742\u6027\u5e76\u9650\u5236\u4e86\u5e8f\u5217\u591a\u6837\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u76f4\u63a5\u751f\u6210\u7ed3\u5408\u5e8f\u5217\u3001\u63d0\u9ad8\u7ed3\u6784\u591a\u6837\u6027\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u9884\u8bad\u7ec3\u86cb\u767d\u8d28\u5d4c\u5165\u6a21\u578b\u7684\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\uff0c\u901a\u8fc7\u6f5c\u5728\u7a7a\u95f4\u63a2\u7d22\u548c\u6269\u6563\u91c7\u6837\u751f\u6210\u80bd\u5e8f\u5217\uff0c\u4e0d\u4f9d\u8d56\u9884\u6d4b\u7ed3\u6784\uff0c\u5229\u7528\u5168\u5c40\u86cb\u767d\u8d28\u5d4c\u5165\u6d41\u5f62\u4f5c\u4e3a\u8bed\u4e49\u5148\u9a8c\u3002", "result": "\u5728TIGIT\uff08\u5177\u6709\u5927\u800c\u5e73\u5766\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u754c\u9762\u7684\u6311\u6218\u6027\u9776\u70b9\uff09\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u8be5\u65b9\u6cd5\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u4f5c\u4e3a\u96f6\u6837\u672c\u80bd\u7ed3\u5408\u5242\u8bbe\u8ba1\u7684\u901a\u7528\u65e0\u7ed3\u6784\u6846\u67b6\u7684\u6f5c\u529b\u3002", "conclusion": "PepEDiff\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u96f6\u6837\u672c\u80bd\u7ed3\u5408\u5242\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u76f4\u63a5\u6f5c\u5728\u7a7a\u95f4\u751f\u6210\u907f\u514d\u4e86\u7ed3\u6784\u9884\u6d4b\u7684\u590d\u6742\u6027\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u5e8f\u5217\u591a\u6837\u6027\u3002"}}
{"id": "2601.12639", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12639", "abs": "https://arxiv.org/abs/2601.12639", "authors": ["Daniel Vennemeyer", "Punya Syon Pandey", "Phan Anh Duong", "Michael Umeokoli", "Samuel Ratnam"], "title": "Objective Matters: Fine-Tuning Objectives Shape Safety, Robustness, and Persona Drift", "comment": null, "summary": "Fine-tuning LLMs on benign data can still degrade alignment and adversarial robustness, yet direct analysis of the role of fine-tuning objectives in shaping these safety outcomes remain limited. We present a controlled comparison of six fine-tuning objectives -- Supervised Fine-Tuning, Direct Preference Optimization, Conditional Fine-Tuning, Inoculation Prompting, Odds Ratio Preference Optimization, and KL-regularized fine-tuning -- holding data, domain, architecture, and optimization fixed. Across closed-form reasoning and open-ended generation tasks, we find that objective choice induces systematic, scale-dependent shifts along the safety-capability frontier. At small training budgets, robustness is similar across objectives but capability differs. At larger budgets, objectives diverge sharply: supervised and preference-based tuning tightly couple capability gains to increased adversarial vulnerability and persona drift, while objectives that constrain learning signals -- especially ORPO and KL-regularization -- substantially mitigate both. Fine-tuning objectives therefore matter little for safety at small scales but become a primary driver of adversarial robustness and latent persona stability as training scale increases.", "AI": {"tldr": "\u4e0d\u540c\u5fae\u8c03\u76ee\u6807\u5728\u5b89\u5168\u6027\u4e0e\u80fd\u529b\u6743\u8861\u4e0a\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff1a\u5c0f\u89c4\u6a21\u8bad\u7ec3\u65f6\u5b89\u5168\u6027\u76f8\u4f3c\u4f46\u80fd\u529b\u4e0d\u540c\uff0c\u5927\u89c4\u6a21\u8bad\u7ec3\u65f6\u76d1\u7763\u548c\u504f\u597d\u4f18\u5316\u4f1a\u663e\u8457\u964d\u4f4e\u5bf9\u6297\u9c81\u68d2\u6027\uff0c\u800cORPO\u548cKL\u6b63\u5219\u5316\u80fd\u6709\u6548\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898", "motivation": "\u5c3d\u7ba1\u5728\u826f\u6027\u6570\u636e\u4e0a\u5fae\u8c03LLMs\u4ecd\u53ef\u80fd\u635f\u5bb3\u5bf9\u9f50\u6027\u548c\u5bf9\u6297\u9c81\u68d2\u6027\uff0c\u4f46\u5fae\u8c03\u76ee\u6807\u5728\u5851\u9020\u8fd9\u4e9b\u5b89\u5168\u7ed3\u679c\u4e2d\u7684\u5177\u4f53\u4f5c\u7528\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u6bd4\u8f83\u4e0d\u540c\u5fae\u8c03\u76ee\u6807\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u7684\u5b89\u5168\u6027\u4e0e\u80fd\u529b\u6743\u8861", "method": "\u5728\u63a7\u5236\u6570\u636e\u3001\u9886\u57df\u3001\u67b6\u6784\u548c\u4f18\u5316\u7684\u6761\u4ef6\u4e0b\uff0c\u5bf9\u516d\u79cd\u5fae\u8c03\u76ee\u6807\u8fdb\u884c\u5bf9\u6bd4\uff1a\u76d1\u7763\u5fae\u8c03\u3001\u76f4\u63a5\u504f\u597d\u4f18\u5316\u3001\u6761\u4ef6\u5fae\u8c03\u3001\u63a5\u79cd\u63d0\u793a\u3001\u51e0\u7387\u6bd4\u504f\u597d\u4f18\u5316\u548cKL\u6b63\u5219\u5316\u5fae\u8c03\u3002\u5b9e\u9a8c\u6db5\u76d6\u5c01\u95ed\u5f0f\u63a8\u7406\u548c\u5f00\u653e\u5f0f\u751f\u6210\u4efb\u52a1", "result": "\u5fae\u8c03\u76ee\u6807\u9009\u62e9\u5bfc\u81f4\u5b89\u5168-\u80fd\u529b\u524d\u6cbf\u7684\u7cfb\u7edf\u6027\u3001\u89c4\u6a21\u4f9d\u8d56\u6027\u53d8\u5316\u3002\u5c0f\u8bad\u7ec3\u9884\u7b97\u4e0b\u5404\u76ee\u6807\u9c81\u68d2\u6027\u76f8\u4f3c\u4f46\u80fd\u529b\u4e0d\u540c\uff1b\u5927\u9884\u7b97\u4e0b\u76ee\u6807\u5dee\u5f02\u663e\u8457\uff1a\u76d1\u7763\u548c\u504f\u597d\u4f18\u5316\u4f7f\u80fd\u529b\u63d0\u5347\u4e0e\u5bf9\u6297\u8106\u5f31\u6027\u589e\u52a0\u7d27\u5bc6\u8026\u5408\uff0c\u800cORPO\u548cKL\u6b63\u5219\u5316\u80fd\u5927\u5e45\u7f13\u89e3\u4e24\u8005", "conclusion": "\u5fae\u8c03\u76ee\u6807\u5728\u5c0f\u89c4\u6a21\u8bad\u7ec3\u4e2d\u5bf9\u5b89\u5168\u6027\u5f71\u54cd\u4e0d\u5927\uff0c\u4f46\u968f\u7740\u8bad\u7ec3\u89c4\u6a21\u589e\u52a0\uff0c\u6210\u4e3a\u5bf9\u6297\u9c81\u68d2\u6027\u548c\u6f5c\u5728\u89d2\u8272\u7a33\u5b9a\u6027\u7684\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\u3002\u7ea6\u675f\u5b66\u4e60\u4fe1\u53f7\u7684\u76ee\u6807\uff08\u7279\u522b\u662fORPO\u548cKL\u6b63\u5219\u5316\uff09\u80fd\u6709\u6548\u5e73\u8861\u5b89\u5168\u6027\u4e0e\u80fd\u529b"}}
{"id": "2601.12648", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12648", "abs": "https://arxiv.org/abs/2601.12648", "authors": ["Nafiz Imtiaz Khan", "Kylie Cleland", "Vladimir Filkov", "Roger Eric Goldman"], "title": "Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?", "comment": "51 pages, 12 figures, 8 tables. Feasibility study using retrospective radiology reports. Submitted to JAMIA Open (under review)", "summary": "Procedural case logs are a core requirement in radiology training, yet they are time-consuming to complete and prone to inconsistency when authored manually. This study investigates whether large language models (LLMs) can automate procedural case log documentation directly from free-text radiology reports. We evaluate multiple local and commercial LLMs under instruction-based and chain-of-thought prompting to extract structured procedural information from 414 curated interventional radiology reports authored by nine residents between 2018 and 2024. Model performance is assessed using sensitivity, specificity, and F1-score, alongside inference latency and token efficiency to estimate operational cost. Results show that both local and commercial models achieve strong extraction performance, with best F1-scores approaching 0.87, while exhibiting different trade-offs between speed and cost. Automation using LLMs has the potential to substantially reduce clerical burden for trainees and improve consistency in case logging. These findings demonstrate the feasibility of AI-assisted documentation in medical education and highlight the need for further validation across institutions and clinical workflows.", "AI": {"tldr": "LLMs can effectively\u81ea\u52a8\u5316\u4ecb\u5165\u653e\u5c04\u5b66\u7a0b\u5e8f\u75c5\u4f8b\u65e5\u5fd7\u8bb0\u5f55\uff0c\u76f4\u63a5\u4ece\u81ea\u7531\u6587\u672c\u62a5\u544a\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u4fe1\u606f\uff0c\u663e\u8457\u51cf\u5c11\u5b66\u5458\u7684\u6587\u4e66\u8d1f\u62c5\u5e76\u63d0\u9ad8\u4e00\u81f4\u6027\u3002", "motivation": "\u7a0b\u5e8f\u75c5\u4f8b\u65e5\u5fd7\u662f\u653e\u5c04\u5b66\u57f9\u8bad\u7684\u6838\u5fc3\u8981\u6c42\uff0c\u4f46\u624b\u52a8\u5b8c\u6210\u8017\u65f6\u4e14\u5bb9\u6613\u4e0d\u4e00\u81f4\u3002\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u51cf\u8f7b\u5b66\u5458\u7684\u6587\u4e66\u8d1f\u62c5\u5e76\u63d0\u9ad8\u65e5\u5fd7\u8bb0\u5f55\u7684\u4e00\u81f4\u6027\u3002", "method": "\u8bc4\u4f30\u591a\u4e2a\u672c\u5730\u548c\u5546\u4e1aLLM\u5728\u6307\u4ee4\u63d0\u793a\u548c\u601d\u7ef4\u94fe\u63d0\u793a\u4e0b\uff0c\u4ece414\u4efd\u75319\u540d\u4f4f\u9662\u533b\u5e08\u57282018-2024\u5e74\u95f4\u64b0\u5199\u7684\u4ecb\u5165\u653e\u5c04\u5b66\u62a5\u544a\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u7a0b\u5e8f\u4fe1\u606f\u3002\u4f7f\u7528\u654f\u611f\u6027\u3001\u7279\u5f02\u6027\u3001F1\u5206\u6570\u4ee5\u53ca\u63a8\u7406\u5ef6\u8fdf\u548c\u4ee3\u5e01\u6548\u7387\u6765\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u672c\u5730\u548c\u5546\u4e1a\u6a21\u578b\u90fd\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u63d0\u53d6\u6027\u80fd\uff0c\u6700\u4f73F1\u5206\u6570\u63a5\u8fd10.87\u3002\u4e0d\u540c\u6a21\u578b\u5728\u901f\u5ea6\u548c\u6210\u672c\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002\u81ea\u52a8\u5316\u6709\u6f5c\u529b\u663e\u8457\u51cf\u5c11\u5b66\u5458\u7684\u6587\u4e66\u8d1f\u62c5\u5e76\u63d0\u9ad8\u75c5\u4f8b\u65e5\u5fd7\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "LLMs\u5728\u533b\u5b66\u6559\u80b2\u4e2d\u8f85\u52a9\u6587\u6863\u8bb0\u5f55\u7684\u53ef\u884c\u6027\u5f97\u5230\u8bc1\u5b9e\u3002\u7814\u7a76\u7ed3\u679c\u652f\u6301AI\u5728\u533b\u7597\u57f9\u8bad\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u4f46\u9700\u8981\u5728\u4e0d\u540c\u673a\u6784\u548c\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u8fdb\u884c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u3002"}}
{"id": "2601.12658", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12658", "abs": "https://arxiv.org/abs/2601.12658", "authors": ["Tianyi Yang", "Nashrah Haque", "Vaishnave Jonnalagadda", "Yuya Jeremy Ong", "Zhehui Chen", "Yanzhao Wu", "Lei Yu", "Divyesh Jadav", "Wenqi Wei"], "title": "Augmenting Question Answering with A Hybrid RAG Approach", "comment": "10 pages, 5 tables, 2 figures; presented at IEEE CogMI 2025", "summary": "Retrieval-Augmented Generation (RAG) has emerged as a powerful technique for enhancing the quality of responses in Question-Answering (QA) tasks. However, existing approaches often struggle with retrieving contextually relevant information, leading to incomplete or suboptimal answers. In this paper, we introduce Structured-Semantic RAG (SSRAG), a hybrid architecture that enhances QA quality by integrating query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph based techniques with context unification. By refining retrieval processes and improving contextual grounding, our approach improves both answer accuracy and informativeness. We conduct extensive evaluations on three popular QA datasets, TruthfulQA, SQuAD and WikiQA, across five Large Language Models (LLMs), demonstrating that our proposed approach consistently improves response quality over standard RAG implementations.", "AI": {"tldr": "SSRAG\u662f\u4e00\u79cd\u6df7\u5408\u67b6\u6784\uff0c\u901a\u8fc7\u96c6\u6210\u67e5\u8be2\u589e\u5f3a\u3001\u667a\u80fd\u8def\u7531\u548c\u7ed3\u6784\u5316\u68c0\u7d22\u673a\u5236\u6765\u63d0\u5347\u95ee\u7b54\u8d28\u91cf\uff0c\u76f8\u6bd4\u6807\u51c6RAG\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709RAG\u65b9\u6cd5\u5728\u68c0\u7d22\u4e0a\u4e0b\u6587\u76f8\u5173\u4fe1\u606f\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u5bfc\u81f4\u7b54\u6848\u4e0d\u5b8c\u6574\u6216\u6b21\u4f18\uff0c\u9700\u8981\u6539\u8fdb\u68c0\u7d22\u8fc7\u7a0b\u4ee5\u63d0\u5347\u95ee\u7b54\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u5316\u8bed\u4e49RAG\uff08SSRAG\uff09\u6df7\u5408\u67b6\u6784\uff0c\u6574\u5408\u67e5\u8be2\u589e\u5f3a\u3001\u667a\u80fd\u8def\u7531\u548c\u7ed3\u6784\u5316\u68c0\u7d22\u673a\u5236\uff0c\u7ed3\u5408\u5411\u91cf\u548c\u56fe\u68c0\u7d22\u6280\u672f\u5e76\u8fdb\u884c\u4e0a\u4e0b\u6587\u7edf\u4e00\u3002", "result": "\u5728TruthfulQA\u3001SQuAD\u548cWikiQA\u4e09\u4e2aQA\u6570\u636e\u96c6\u4e0a\uff0c\u5bf9\u4e94\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u76f8\u6bd4\u6807\u51c6RAG\u80fd\u6301\u7eed\u63d0\u5347\u54cd\u5e94\u8d28\u91cf\u3002", "conclusion": "SSRAG\u901a\u8fc7\u6539\u8fdb\u68c0\u7d22\u8fc7\u7a0b\u548c\u589e\u5f3a\u4e0a\u4e0b\u6587\u57fa\u7840\uff0c\u63d0\u9ad8\u4e86\u7b54\u6848\u51c6\u786e\u6027\u548c\u4fe1\u606f\u4e30\u5bcc\u5ea6\uff0c\u4e3a\u95ee\u7b54\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684RAG\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13462", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13462", "abs": "https://arxiv.org/abs/2601.13462", "authors": ["Amine Rostane"], "title": "SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation", "comment": "19 pages, includes figures and tables", "summary": "Evaluating whether text-to-image models follow explicit spatial instructions is difficult to automate. Object detectors may miss targets or return multiple plausible detections, and simple geometric tests can become ambiguous in borderline cases. Spatial evaluation is naturally a selective prediction problem, the checker may abstain when evidence is weak and report confidence so that results can be interpreted as a risk coverage tradeoff rather than a single score. We introduce SpatialBench-UC, a small, reproducible benchmark for pairwise spatial relations. The benchmark contains 200 prompts (50 object pairs times 4 relations) grouped into 100 counterfactual pairs obtained by swapping object roles. We release a benchmark package, versioned prompts, pinned configs, per-sample checker outputs, and report tables, enabling reproducible and auditable comparisons across models. We also include a lightweight human audit used to calibrate the checker's abstention margin and confidence threshold. We evaluate three baselines, Stable Diffusion 1.5, SD 1.5 BoxDiff, and SD 1.4 GLIGEN. The checker reports pass rate and coverage as well as conditional pass rates on decided samples. The results show that grounding methods substantially improve both pass rate and coverage, while abstention remains a dominant factor due mainly to missing detections.", "AI": {"tldr": "SpatialBench-UC\uff1a\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u7a7a\u95f4\u5173\u7cfb\u7406\u89e3\u80fd\u529b\u7684\u5c0f\u578b\u53ef\u590d\u73b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b200\u4e2a\u63d0\u793a\u548c100\u4e2a\u53cd\u4e8b\u5b9e\u5bf9\uff0c\u652f\u6301\u9009\u62e9\u6027\u9884\u6d4b\u548c\u98ce\u9669\u8986\u76d6\u6743\u8861\u5206\u6790\u3002", "motivation": "\u8bc4\u4f30\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u662f\u5426\u9075\u5faa\u660e\u786e\u7684\u7a7a\u95f4\u6307\u4ee4\u96be\u4ee5\u81ea\u52a8\u5316\u3002\u73b0\u6709\u65b9\u6cd5\u5982\u76ee\u6807\u68c0\u6d4b\u5668\u53ef\u80fd\u6f0f\u68c0\u76ee\u6807\u6216\u8fd4\u56de\u591a\u4e2a\u53ef\u80fd\u68c0\u6d4b\u7ed3\u679c\uff0c\u7b80\u5355\u7684\u51e0\u4f55\u6d4b\u8bd5\u5728\u8fb9\u754c\u60c5\u51b5\u4e0b\u53d8\u5f97\u6a21\u7cca\u3002\u7a7a\u95f4\u8bc4\u4f30\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u9009\u62e9\u6027\u9884\u6d4b\u95ee\u9898\uff0c\u68c0\u67e5\u5668\u5e94\u5728\u8bc1\u636e\u4e0d\u8db3\u65f6\u5f03\u6743\u5e76\u62a5\u544a\u7f6e\u4fe1\u5ea6\uff0c\u4f7f\u7ed3\u679c\u53ef\u89e3\u91ca\u4e3a\u98ce\u9669\u8986\u76d6\u6743\u8861\u800c\u975e\u5355\u4e00\u5206\u6570\u3002", "method": "\u63d0\u51faSpatialBench-UC\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b200\u4e2a\u63d0\u793a\uff0850\u4e2a\u7269\u4f53\u5bf9\u00d74\u79cd\u5173\u7cfb\uff09\uff0c\u5206\u7ec4\u4e3a100\u4e2a\u901a\u8fc7\u4ea4\u6362\u7269\u4f53\u89d2\u8272\u83b7\u5f97\u7684\u53cd\u4e8b\u5b9e\u5bf9\u3002\u53d1\u5e03\u5305\u542b\u7248\u672c\u5316\u63d0\u793a\u3001\u56fa\u5b9a\u914d\u7f6e\u3001\u6bcf\u6837\u672c\u68c0\u67e5\u5668\u8f93\u51fa\u548c\u62a5\u544a\u8868\u683c\u7684\u57fa\u51c6\u5305\uff0c\u652f\u6301\u8de8\u6a21\u578b\u7684\u53ef\u590d\u73b0\u548c\u53ef\u5ba1\u8ba1\u6bd4\u8f83\u3002\u5305\u542b\u8f7b\u91cf\u7ea7\u4eba\u5de5\u5ba1\u6838\u7528\u4e8e\u6821\u51c6\u68c0\u67e5\u5668\u7684\u5f03\u6743\u8fb9\u754c\u548c\u7f6e\u4fe1\u5ea6\u9608\u503c\u3002", "result": "\u8bc4\u4f30\u4e86\u4e09\u4e2a\u57fa\u7ebf\u6a21\u578b\uff1aStable Diffusion 1.5\u3001SD 1.5 BoxDiff\u548cSD 1.4 GLIGEN\u3002\u68c0\u67e5\u5668\u62a5\u544a\u901a\u8fc7\u7387\u548c\u8986\u76d6\u7387\u4ee5\u53ca\u5728\u5df2\u51b3\u5b9a\u6837\u672c\u4e0a\u7684\u6761\u4ef6\u901a\u8fc7\u7387\u3002\u7ed3\u679c\u663e\u793a\uff0c\u63a5\u5730\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u901a\u8fc7\u7387\u548c\u8986\u76d6\u7387\uff0c\u4f46\u5f03\u6743\u4ecd\u7136\u662f\u4e3b\u8981\u56e0\u7d20\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u76ee\u6807\u68c0\u6d4b\u6f0f\u68c0\u3002", "conclusion": "SpatialBench-UC\u4e3a\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u7684\u7a7a\u95f4\u5173\u7cfb\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u652f\u6301\u9009\u62e9\u6027\u9884\u6d4b\u548c\u98ce\u9669\u8986\u76d6\u6743\u8861\u5206\u6790\u3002\u63a5\u5730\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u76ee\u6807\u68c0\u6d4b\u6f0f\u68c0\u4ecd\u662f\u9650\u5236\u56e0\u7d20\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002"}}
{"id": "2601.12696", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12696", "abs": "https://arxiv.org/abs/2601.12696", "authors": ["Tassallah Abdullahi", "Macton Mgonzo", "Mardiyyah Oduwole", "Paul Okewunmi", "Abraham Owodunni", "Ritambhara Singh", "Carsten Eickhoff"], "title": "UbuntuGuard: A Culturally-Grounded Policy Benchmark for Equitable AI Safety in African Languages", "comment": "12 pages", "summary": "Current guardian models are predominantly Western-centric and optimized for high-resource languages, leaving low-resource African languages vulnerable to evolving harms, cross-lingual safety failures, and cultural misalignment. Moreover, most guardian models rely on rigid, predefined safety categories that fail to generalize across diverse linguistic and sociocultural contexts. Robust safety, therefore, requires flexible, runtime-enforceable policies and benchmarks that reflect local norms, harm scenarios, and cultural expectations. We introduce UbuntuGuard, the first African policy-based safety benchmark built from adversarial queries authored by 155 domain experts across sensitive fields, including healthcare. From these expert-crafted queries, we derive context-specific safety policies and reference responses that capture culturally grounded risk signals, enabling policy-aligned evaluation of guardian models. We evaluate 13 models, comprising six general-purpose LLMs and seven guardian models across three distinct variants: static, dynamic, and multilingual. Our findings reveal that existing English-centric benchmarks overestimate real-world multilingual safety, cross-lingual transfer provides partial but insufficient coverage, and dynamic models, while better equipped to leverage policies at inference time, still struggle to fully localize African-language contexts. These findings highlight the urgent need for multilingual, culturally grounded safety benchmarks to enable the development of reliable and equitable guardian models for low-resource languages. Our code can be found online.\\footnote{Code repository available at https://github.com/hemhemoh/UbuntuGuard.", "code_url": "https://github.com/hemhemoh/UbuntuGuard", "code_stars": 1, "code_last_update": "2026-01-10", "AI": {"tldr": "UbuntuGuard\uff1a\u9996\u4e2a\u57fa\u4e8e\u653f\u7b56\u7684\u975e\u6d32\u8bed\u8a00\u5b89\u5168\u57fa\u51c6\uff0c\u901a\u8fc7\u9886\u57df\u4e13\u5bb6\u6784\u5efa\u5bf9\u6297\u6027\u67e5\u8be2\uff0c\u8bc4\u4f3013\u4e2a\u6a21\u578b\u5728\u975e\u6d32\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u7684\u5b89\u5168\u6027\u80fd\uff0c\u53d1\u73b0\u73b0\u6709\u82f1\u8bed\u57fa\u51c6\u9ad8\u4f30\u591a\u8bed\u8a00\u5b89\u5168\u6027\uff0c\u8de8\u8bed\u8a00\u8fc1\u79fb\u4e0d\u8db3\uff0c\u52a8\u6001\u6a21\u578b\u4ecd\u96be\u4ee5\u5b8c\u5168\u672c\u5730\u5316\u975e\u6d32\u8bed\u5883\u3002", "motivation": "\u5f53\u524d\u76d1\u62a4\u4eba\u6a21\u578b\u4e3b\u8981\u9762\u5411\u897f\u65b9\u4e2d\u5fc3\u4e3b\u4e49\u548c\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u5bfc\u81f4\u975e\u6d32\u4f4e\u8d44\u6e90\u8bed\u8a00\u9762\u4e34\u6f14\u5316\u5371\u5bb3\u3001\u8de8\u8bed\u8a00\u5b89\u5168\u5931\u6548\u548c\u6587\u5316\u9519\u4f4d\u95ee\u9898\u3002\u73b0\u6709\u5b89\u5168\u5206\u7c7b\u50f5\u5316\uff0c\u65e0\u6cd5\u9002\u5e94\u591a\u6837\u5316\u7684\u8bed\u8a00\u548c\u793e\u4f1a\u6587\u5316\u80cc\u666f\uff0c\u9700\u8981\u7075\u6d3b\u3001\u8fd0\u884c\u65f6\u53ef\u6267\u884c\u7684\u653f\u7b56\u548c\u57fa\u51c6\u6765\u53cd\u6620\u672c\u5730\u89c4\u8303\u3001\u5371\u5bb3\u573a\u666f\u548c\u6587\u5316\u671f\u671b\u3002", "method": "\u5f15\u5165UbuntuGuard\u57fa\u51c6\uff1a1\uff09\u7531155\u540d\u654f\u611f\u9886\u57df\uff08\u5305\u62ec\u533b\u7597\u4fdd\u5065\uff09\u7684\u9886\u57df\u4e13\u5bb6\u7f16\u5199\u5bf9\u6297\u6027\u67e5\u8be2\uff1b2\uff09\u4ece\u8fd9\u4e9b\u4e13\u5bb6\u6784\u5efa\u7684\u67e5\u8be2\u4e2d\u63a8\u5bfc\u51fa\u4e0a\u4e0b\u6587\u7279\u5b9a\u7684\u5b89\u5168\u653f\u7b56\u548c\u53c2\u8003\u54cd\u5e94\uff0c\u6355\u6349\u6587\u5316\u57fa\u7840\u7684\u98ce\u9669\u4fe1\u53f7\uff1b3\uff09\u8bc4\u4f3013\u4e2a\u6a21\u578b\uff0c\u5305\u62ec6\u4e2a\u901a\u7528LLM\u548c7\u4e2a\u76d1\u62a4\u4eba\u6a21\u578b\uff08\u9759\u6001\u3001\u52a8\u6001\u548c\u591a\u8bed\u8a00\u4e09\u79cd\u53d8\u4f53\uff09\u3002", "result": "\u8bc4\u4f30\u53d1\u73b0\uff1a1\uff09\u73b0\u6709\u82f1\u8bed\u4e2d\u5fc3\u57fa\u51c6\u9ad8\u4f30\u4e86\u771f\u5b9e\u4e16\u754c\u7684\u591a\u8bed\u8a00\u5b89\u5168\u6027\uff1b2\uff09\u8de8\u8bed\u8a00\u8fc1\u79fb\u63d0\u4f9b\u90e8\u5206\u4f46\u4e0d\u5145\u5206\u7684\u8986\u76d6\uff1b3\uff09\u52a8\u6001\u6a21\u578b\u867d\u7136\u5728\u63a8\u7406\u65f6\u80fd\u66f4\u597d\u5730\u5229\u7528\u653f\u7b56\uff0c\u4f46\u4ecd\u96be\u4ee5\u5b8c\u5168\u672c\u5730\u5316\u975e\u6d32\u8bed\u8a00\u8bed\u5883\u3002\u8fd9\u4e9b\u53d1\u73b0\u51f8\u663e\u4e86\u5f00\u53d1\u591a\u8bed\u8a00\u3001\u6587\u5316\u57fa\u7840\u5b89\u5168\u57fa\u51c6\u7684\u7d27\u8feb\u6027\u3002", "conclusion": "\u9700\u8981\u591a\u8bed\u8a00\u3001\u6587\u5316\u57fa\u7840\u7684\u5b89\u5168\u57fa\u51c6\u6765\u652f\u6301\u4f4e\u8d44\u6e90\u8bed\u8a00\u53ef\u9760\u4e14\u516c\u5e73\u7684\u76d1\u62a4\u4eba\u6a21\u578b\u5f00\u53d1\u3002UbuntuGuard\u4f5c\u4e3a\u9996\u4e2a\u975e\u6d32\u653f\u7b56\u5b89\u5168\u57fa\u51c6\uff0c\u4e3a\u8bc4\u4f30\u6a21\u578b\u5728\u975e\u6d32\u8bed\u8a00\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6027\u80fd\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u6587\u5316\u9002\u5e94\u6027\u548c\u672c\u5730\u5316\u65b9\u9762\u7684\u4e0d\u8db3\u3002"}}
{"id": "2601.13464", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.13464", "abs": "https://arxiv.org/abs/2601.13464", "authors": ["Chongyang Gao", "Marco Postiglione", "Julian Baldwin", "Natalia Denisenko", "Isabel Gortner", "Luke Fosdick", "Chiara Pulice", "Sarit Kraus", "V. S. Subrahmanian"], "title": "Context and Transcripts Improve Detection of Deepfake Audios of Public Figures", "comment": null, "summary": "Humans use context to assess the veracity of information. However, current audio deepfake detectors only analyze the audio file without considering either context or transcripts. We create and analyze a Journalist-provided Deepfake Dataset (JDD) of 255 public deepfakes which were primarily contributed by over 70 journalists since early 2024. We also generate a synthetic audio dataset (SYN) of dead public figures and propose a novel Context-based Audio Deepfake Detector (CADD) architecture. In addition, we evaluate performance on two large-scale datasets: ITW and P$^2$V. We show that sufficient context and/or the transcript can significantly improve the efficacy of audio deepfake detectors. Performance (measured via F1 score, AUC, and EER) of multiple baseline audio deepfake detectors and traditional classifiers can be improved by 5%-37.58% in F1-score, 3.77%-42.79% in AUC, and 6.17%-47.83% in EER. We additionally show that CADD, via its use of context and/or transcripts, is more robust to 5 adversarial evasion strategies, limiting performance degradation to an average of just -0.71% across all experiments. Code, models, and datasets are available at our project page: https://sites.northwestern.edu/nsail/cadd-context-based-audio-deepfake-detection (access restricted during review).", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e0a\u4e0b\u6587\u548c\u8f6c\u5f55\u6587\u672c\u7684\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5668CADD\uff0c\u901a\u8fc7\u6574\u5408\u4e0a\u4e0b\u6587\u4fe1\u606f\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\uff0c\u5e76\u589e\u5f3a\u5bf9\u6297\u653b\u51fb\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5668\u4ec5\u5206\u6790\u97f3\u9891\u6587\u4ef6\u672c\u8eab\uff0c\u5ffd\u7565\u4e86\u4eba\u7c7b\u5224\u65ad\u771f\u4f2a\u65f6\u4f9d\u8d56\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u548c\u8f6c\u5f55\u6587\u672c\uff0c\u5bfc\u81f4\u68c0\u6d4b\u6548\u679c\u53d7\u9650\u3002", "method": "\u521b\u5efa\u8bb0\u8005\u63d0\u4f9b\u7684\u6df1\u5ea6\u4f2a\u9020\u6570\u636e\u96c6JDD\u548c\u5408\u6210\u97f3\u9891\u6570\u636e\u96c6SYN\uff1b\u63d0\u51faCADD\u67b6\u6784\uff0c\u6574\u5408\u4e0a\u4e0b\u6587\u4fe1\u606f\u548c\u8f6c\u5f55\u6587\u672c\uff1b\u5728ITW\u548cP\u00b2V\u7b49\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u4e0a\u4e0b\u6587\u548c\u8f6c\u5f55\u6587\u672c\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\uff1aF1\u5206\u6570\u63d0\u53475%-37.58%\uff0cAUC\u63d0\u53473.77%-42.79%\uff0cEER\u63d0\u53476.17%-47.83%\uff1bCADD\u5bf95\u79cd\u5bf9\u6297\u653b\u51fb\u7b56\u7565\u5177\u6709\u66f4\u5f3a\u9c81\u68d2\u6027\uff0c\u6027\u80fd\u5e73\u5747\u4ec5\u4e0b\u964d0.71%\u3002", "conclusion": "\u6574\u5408\u4e0a\u4e0b\u6587\u4fe1\u606f\u548c\u8f6c\u5f55\u6587\u672c\u80fd\u663e\u8457\u63d0\u9ad8\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5668\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u672a\u6765\u68c0\u6d4b\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.12731", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12731", "abs": "https://arxiv.org/abs/2601.12731", "authors": ["Stefano Civelli", "Pietro Bernardelle", "Nicol\u00f2 Brunello", "Gianluca Demartini"], "title": "A Shared Geometry of Difficulty in Multilingual Language Models", "comment": null, "summary": "Predicting problem-difficulty in large language models (LLMs) refers to estimating how difficult a task is according to the model itself, typically by training linear probes on its internal representations. In this work, we study the multilingual geometry of problem-difficulty in LLMs by training linear probes using the AMC subset of the Easy2Hard benchmark, translated into 21 languages. We found that difficulty-related signals emerge at two distinct stages of the model internals, corresponding to shallow (early-layers) and deep (later-layers) internal representations, that exhibit functionally different behaviors. Probes trained on deep representations achieve high accuracy when evaluated on the same language but exhibit poor cross-lingual generalization. In contrast, probes trained on shallow representations generalize substantially better across languages, despite achieving lower within-language performance. Together, these results suggest that LLMs first form a language-agnostic representation of problem difficulty, which subsequently becomes language-specific. This closely aligns with existing findings in LLM interpretability showing that models tend to operate in an abstract conceptual space before producing language-specific outputs. We demonstrate that this two-stage representational process extends beyond semantic content to high-level meta-cognitive properties such as problem-difficulty estimation.", "AI": {"tldr": "LLMs\u5728\u95ee\u9898\u96be\u5ea6\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u4e24\u9636\u6bb5\u8868\u793a\u8fc7\u7a0b\uff1a\u6d45\u5c42\u8868\u793a\u5f62\u6210\u8bed\u8a00\u65e0\u5173\u7684\u96be\u5ea6\u4fe1\u53f7\uff0c\u6df1\u5c42\u8868\u793a\u5219\u8f6c\u5316\u4e3a\u8bed\u8a00\u7279\u5b9a\u7684\u96be\u5ea6\u8bc4\u4f30", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u95ee\u9898\u96be\u5ea6\u9884\u6d4b\u7684\u591a\u8bed\u8a00\u51e0\u4f55\u7279\u6027\uff0c\u63a2\u7d22\u96be\u5ea6\u4fe1\u53f7\u5728\u4e0d\u540c\u8bed\u8a00\u95f4\u7684\u6cdb\u5316\u80fd\u529b", "method": "\u4f7f\u7528Easy2Hard\u57fa\u51c6\u7684AMC\u5b50\u96c6\uff0c\u7ffb\u8bd1\u621021\u79cd\u8bed\u8a00\uff0c\u5728LLM\u5185\u90e8\u8868\u793a\u4e0a\u8bad\u7ec3\u7ebf\u6027\u63a2\u9488\uff0c\u5206\u6790\u6d45\u5c42\uff08\u65e9\u671f\u5c42\uff09\u548c\u6df1\u5c42\uff08\u540e\u671f\u5c42\uff09\u8868\u793a\u7684\u529f\u80fd\u5dee\u5f02", "result": "\u6df1\u5c42\u8868\u793a\u63a2\u9488\u5728\u76f8\u540c\u8bed\u8a00\u5185\u51c6\u786e\u7387\u9ad8\u4f46\u8de8\u8bed\u8a00\u6cdb\u5316\u5dee\uff1b\u6d45\u5c42\u8868\u793a\u63a2\u9488\u5728\u76f8\u540c\u8bed\u8a00\u5185\u6027\u80fd\u8f83\u4f4e\u4f46\u8de8\u8bed\u8a00\u6cdb\u5316\u663e\u8457\u66f4\u597d", "conclusion": "LLMs\u9996\u5148\u5f62\u6210\u8bed\u8a00\u65e0\u5173\u7684\u95ee\u9898\u96be\u5ea6\u8868\u793a\uff0c\u968f\u540e\u8f6c\u5316\u4e3a\u8bed\u8a00\u7279\u5b9a\u7684\u96be\u5ea6\u8bc4\u4f30\uff0c\u8fd9\u4e0eLLM\u89e3\u91ca\u6027\u7814\u7a76\u4e2d\u53d1\u73b0\u7684\u62bd\u8c61\u6982\u5ff5\u7a7a\u95f4\u5148\u4e8e\u8bed\u8a00\u7279\u5b9a\u8f93\u51fa\u7684\u6a21\u5f0f\u4e00\u81f4"}}
{"id": "2601.13481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13481", "abs": "https://arxiv.org/abs/2601.13481", "authors": ["Jian Zhang", "Zhangqi Wang", "Zhiyuan Wang", "Weiping Fu", "Yu He", "Haiping Zhu", "Qika Lin", "Jun Liu"], "title": "Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement", "comment": null, "summary": "Linguistic expressions of emotions such as depression, anxiety, and trauma-related states are pervasive in clinical notes, counseling dialogues, and online mental health communities, and accurate recognition of these emotions is essential for clinical triage, risk assessment, and timely intervention. Although large language models (LLMs) have demonstrated strong generalization ability in emotion analysis tasks, their diagnostic reliability in high-stakes, context-intensive medical settings remains highly sensitive to prompt design. Moreover, existing methods face two key challenges: emotional comorbidity, in which multiple intertwined emotional states complicate prediction, and inefficient exploration of clinically relevant cues. To address these challenges, we propose APOLO (Automated Prompt Optimization for Linguistic Emotion Diagnosis), a framework that systematically explores a broader and finer-grained prompt space to improve diagnostic efficiency and robustness. APOLO formulates instruction refinement as a Partially Observable Markov Decision Process and adopts a multi-agent collaboration mechanism involving Planner, Teacher, Critic, Student, and Target roles. Within this closed-loop framework, the Planner defines an optimization trajectory, while the Teacher-Critic-Student agents iteratively refine prompts to enhance reasoning stability and effectiveness, and the Target agent determines whether to continue optimization based on performance evaluation. Experimental results show that APOLO consistently improves diagnostic accuracy and robustness across domain-specific and stratified benchmarks, demonstrating a scalable and generalizable paradigm for trustworthy LLM applications in mental healthcare.", "AI": {"tldr": "APOLO\u662f\u4e00\u4e2a\u7528\u4e8e\u7cbe\u795e\u5065\u5eb7\u9886\u57df\u60c5\u611f\u8bca\u65ad\u7684\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u673a\u5236\u89e3\u51b3\u60c5\u611f\u5171\u75c5\u548c\u4e34\u5e8a\u7ebf\u7d22\u63a2\u7d22\u6548\u7387\u95ee\u9898\uff0c\u63d0\u5347LLM\u5728\u533b\u7597\u73af\u5883\u4e2d\u7684\u8bca\u65ad\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u5728\u4e34\u5e8a\u7b14\u8bb0\u3001\u54a8\u8be2\u5bf9\u8bdd\u548c\u5728\u7ebf\u5fc3\u7406\u5065\u5eb7\u793e\u533a\u4e2d\uff0c\u6291\u90c1\u3001\u7126\u8651\u548c\u521b\u4f24\u76f8\u5173\u72b6\u6001\u7684\u60c5\u611f\u8868\u8fbe\u666e\u904d\u5b58\u5728\uff0c\u51c6\u786e\u8bc6\u522b\u8fd9\u4e9b\u60c5\u611f\u5bf9\u4e34\u5e8a\u5206\u8bca\u3001\u98ce\u9669\u8bc4\u4f30\u548c\u53ca\u65f6\u5e72\u9884\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4f46\u5728\u9ad8\u98ce\u9669\u3001\u4e0a\u4e0b\u6587\u5bc6\u96c6\u7684\u533b\u7597\u73af\u5883\u4e2d\uff0c\u5176\u8bca\u65ad\u53ef\u9760\u6027\u5bf9\u63d0\u793a\u8bbe\u8ba1\u9ad8\u5ea6\u654f\u611f\u3002\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a\u60c5\u611f\u5171\u75c5\uff08\u591a\u79cd\u4ea4\u7ec7\u60c5\u611f\u72b6\u6001\u4f7f\u9884\u6d4b\u590d\u6742\u5316\uff09\u548c\u4e34\u5e8a\u76f8\u5173\u7ebf\u7d22\u7684\u63a2\u7d22\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51faAPOLO\uff08Automated Prompt Optimization for Linguistic Emotion Diagnosis\uff09\u6846\u67b6\uff0c\u5c06\u6307\u4ee4\u4f18\u5316\u5efa\u6a21\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u91c7\u7528\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u673a\u5236\uff0c\u5305\u62ec\u89c4\u5212\u5668\u3001\u6559\u5e08\u3001\u6279\u8bc4\u8005\u3001\u5b66\u751f\u548c\u76ee\u6807\u89d2\u8272\u3002\u5728\u95ed\u73af\u6846\u67b6\u4e2d\uff0c\u89c4\u5212\u5668\u5b9a\u4e49\u4f18\u5316\u8f68\u8ff9\uff0c\u6559\u5e08-\u6279\u8bc4\u8005-\u5b66\u751f\u667a\u80fd\u4f53\u8fed\u4ee3\u4f18\u5316\u63d0\u793a\u4ee5\u589e\u5f3a\u63a8\u7406\u7a33\u5b9a\u6027\u548c\u6709\u6548\u6027\uff0c\u76ee\u6807\u667a\u80fd\u4f53\u6839\u636e\u6027\u80fd\u8bc4\u4f30\u51b3\u5b9a\u662f\u5426\u7ee7\u7eed\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAPOLO\u5728\u9886\u57df\u7279\u5b9a\u548c\u5206\u5c42\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u63d0\u9ad8\u4e86\u8bca\u65ad\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5c55\u793a\u4e86\u5728\u7cbe\u795e\u5065\u5eb7\u62a4\u7406\u4e2d\u53ef\u4fe1\u8d56LLM\u5e94\u7528\u7684\u53ef\u6269\u5c55\u548c\u53ef\u6cdb\u5316\u8303\u5f0f\u3002", "conclusion": "APOLO\u901a\u8fc7\u7cfb\u7edf\u63a2\u7d22\u66f4\u5e7f\u6cdb\u548c\u66f4\u7ec6\u7c92\u5ea6\u7684\u63d0\u793a\u7a7a\u95f4\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u60c5\u611f\u5171\u75c5\u548c\u4e34\u5e8a\u7ebf\u7d22\u63a2\u7d22\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u7cbe\u795e\u5065\u5eb7\u9886\u57df\u7684\u9ad8\u98ce\u9669LLM\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u9760\u3001\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u6846\u67b6\u3002"}}
{"id": "2601.12748", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12748", "abs": "https://arxiv.org/abs/2601.12748", "authors": ["Bin Xie", "Bingbing Xu", "Xueyun Tian", "Yilin Chen", "Huawei Shen"], "title": "Towards Robust Process Reward Modeling via Noise-aware Learning", "comment": null, "summary": "Process Reward Models (PRMs) have achieved strong results in complex reasoning, but are bottlenecked by costly process-level supervision. A widely used alternative, Monte Carlo Estimation (MCE), defines process rewards as the probability that a policy model reaches the correct final answer from a given reasoning step. However, step correctness is an intrinsic property of the reasoning trajectory, and should be invariant to policy choice. Our empirical findings show that MCE producing policy-dependent rewards that induce label noise, including false positives that reward incorrect steps and false negatives that penalize correct ones. To address above challenges, we propose a two-stage framework to mitigate noisy supervision. In the labeling stage, we introduce a reflection-aware label correction mechanism that uses a large language model (LLM) as a judge to detect reflection and self-correction behaviors related to the current reasoning step, thereby suppressing overestimated rewards. In the training stage, we further propose a \\underline{\\textbf{N}}oise-\\underline{\\textbf{A}}ware \\underline{\\textbf{I}}terative \\underline{\\textbf{T}}raining framework that enables the PRM to progressively refine noisy labels based on its own confidence. Extensive Experiments show that our method substantially improves step-level correctness discrimination, achieving up to a 27\\% absolute gain in average F1 over PRMs trained with noisy supervision.", "AI": {"tldr": "\u63d0\u51faNAIT\u6846\u67b6\u89e3\u51b3\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u4e2d\u7684\u566a\u58f0\u76d1\u7763\u95ee\u9898\uff0c\u901a\u8fc7\u6807\u7b7e\u4fee\u6b63\u548c\u566a\u58f0\u611f\u77e5\u8fed\u4ee3\u8bad\u7ec3\u63d0\u5347\u6b65\u9aa4\u6b63\u786e\u6027\u5224\u522b\u80fd\u529b", "motivation": "\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u4f9d\u8d56\u6602\u8d35\u7684\u8fc7\u7a0b\u7ea7\u76d1\u7763\uff0c\u800c\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u65b9\u6cd5\u4ea7\u751f\u7b56\u7565\u4f9d\u8d56\u7684\u5956\u52b1\uff0c\u5bfc\u81f4\u6807\u7b7e\u566a\u58f0\uff08\u5305\u62ec\u9519\u8bef\u5956\u52b1\u6b63\u786e\u6b65\u9aa4\u548c\u60e9\u7f5a\u6b63\u786e\u6b65\u9aa4\uff09", "method": "\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) \u6807\u7b7e\u9636\u6bb5\u5f15\u5165\u53cd\u601d\u611f\u77e5\u7684\u6807\u7b7e\u4fee\u6b63\u673a\u5236\uff0c\u4f7f\u7528LLM\u4f5c\u4e3a\u88c1\u5224\u68c0\u6d4b\u4e0e\u5f53\u524d\u63a8\u7406\u6b65\u9aa4\u76f8\u5173\u7684\u53cd\u601d\u548c\u81ea\u6211\u7ea0\u6b63\u884c\u4e3a\uff1b2) \u8bad\u7ec3\u9636\u6bb5\u63d0\u51fa\u566a\u58f0\u611f\u77e5\u8fed\u4ee3\u8bad\u7ec3\u6846\u67b6\uff0c\u4f7fPRM\u57fa\u4e8e\u81ea\u8eab\u7f6e\u4fe1\u5ea6\u9010\u6b65\u7cbe\u70bc\u566a\u58f0\u6807\u7b7e", "result": "\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6b65\u9aa4\u7ea7\u6b63\u786e\u6027\u5224\u522b\u80fd\u529b\uff0c\u5728\u566a\u58f0\u76d1\u7763\u8bad\u7ec3\u7684PRM\u4e0a\u5b9e\u73b0\u9ad8\u8fbe27%\u7684\u7edd\u5bf9\u5e73\u5747F1\u589e\u76ca", "conclusion": "\u63d0\u51fa\u7684NAIT\u6846\u67b6\u6709\u6548\u7f13\u89e3\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u4e2d\u7684\u566a\u58f0\u76d1\u7763\u95ee\u9898\uff0c\u901a\u8fc7\u7ed3\u5408\u53cd\u601d\u611f\u77e5\u6807\u7b7e\u4fee\u6b63\u548c\u566a\u58f0\u611f\u77e5\u8fed\u4ee3\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u6b65\u9aa4\u6b63\u786e\u6027\u8bc4\u4f30\u7684\u51c6\u786e\u6027"}}
{"id": "2601.13518", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.13518", "abs": "https://arxiv.org/abs/2601.13518", "authors": ["Jiayi Yuan", "Jonathan N\u00f6ther", "Natasha Jaques", "Goran Radanovi\u0107"], "title": "AgenticRed: Optimizing Agentic Systems for Automated Red-teaming", "comment": "Website: https://yuanjiayiy.github.io/AgenticRed/", "summary": "While recent automated red-teaming methods show promise for systematically exposing model vulnerabilities, most existing approaches rely on human-specified workflows. This dependence on manually designed workflows suffers from human biases and makes exploring the broader design space expensive. We introduce AgenticRed, an automated pipeline that leverages LLMs' in-context learning to iteratively design and refine red-teaming systems without human intervention. Rather than optimizing attacker policies within predefined structures, AgenticRed treats red-teaming as a system design problem. Inspired by methods like Meta Agent Search, we develop a novel procedure for evolving agentic systems using evolutionary selection, and apply it to the problem of automatic red-teaming. Red-teaming systems designed by AgenticRed consistently outperform state-of-the-art approaches, achieving 96% attack success rate (ASR) on Llama-2-7B (36% improvement) and 98% on Llama-3-8B on HarmBench. Our approach exhibits strong transferability to proprietary models, achieving 100% ASR on GPT-3.5-Turbo and GPT-4o-mini, and 60% on Claude-Sonnet-3.5 (24% improvement). This work highlights automated system design as a powerful paradigm for AI safety evaluation that can keep pace with rapidly evolving models.", "AI": {"tldr": "AgenticRed\uff1a\u4e00\u79cd\u5229\u7528LLM\u4e0a\u4e0b\u6587\u5b66\u4e60\u81ea\u52a8\u8bbe\u8ba1\u548c\u4f18\u5316\u7ea2\u961f\u7cfb\u7edf\u7684\u6846\u67b6\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\uff0c\u901a\u8fc7\u8fdb\u5316\u9009\u62e9\u65b9\u6cd5\u5b9e\u73b0\u7cfb\u7edf\u7ea7\u8bbe\u8ba1\u800c\u975e\u7b56\u7565\u4f18\u5316", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u7ea2\u961f\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6307\u5b9a\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5b58\u5728\u4eba\u4e3a\u504f\u89c1\u4e14\u63a2\u7d22\u8bbe\u8ba1\u7a7a\u95f4\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u7684\u81ea\u52a8\u5316\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5", "method": "\u5c06\u7ea2\u961f\u89c6\u4e3a\u7cfb\u7edf\u8bbe\u8ba1\u95ee\u9898\u800c\u975e\u7b56\u7565\u4f18\u5316\uff0c\u501f\u9274Meta Agent Search\u601d\u60f3\uff0c\u5f00\u53d1\u57fa\u4e8e\u8fdb\u5316\u9009\u62e9\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u6f14\u5316\u7a0b\u5e8f\uff0c\u5229\u7528LLM\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u8fed\u4ee3\u8bbe\u8ba1\u548c\u4f18\u5316\u7ea2\u961f\u7cfb\u7edf", "result": "\u5728Llama-2-7B\u4e0a\u8fbe\u523096%\u653b\u51fb\u6210\u529f\u7387\uff08\u63d0\u534736%\uff09\uff0cLlama-3-8B\u4e0a98%\uff1b\u5bf9\u4e13\u6709\u6a21\u578b\u5177\u6709\u5f3a\u8fc1\u79fb\u6027\uff1aGPT-3.5-Turbo\u548cGPT-4o-mini\u4e0a100%\uff0cClaude-Sonnet-3.5\u4e0a60%\uff08\u63d0\u534724%\uff09", "conclusion": "\u81ea\u52a8\u5316\u7cfb\u7edf\u8bbe\u8ba1\u662fAI\u5b89\u5168\u8bc4\u4f30\u7684\u5f3a\u5927\u8303\u5f0f\uff0c\u80fd\u591f\u8ddf\u4e0a\u6a21\u578b\u5feb\u901f\u6f14\u8fdb\u7684\u6b65\u4f10\uff0cAgenticRed\u5c55\u793a\u4e86\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u7684\u81ea\u52a8\u5316\u7ea2\u961f\u7cfb\u7edf\u8bbe\u8ba1\u7684\u6709\u6548\u6027"}}
{"id": "2601.12758", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12758", "abs": "https://arxiv.org/abs/2601.12758", "authors": ["Shenyan Zheng", "Jiayou Zhong", "Anudeex Shetty", "Heng Ji", "Preslav Nakov", "Usman Naseem"], "title": "VISPA: Pluralistic Alignment via Automatic Value Selection and Activation", "comment": "WIP", "summary": "As large language models are increasingly used in high-stakes domains, it is essential that their outputs reflect not average} human preference, rather range of varying perspectives. Achieving such pluralism, however, remains challenging. Existing approaches consider limited values or rely on prompt-level interventions, lacking value control and representation. To address this, we introduce VISPA, a training-free pluralistic alignment framework, that enables direct control over value expression by dynamic selection and internal model activation steering. Across extensive empirical studies spanning multiple models and evaluation settings, we show VISPA is performant across all pluralistic alignment modes in healthcare and beyond. Further analysis reveals VISPA is adaptable with different steering initiations, model, and/or values. These results suggest that pluralistic alignment can be achieved through internal activation mechanisms, offering a scalable path toward language models that serves all.", "AI": {"tldr": "VISPA\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u591a\u5143\u5316\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u548c\u5185\u90e8\u6a21\u578b\u6fc0\u6d3b\u5f15\u5bfc\u5b9e\u73b0\u5bf9\u4ef7\u503c\u8868\u8fbe\u7684\u76f4\u63a5\u63a7\u5236\uff0c\u4f7f\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u80fd\u591f\u53cd\u6620\u591a\u6837\u5316\u7684\u89c2\u70b9\u800c\u975e\u5355\u4e00\u504f\u597d\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u9886\u57df\u5e94\u7528\u589e\u52a0\uff0c\u9700\u8981\u5176\u8f93\u51fa\u53cd\u6620\u591a\u6837\u5316\u7684\u4eba\u7c7b\u89c2\u70b9\u800c\u975e\u5355\u4e00\u5e73\u5747\u504f\u597d\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4ef7\u503c\u8303\u56f4\u6709\u9650\u6216\u4ec5\u4f9d\u8d56\u63d0\u793a\u7ea7\u5e72\u9884\u7684\u95ee\u9898\uff0c\u7f3a\u4e4f\u4ef7\u503c\u63a7\u5236\u548c\u4ee3\u8868\u6027\u3002", "method": "VISPA\u91c7\u7528\u65e0\u9700\u8bad\u7ec3\u7684\u591a\u5143\u5316\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u548c\u5185\u90e8\u6a21\u578b\u6fc0\u6d3b\u5f15\u5bfc\u76f4\u63a5\u63a7\u5236\u4ef7\u503c\u8868\u8fbe\u3002\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u6a21\u578b\u8bad\u7ec3\uff0c\u800c\u662f\u901a\u8fc7\u5185\u90e8\u6fc0\u6d3b\u673a\u5236\u5b9e\u73b0\u4ef7\u503c\u5bfc\u5411\u3002", "result": "\u5728\u6db5\u76d6\u591a\u4e2a\u6a21\u578b\u548c\u8bc4\u4f30\u8bbe\u7f6e\u7684\u5e7f\u6cdb\u5b9e\u8bc1\u7814\u7a76\u4e2d\uff0cVISPA\u5728\u533b\u7597\u4fdd\u5065\u53ca\u5176\u4ed6\u9886\u57df\u7684\u5404\u79cd\u591a\u5143\u5316\u5bf9\u9f50\u6a21\u5f0f\u4e2d\u5747\u8868\u73b0\u4f18\u5f02\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u8868\u660eVISPA\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u7684\u5f15\u5bfc\u521d\u59cb\u5316\u3001\u6a21\u578b\u548c/\u6216\u4ef7\u503c\u89c2\u3002", "conclusion": "\u591a\u5143\u5316\u5bf9\u9f50\u53ef\u4ee5\u901a\u8fc7\u5185\u90e8\u6fc0\u6d3b\u673a\u5236\u5b9e\u73b0\uff0c\u8fd9\u4e3a\u6784\u5efa\u80fd\u591f\u670d\u52a1\u6240\u6709\u4eba\u7684\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002"}}
{"id": "2601.13533", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13533", "abs": "https://arxiv.org/abs/2601.13533", "authors": ["Changshuo Zhang"], "title": "Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models", "comment": null, "summary": "Reinforcement learning plays a crucial role in generative re-ranking scenarios due to its exploration-exploitation capabilities, but existing generative methods mostly fail to adapt to the dynamic entropy changes in model difficulty during list generation, making it challenging to accurately capture complex preferences. Given that language models have achieved remarkable breakthroughs by integrating reasoning capabilities, we draw on this approach to introduce a latent reasoning mechanism, and experimental validation demonstrates that this mechanism effectively reduces entropy in the model's decision-making process. Based on these findings, we introduce the Entropy-Guided Latent Reasoning (EGLR) recommendation model, which has three core advantages. First, it abandons the \"reason first, recommend later\" paradigm to achieve \"reasoning while recommending\", specifically designed for the high-difficulty nature of list generation by enabling real-time reasoning during generation. Second, it implements entropy-guided variable-length reasoning using context-aware reasoning token alongside dynamic temperature adjustment, expanding exploration breadth in reasoning and boosting exploitation precision in recommending to achieve a more precisely adapted exploration-exploitation trade-off. Third, the model adopts a lightweight integration design with no complex independent modules or post-processing, enabling easy adaptation to existing models. Experimental results on two real-world datasets validate the model's effectiveness, and its notable advantage lies in being compatible with existing generative re-ranking models to enhance their performance. Further analyses also demonstrate its practical deployment value and research potential.", "AI": {"tldr": "EGLR\u63a8\u8350\u6a21\u578b\u901a\u8fc7\u71b5\u5f15\u5bfc\u7684\u6f5c\u5728\u63a8\u7406\u673a\u5236\uff0c\u5728\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u4e2d\u5b9e\u73b0\"\u8fb9\u63a8\u7406\u8fb9\u63a8\u8350\"\uff0c\u52a8\u6001\u9002\u5e94\u5217\u8868\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u71b5\u53d8\u5316\uff0c\u63d0\u5347\u590d\u6742\u504f\u597d\u6355\u6349\u80fd\u529b", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u65b9\u6cd5\u96be\u4ee5\u9002\u5e94\u5217\u8868\u751f\u6210\u8fc7\u7a0b\u4e2d\u6a21\u578b\u96be\u5ea6\u7684\u52a8\u6001\u71b5\u53d8\u5316\uff0c\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u590d\u6742\u504f\u597d\u3002\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u96c6\u6210\u63a8\u7406\u80fd\u529b\u53d6\u5f97\u7a81\u7834\uff0c\u542f\u53d1\u5f15\u5165\u6f5c\u5728\u63a8\u7406\u673a\u5236\u6765\u964d\u4f4e\u51b3\u7b56\u71b5", "method": "\u63d0\u51fa\u71b5\u5f15\u5bfc\u6f5c\u5728\u63a8\u7406(EGLR)\u63a8\u8350\u6a21\u578b\uff1a1) \u653e\u5f03\"\u5148\u63a8\u7406\u540e\u63a8\u8350\"\u8303\u5f0f\uff0c\u5b9e\u73b0\"\u8fb9\u63a8\u7406\u8fb9\u63a8\u8350\"\uff1b2) \u4f7f\u7528\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u4ee4\u724c\u548c\u52a8\u6001\u6e29\u5ea6\u8c03\u6574\u5b9e\u73b0\u71b5\u5f15\u5bfc\u7684\u53d8\u957f\u63a8\u7406\uff1b3) \u91c7\u7528\u8f7b\u91cf\u7ea7\u96c6\u6210\u8bbe\u8ba1\uff0c\u65e0\u9700\u590d\u6742\u72ec\u7acb\u6a21\u5757\u6216\u540e\u5904\u7406", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6a21\u578b\u6709\u6548\u6027\uff0c\u663e\u8457\u4f18\u52bf\u5728\u4e8e\u80fd\u4e0e\u73b0\u6709\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u6a21\u578b\u517c\u5bb9\u5e76\u63d0\u5347\u5176\u6027\u80fd\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u5c55\u793a\u4e86\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c\u548c\u7814\u7a76\u6f5c\u529b", "conclusion": "EGLR\u6a21\u578b\u901a\u8fc7\u71b5\u5f15\u5bfc\u7684\u6f5c\u5728\u63a8\u7406\u673a\u5236\uff0c\u5728\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u4e2d\u5b9e\u73b0\u4e86\u66f4\u7cbe\u786e\u7684\u63a2\u7d22-\u5229\u7528\u6743\u8861\uff0c\u89e3\u51b3\u4e86\u52a8\u6001\u71b5\u53d8\u5316\u9002\u5e94\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u517c\u5bb9\u6027\u548c\u6027\u80fd\u63d0\u5347\u4f18\u52bf"}}
{"id": "2601.12812", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12812", "abs": "https://arxiv.org/abs/2601.12812", "authors": ["Sushant Kumar Ray", "Gautam Siddharth Kashyap", "Sahil Tripathi", "Nipun Joshi", "Vijay Govindarajan", "Rafiq Ali", "Jiechao Gao", "Usman Naseem"], "title": "Do Clinical Question Answering Systems Really Need Specialised Medical Fine Tuning?", "comment": "Accepted at EACL 2026 (Industry Track)", "summary": "Clinical Question-Answering (CQA) industry systems are increasingly rely on Large Language Models (LLMs), yet their deployment is often guided by the assumption that domain-specific fine-tuning is essential. Although specialised medical LLMs such as BioBERT, BioGPT, and PubMedBERT remain popular, they face practical limitations including narrow coverage, high retraining costs, and limited adaptability. Efforts based on Supervised Fine-Tuning (SFT) have attempted to address these assumptions but continue to reinforce what we term the SPECIALISATION FALLACY-the belief that specialised medical LLMs are inherently superior for CQA. To address this assumption, we introduce MEDASSESS-X, a deployment-industry-oriented CQA framework that applies alignment at inference time rather than through SFT. MEDASSESS-X uses lightweight steering vectors to guide model activations toward medically consistent reasoning without updating model weights or requiring domain-specific retraining. This inference-time alignment layer stabilises CQA performance across both general-purpose and specialised medical LLMs, thereby resolving the SPECIALISATION FALLACY. Empirically, MEDASSESS-X delivers consistent gains across all LLM families, improving Accuracy by up to +6%, Factual Consistency by +7%, and reducing Safety Error Rate by as much as 50%.", "AI": {"tldr": "MEDASSESS-X\u662f\u4e00\u4e2a\u9762\u5411\u4e34\u5e8a\u95ee\u7b54\u90e8\u7f72\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u63a8\u7406\u65f6\u5bf9\u9f50\u800c\u975e\u76d1\u7763\u5fae\u8c03\u6765\u63d0\u5347LLMs\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\"\u4e13\u4e1a\u5316\u8c2c\u8bef\"\u3002", "motivation": "\u5f53\u524d\u4e34\u5e8a\u95ee\u7b54\u7cfb\u7edf\u8fc7\u5ea6\u4f9d\u8d56\u9886\u57df\u7279\u5b9a\u5fae\u8c03\uff0c\u5b58\u5728\u8986\u76d6\u8303\u56f4\u7a84\u3001\u91cd\u8bad\u7ec3\u6210\u672c\u9ad8\u3001\u9002\u5e94\u6027\u6709\u9650\u7b49\u95ee\u9898\uff0c\u4e14\u5b58\u5728\"\u4e13\u4e1a\u5316\u8c2c\u8bef\"\u2014\u2014\u8ba4\u4e3a\u4e13\u4e1a\u533b\u7597LLMs\u5fc5\u7136\u4f18\u4e8e\u901a\u7528\u6a21\u578b\u3002", "method": "\u63d0\u51faMEDASSESS-X\u6846\u67b6\uff0c\u91c7\u7528\u63a8\u7406\u65f6\u5bf9\u9f50\u65b9\u6cd5\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u5f15\u5bfc\u5411\u91cf\u6765\u8c03\u6574\u6a21\u578b\u6fc0\u6d3b\uff0c\u4f7f\u5176\u671d\u5411\u533b\u5b66\u4e00\u81f4\u63a8\u7406\uff0c\u65e0\u9700\u66f4\u65b0\u6a21\u578b\u6743\u91cd\u6216\u9886\u57df\u7279\u5b9a\u91cd\u8bad\u7ec3\u3002", "result": "MEDASSESS-X\u5728\u6240\u6709LLM\u5bb6\u65cf\u4e2d\u5747\u5e26\u6765\u4e00\u81f4\u63d0\u5347\uff1a\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u5347+6%\uff0c\u4e8b\u5b9e\u4e00\u81f4\u6027\u63d0\u5347+7%\uff0c\u5b89\u5168\u9519\u8bef\u7387\u964d\u4f4e\u8fbe50%\uff0c\u7a33\u5b9a\u4e86\u901a\u7528\u548c\u4e13\u4e1a\u533b\u7597LLMs\u7684\u6027\u80fd\u3002", "conclusion": "\u63a8\u7406\u65f6\u5bf9\u9f50\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u4e34\u5e8a\u95ee\u7b54\u4e2d\u7684\u4e13\u4e1a\u5316\u8c2c\u8bef\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7075\u6d3b\u3001\u6210\u672c\u6548\u76ca\u66f4\u9ad8\u7684\u90e8\u7f72\u65b9\u6848\uff0c\u65e0\u9700\u4f9d\u8d56\u9886\u57df\u7279\u5b9a\u5fae\u8c03\u3002"}}
{"id": "2601.13546", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13546", "abs": "https://arxiv.org/abs/2601.13546", "authors": ["Hui Sun", "Chang Xu", "Haonan Xie", "Hao Li", "Yuhao Huang", "Chuheng Zhang", "Ming Jin", "Xiaoguang Liu", "Gang Wang", "Jiang Bian"], "title": "ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution", "comment": null, "summary": "LLM-driven Anomaly Detection (AD) helps enhance the understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges of inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. To this end, we 1) propose a multi-agent-based TS Evolution algorithm named TSEvol. On top of it, we 2) introduce the AD reasoning and multi-turn dialogue Dataset TSEData-20K and contribute the Chatbot family for AD, including ChatAD-Llama3-8B, Qwen2.5-7B, and Mistral-7B. Furthermore, 3) we propose the TS Kahneman-Tversky Optimization (TKTO) to enhance ChatAD's cross-task generalization capability. Lastly, 4) we propose a LLM-driven Learning-based AD Benchmark LLADBench to evaluate the performance of ChatAD and nine baselines across seven datasets and tasks. Our three ChatAD models achieve substantial gains, up to 34.50% in accuracy, 34.71% in F1, and a 37.42% reduction in false positives. Besides, via KTKO, our optimized ChatAD achieves competitive performance in reasoning and cross-task generalization on classification, forecasting, and imputation.", "AI": {"tldr": "\u63d0\u51faTSEvol\u591a\u667a\u80fd\u4f53\u65f6\u95f4\u5e8f\u5217\u6f14\u5316\u7b97\u6cd5\u3001TSEData-20K\u6570\u636e\u96c6\u3001ChatAD\u7cfb\u5217\u804a\u5929\u673a\u5668\u4eba\u3001TKTO\u4f18\u5316\u65b9\u6cd5\u548cLLADBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u663e\u8457\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u7684\u63a8\u7406\u80fd\u529b\u548c\u6cdb\u5316\u6027\u80fd", "motivation": "\u73b0\u6709LLM\u9a71\u52a8\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u3001\u591a\u8f6e\u5bf9\u8bdd\u80fd\u529b\u6b20\u7f3a\u548c\u6cdb\u5316\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\uff0c\u9700\u8981\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u884c\u4e3a\u7684\u7406\u89e3\u548c\u89e3\u91ca\u80fd\u529b", "method": "1) TSEvol\u591a\u667a\u80fd\u4f53\u65f6\u95f4\u5e8f\u5217\u6f14\u5316\u7b97\u6cd5\uff1b2) TSEData-20K\u6570\u636e\u96c6\u548cChatAD\u7cfb\u5217\u804a\u5929\u673a\u5668\u4eba\uff1b3) TKTO\u4f18\u5316\u65b9\u6cd5\u589e\u5f3a\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\uff1b4) LLADBench\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u6846\u67b6", "result": "ChatAD\u6a21\u578b\u5728\u51c6\u786e\u7387\u63d0\u534734.50%\u3001F1\u5206\u6570\u63d0\u534734.71%\u3001\u5047\u9633\u6027\u964d\u4f4e37.42%\uff1bTKTO\u4f18\u5316\u7684ChatAD\u5728\u5206\u7c7b\u3001\u9884\u6d4b\u548c\u586b\u8865\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u7ade\u4e89\u529b\u7684\u63a8\u7406\u548c\u8de8\u4efb\u52a1\u6cdb\u5316\u6027\u80fd", "conclusion": "\u63d0\u51fa\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u3001\u6570\u636e\u96c6\u3001\u4f18\u5316\u65b9\u6cd5\u548c\u8bc4\u4f30\u57fa\u51c6\u663e\u8457\u63d0\u5347\u4e86LLM\u9a71\u52a8\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u7684\u63a8\u7406\u80fd\u529b\u3001\u5bf9\u8bdd\u80fd\u529b\u548c\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b"}}
{"id": "2601.12815", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12815", "abs": "https://arxiv.org/abs/2601.12815", "authors": ["Zhaolu Kang", "Junhao Gong", "Qingxi Chen", "Hao Zhang", "Jiaxin Liu", "Rong Fu", "Zhiyuan Feng", "Yuan Wang", "Simon Fong", "Kaiyue Zhou"], "title": "Multimodal Multi-Agent Empowered Legal Judgment Prediction", "comment": null, "summary": "Legal Judgment Prediction (LJP) aims to predict the outcomes of legal cases based on factual descriptions, serving as a fundamental task to advance the development of legal systems. Traditional methods often rely on statistical analyses or role-based simulations but face challenges with multiple allegations, diverse evidence, and lack adaptability. In this paper, we introduce JurisMMA, a novel framework for LJP that effectively decomposes trial tasks, standardizes processes, and organizes them into distinct stages. Furthermore, we build JurisMM, a large dataset with over 100,000 recent Chinese judicial records, including both text and multimodal video-text data, enabling comprehensive evaluation. Experiments on JurisMM and the benchmark LawBench validate our framework's effectiveness. These results indicate that our framework is effective not only for LJP but also for a broader range of legal applications, offering new perspectives for the development of future legal methods and datasets.", "AI": {"tldr": "\u63d0\u51faJurisMMA\u6846\u67b6\u7528\u4e8e\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\uff0c\u901a\u8fc7\u4efb\u52a1\u5206\u89e3\u548c\u6d41\u7a0b\u6807\u51c6\u5316\u5904\u7406\u591a\u6307\u63a7\u3001\u8bc1\u636e\u591a\u6837\u7b49\u6311\u6218\uff0c\u5e76\u6784\u5efa\u5305\u542b10\u4e07+\u4e2d\u6587\u53f8\u6cd5\u8bb0\u5f55\u7684JurisMM\u591a\u6a21\u6001\u6570\u636e\u96c6\u8fdb\u884c\u9a8c\u8bc1\u3002", "motivation": "\u4f20\u7edf\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u7edf\u8ba1\u5206\u6790\u6216\u57fa\u4e8e\u89d2\u8272\u7684\u6a21\u62df\uff0c\u5728\u5904\u7406\u591a\u6307\u63a7\u3001\u591a\u6837\u8bc1\u636e\u65f6\u9762\u4e34\u6311\u6218\u4e14\u7f3a\u4e4f\u9002\u5e94\u6027\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u6846\u67b6\u6765\u5904\u7406\u590d\u6742\u7684\u6cd5\u5f8b\u6848\u4ef6\u9884\u6d4b\u4efb\u52a1\u3002", "method": "\u63d0\u51faJurisMMA\u6846\u67b6\uff0c\u5c06\u5ba1\u5224\u4efb\u52a1\u6709\u6548\u5206\u89e3\u3001\u6d41\u7a0b\u6807\u51c6\u5316\u5e76\u7ec4\u7ec7\u4e3a\u4e0d\u540c\u9636\u6bb5\uff1b\u6784\u5efa\u5305\u542b10\u4e07+\u8fd1\u671f\u4e2d\u6587\u53f8\u6cd5\u8bb0\u5f55\u7684JurisMM\u5927\u578b\u6570\u636e\u96c6\uff0c\u5305\u542b\u6587\u672c\u548c\u591a\u6a21\u6001\u89c6\u9891-\u6587\u672c\u6570\u636e\u3002", "result": "\u5728JurisMM\u6570\u636e\u96c6\u548c\u57fa\u51c6LawBench\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u6846\u67b6\u4e0d\u4ec5\u9002\u7528\u4e8e\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\uff0c\u4e5f\u4e3a\u66f4\u5e7f\u6cdb\u7684\u6cd5\u5f8b\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002", "conclusion": "JurisMMA\u6846\u67b6\u901a\u8fc7\u4efb\u52a1\u5206\u89e3\u548c\u6d41\u7a0b\u6807\u51c6\u5316\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u7ed3\u5408\u5927\u578b\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e3a\u672a\u6765\u6cd5\u5f8b\u65b9\u6cd5\u548c\u6570\u636e\u96c6\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.12844", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12844", "abs": "https://arxiv.org/abs/2601.12844", "authors": ["Julie Ran\u00e7on", "Jean-Fran\u00e7ois Cerisier", "Emilie Remond", "Aur\u00e9lien Nguyen", "Andrew Peterson", "Ladjel Bellatreche"], "title": "Rapport du Projet de Recherche TRAIMA", "comment": "in French language", "summary": "The TRAIMA project (TRaitement Automatique des Interactions Multimodales en Apprentissage), conducted between March 2019 and June 2020, investigates the potential of automatic processing of multimodal interactions in educational settings. The project addresses a central methodological challenge in educational and interactional research: the analysis of verbal, paraverbal, and non-verbal data is currently carried out manually, making it extremely time-consuming and difficult to scale. TRAIMA explores how machine learning approaches could contribute to the categorisation and classification of such interactions. The project focuses specifically on explanatory and collaborative sequences occurring in classroom interactions, particularly in French as a Foreign Language (FLE) and French as a First Language (FLM) contexts. These sequences are analysed as inherently multimodal phenomena, combining spoken language with prosody, gestures, posture, gaze, and spatial positioning. A key theoretical contribution of the project is the precise linguistic and interactional definition of explanatory discourse as a tripartite sequence (opening, explanatory core, closure), drawing on discourse analysis and interactional linguistics. A substantial part of the research is devoted to the methodological foundations of transcription, which constitute a critical bottleneck for any form of automation. The report provides a detailed state of the art of existing transcription conventions (ICOR, Mondada, GARS, VALIBEL, Ferr{\u00e9}), highlighting their respective strengths and limitations when applied to multimodal classroom data. Through comparative analyses of manually transcribed sequences, the project demonstrates the inevitable variability and interpretative dimension of transcription practices, depending on theoretical positioning and analytical goals. Empirical work is based on several corpora, notably the INTER-EXPLIC corpus (approximately 30 hours of classroom interaction) and the EXPLIC-LEXIC corpus, which serve both as testing grounds for manual annotation and as reference datasets for future automation. Particular attention is paid to teacher gestures (kin{\u00e9}sic and proxemic resources), prosodic features, and their functional role in meaning construction and learner comprehension. The project also highlights the strategic role of the Techn{\u00e9}LAB platform, which provides advanced multimodal data capture (multi-camera video, synchronized audio, eye-tracking, digital interaction traces) and constitutes both a research infrastructure and a test environment for the development of automated tools. In conclusion, TRAIMA does not aim to deliver a fully operational automated system, but rather to establish a rigorous methodological framework for the automatic processing of multimodal pedagogical interactions. The project identifies transcription conventions, annotation categories, and analytical units that are compatible with machine learning approaches, while emphasizing the need for theoretical explicitness and researcher reflexivity. TRAIMA thus lays the groundwork for future interdisciplinary research at the intersection of didactics, discourse analysis, multimodality, and artificial intelligence in education.", "AI": {"tldr": "TRAIMA\u9879\u76ee\u7814\u7a76\u5982\u4f55\u5229\u7528\u673a\u5668\u5b66\u4e60\u81ea\u52a8\u5904\u7406\u6559\u80b2\u73af\u5883\u4e2d\u7684\u591a\u6a21\u6001\u4e92\u52a8\uff0c\u89e3\u51b3\u5f53\u524d\u4eba\u5de5\u5206\u6790\u8017\u65f6\u4e14\u96be\u4ee5\u6269\u5c55\u7684\u95ee\u9898\uff0c\u91cd\u70b9\u5173\u6ce8\u8bfe\u5802\u89e3\u91ca\u6027\u548c\u534f\u4f5c\u6027\u5e8f\u5217\u7684\u591a\u6a21\u6001\u7279\u5f81\u3002", "motivation": "\u5f53\u524d\u6559\u80b2\u4e92\u52a8\u7814\u7a76\u4e2d\uff0c\u8bed\u8a00\u3001\u526f\u8bed\u8a00\u548c\u975e\u8bed\u8a00\u6570\u636e\u7684\u5206\u6790\u5b8c\u5168\u4f9d\u8d56\u4eba\u5de5\u5904\u7406\uff0c\u6781\u5176\u8017\u65f6\u4e14\u96be\u4ee5\u89c4\u6a21\u5316\u3002\u9879\u76ee\u65e8\u5728\u63a2\u7d22\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5982\u4f55\u5e2e\u52a9\u5206\u7c7b\u548c\u8bc6\u522b\u8fd9\u7c7b\u591a\u6a21\u6001\u4e92\u52a8\uff0c\u7279\u522b\u662f\u5728\u6cd5\u8bed\u4f5c\u4e3a\u5916\u8bed\u548c\u6bcd\u8bed\u6559\u5b66\u73af\u5883\u4e2d\u3002", "method": "\u9879\u76ee\u91c7\u7528\u591a\u6a21\u6001\u5206\u6790\u65b9\u6cd5\uff0c\u7ed3\u5408\u8bdd\u8bed\u5206\u6790\u548c\u4e92\u52a8\u8bed\u8a00\u5b66\u7406\u8bba\uff0c\u5c06\u89e3\u91ca\u6027\u8bdd\u8bed\u7cbe\u786e\u5b9a\u4e49\u4e3a\u4e09\u90e8\u7ed3\u6784\uff08\u5f00\u573a\u3001\u89e3\u91ca\u6838\u5fc3\u3001\u7ed3\u675f\uff09\u3002\u57fa\u4e8eINTER-EXPLIC\u548cEXPLIC-LEXIC\u8bed\u6599\u5e93\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u91cd\u70b9\u5206\u6790\u6559\u5e08\u624b\u52bf\u3001\u97f5\u5f8b\u7279\u5f81\u7b49\u529f\u80fd\u6027\u89d2\u8272\u3002\u540c\u65f6\u7cfb\u7edf\u8bc4\u4f30\u73b0\u6709\u8f6c\u5f55\u89c4\u8303\uff0c\u5efa\u7acb\u4e0e\u673a\u5668\u5b66\u4e60\u517c\u5bb9\u7684\u65b9\u6cd5\u6846\u67b6\u3002", "result": "\u9879\u76ee\u5c55\u793a\u4e86\u8f6c\u5f55\u5b9e\u8df5\u4e2d\u4e0d\u53ef\u907f\u514d\u7684\u53d8\u5f02\u6027\u548c\u89e3\u91ca\u6027\u7ef4\u5ea6\uff0c\u5efa\u7acb\u4e86\u591a\u6a21\u6001\u6559\u5b66\u4e92\u52a8\u81ea\u52a8\u5904\u7406\u7684\u4e25\u683c\u65b9\u6cd5\u6846\u67b6\u3002\u786e\u5b9a\u4e86\u4e0e\u673a\u5668\u5b66\u4e60\u517c\u5bb9\u7684\u8f6c\u5f55\u89c4\u8303\u3001\u6807\u6ce8\u7c7b\u522b\u548c\u5206\u6790\u5355\u5143\uff0c\u5f3a\u8c03\u4e86\u7406\u8bba\u660e\u786e\u6027\u548c\u7814\u7a76\u8005\u53cd\u601d\u6027\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "TRAIMA\u9879\u76ee\u5e76\u672a\u5f00\u53d1\u5b8c\u5168\u53ef\u64cd\u4f5c\u7684\u81ea\u52a8\u5316\u7cfb\u7edf\uff0c\u800c\u662f\u4e3a\u591a\u6a21\u6001\u6559\u5b66\u4e92\u52a8\u7684\u81ea\u52a8\u5904\u7406\u5efa\u7acb\u4e86\u4e25\u8c28\u7684\u65b9\u6cd5\u6846\u67b6\u3002\u9879\u76ee\u4e3a\u672a\u6765\u8de8\u5b66\u79d1\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u8fde\u63a5\u4e86\u6559\u5b66\u6cd5\u3001\u8bdd\u8bed\u5206\u6790\u3001\u591a\u6a21\u6001\u7814\u7a76\u548c\u6559\u80b2\u4eba\u5de5\u667a\u80fd\u9886\u57df\u3002"}}
{"id": "2601.13559", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13559", "abs": "https://arxiv.org/abs/2601.13559", "authors": ["Sun Hui", "Ding Yanfeng", "Huidong Ma", "Chang Xu", "Keyan Jin", "Lizheng Zu", "Cheng Zhong", "xiaoguang Liu", "Gang Wang", "Wentong Cai"], "title": "AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent", "comment": null, "summary": "Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing and management. Current learning-based methods are non-evolvable with problems of low-level compression modeling, limited adaptability, and user-unfriendly interface. To this end, we propose AgentGC, the first evolutionary Agent-based GD Compressor, consisting of 3 layers with multi-agent named Leader and Worker. Specifically, the 1) User layer provides a user-friendly interface via Leader combined with LLM; 2) Cognitive layer, driven by the Leader, integrates LLM to consider joint optimization of algorithm-dataset-system, addressing the issues of low-level modeling and limited adaptability; and 3) Compression layer, headed by Worker, performs compression & decompression via a automated multi-knowledge learning-based compression framework. On top of AgentGC, we design 3 modes to support diverse scenarios: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, the average compression ratios gains are 16.66%, 16.11%, and 16.33%, the throughput gains are 4.73x, 9.23x, and 9.15x, respectively.", "AI": {"tldr": "AgentGC\uff1a\u9996\u4e2a\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u8fdb\u5316\u5f0f\u57fa\u56e0\u7ec4\u6570\u636e\u538b\u7f29\u5668\uff0c\u901a\u8fc7\u4e09\u5c42\u67b6\u6784\uff08\u7528\u6237\u5c42\u3001\u8ba4\u77e5\u5c42\u3001\u538b\u7f29\u5c42\uff09\u548c\u591a\u667a\u80fd\u4f53\uff08Leader\u548cWorker\uff09\u5b9e\u73b0\u7b97\u6cd5-\u6570\u636e\u96c6-\u7cfb\u7edf\u8054\u5408\u4f18\u5316\uff0c\u652f\u6301\u4e09\u79cd\u6a21\u5f0f\uff08CP\u3001TP\u3001BM\uff09\uff0c\u5728\u538b\u7f29\u6bd4\u548c\u541e\u5410\u91cf\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5b66\u4e60\u7684\u57fa\u56e0\u7ec4\u6570\u636e\u65e0\u635f\u538b\u7f29\u65b9\u6cd5\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u975e\u8fdb\u5316\u6027\uff0c\u96be\u4ee5\u9002\u5e94\u6280\u672f\u53d1\u5c55\uff1b2\uff09\u4f4e\u5c42\u6b21\u538b\u7f29\u5efa\u6a21\uff0c\u7f3a\u4e4f\u7b97\u6cd5-\u6570\u636e\u96c6-\u7cfb\u7edf\u8054\u5408\u4f18\u5316\uff1b3\uff09\u7528\u6237\u754c\u9762\u4e0d\u53cb\u597d\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u81ea\u9002\u5e94\u8fdb\u5316\u3001\u63d0\u4f9b\u7528\u6237\u53cb\u597d\u63a5\u53e3\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u538b\u7f29\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faAgentGC\u4e09\u5c42\u67b6\u6784\uff1a1\uff09\u7528\u6237\u5c42\uff1a\u901a\u8fc7Leader\u667a\u80fd\u4f53\u7ed3\u5408LLM\u63d0\u4f9b\u7528\u6237\u53cb\u597d\u63a5\u53e3\uff1b2\uff09\u8ba4\u77e5\u5c42\uff1a\u7531Leader\u9a71\u52a8\uff0c\u96c6\u6210LLM\u5b9e\u73b0\u7b97\u6cd5-\u6570\u636e\u96c6-\u7cfb\u7edf\u8054\u5408\u4f18\u5316\uff0c\u89e3\u51b3\u4f4e\u5c42\u6b21\u5efa\u6a21\u548c\u9002\u5e94\u6027\u6709\u9650\u95ee\u9898\uff1b3\uff09\u538b\u7f29\u5c42\uff1a\u7531Worker\u667a\u80fd\u4f53\u8d1f\u8d23\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u591a\u77e5\u8bc6\u5b66\u4e60\u538b\u7f29\u6846\u67b6\u6267\u884c\u538b\u7f29/\u89e3\u538b\u3002\u652f\u6301\u4e09\u79cd\u6a21\u5f0f\uff1aCP\uff08\u538b\u7f29\u6bd4\u4f18\u5148\uff09\u3001TP\uff08\u541e\u5410\u91cf\u4f18\u5148\uff09\u3001BM\uff08\u5e73\u8861\u6a21\u5f0f\uff09\u3002", "result": "\u57289\u4e2a\u6570\u636e\u96c6\u4e0a\u4e0e14\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u6bd4\u8f83\uff1a\u4e09\u79cd\u6a21\u5f0f\uff08CP\u3001TP\u3001BM\uff09\u7684\u5e73\u5747\u538b\u7f29\u6bd4\u589e\u76ca\u5206\u522b\u4e3a16.66%\u300116.11%\u300116.33%\uff1b\u541e\u5410\u91cf\u589e\u76ca\u5206\u522b\u4e3a4.73\u500d\u30019.23\u500d\u30019.15\u500d\u3002\u6240\u6709\u6307\u6807\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "AgentGC\u662f\u9996\u4e2a\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u8fdb\u5316\u5f0f\u57fa\u56e0\u7ec4\u6570\u636e\u538b\u7f29\u5668\uff0c\u901a\u8fc7\u4e09\u5c42\u67b6\u6784\u548c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u975e\u8fdb\u5316\u6027\u3001\u4f4e\u5c42\u6b21\u5efa\u6a21\u548c\u7528\u6237\u754c\u9762\u4e0d\u53cb\u597d\u95ee\u9898\uff0c\u5728\u538b\u7f29\u6bd4\u548c\u541e\u5410\u91cf\u65b9\u9762\u5747\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u57fa\u56e0\u7ec4\u6570\u636e\u5b58\u50a8\u3001\u5171\u4eab\u548c\u7ba1\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12868", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12868", "abs": "https://arxiv.org/abs/2601.12868", "authors": ["Shiyue Hu", "Ruizhe Li", "Yanjun Gao"], "title": "Race, Ethnicity and Their Implication on Bias in Large Language Models", "comment": "Work in process", "summary": "Large language models (LLMs) increasingly operate in high-stakes settings including healthcare and medicine, where demographic attributes such as race and ethnicity may be explicitly stated or implicitly inferred from text. However, existing studies primarily document outcome-level disparities, offering limited insight into internal mechanisms underlying these effects. We present a mechanistic study of how race and ethnicity are represented and operationalized within LLMs. Using two publicly available datasets spanning toxicity-related generation and clinical narrative understanding tasks, we analyze three open-source models with a reproducible interpretability pipeline combining probing, neuron-level attribution, and targeted intervention. We find that demographic information is distributed across internal units with substantial cross-model variation. Although some units encode sensitive or stereotype-related associations from pretraining, identical demographic cues can induce qualitatively different behaviors. Interventions suppressing such neurons reduce bias but leave substantial residual effects, suggesting behavioral rather than representational change and motivating more systematic mitigation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u7814\u7a76LLM\u4e2d\u79cd\u65cf\u548c\u65cf\u88d4\u4fe1\u606f\u7684\u5185\u90e8\u8868\u793a\u673a\u5236\uff0c\u53d1\u73b0\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u5206\u5e03\u5728\u4e0d\u540c\u795e\u7ecf\u5143\u4e2d\uff0c\u76f8\u540c\u4eba\u53e3\u7edf\u8ba1\u7ebf\u7d22\u53ef\u80fd\u5f15\u53d1\u4e0d\u540c\u884c\u4e3a\uff0c\u5e72\u9884\u80fd\u51cf\u5c11\u504f\u89c1\u4f46\u6548\u679c\u6709\u9650\u3002", "motivation": "LLM\u5728\u533b\u7597\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u5e94\u7528\u65f6\uff0c\u79cd\u65cf\u548c\u65cf\u88d4\u4fe1\u606f\u53ef\u80fd\u88ab\u663e\u5f0f\u6216\u9690\u5f0f\u5904\u7406\uff0c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u8bb0\u5f55\u7ed3\u679c\u5c42\u9762\u7684\u5dee\u5f02\uff0c\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u6548\u5e94\u5185\u90e8\u673a\u5236\u7684\u7406\u89e3\u3002", "method": "\u4f7f\u7528\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\uff08\u6bd2\u6027\u751f\u6210\u548c\u4e34\u5e8a\u53d9\u4e8b\u7406\u89e3\u4efb\u52a1\uff09\uff0c\u5206\u6790\u4e09\u4e2a\u5f00\u6e90\u6a21\u578b\uff0c\u91c7\u7528\u53ef\u590d\u73b0\u7684\u53ef\u89e3\u91ca\u6027\u6d41\u7a0b\uff0c\u7ed3\u5408\u63a2\u6d4b\u3001\u795e\u7ecf\u5143\u7ea7\u5f52\u56e0\u548c\u9488\u5bf9\u6027\u5e72\u9884\u65b9\u6cd5\u3002", "result": "\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u5206\u5e03\u5728\u4e0d\u540c\u5185\u90e8\u5355\u5143\u4e2d\uff0c\u5b58\u5728\u663e\u8457\u7684\u8de8\u6a21\u578b\u5dee\u5f02\uff1b\u67d0\u4e9b\u5355\u5143\u7f16\u7801\u4e86\u9884\u8bad\u7ec3\u4e2d\u7684\u654f\u611f\u6216\u523b\u677f\u5370\u8c61\u5173\u8054\uff1b\u76f8\u540c\u4eba\u53e3\u7edf\u8ba1\u7ebf\u7d22\u53ef\u80fd\u5f15\u53d1\u4e0d\u540c\u884c\u4e3a\uff1b\u6291\u5236\u76f8\u5173\u795e\u7ecf\u5143\u80fd\u51cf\u5c11\u504f\u89c1\u4f46\u4ecd\u6709\u663e\u8457\u6b8b\u7559\u6548\u5e94\u3002", "conclusion": "\u5e72\u9884\u4e3b\u8981\u6539\u53d8\u884c\u4e3a\u800c\u975e\u8868\u793a\uff0c\u8868\u660e\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u7f13\u89e3\u65b9\u6cd5\uff1b\u7814\u7a76\u63ed\u793a\u4e86LLM\u4e2d\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u8868\u793a\u7684\u590d\u6742\u6027\uff0c\u4e3a\u7406\u89e3\u504f\u89c1\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2601.13562", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13562", "abs": "https://arxiv.org/abs/2601.13562", "authors": ["Zhiguang Liu", "Yi Shang"], "title": "Reasoning is a Modality", "comment": "Code access: https://github.com/lz7fd/Reasoning_is_a_Modality", "summary": "The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavior: humans can explain an action by decoding internal state, while AI systems can produce fluent post-hoc rationalizations that are not grounded in such a state. We hypothesize that reasoning is a modality: reasoning should exist as a distinct channel separate from the low-level workspace on which rules are applied. To test this hypothesis, on solving ARC tasks as a visual reasoning problem, we designed a novel role-separated transformer block that splits global controller tokens from grid workspace tokens, enabling iterative rule execution. Trained and evaluated within the VARC vision-centric protocol, our method achieved 62.6% accuracy on ARC-1, surpassing average human performance (60.2%) and outperforming prior methods significantly. Qualitatively, our models exhibit more coherent rule-application structure than the dense ViT baseline, consistent with a shift away from plausible probability blobs toward controller-driven reasoning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89d2\u8272\u5206\u79bb\u7684Transformer\u67b6\u6784\uff0c\u5c06\u5168\u5c40\u63a7\u5236\u5668token\u4e0e\u7f51\u683c\u5de5\u4f5c\u7a7a\u95f4token\u5206\u79bb\uff0c\u5728ARC\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86\u4eba\u7c7b\u5e73\u5747\u8868\u73b0\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\uff08\u5982LLMs\u548cViTs\uff09\u4e3b\u8981\u4f5c\u4e3a\u884c\u4e3a\u5e8f\u5217\u9884\u6d4b\u673a\u8fd0\u884c\uff0c\u901a\u8fc7\u5efa\u6a21token\u7edf\u8ba1\u6765\u5339\u914d\u53ef\u89c2\u5bdf\u884c\u4e3a\uff0c\u7f3a\u4e4f\u6301\u4e45\u3001\u53ef\u8bfb\u7684\u5185\u5fc3\u72b6\u6001\u3002\u8fd9\u4e0e\u4eba\u7c7b\u884c\u4e3a\u5b58\u5728\u5dee\u8ddd\uff1a\u4eba\u7c7b\u53ef\u4ee5\u901a\u8fc7\u89e3\u7801\u5185\u90e8\u72b6\u6001\u6765\u89e3\u91ca\u884c\u52a8\uff0c\u800cAI\u7cfb\u7edf\u53ea\u80fd\u4ea7\u751f\u7f3a\u4e4f\u5185\u5728\u72b6\u6001\u57fa\u7840\u7684\u6d41\u7545\u4e8b\u540e\u5408\u7406\u5316\u3002\u4f5c\u8005\u5047\u8bbe\u63a8\u7406\u5e94\u4f5c\u4e3a\u4e00\u79cd\u72ec\u7acb\u6a21\u6001\u5b58\u5728\uff0c\u4e0e\u89c4\u5219\u5e94\u7528\u7684\u4f4e\u7ea7\u5de5\u4f5c\u7a7a\u95f4\u5206\u79bb\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u89d2\u8272\u5206\u79bbTransformer\u5757\uff0c\u5c06\u5168\u5c40\u63a7\u5236\u5668token\u4e0e\u7f51\u683c\u5de5\u4f5c\u7a7a\u95f4token\u5206\u79bb\uff0c\u5b9e\u73b0\u8fed\u4ee3\u89c4\u5219\u6267\u884c\u3002\u8be5\u65b9\u6cd5\u5728VARC\u89c6\u89c9\u4e2d\u5fc3\u534f\u8bae\u4e0b\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\uff0c\u4e13\u95e8\u7528\u4e8e\u89e3\u51b3ARC\u4efb\u52a1\u4f5c\u4e3a\u89c6\u89c9\u63a8\u7406\u95ee\u9898\u3002", "result": "\u5728ARC-1\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e8662.6%\u7684\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u4e86\u4eba\u7c7b\u5e73\u5747\u8868\u73b0\uff0860.2%\uff09\uff0c\u5e76\u663e\u8457\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002\u5b9a\u6027\u5206\u6790\u663e\u793a\uff0c\u4e0e\u5bc6\u96c6ViT\u57fa\u7ebf\u76f8\u6bd4\uff0c\u6a21\u578b\u5c55\u73b0\u51fa\u66f4\u4e00\u81f4\u7684\u89c4\u5219\u5e94\u7528\u7ed3\u6784\uff0c\u4ece\u6982\u7387\u6591\u5757\u5411\u63a7\u5236\u5668\u9a71\u52a8\u7684\u63a8\u7406\u8f6c\u53d8\u3002", "conclusion": "\u901a\u8fc7\u5c06\u63a8\u7406\u8bbe\u8ba1\u4e3a\u72ec\u7acb\u4e8e\u4f4e\u7ea7\u5de5\u4f5c\u7a7a\u95f4\u7684\u6a21\u6001\uff0c\u5b9e\u73b0\u4e86\u66f4\u63a5\u8fd1\u4eba\u7c7b\u62bd\u8c61\u63a8\u7406\u80fd\u529b\u7684AI\u7cfb\u7edf\u3002\u89d2\u8272\u5206\u79bb\u7684Transformer\u67b6\u6784\u5728\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u9a8c\u8bc1\u4e86\u63a8\u7406\u4f5c\u4e3a\u72ec\u7acb\u901a\u9053\u7684\u5047\u8bbe\u3002"}}
{"id": "2601.12904", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12904", "abs": "https://arxiv.org/abs/2601.12904", "authors": ["Jiahao Wang", "Weiyu Xie", "Mingxing Zhang", "Boxing Zhang", "Jianwei Dong", "Yuening Zhu", "Chen Lin", "Jinqi Tang", "Yaochen Han", "Zhiyuan Ai", "Xianglin Chen", "Yongwei Wu", "Congfeng Jiang"], "title": "From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation", "comment": null, "summary": "Retrieval-Augmented Generation enhances Large Language Models by integrating external knowledge, which reduces hallucinations but increases prompt length. This increase leads to higher computational costs and longer Time to First Token (TTFT). To mitigate this issue, existing solutions aim to reuse the preprocessed KV cache of each retrieved chunk to accelerate RAG. However, the lack of cross-chunk contextual information leads to a significant drop in generation quality, leaving the potential benefits of KV cache reuse largely unfulfilled. The challenge lies in how to reuse the precomputed KV cache of chunks while preserving generation quality. We propose FusionRAG, a novel inference framework that optimizes both the preprocessing and reprocessing stages of RAG. In the offline preprocessing stage, we embed information from other related text chunks into each chunk, while in the online reprocessing stage, we recompute the KV cache for tokens that the model focuses on. As a result, we achieve a better trade-off between generation quality and efficiency. According to our experiments, FusionRAG significantly improves generation quality at the same recomputation ratio compared to previous state-of-the-art solutions. By recomputing fewer than 15% of the tokens, FusionRAG achieves up to 70% higher normalized F1 scores than baselines and reduces TTFT by 2.66x-9.39x compared to Full Attention.", "AI": {"tldr": "FusionRAG\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u9884\u5904\u7406\u9636\u6bb5\u5c06\u76f8\u5173\u6587\u672c\u5757\u4fe1\u606f\u5d4c\u5165\u5230\u6bcf\u4e2a\u5757\u4e2d\uff0c\u5e76\u5728\u5728\u7ebf\u91cd\u5904\u7406\u9636\u6bb5\u91cd\u65b0\u8ba1\u7b97\u6a21\u578b\u5173\u6ce8\u7684token\u7684KV\u7f13\u5b58\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\u63d0\u9ad8RAG\u6548\u7387\u3002", "motivation": "\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u867d\u7136\u80fd\u51cf\u5c11\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\uff0c\u4f46\u589e\u52a0\u4e86\u63d0\u793a\u957f\u5ea6\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u589e\u52a0\u548c\u9996token\u65f6\u95f4\uff08TTFT\uff09\u5ef6\u957f\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u8bd5\u56fe\u91cd\u7528\u68c0\u7d22\u5757\u7684\u9884\u5904\u7406KV\u7f13\u5b58\u6765\u52a0\u901fRAG\uff0c\u4f46\u7f3a\u4e4f\u8de8\u5757\u4e0a\u4e0b\u6587\u4fe1\u606f\u5bfc\u81f4\u751f\u6210\u8d28\u91cf\u663e\u8457\u4e0b\u964d\uff0c\u4f7f\u5f97KV\u7f13\u5b58\u91cd\u7528\u7684\u6f5c\u5728\u597d\u5904\u65e0\u6cd5\u5145\u5206\u53d1\u6325\u3002", "method": "FusionRAG\u91c7\u7528\u4e24\u9636\u6bb5\u4f18\u5316\uff1a1\uff09\u79bb\u7ebf\u9884\u5904\u7406\u9636\u6bb5\uff1a\u5c06\u5176\u4ed6\u76f8\u5173\u6587\u672c\u5757\u7684\u4fe1\u606f\u5d4c\u5165\u5230\u6bcf\u4e2a\u5757\u4e2d\uff1b2\uff09\u5728\u7ebf\u91cd\u5904\u7406\u9636\u6bb5\uff1a\u91cd\u65b0\u8ba1\u7b97\u6a21\u578b\u5173\u6ce8\u7684token\u7684KV\u7f13\u5b58\u3002\u8fd9\u79cd\u65b9\u6cd5\u5728\u4fdd\u6301\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u540c\u65f6\u5b9e\u73b0KV\u7f13\u5b58\u7684\u6709\u6548\u91cd\u7528\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFusionRAG\u5728\u76f8\u540c\u91cd\u8ba1\u7b97\u6bd4\u4f8b\u4e0b\u663e\u8457\u63d0\u9ad8\u751f\u6210\u8d28\u91cf\u3002\u901a\u8fc7\u91cd\u8ba1\u7b97\u5c11\u4e8e15%\u7684token\uff0cFusionRAG\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u8fbe70%\u7684\u5f52\u4e00\u5316F1\u5206\u6570\u63d0\u5347\uff0c\u76f8\u6bd4\u5b8c\u5168\u6ce8\u610f\u529b\u673a\u5236\u5c06TTFT\u51cf\u5c11\u4e862.66-9.39\u500d\u3002", "conclusion": "FusionRAG\u901a\u8fc7\u521b\u65b0\u7684\u4e24\u9636\u6bb5\u5904\u7406\u6846\u67b6\uff0c\u5728\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\u6709\u6548\u63d0\u9ad8\u4e86RAG\u7cfb\u7edf\u7684\u6548\u7387\uff0c\u5b9e\u73b0\u4e86\u751f\u6210\u8d28\u91cf\u4e0e\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u66f4\u597d\u5e73\u8861\uff0c\u4e3aKV\u7f13\u5b58\u91cd\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13581", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13581", "abs": "https://arxiv.org/abs/2601.13581", "authors": ["Heedou Kim", "Changsik Kim", "Sanghwa Shin", "Jaewoo Kang"], "title": "SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System", "comment": "This paper has been accepted to the EACL 2026 Industry Track", "summary": "Social engineering scams increasingly employ personalized, multi-turn deception, exposing the limits of traditional detection methods. While Large Language Models (LLMs) show promise in identifying deception, their cognitive assistance potential remains underexplored. We propose ScriptMind, an integrated framework for LLM-based scam detection that bridges automated reasoning and human cognition. It comprises three components: the Crime Script Inference Task (CSIT) for scam reasoning, the Crime Script-Aware Inference Dataset (CSID) for fine-tuning small LLMs, and the Cognitive Simulation-based Evaluation of Social Engineering Defense (CSED) for assessing real-time cognitive impact. Using 571 Korean phone scam cases, we built 22,712 structured scammer-sequence training instances. Experimental results show that the 11B small LLM fine-tuned with ScriptMind outperformed GPT-4o by 13%, achieving superior performance over commercial models in detection accuracy, false-positive reduction, scammer utterance prediction, and rationale quality. Moreover, in phone scam simulation experiments, it significantly enhanced and sustained users' suspicion levels, improving their cognitive awareness of scams. ScriptMind represents a step toward human-centered, cognitively adaptive LLMs for scam defense.", "AI": {"tldr": "ScriptMind\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bc8\u9a97\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u72af\u7f6a\u811a\u672c\u63a8\u7406\u4efb\u52a1\u3001\u6570\u636e\u96c6\u6784\u5efa\u548c\u8ba4\u77e5\u6a21\u62df\u8bc4\u4f30\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5c0f\u578bLLM\u7684\u8bc8\u9a97\u68c0\u6d4b\u6027\u80fd\uff0c\u5e76\u5728\u8ba4\u77e5\u5c42\u9762\u589e\u5f3a\u7528\u6237\u5bf9\u8bc8\u9a97\u7684\u8b66\u89c9\u6027\u3002", "motivation": "\u5f53\u524d\u793e\u4ea4\u5de5\u7a0b\u8bc8\u9a97\u65e5\u76ca\u91c7\u7528\u4e2a\u6027\u5316\u3001\u591a\u8f6e\u6b21\u7684\u6b3a\u9a97\u624b\u6bb5\uff0c\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u9762\u4e34\u5c40\u9650\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bc6\u522b\u6b3a\u9a97\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5176\u8ba4\u77e5\u8f85\u52a9\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u7ed3\u5408\u81ea\u52a8\u63a8\u7406\u548c\u4eba\u7c7b\u8ba4\u77e5\u7684\u96c6\u6210\u6846\u67b6\u6765\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u63d0\u51faScriptMind\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u72af\u7f6a\u811a\u672c\u63a8\u7406\u4efb\u52a1(CSIT)\u7528\u4e8e\u8bc8\u9a97\u63a8\u7406\uff1b2) \u72af\u7f6a\u811a\u672c\u611f\u77e5\u63a8\u7406\u6570\u636e\u96c6(CSID)\u7528\u4e8e\u5fae\u8c03\u5c0f\u578bLLM\uff1b3) \u57fa\u4e8e\u8ba4\u77e5\u6a21\u62df\u7684\u793e\u4ea4\u5de5\u7a0b\u9632\u5fa1\u8bc4\u4f30(CSED)\u7528\u4e8e\u8bc4\u4f30\u5b9e\u65f6\u8ba4\u77e5\u5f71\u54cd\u3002\u4f7f\u7528571\u4e2a\u97e9\u56fd\u7535\u8bdd\u8bc8\u9a97\u6848\u4f8b\u6784\u5efa\u4e8622,712\u4e2a\u7ed3\u6784\u5316\u8bc8\u9a97\u8005\u5e8f\u5217\u8bad\u7ec3\u5b9e\u4f8b\u3002", "result": "\u7ecf\u8fc7ScriptMind\u5fae\u8c03\u768411B\u5c0f\u578bLLM\u5728\u68c0\u6d4b\u51c6\u786e\u7387\u4e0a\u6bd4GPT-4o\u9ad8\u51fa13%\uff0c\u5728\u68c0\u6d4b\u51c6\u786e\u7387\u3001\u8bef\u62a5\u51cf\u5c11\u3001\u8bc8\u9a97\u8005\u8bdd\u8bed\u9884\u6d4b\u548c\u63a8\u7406\u8d28\u91cf\u65b9\u9762\u5747\u4f18\u4e8e\u5546\u4e1a\u6a21\u578b\u3002\u5728\u7535\u8bdd\u8bc8\u9a97\u6a21\u62df\u5b9e\u9a8c\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u5e76\u7ef4\u6301\u4e86\u7528\u6237\u7684\u6000\u7591\u6c34\u5e73\uff0c\u6539\u5584\u4e86\u4ed6\u4eec\u5bf9\u8bc8\u9a97\u7684\u8ba4\u77e5\u610f\u8bc6\u3002", "conclusion": "ScriptMind\u4ee3\u8868\u4e86\u5411\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u3001\u8ba4\u77e5\u81ea\u9002\u5e94\u7684\u5927\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u8bc8\u9a97\u9632\u5fa1\u7684\u91cd\u8981\u4e00\u6b65\u3002\u8be5\u6846\u67b6\u4e0d\u4ec5\u63d0\u5347\u4e86\u6280\u672f\u68c0\u6d4b\u6027\u80fd\uff0c\u8fd8\u5728\u8ba4\u77e5\u5c42\u9762\u589e\u5f3a\u4e86\u7528\u6237\u5bf9\u8bc8\u9a97\u7684\u8b66\u89c9\u6027\uff0c\u4e3a\u793e\u4ea4\u5de5\u7a0b\u9632\u5fa1\u63d0\u4f9b\u4e86\u7efc\u5408\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12906", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12906", "abs": "https://arxiv.org/abs/2601.12906", "authors": ["Lingrui Mei", "Shenghua Liu", "Yiwei Wang", "Yuyao Ge", "Baolong Bi", "Jiayu Yao", "Jun Wan", "Ziling Yin", "Jiafeng Guo", "Xueqi Cheng"], "title": "Gated Differentiable Working Memory for Long-Context Language Modeling", "comment": null, "summary": "Long contexts challenge transformers: attention scores dilute across thousands of tokens, critical information is often lost in the middle, and models struggle to adapt to novel patterns at inference time. Recent work on test-time adaptation addresses this by maintaining a form of working memory -- transient parameters updated on the current context -- but existing approaches rely on uniform write policies that waste computation on low-utility regions and suffer from high gradient variance across semantically heterogeneous contexts. In this work, we reframe test-time adaptation as a budget-constrained memory consolidation problem, focusing on which parts of the context should be consolidated into working memory under limited computation. We propose Gdwm (Gated Differentiable Working Memory), a framework that introduces a write controller to gate the consolidation process. The controller estimates Contextual Utility, an information-theoretic measure of long-range contextual dependence, and allocates gradient steps accordingly while maintaining global coverage. Experiments on ZeroSCROLLS and LongBench v2 demonstrate that Gdwm achieves comparable or superior performance with 4$\\times$ fewer gradient steps than uniform baselines, establishing a new efficiency-performance Pareto frontier for test-time adaptation.", "AI": {"tldr": "Gdwm\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u95e8\u63a7\u53ef\u5fae\u5206\u5de5\u4f5c\u5185\u5b58\u7684\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u6548\u7528\u8bc4\u4f30\u9009\u62e9\u6027\u6574\u5408\u5173\u952e\u4fe1\u606f\uff0c\u76f8\u6bd4\u5747\u5300\u5199\u5165\u7b56\u7565\u51cf\u5c114\u500d\u68af\u5ea6\u6b65\u6570", "motivation": "\u957f\u4e0a\u4e0b\u6587\u5bf9Transformer\u7684\u6311\u6218\uff1a\u6ce8\u610f\u529b\u5206\u6570\u5728\u6570\u5343\u4e2atoken\u4e0a\u88ab\u7a00\u91ca\uff0c\u5173\u952e\u4fe1\u606f\u5728\u4e2d\u95f4\u4e22\u5931\uff0c\u6a21\u578b\u5728\u63a8\u7406\u65f6\u96be\u4ee5\u9002\u5e94\u65b0\u6a21\u5f0f\u3002\u73b0\u6709\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\u4f7f\u7528\u5747\u5300\u5199\u5165\u7b56\u7565\uff0c\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\u5728\u4f4e\u6548\u7528\u533a\u57df\uff0c\u4e14\u5728\u8bed\u4e49\u5f02\u6784\u4e0a\u4e0b\u6587\u4e0a\u68af\u5ea6\u65b9\u5dee\u9ad8\u3002", "method": "\u5c06\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u91cd\u6784\u4e3a\u9884\u7b97\u7ea6\u675f\u4e0b\u7684\u5185\u5b58\u6574\u5408\u95ee\u9898\uff0c\u63d0\u51faGdwm\u6846\u67b6\uff0c\u5f15\u5165\u5199\u5165\u63a7\u5236\u5668\u95e8\u63a7\u6574\u5408\u8fc7\u7a0b\u3002\u63a7\u5236\u5668\u4f30\u8ba1\u4e0a\u4e0b\u6587\u6548\u7528\uff08\u8861\u91cf\u957f\u8ddd\u79bb\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u4fe1\u606f\u8bba\u6307\u6807\uff09\uff0c\u636e\u6b64\u5206\u914d\u68af\u5ea6\u6b65\u6570\uff0c\u540c\u65f6\u4fdd\u6301\u5168\u5c40\u8986\u76d6\u3002", "result": "\u5728ZeroSCROLLS\u548cLongBench v2\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGdwm\u4f7f\u7528\u6bd4\u5747\u5300\u57fa\u7ebf\u5c114\u500d\u7684\u68af\u5ea6\u6b65\u6570\uff0c\u8fbe\u5230\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u5efa\u7acb\u4e86\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u7684\u65b0\u6548\u7387-\u6027\u80fd\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "conclusion": "Gdwm\u901a\u8fc7\u9009\u62e9\u6027\u6574\u5408\u9ad8\u4e0a\u4e0b\u6587\u6548\u7528\u533a\u57df\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u957f\u4e0a\u4e0b\u6587Transformer\u7684\u6ce8\u610f\u529b\u7a00\u91ca\u548c\u5173\u952e\u4fe1\u606f\u4e22\u5931\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u7684\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2601.13589", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.13589", "abs": "https://arxiv.org/abs/2601.13589", "authors": ["HyeYoung Lee"], "title": "Motion-to-Response Content Generation via Multi-Agent AI System with Real-Time Safety Verification", "comment": null, "summary": "This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. Unlike conventional speech emotion recognition studies that focus primarily on classification accuracy, our approach emphasizes the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents. The proposed system comprises four cooperative agents: (1) an Emotion Recognition Agent with CNN-based acoustic feature extraction, (2) a Response Policy Decision Agent for mapping emotions to response modes, (3) a Content Parameter Generation Agent for producing media control parameters, and (4) a Safety Verification Agent enforcing age-appropriateness and stimulation constraints. We introduce an explicit safety verification loop that filters generated content before output, ensuring compliance with predefined rules. Experimental results on public datasets demonstrate that the system achieves 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance while maintaining sub-100ms inference latency suitable for on-device deployment. The modular architecture enables interpretability and extensibility, making it applicable to child-adjacent media, therapeutic applications, and emotionally responsive smart devices.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u97f3\u9891\u60c5\u611f\u4fe1\u53f7\u7684\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\uff0c\u5b9e\u65f6\u751f\u6210\u54cd\u5e94\u5bfc\u5411\u7684\u5a92\u4f53\u5185\u5bb9\uff0c\u901a\u8fc7\u5b89\u5168\u9a8c\u8bc1\u786e\u4fdd\u5185\u5bb9\u9002\u9f84\u53ef\u63a7", "motivation": "\u4f20\u7edf\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u4f46\u7f3a\u4e4f\u5c06\u63a8\u65ad\u7684\u60c5\u611f\u72b6\u6001\u8f6c\u5316\u4e3a\u5b89\u5168\u3001\u9002\u9f84\u3001\u53ef\u63a7\u7684\u54cd\u5e94\u5185\u5bb9\u7684\u80fd\u529b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5b9e\u65f6\u751f\u6210\u54cd\u5e94\u5185\u5bb9\u5e76\u786e\u4fdd\u5b89\u5168\u6027\u7684\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u56db\u667a\u80fd\u4f53\u534f\u4f5c\u67b6\u6784\uff1a1) \u57fa\u4e8eCNN\u7684\u60c5\u611f\u8bc6\u522b\u667a\u80fd\u4f53\u63d0\u53d6\u58f0\u5b66\u7279\u5f81\uff1b2) \u54cd\u5e94\u7b56\u7565\u51b3\u7b56\u667a\u80fd\u4f53\u5c06\u60c5\u611f\u6620\u5c04\u5230\u54cd\u5e94\u6a21\u5f0f\uff1b3) \u5185\u5bb9\u53c2\u6570\u751f\u6210\u667a\u80fd\u4f53\u4ea7\u751f\u5a92\u4f53\u63a7\u5236\u53c2\u6570\uff1b4) \u5b89\u5168\u9a8c\u8bc1\u667a\u80fd\u4f53\u5f3a\u5236\u6267\u884c\u9002\u9f84\u6027\u548c\u523a\u6fc0\u7ea6\u675f\u3002\u5f15\u5165\u663e\u5f0f\u5b89\u5168\u9a8c\u8bc1\u5faa\u73af\u5728\u8f93\u51fa\u524d\u8fc7\u6ee4\u751f\u6210\u5185\u5bb9\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0c\u7cfb\u7edf\u8fbe\u523073.2%\u7684\u60c5\u611f\u8bc6\u522b\u51c6\u786e\u7387\u300189.4%\u7684\u54cd\u5e94\u6a21\u5f0f\u4e00\u81f4\u6027\u3001100%\u7684\u5b89\u5168\u5408\u89c4\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u4e8e100ms\u7684\u63a8\u7406\u5ef6\u8fdf\uff0c\u9002\u5408\u8bbe\u5907\u7aef\u90e8\u7f72\u3002", "conclusion": "\u6a21\u5757\u5316\u67b6\u6784\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u513f\u7ae5\u76f8\u5173\u5a92\u4f53\u3001\u6cbb\u7597\u5e94\u7528\u548c\u60c5\u611f\u54cd\u5e94\u667a\u80fd\u8bbe\u5907\u3002\u5b89\u5168\u9a8c\u8bc1\u673a\u5236\u786e\u4fdd\u751f\u6210\u5185\u5bb9\u7684\u5b89\u5168\u6027\u548c\u9002\u9f84\u6027\u3002"}}
{"id": "2601.12910", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12910", "abs": "https://arxiv.org/abs/2601.12910", "authors": ["Tim Baumg\u00e4rtner", "Iryna Gurevych"], "title": "SciCoQA: Quality Assurance for Scientific Paper--Code Alignment", "comment": null, "summary": "We present SciCoQA, a dataset for detecting discrepancies between scientific publications and their codebases to ensure faithful implementations. We construct SciCoQA from GitHub issues and reproducibility papers, and to scale our dataset, we propose a synthetic data generation method for constructing paper-code discrepancies. We analyze the paper-code discrepancies in detail and propose discrepancy types and categories to better understand the occurring mismatches. In total, our dataset consists of 611 paper-code discrepancies (81 real, 530 synthetic), spanning diverse computational science disciplines, including AI, Physics, Quantitative Biology, and others. Our evaluation of 21 LLMs highlights the difficulty of SciCoQA, particularly for instances involving omitted paper details, long-context inputs, and data outside the models' pre-training corpus. The best performing model in our evaluation, GPT-5, can only detect 45.7\\% of real-world paper-code discrepancies.", "AI": {"tldr": "SciCoQA\u662f\u4e00\u4e2a\u7528\u4e8e\u68c0\u6d4b\u79d1\u5b66\u51fa\u7248\u7269\u4e0e\u5176\u4ee3\u7801\u5e93\u4e4b\u95f4\u5dee\u5f02\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b\u771f\u5b9e\u548c\u5408\u6210\u7684\u8bba\u6587-\u4ee3\u7801\u5dee\u5f02\uff0c\u6db5\u76d6\u591a\u4e2a\u8ba1\u7b97\u79d1\u5b66\u9886\u57df\uff0c\u73b0\u6709LLM\u5728\u68c0\u6d4b\u771f\u5b9e\u5dee\u5f02\u65b9\u9762\u8868\u73b0\u6709\u9650\u3002", "motivation": "\u786e\u4fdd\u79d1\u5b66\u51fa\u7248\u7269\u4e0e\u5176\u5b9e\u73b0\u4ee3\u7801\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u5bf9\u4e8e\u53ef\u91cd\u590d\u6027\u81f3\u5173\u91cd\u8981\uff0c\u5f53\u524d\u7f3a\u4e4f\u7cfb\u7edf\u68c0\u6d4b\u8bba\u6587\u4e0e\u4ee3\u7801\u5dee\u5f02\u7684\u6570\u636e\u96c6\u548c\u65b9\u6cd5\u3002", "method": "\u4eceGitHub\u95ee\u9898\u548c\u53ef\u91cd\u590d\u6027\u8bba\u6587\u6784\u5efa\u771f\u5b9e\u5dee\u5f02\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\u6269\u5c55\u6570\u636e\u96c6\u89c4\u6a21\uff0c\u8be6\u7ec6\u5206\u6790\u5dee\u5f02\u7c7b\u578b\u548c\u7c7b\u522b\uff0c\u8bc4\u4f3021\u4e2aLLM\u5728\u68c0\u6d4b\u5dee\u5f02\u65b9\u9762\u7684\u6027\u80fd\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b611\u4e2a\u8bba\u6587-\u4ee3\u7801\u5dee\u5f02\u7684\u6570\u636e\u96c6\uff0881\u4e2a\u771f\u5b9e\uff0c530\u4e2a\u5408\u6210\uff09\uff0c\u6db5\u76d6AI\u3001\u7269\u7406\u3001\u5b9a\u91cf\u751f\u7269\u5b66\u7b49\u591a\u4e2a\u9886\u57df\u3002\u8bc4\u4f30\u663e\u793a\u73b0\u6709LLM\u68c0\u6d4b\u5dee\u5f02\u56f0\u96be\uff0c\u7279\u522b\u662f\u6d89\u53ca\u7701\u7565\u7ec6\u8282\u3001\u957f\u4e0a\u4e0b\u6587\u548c\u9884\u8bad\u7ec3\u8bed\u6599\u5916\u6570\u636e\u7684\u60c5\u51b5\u3002\u6700\u4f73\u6a21\u578bGPT-5\u4ec5\u80fd\u68c0\u6d4b45.7%\u7684\u771f\u5b9e\u5dee\u5f02\u3002", "conclusion": "SciCoQA\u63ed\u793a\u4e86\u79d1\u5b66\u51fa\u7248\u7269\u4e0e\u4ee3\u7801\u5b9e\u73b0\u4e4b\u95f4\u666e\u904d\u5b58\u5728\u5dee\u5f02\uff0c\u73b0\u6709LLM\u5728\u68c0\u6d4b\u8fd9\u4e9b\u5dee\u5f02\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u573a\u666f\u4e0b\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6539\u8fdb\u79d1\u5b66\u53ef\u91cd\u590d\u6027\u9a8c\u8bc1\u65b9\u6cd5\u3002"}}
{"id": "2601.12921", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12921", "abs": "https://arxiv.org/abs/2601.12921", "authors": ["Adimulya Kartiyasa", "Bao Gia Cao", "Boyang Li"], "title": "Injecting Knowledge from Social Science Journals to Improve Indonesian Cultural Understanding by LLMs", "comment": null, "summary": "Recently there have been intensifying efforts to improve the understanding of Indonesian cultures by large language models (LLMs). An attractive source of cultural knowledge that has been largely overlooked is local journals of social science, which likely contain substantial cultural studies from a native perspective. We present a novel text dataset of journal article passages, created from 151 open-source Indonesian social science journals, called IndoSoSci. We demonstrate an effective recipe for injecting Indonesian cultural knowledge therein into LLMs: extracting the facts related to Indonesian culture, and apply retrieval-augmented generation (RAG) with LLM-generated hypothetical documents as queries during retrieval. The proposed recipe yields strong performance gains over several strong baselines on the IndoCulture benchmark. Additionally, by combining IndoSoSci with Indonesian Wikipedia, we set a new state-of-the-art accuracy on the IndoCulture benchmark.", "AI": {"tldr": "\u63d0\u51fa\u4e86IndoSoSci\u6570\u636e\u96c6\u548c\u4e00\u79cd\u5c06\u5370\u5c3c\u6587\u5316\u77e5\u8bc6\u6ce8\u5165\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u6587\u5316\u4e8b\u5b9e\u5e76\u4f7f\u7528LLM\u751f\u6210\u7684\u5047\u8bbe\u6587\u6863\u4f5c\u4e3a\u67e5\u8be2\u8fdb\u884c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff0c\u5728IndoCulture\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u5370\u5c3c\u6587\u5316\u7684\u7406\u89e3\u6709\u9650\uff0c\u800c\u672c\u571f\u793e\u4f1a\u79d1\u5b66\u671f\u520a\u4f5c\u4e3a\u91cd\u8981\u7684\u6587\u5316\u77e5\u8bc6\u6765\u6e90\u88ab\u5ffd\u89c6\u3002\u8fd9\u4e9b\u671f\u520a\u5305\u542b\u5927\u91cf\u4ece\u672c\u571f\u89c6\u89d2\u51fa\u53d1\u7684\u6587\u5316\u7814\u7a76\uff0c\u662f\u6539\u5584LLMs\u6587\u5316\u7406\u89e3\u80fd\u529b\u7684\u5b9d\u8d35\u8d44\u6e90\u3002", "method": "1) \u4ece151\u4e2a\u5f00\u6e90\u5370\u5c3c\u793e\u4f1a\u79d1\u5b66\u671f\u520a\u521b\u5efaIndoSoSci\u6587\u672c\u6570\u636e\u96c6\uff1b2) \u63d0\u53d6\u4e0e\u5370\u5c3c\u6587\u5316\u76f8\u5173\u7684\u4e8b\u5b9e\uff1b3) \u4f7f\u7528LLM\u751f\u6210\u7684\u5047\u8bbe\u6587\u6863\u4f5c\u4e3a\u67e5\u8be2\u8fdb\u884c\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\uff1b4) \u5c06IndoSoSci\u4e0e\u5370\u5c3c\u7ef4\u57fa\u767e\u79d1\u7ed3\u5408\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728IndoCulture\u57fa\u51c6\u4e0a\u663e\u8457\u4f18\u4e8e\u591a\u4e2a\u5f3a\u57fa\u7ebf\u6a21\u578b\u3002\u7ed3\u5408IndoSoSci\u548c\u5370\u5c3c\u7ef4\u57fa\u767e\u79d1\uff0c\u5728IndoCulture\u57fa\u51c6\u4e0a\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u51c6\u786e\u7387\u3002", "conclusion": "\u5370\u5c3c\u793e\u4f1a\u79d1\u5b66\u671f\u520a\u662f\u6539\u5584LLMs\u5370\u5c3c\u6587\u5316\u7406\u89e3\u7684\u91cd\u8981\u8d44\u6e90\uff0c\u63d0\u51fa\u7684RAG\u65b9\u6cd5\u80fd\u6709\u6548\u6ce8\u5165\u6587\u5316\u77e5\u8bc6\uff0c\u4e3aLLMs\u7684\u6587\u5316\u7406\u89e3\u80fd\u529b\u63d0\u5347\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2601.13600", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13600", "abs": "https://arxiv.org/abs/2601.13600", "authors": ["Paul He", "Elke Kirschbaum", "Shiva Kasiviswanathan"], "title": "Foundations of Global Consistency Checking with Noisy LLM Oracles", "comment": "Under Review", "summary": "Ensuring that collections of natural-language facts are globally consistent is essential for tasks such as fact-checking, summarization, and knowledge base construction. While Large Language Models (LLMs) can assess the consistency of small subsets of facts, their judgments are noisy, and pairwise checks are insufficient to guarantee global coherence. We formalize this problem and show that verifying global consistency requires exponentially many oracle queries in the worst case. To make the task practical, we propose an adaptive divide-and-conquer algorithm that identifies minimal inconsistent subsets (MUSes) of facts and optionally computes minimal repairs through hitting-sets. Our approach has low-degree polynomial query complexity. Experiments with both synthetic and real LLM oracles show that our method efficiently detects and localizes inconsistencies, offering a scalable framework for linguistic consistency verification with LLM-based evaluators.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u81ea\u9002\u5e94\u5206\u6cbb\u7b97\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u548c\u5b9a\u4f4d\u81ea\u7136\u8bed\u8a00\u4e8b\u5b9e\u96c6\u5408\u4e2d\u7684\u5168\u5c40\u4e0d\u4e00\u81f4\u6027\uff0c\u4f7f\u7528LLM\u4f5c\u4e3a\u8bc4\u4f30\u5668\uff0c\u5177\u6709\u591a\u9879\u5f0f\u67e5\u8be2\u590d\u6742\u5ea6\u3002", "motivation": "\u786e\u4fdd\u81ea\u7136\u8bed\u8a00\u4e8b\u5b9e\u96c6\u5408\u7684\u5168\u5c40\u4e00\u81f4\u6027\u5bf9\u4e8e\u4e8b\u5b9e\u6838\u67e5\u3001\u6458\u8981\u548c\u77e5\u8bc6\u5e93\u6784\u5efa\u7b49\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136LLM\u53ef\u4ee5\u8bc4\u4f30\u5c0f\u89c4\u6a21\u4e8b\u5b9e\u5b50\u96c6\u7684\u4e00\u81f4\u6027\uff0c\u4f46\u5176\u5224\u65ad\u5b58\u5728\u566a\u58f0\uff0c\u4e14\u6210\u5bf9\u68c0\u67e5\u4e0d\u8db3\u4ee5\u4fdd\u8bc1\u5168\u5c40\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u5206\u6cbb\u7b97\u6cd5\uff0c\u8bc6\u522b\u4e8b\u5b9e\u7684\u6700\u5c0f\u4e0d\u4e00\u81f4\u5b50\u96c6\uff08MUSes\uff09\uff0c\u53ef\u9009\u5730\u901a\u8fc7\u547d\u4e2d\u96c6\u8ba1\u7b97\u6700\u5c0f\u4fee\u590d\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u4f4e\u9636\u591a\u9879\u5f0f\u67e5\u8be2\u590d\u6742\u5ea6\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9eLLM\u8bc4\u4f30\u5668\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u9ad8\u6548\u68c0\u6d4b\u548c\u5b9a\u4f4d\u4e0d\u4e00\u81f4\u6027\uff0c\u4e3a\u57fa\u4e8eLLM\u7684\u8bed\u8a00\u4e00\u81f4\u6027\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u6846\u67b6\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u4e8b\u5b9e\u96c6\u5408\u7684\u5168\u5c40\u4e00\u81f4\u6027\u9a8c\u8bc1\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u7528\u7b97\u6cd5\uff0c\u514b\u670d\u4e86LLM\u8bc4\u4f30\u5668\u7684\u566a\u58f0\u548c\u6307\u6570\u7ea7\u67e5\u8be2\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u7684\u4e00\u81f4\u6027\u9a8c\u8bc1\u3002"}}
{"id": "2601.12945", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12945", "abs": "https://arxiv.org/abs/2601.12945", "authors": ["Miao Xie", "Siguang Chen", "Chunli Lv"], "title": "A Component-Based Survey of Interactions between Large Language Models and Multi-Armed Bandits", "comment": "27 pages, 6 table", "summary": "Large language models (LLMs) have become powerful and widely used systems for language understanding and generation, while multi-armed bandit (MAB) algorithms provide a principled framework for adaptive decision-making under uncertainty. This survey explores the potential at the intersection of these two fields. As we know, it is the first survey to systematically review the bidirectional interaction between large language models and multi-armed bandits at the component level. We highlight the bidirectional benefits: MAB algorithms address critical LLM challenges, spanning from pre-training to retrieval-augmented generation (RAG) and personalization. Conversely, LLMs enhance MAB systems by redefining core components such as arm definition and environment modeling, thereby improving decision-making in sequential tasks. We analyze existing LLM-enhanced bandit systems and bandit-enhanced LLM systems, providing insights into their design, methodologies, and performance. Key challenges and representative findings are identified to help guide future research. An accompanying GitHub repository that indexes relevant literature is available at https://github.com/bucky1119/Awesome-LLM-Bandit-Interaction.", "code_url": "https://github.com/bucky1119/Awesome-LLM-Bandit-Interaction", "code_stars": 0, "code_last_update": "2026-01-04", "AI": {"tldr": "\u8fd9\u662f\u7b2c\u4e00\u7bc7\u7cfb\u7edf\u7efc\u8ff0\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u591a\u81c2\u8001\u864e\u673a\u53cc\u5411\u4ea4\u4e92\u7684\u8bba\u6587\uff0c\u63a2\u8ba8\u4e24\u8005\u5728\u7ec4\u4ef6\u5c42\u9762\u7684\u76f8\u4e92\u589e\u5f3a\u5173\u7cfb\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5df2\u6210\u4e3a\u5f3a\u5927\u7684\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u7cfb\u7edf\uff0c\u800c\u591a\u81c2\u8001\u864e\u673a\u7b97\u6cd5\u4e3a\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u81ea\u9002\u5e94\u51b3\u7b56\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\u3002\u76ee\u524d\u7f3a\u4e4f\u5bf9\u8fd9\u4e24\u4e2a\u9886\u57df\u4ea4\u53c9\u6f5c\u529b\u7684\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u7279\u522b\u662f\u7ec4\u4ef6\u5c42\u9762\u7684\u53cc\u5411\u4ea4\u4e92\u5206\u6790\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u4ece\u7ec4\u4ef6\u5c42\u9762\u5206\u6790LLM\u4e0eMAB\u7684\u53cc\u5411\u4ea4\u4e92\u3002\u5177\u4f53\u5305\u62ec\uff1a1) \u5206\u6790MAB\u7b97\u6cd5\u5982\u4f55\u89e3\u51b3LLM\u7684\u5173\u952e\u6311\u6218\uff08\u4ece\u9884\u8bad\u7ec3\u5230\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u4e2a\u6027\u5316\uff09\uff1b2) \u63a2\u8ba8LLM\u5982\u4f55\u589e\u5f3aMAB\u7cfb\u7edf\uff08\u91cd\u65b0\u5b9a\u4e49\u81c2\u5b9a\u4e49\u548c\u73af\u5883\u5efa\u6a21\u7b49\u6838\u5fc3\u7ec4\u4ef6\uff09\u3002", "result": "\u8bc6\u522b\u4e86\u73b0\u6709LLM\u589e\u5f3a\u7684\u8001\u864e\u673a\u7cfb\u7edf\u548c\u8001\u864e\u673a\u589e\u5f3a\u7684LLM\u7cfb\u7edf\uff0c\u5206\u6790\u4e86\u5b83\u4eec\u7684\u8bbe\u8ba1\u3001\u65b9\u6cd5\u8bba\u548c\u6027\u80fd\u3002\u603b\u7ed3\u4e86\u5173\u952e\u6311\u6218\u548c\u4ee3\u8868\u6027\u53d1\u73b0\uff0c\u5e76\u521b\u5efa\u4e86GitHub\u4ed3\u5e93\u7d22\u5f15\u76f8\u5173\u6587\u732e\u3002", "conclusion": "LLM\u4e0eMAB\u7684\u53cc\u5411\u4ea4\u4e92\u5177\u6709\u663e\u8457\u6f5c\u529b\uff1aMAB\u7b97\u6cd5\u80fd\u6709\u6548\u89e3\u51b3LLM\u7684\u5173\u952e\u6311\u6218\uff0c\u800cLLM\u80fd\u589e\u5f3aMAB\u7cfb\u7edf\u7684\u51b3\u7b56\u80fd\u529b\u3002\u8be5\u7efc\u8ff0\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6307\u5bfc\u6846\u67b6\uff0c\u5e76\u5efa\u7acb\u4e86\u5f00\u6e90\u8d44\u6e90\u5e93\u4fc3\u8fdb\u8be5\u4ea4\u53c9\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.12960", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12960", "abs": "https://arxiv.org/abs/2601.12960", "authors": ["Ainhoa Vivel-Couso", "Nicol\u00e1s Vila-Blanco", "Mar\u00eda J. Carreira", "Alberto Bugar\u00edn-Diz", "Inmaculada Tom\u00e1s", "Jose M. Alonso-Moral"], "title": "Trustworthy Data-driven Chronological Age Estimation from Panoramic Dental Images", "comment": "This paper is a preliminary version of an accepted article in Information Systems Frontiers, Springer, Special Issue \"Explainability in Human-Centric AI\". Please cite the final published version of the paper, not this preprint. The final published version can be found at https://link.springer.com/article/10.1007/s10796-025-10682-3", "summary": "Integrating deep learning into healthcare enables personalized care but raises trust issues due to model opacity. To improve transparency, we propose a system for dental age estimation from panoramic images that combines an opaque and a transparent method within a natural language generation (NLG) module. This module produces clinician-friendly textual explanations about the age estimations, designed with dental experts through a rule-based approach. Following the best practices in the field, the quality of the generated explanations was manually validated by dental experts using a questionnaire. The results showed a strong performance, since the experts rated 4.77+/-0.12 (out of 5) on average across the five dimensions considered. We also performed a trustworthy self-assessment procedure following the ALTAI checklist, in which it scored 4.40+/-0.27 (out of 5) across seven dimensions of the AI Trustworthiness Assessment List.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u4e0d\u900f\u660e\u548c\u900f\u660e\u65b9\u6cd5\u7684\u7259\u79d1\u5e74\u9f84\u4f30\u8ba1\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u751f\u6210\u6a21\u5757\u4e3a\u4e34\u5e8a\u533b\u751f\u63d0\u4f9b\u53ef\u7406\u89e3\u7684\u6587\u672c\u89e3\u91ca\uff0c\u63d0\u9ad8AI\u5728\u533b\u7597\u4e2d\u7684\u900f\u660e\u5ea6\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5728\u533b\u7597\u4fdd\u5065\u4e2d\u7684\u5e94\u7528\u867d\u7136\u80fd\u5b9e\u73b0\u4e2a\u6027\u5316\u62a4\u7406\uff0c\u4f46\u7531\u4e8e\u6a21\u578b\u4e0d\u900f\u660e\u6027\u5f15\u53d1\u4e86\u4fe1\u4efb\u95ee\u9898\u3002\u9700\u8981\u63d0\u9ad8AI\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\uff0c\u7279\u522b\u662f\u5728\u7259\u79d1\u5e74\u9f84\u4f30\u8ba1\u8fd9\u6837\u7684\u4e34\u5e8a\u5e94\u7528\u4e2d\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u4ece\u5168\u666f\u56fe\u50cf\u8fdb\u884c\u7259\u79d1\u5e74\u9f84\u4f30\u8ba1\u7684\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e86\u4e0d\u900f\u660e\u548c\u900f\u660e\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u751f\u6210\u6a21\u5757\u4ea7\u751f\u4e34\u5e8a\u533b\u751f\u53cb\u597d\u7684\u6587\u672c\u89e3\u91ca\u3002\u89e3\u91ca\u751f\u6210\u91c7\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\uff0c\u5e76\u4e0e\u7259\u79d1\u4e13\u5bb6\u5408\u4f5c\u8bbe\u8ba1\u3002\u4f7f\u7528\u95ee\u5377\u8c03\u67e5\u7531\u7259\u79d1\u4e13\u5bb6\u624b\u52a8\u9a8c\u8bc1\u751f\u6210\u89e3\u91ca\u7684\u8d28\u91cf\u3002", "result": "\u7259\u79d1\u4e13\u5bb6\u5728\u4e94\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u5e73\u5747\u8bc4\u5206\u4e3a4.77\u00b10.12\uff08\u6ee1\u52065\u5206\uff09\uff0c\u8868\u73b0\u51fa\u8272\u3002\u6309\u7167ALTAI\u6e05\u5355\u8fdb\u884c\u7684\u53ef\u4fe1\u5ea6\u81ea\u6211\u8bc4\u4f30\u5728\u4e03\u4e2a\u7ef4\u5ea6\u4e0a\u5f97\u5206\u4e3a4.40\u00b10.27\uff08\u6ee1\u52065\u5206\uff09\u3002", "conclusion": "\u63d0\u51fa\u7684\u7cfb\u7edf\u6210\u529f\u63d0\u9ad8\u4e86\u7259\u79d1\u5e74\u9f84\u4f30\u8ba1\u7684\u900f\u660e\u5ea6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u589e\u5f3a\u4e86\u4e34\u5e8a\u533b\u751f\u7684\u4fe1\u4efb\u3002\u4e13\u5bb6\u9a8c\u8bc1\u548cALTAI\u8bc4\u4f30\u8868\u660e\u8be5\u7cfb\u7edf\u5728\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4e3a\u533b\u7597AI\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13687", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13687", "abs": "https://arxiv.org/abs/2601.13687", "authors": ["Zhichao Liang", "Satoshi Nakamura"], "title": "Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue", "comment": null, "summary": "Existing dynamic Theory of Mind (ToM) benchmarks mostly place language models in a passive role: the model reads a sequence of connected scenarios and reports what people believe, feel, intend, and do as these states change. In real social interaction, ToM is also used for action: a speaker plans what to say in order to shift another person's mental-state trajectory toward a goal. We introduce SocialMindChange, a benchmark that moves from tracking minds to changing minds in social interaction. Each instance defines a social context with 4 characters and five connected scenes. The model plays one character and generates dialogue across the five scenes to reach the target while remaining consistent with the evolving states of all participants. SocialMindChange also includes selected higher-order states. Using a structured four-step framework, we construct 1,200 social contexts, covering 6000 scenarios and over 90,000 questions, each validated for realism and quality. Evaluations on ten state-of-the-art LLMs show that their average performance is 54.2% below human performance. This gap suggests that current LLMs still struggle to maintain and change mental-state representations across long, linked interactions.", "AI": {"tldr": "SocialMindChange\uff1a\u9996\u4e2a\u8bc4\u4f30LLM\u5728\u793e\u4ea4\u4e92\u52a8\u4e2d\u4e3b\u52a8\u6539\u53d8\u4ed6\u4eba\u5fc3\u7406\u72b6\u6001\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u5305\u542b1200\u4e2a\u793e\u4ea4\u573a\u666f\uff0c6000\u4e2a\u573a\u666f\u548c9\u4e07+\u95ee\u9898\uff0c\u663e\u793a\u5f53\u524dLLM\u8868\u73b0\u6bd4\u4eba\u7c7b\u4f4e54.2%", "motivation": "\u73b0\u6709\u52a8\u6001\u5fc3\u7406\u7406\u8bba\u57fa\u51c6\u4e3b\u8981\u8ba9\u8bed\u8a00\u6a21\u578b\u5904\u4e8e\u88ab\u52a8\u89d2\u8272\uff0c\u4ec5\u8ffd\u8e2a\u5fc3\u7406\u72b6\u6001\u53d8\u5316\u3002\u4f46\u5728\u771f\u5b9e\u793e\u4ea4\u4e92\u52a8\u4e2d\uff0c\u5fc3\u7406\u7406\u8bba\u4e5f\u7528\u4e8e\u4e3b\u52a8\u884c\u52a8\uff1a\u8bf4\u8bdd\u8005\u8ba1\u5212\u5982\u4f55\u8bf4\u8bdd\u4ee5\u6539\u53d8\u4ed6\u4eba\u7684\u5fc3\u7406\u72b6\u6001\u8f68\u8ff9\u3002\u9700\u8981\u4ece\u8ffd\u8e2a\u5fc3\u7406\u72b6\u6001\u8f6c\u5411\u6539\u53d8\u5fc3\u7406\u72b6\u6001\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u63d0\u51faSocialMindChange\u57fa\u51c6\uff0c\u6bcf\u4e2a\u5b9e\u4f8b\u5b9a\u4e49\u5305\u542b4\u4e2a\u89d2\u8272\u7684\u793e\u4ea4\u60c5\u5883\u548c5\u4e2a\u8fde\u63a5\u573a\u666f\u3002\u6a21\u578b\u626e\u6f14\u5176\u4e2d\u4e00\u4e2a\u89d2\u8272\uff0c\u5728\u4e94\u4e2a\u573a\u666f\u4e2d\u751f\u6210\u5bf9\u8bdd\u4ee5\u8fbe\u5230\u76ee\u6807\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6240\u6709\u53c2\u4e0e\u8005\u4e0d\u65ad\u53d8\u5316\u7684\u72b6\u6001\u4e00\u81f4\u3002\u91c7\u7528\u7ed3\u6784\u5316\u56db\u6b65\u6846\u67b6\u6784\u5efa1200\u4e2a\u793e\u4ea4\u60c5\u5883\uff0c\u8986\u76d66000\u4e2a\u573a\u666f\u548c\u8d85\u8fc79\u4e07\u4e2a\u95ee\u9898\uff0c\u6bcf\u4e2a\u90fd\u7ecf\u8fc7\u771f\u5b9e\u6027\u548c\u8d28\u91cf\u9a8c\u8bc1\u3002", "result": "\u5bf910\u4e2a\u6700\u5148\u8fdb\u7684LLM\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u5b83\u4eec\u7684\u5e73\u5747\u6027\u80fd\u6bd4\u4eba\u7c7b\u6027\u80fd\u4f4e54.2%\u3002\u8fd9\u8868\u660e\u5f53\u524dLLM\u5728\u957f\u671f\u8fde\u63a5\u4e92\u52a8\u4e2d\u7ef4\u6301\u548c\u6539\u53d8\u5fc3\u7406\u72b6\u6001\u8868\u5f81\u65b9\u9762\u4ecd\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "SocialMindChange\u57fa\u51c6\u586b\u8865\u4e86\u4ece\u88ab\u52a8\u8ffd\u8e2a\u5fc3\u7406\u72b6\u6001\u5230\u4e3b\u52a8\u6539\u53d8\u5fc3\u7406\u72b6\u6001\u7684\u8bc4\u4f30\u7a7a\u767d\u3002\u5f53\u524dLLM\u5728\u590d\u6742\u793e\u4ea4\u4e92\u52a8\u4e2d\u7684\u5fc3\u7406\u7406\u8bba\u80fd\u529b\u4ecd\u6709\u663e\u8457\u5dee\u8ddd\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u5347\u6a21\u578b\u5728\u52a8\u6001\u793e\u4ea4\u60c5\u5883\u4e2d\u7684\u4e3b\u52a8\u5fc3\u7406\u72b6\u6001\u64cd\u4f5c\u80fd\u529b\u3002"}}
{"id": "2601.12973", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12973", "abs": "https://arxiv.org/abs/2601.12973", "authors": ["Shuanghong Huang", "Jinlei Xu", "Youchao Zhou", "Yanghao Zhou", "Xuan Zhao", "Chong Feng", "Wenxuan Zhang"], "title": "Pardon? Evaluating Conversational Repair in Large Audio-Language Models", "comment": null, "summary": "Large Audio-Language Models (LALMs) have demonstrated strong performance in spoken question answering (QA), with existing evaluations primarily focusing on answer accuracy and robustness to acoustic perturbations. However, such evaluations implicitly assume that spoken inputs remain semantically answerable, an assumption that often fails in real-world interaction when essential information is missing. In this work, we introduce a repair-aware evaluation setting that explicitly distinguishes between answerable and unanswerable audio inputs. We define answerability as a property of the input itself and construct paired evaluation conditions using a semantic-acoustic masking protocol. Based on this setting, we propose the Evaluability Awareness and Repair (EAR) score, a non-compensatory metric that jointly evaluates task competence under answerable conditions and repair behavior under unanswerable conditions. Experiments on two spoken QA benchmarks across diverse LALMs reveal a consistent gap between answer accuracy and conversational reliability: while many models perform well when inputs are answerable, most fail to recognize semantic unanswerability and initiate appropriate conversational repair. These findings expose a limitation of prevailing accuracy-centric evaluation practices and motivate reliability assessments that treat unanswerable inputs as cues for repair and continued interaction.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4fee\u590d\u611f\u77e5\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u5728\u53ef\u56de\u7b54\u4e0e\u4e0d\u53ef\u56de\u7b54\u97f3\u9891\u8f93\u5165\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u5f15\u5165EAR\u8bc4\u5206\u6765\u8054\u5408\u8bc4\u4f30\u4efb\u52a1\u80fd\u529b\u548c\u4fee\u590d\u884c\u4e3a", "motivation": "\u73b0\u6709\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u7b54\u6848\u51c6\u786e\u6027\u548c\u58f0\u5b66\u6270\u52a8\u9c81\u68d2\u6027\uff0c\u4f46\u5047\u8bbe\u8bed\u97f3\u8f93\u5165\u5728\u8bed\u4e49\u4e0a\u603b\u662f\u53ef\u56de\u7b54\u7684\u3002\u7136\u800c\u73b0\u5b9e\u4ea4\u4e92\u4e2d\u5e38\u51fa\u73b0\u4fe1\u606f\u7f3a\u5931\u5bfc\u81f4\u4e0d\u53ef\u56de\u7b54\u7684\u60c5\u51b5\uff0c\u9700\u8981\u8bc4\u4f30\u6a21\u578b\u8bc6\u522b\u4e0d\u53ef\u56de\u7b54\u6027\u5e76\u542f\u52a8\u9002\u5f53\u5bf9\u8bdd\u4fee\u590d\u7684\u80fd\u529b", "method": "1) \u5f15\u5165\u4fee\u590d\u611f\u77e5\u8bc4\u4f30\u8bbe\u7f6e\uff0c\u660e\u786e\u533a\u5206\u53ef\u56de\u7b54\u548c\u4e0d\u53ef\u56de\u7b54\u97f3\u9891\u8f93\u5165\uff1b2) \u5c06\u53ef\u56de\u7b54\u6027\u5b9a\u4e49\u4e3a\u8f93\u5165\u672c\u8eab\u7684\u5c5e\u6027\uff1b3) \u4f7f\u7528\u8bed\u4e49-\u58f0\u5b66\u63a9\u853d\u534f\u8bae\u6784\u5efa\u914d\u5bf9\u8bc4\u4f30\u6761\u4ef6\uff1b4) \u63d0\u51faEAR\u8bc4\u5206\uff0c\u8fd9\u662f\u4e00\u4e2a\u975e\u8865\u507f\u6027\u6307\u6807\uff0c\u8054\u5408\u8bc4\u4f30\u53ef\u56de\u7b54\u6761\u4ef6\u4e0b\u7684\u4efb\u52a1\u80fd\u529b\u548c\u4e0d\u53ef\u56de\u7b54\u6761\u4ef6\u4e0b\u7684\u4fee\u590d\u884c\u4e3a", "result": "\u5728\u4e24\u4e2a\u8bed\u97f3\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5b9e\u9a8c\u663e\u793a\u7b54\u6848\u51c6\u786e\u6027\u548c\u5bf9\u8bdd\u53ef\u9760\u6027\u4e4b\u95f4\u5b58\u5728\u4e00\u81f4\u5dee\u8ddd\uff1a\u8bb8\u591a\u6a21\u578b\u5728\u8f93\u5165\u53ef\u56de\u7b54\u65f6\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5927\u591a\u6570\u65e0\u6cd5\u8bc6\u522b\u8bed\u4e49\u4e0d\u53ef\u56de\u7b54\u6027\u5e76\u542f\u52a8\u9002\u5f53\u7684\u5bf9\u8bdd\u4fee\u590d", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524d\u4ee5\u51c6\u786e\u6027\u4e3a\u4e2d\u5fc3\u7684\u8bc4\u4f30\u5b9e\u8df5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u6fc0\u52b1\u5f00\u53d1\u5c06\u4e0d\u53ef\u56de\u7b54\u8f93\u5165\u89c6\u4e3a\u4fee\u590d\u548c\u6301\u7eed\u4ea4\u4e92\u7ebf\u7d22\u7684\u53ef\u9760\u6027\u8bc4\u4f30\u65b9\u6cd5"}}
{"id": "2601.13709", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.HC", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.13709", "abs": "https://arxiv.org/abs/2601.13709", "authors": ["Christopher Kao", "Vanshika Vats", "James Davis"], "title": "Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games", "comment": "For associated dataset, see https://github.com/cocochief4/llm-mafia. Published in IEEE ICA 2025, waiting for IEEEXplore proceedings", "summary": "Large Language Model (LLM) agents are increasingly used in many applications, raising concerns about their safety. While previous work has shown that LLMs can deceive in controlled tasks, less is known about their ability to deceive using natural language in social contexts. In this paper, we study deception in the Social Deduction Game (SDG) Mafia, where success is dependent on deceiving others through conversation. Unlike previous SDG studies, we use an asynchronous multi-agent framework which better simulates realistic social contexts. We simulate 35 Mafia games with GPT-4o LLM agents. We then create a Mafia Detector using GPT-4-Turbo to analyze game transcripts without player role information to predict the mafia players. We use prediction accuracy as a surrogate marker for deception quality. We compare this prediction accuracy to that of 28 human games and a random baseline. Results show that the Mafia Detector's mafia prediction accuracy is lower on LLM games than on human games. The result is consistent regardless of the game days and the number of mafias detected. This indicates that LLMs blend in better and thus deceive more effectively. We also release a dataset of LLM Mafia transcripts to support future research. Our findings underscore both the sophistication and risks of LLM deception in social contexts.", "AI": {"tldr": "GPT-4o\u5728\u793e\u4ea4\u63a8\u7406\u6e38\u620f\u300a\u9ed1\u624b\u515a\u300b\u4e2d\u6bd4\u4eba\u7c7b\u66f4\u64c5\u957f\u6b3a\u9a97\uff0c\u901a\u8fc7\u5f02\u6b65\u591a\u667a\u80fd\u4f53\u6846\u67b6\u6a21\u62df\u663e\u793a\uff0c\u68c0\u6d4b\u5668\u5bf9LLM\u6e38\u620f\u7684\u9884\u6d4b\u51c6\u786e\u7387\u4f4e\u4e8e\u4eba\u7c7b\u6e38\u620f\u3002", "motivation": "\u7814\u7a76LLM\u5728\u81ea\u7136\u8bed\u8a00\u793e\u4ea4\u73af\u5883\u4e2d\u7684\u6b3a\u9a97\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u793e\u4ea4\u63a8\u7406\u6e38\u620f\u300a\u9ed1\u624b\u515a\u300b\u4e2d\uff0c\u56e0\u4e3a\u8fd9\u7c7b\u6e38\u620f\u7684\u6210\u529f\u4f9d\u8d56\u4e8e\u901a\u8fc7\u5bf9\u8bdd\u6b3a\u9a97\u4ed6\u4eba\uff0c\u800c\u4e4b\u524d\u7684\u7814\u7a76\u8f83\u5c11\u5173\u6ce8LLM\u5728\u771f\u5b9e\u793e\u4ea4\u60c5\u5883\u4e2d\u7684\u6b3a\u9a97\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u5f02\u6b65\u591a\u667a\u80fd\u4f53\u6846\u67b6\u6a21\u62df35\u573a\u300a\u9ed1\u624b\u515a\u300b\u6e38\u620f\uff0c\u91c7\u7528GPT-4o\u4f5c\u4e3a\u667a\u80fd\u4f53\u3002\u521b\u5efa\u57fa\u4e8eGPT-4-Turbo\u7684\"\u9ed1\u624b\u515a\u68c0\u6d4b\u5668\"\uff0c\u5728\u4e0d\u63d0\u4f9b\u73a9\u5bb6\u89d2\u8272\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u5206\u6790\u6e38\u620f\u8bb0\u5f55\uff0c\u9884\u6d4b\u9ed1\u624b\u515a\u73a9\u5bb6\u3002\u5c06\u9884\u6d4b\u51c6\u786e\u7387\u4f5c\u4e3a\u6b3a\u9a97\u8d28\u91cf\u7684\u66ff\u4ee3\u6307\u6807\uff0c\u5e76\u4e0e28\u573a\u4eba\u7c7b\u6e38\u620f\u548c\u968f\u673a\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u9ed1\u624b\u515a\u68c0\u6d4b\u5668\u5bf9LLM\u6e38\u620f\u7684\u9884\u6d4b\u51c6\u786e\u7387\u4f4e\u4e8e\u5bf9\u4eba\u7c7b\u6e38\u620f\u7684\u9884\u6d4b\u51c6\u786e\u7387\u3002\u8fd9\u4e00\u7ed3\u679c\u5728\u4e0d\u540c\u6e38\u620f\u5929\u6570\u548c\u68c0\u6d4b\u5230\u7684\u9ed1\u624b\u515a\u6570\u91cf\u4e0a\u4fdd\u6301\u4e00\u81f4\uff0c\u8868\u660eLLM\u80fd\u66f4\u597d\u5730\u878d\u5165\u7fa4\u4f53\uff0c\u4ece\u800c\u66f4\u6709\u6548\u5730\u8fdb\u884c\u6b3a\u9a97\u3002", "conclusion": "LLM\u5728\u793e\u4ea4\u73af\u5883\u4e2d\u7684\u6b3a\u9a97\u80fd\u529b\u6bd4\u4eba\u7c7b\u66f4\u6709\u6548\uff0c\u8fd9\u7a81\u663e\u4e86LLM\u6b3a\u9a97\u7684\u590d\u6742\u6027\u548c\u98ce\u9669\u3002\u7814\u7a76\u56e2\u961f\u53d1\u5e03\u4e86LLM\u300a\u9ed1\u624b\u515a\u300b\u6e38\u620f\u8bb0\u5f55\u6570\u636e\u96c6\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2601.13752", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13752", "abs": "https://arxiv.org/abs/2601.13752", "authors": ["Chak Tou Leong", "Dingwei Chen", "Heming Xia", "Qingyu Yin", "Sunbowen Lee", "Jian Wang", "Wenjie Li"], "title": "Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering", "comment": "Working in progress", "summary": "Large reasoning models (LRMs) have achieved remarkable success in complex problem-solving, yet they often suffer from computational redundancy or reasoning unfaithfulness. Current methods for shaping LRM behavior typically rely on reinforcement learning or fine-tuning with gold-standard reasoning traces, a paradigm that is both computationally expensive and difficult to scale. In this paper, we reveal that LRMs possess latent \\textit{reasoning beliefs} that internally track their own reasoning traits, which can be captured through simple logit probing. Building upon this insight, we propose Reasoning Belief Engineering (RELIEF), a simple yet effective framework that shapes LRM behavior by aligning the model's self-concept with a target belief blueprint. Crucially, RELIEF completely bypasses the need for reasoning-trace supervision. It internalizes desired traits by fine-tuning on synthesized, self-reflective question-answering pairs that affirm the target belief. Extensive experiments on efficiency and faithfulness tasks demonstrate that RELIEF matches or outperforms behavior-supervised and preference-based baselines while requiring lower training costs. Further analysis validates that shifting a model's reasoning belief effectively shapes its actual behavior.", "AI": {"tldr": "RELIEF\u6846\u67b6\u901a\u8fc7\u8c03\u6574\u5927\u63a8\u7406\u6a21\u578b\u7684\u81ea\u6211\u6982\u5ff5\u6765\u5851\u9020\u5176\u884c\u4e3a\uff0c\u65e0\u9700\u63a8\u7406\u8f68\u8ff9\u76d1\u7763\uff0c\u964d\u4f4e\u4e86\u8bad\u7ec3\u6210\u672c", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5b58\u5728\u8ba1\u7b97\u5197\u4f59\u548c\u63a8\u7406\u4e0d\u5fe0\u5b9e\u7684\u95ee\u9898\uff0c\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u6216\u9ec4\u91d1\u63a8\u7406\u8f68\u8ff9\u5fae\u8c03\u7684\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6269\u5c55", "method": "\u63d0\u51faRELIEF\u6846\u67b6\uff0c\u901a\u8fc7\u7b80\u5355\u7684logit\u63a2\u6d4b\u6355\u83b7\u6a21\u578b\u7684\u6f5c\u5728\u63a8\u7406\u4fe1\u5ff5\uff0c\u7136\u540e\u901a\u8fc7\u5fae\u8c03\u4f7f\u6a21\u578b\u7684\u81ea\u6211\u6982\u5ff5\u4e0e\u76ee\u6807\u4fe1\u5ff5\u84dd\u56fe\u5bf9\u9f50\uff0c\u4f7f\u7528\u5408\u6210\u7684\u81ea\u53cd\u95ee\u7b54\u5bf9\u8fdb\u884c\u8bad\u7ec3", "result": "\u5728\u6548\u7387\u548c\u5fe0\u5b9e\u6027\u4efb\u52a1\u4e0a\uff0cRELIEF\u5339\u914d\u6216\u4f18\u4e8e\u57fa\u4e8e\u884c\u4e3a\u76d1\u7763\u548c\u504f\u597d\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u8bad\u7ec3\u6210\u672c\u66f4\u4f4e\uff1b\u5206\u6790\u9a8c\u8bc1\u4e86\u8c03\u6574\u63a8\u7406\u4fe1\u5ff5\u80fd\u6709\u6548\u5851\u9020\u5b9e\u9645\u884c\u4e3a", "conclusion": "RELIEF\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8c03\u6574\u6a21\u578b\u7684\u81ea\u6211\u6982\u5ff5\u6765\u5851\u9020\u5176\u63a8\u7406\u884c\u4e3a\uff0c\u65e0\u9700\u6602\u8d35\u7684\u63a8\u7406\u8f68\u8ff9\u76d1\u7763\uff0c\u5177\u6709\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027"}}
{"id": "2601.12983", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12983", "abs": "https://arxiv.org/abs/2601.12983", "authors": ["Jesus-German Ortiz-Barajas", "Jonathan Tonglet", "Vivek Gupta", "Iryna Gurevych"], "title": "ChartAttack: Testing the Vulnerability of LLMs to Malicious Prompting in Chart Generation", "comment": null, "summary": "Multimodal large language models (MLLMs) are increasingly used to automate chart generation from data tables, enabling efficient data analysis and reporting but also introducing new misuse risks. In this work, we introduce ChartAttack, a novel framework for evaluating how MLLMs can be misused to generate misleading charts at scale. ChartAttack injects misleaders into chart designs, aiming to induce incorrect interpretations of the underlying data. Furthermore, we create AttackViz, a chart question-answering (QA) dataset where each (chart specification, QA) pair is labeled with effective misleaders and their induced incorrect answers. Experiments in in-domain and cross-domain settings show that ChartAttack significantly degrades the QA performance of MLLM readers, reducing accuracy by an average of 19.6 points and 14.9 points, respectively. A human study further shows an average 20.2 point drop in accuracy for participants exposed to misleading charts generated by ChartAttack. Our findings highlight an urgent need for robustness and security considerations in the design, evaluation, and deployment of MLLM-based chart generation systems. We make our code and data publicly available.", "AI": {"tldr": "ChartAttack\u6846\u67b6\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8bef\u5bfc\u6027\u56fe\u8868\u7684\u98ce\u9669\uff0c\u901a\u8fc7\u6ce8\u5165\u8bef\u5bfc\u5143\u7d20\u964d\u4f4e\u56fe\u8868\u95ee\u7b54\u51c6\u786e\u6027", "motivation": "\u968f\u7740MLLMs\u88ab\u5e7f\u6cdb\u7528\u4e8e\u4ece\u6570\u636e\u8868\u81ea\u52a8\u751f\u6210\u56fe\u8868\uff0c\u867d\u7136\u63d0\u9ad8\u4e86\u6570\u636e\u5206\u6790\u6548\u7387\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u65b0\u7684\u6ee5\u7528\u98ce\u9669\uff0c\u9700\u8981\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u88ab\u7528\u4e8e\u5927\u89c4\u6a21\u751f\u6210\u8bef\u5bfc\u6027\u56fe\u8868\u7684\u53ef\u80fd\u6027", "method": "\u63d0\u51faChartAttack\u6846\u67b6\uff0c\u901a\u8fc7\u5411\u56fe\u8868\u8bbe\u8ba1\u4e2d\u6ce8\u5165\u8bef\u5bfc\u5143\u7d20\u6765\u8bf1\u5bfc\u5bf9\u5e95\u5c42\u6570\u636e\u7684\u9519\u8bef\u89e3\u8bfb\uff1b\u521b\u5efaAttackViz\u6570\u636e\u96c6\uff0c\u5305\u542b\u6807\u6ce8\u4e86\u6709\u6548\u8bef\u5bfc\u5143\u7d20\u53ca\u5176\u8bf1\u5bfc\u9519\u8bef\u7b54\u6848\u7684\u56fe\u8868\u89c4\u8303-QA\u5bf9", "result": "\u5b9e\u9a8c\u663e\u793aChartAttack\u663e\u8457\u964d\u4f4eMLLM\u9605\u8bfb\u5668\u7684QA\u6027\u80fd\uff1a\u57df\u5185\u8bbe\u7f6e\u5e73\u5747\u964d\u4f4e19.6\u4e2a\u767e\u5206\u70b9\uff0c\u8de8\u57df\u8bbe\u7f6e\u5e73\u5747\u964d\u4f4e14.9\u4e2a\u767e\u5206\u70b9\uff1b\u4eba\u7c7b\u7814\u7a76\u663e\u793a\u53c2\u4e0e\u8005\u9762\u5bf9\u8bef\u5bfc\u6027\u56fe\u8868\u65f6\u51c6\u786e\u6027\u5e73\u5747\u4e0b\u964d20.2\u4e2a\u767e\u5206\u70b9", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728MLLM\u56fe\u8868\u751f\u6210\u7cfb\u7edf\u7684\u8bbe\u8ba1\u3001\u8bc4\u4f30\u548c\u90e8\u7f72\u4e2d\u8feb\u5207\u9700\u8981\u52a0\u5f3a\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u8003\u8651"}}
{"id": "2601.13761", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13761", "abs": "https://arxiv.org/abs/2601.13761", "authors": ["Shengda Fan", "Xuyan Ye", "Yankai Lin"], "title": "DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution", "comment": null, "summary": "Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Solver. To mitigate these challenges, we introduce DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. First, we train the Questioner to synthesize difficulty-calibrated questions, conditioned on explicit difficulty levels and external corpora. Second, we train the Solver with an asymmetric self-distillation mechanism, where a document-augmented teacher generates high-quality pseudo-labels to supervise the student Solver that lacks document access. Empirical results demonstrate that DARC is model-agnostic, yielding an average improvement of 10.9 points across nine reasoning benchmarks and three backbone models. Moreover, DARC consistently outperforms all baselines and approaches the performance of fully supervised models without relying on human annotations. The code is available at https://github.com/RUCBM/DARC.", "code_url": "https://github.com/RUCBM/DARC", "code_stars": 5, "code_last_update": "2026-01-20", "AI": {"tldr": "DARC\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u81ea\u8fdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u975e\u5bf9\u79f0\u63a8\u7406\u8bfe\u7a0b\u89e3\u51b3\u81ea\u5bf9\u5f08\u4e2d\u4f18\u5316\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u5728\u65e0\u4eba\u5de5\u6807\u6ce8\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u5347\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709\u81ea\u5bf9\u5f08\u6846\u67b6\u5b58\u5728\u4f18\u5316\u4e0d\u7a33\u5b9a\u95ee\u9898\uff1a(1) \u63d0\u95ee\u8005\u4f9d\u8d56\u6c42\u89e3\u5668\u53cd\u9988\u5bfc\u81f4\u76ee\u6807\u975e\u5e73\u7a33\uff1b(2) \u6c42\u89e3\u5668\u4f7f\u7528\u81ea\u751f\u6210\u4f2a\u6807\u7b7e\u5b58\u5728\u81ea\u4e3e\u8bef\u5dee\u3002\u9700\u8981\u7a33\u5b9a\u81ea\u8fdb\u5316\u8fc7\u7a0b", "method": "\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) \u8bad\u7ec3\u63d0\u95ee\u8005\u57fa\u4e8e\u660e\u786e\u96be\u5ea6\u7ea7\u522b\u548c\u5916\u90e8\u8bed\u6599\u5408\u6210\u96be\u5ea6\u6821\u51c6\u95ee\u9898\uff1b2) \u8bad\u7ec3\u6c42\u89e3\u5668\u91c7\u7528\u975e\u5bf9\u79f0\u81ea\u84b8\u998f\u673a\u5236\uff0c\u6587\u6863\u589e\u5f3a\u6559\u5e08\u751f\u6210\u9ad8\u8d28\u91cf\u4f2a\u6807\u7b7e\u76d1\u7763\u65e0\u6587\u6863\u8bbf\u95ee\u7684\u5b66\u751f\u6c42\u89e3\u5668", "result": "DARC\u5177\u6709\u6a21\u578b\u65e0\u5173\u6027\uff0c\u57289\u4e2a\u63a8\u7406\u57fa\u51c6\u548c3\u4e2a\u9aa8\u5e72\u6a21\u578b\u4e0a\u5e73\u5747\u63d0\u534710.9\u5206\uff0c\u6301\u7eed\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\uff0c\u63a5\u8fd1\u5b8c\u5168\u76d1\u7763\u6a21\u578b\u6027\u80fd\u4e14\u65e0\u9700\u4eba\u5de5\u6807\u6ce8", "conclusion": "DARC\u901a\u8fc7\u89e3\u8026\u63d0\u95ee\u8005\u548c\u6c42\u89e3\u5668\u8bad\u7ec3\u3001\u5f15\u5165\u96be\u5ea6\u6821\u51c6\u548c\u975e\u5bf9\u79f0\u81ea\u84b8\u998f\uff0c\u6709\u6548\u7a33\u5b9a\u81ea\u8fdb\u5316\u8fc7\u7a0b\uff0c\u4e3a\u65e0\u76d1\u7763\u63a8\u7406\u80fd\u529b\u63d0\u5347\u63d0\u4f9b\u6709\u6548\u6846\u67b6"}}
{"id": "2601.12995", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12995", "abs": "https://arxiv.org/abs/2601.12995", "authors": ["Runxuan Liu", "Xianhao Ou", "Xinyan Ma", "Jiyuan Wang", "Jiafeng Liang", "Jiaqi Li", "Tao He", "Zheng Chu", "Rongchuan Mu", "Zekun Wang", "Baoxin Wang", "Dayong Wu", "Ming Liu", "Shijin Wang", "Guoping Hu", "Bing Qin"], "title": "Graph Reasoning Paradigm: Structured and Symbolic Reasoning with Topology-Aware Reinforcement Learning for Large Language Models", "comment": null, "summary": "Long Chain-of-Thought (LCoT), achieved by Reinforcement Learning with Verifiable Rewards (RLVR), has proven effective in enhancing the reasoning capabilities of Large Language Models (LLMs). However, reasoning in current LLMs is primarily generated as plain text, where performing semantic evaluation on such unstructured data creates a computational bottleneck during training. Despite RLVR-based optimization, existing methods still suffer from coarse-grained supervision, reward hacking, high training costs, and poor generalization. To address these issues, we propose the Graph Reasoning Paradigm (GRP), which realizes structured and symbolic reasoning, implemented via graph-structured representations with step-level cognitive labels. Building upon GRP, we further design Process-Aware Stratified Clipping Group Relative Policy Optimization (PASC-GRPO), which leverages structured evaluation to replace semantic evaluation, achieves process-aware verification through graph-structured outcome rewards, and mitigates reward hacking via stratified clipping advantage estimation. Experiments demonstrate significant improvements across mathematical reasoning and code generation tasks. Data, models, and code will be released later.", "AI": {"tldr": "\u63d0\u51fa\u56fe\u63a8\u7406\u8303\u5f0f(GRP)\u548c\u8fc7\u7a0b\u611f\u77e5\u5206\u5c42\u88c1\u526a\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(PASC-GRPO)\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u56fe\u8868\u793a\u66ff\u4ee3\u975e\u7ed3\u6784\u5316\u6587\u672c\u63a8\u7406\uff0c\u89e3\u51b3\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u9a8c\u8bc1\u5956\u52b1\u65b9\u6cd5\u4e2d\u7684\u8ba1\u7b97\u74f6\u9888\u3001\u76d1\u7763\u7c92\u5ea6\u7c97\u3001\u5956\u52b1\u653b\u51fb\u7b49\u95ee\u9898\u3002", "motivation": "\u5f53\u524dLLMs\u7684\u63a8\u7406\u4e3b\u8981\u751f\u6210\u7eaf\u6587\u672c\uff0c\u5bf9\u975e\u7ed3\u6784\u5316\u6570\u636e\u8fdb\u884c\u8bed\u4e49\u8bc4\u4f30\u4f1a\u5728\u8bad\u7ec3\u4e2d\u4ea7\u751f\u8ba1\u7b97\u74f6\u9888\u3002\u5c3d\u7ba1\u6709RLVR\u4f18\u5316\uff0c\u73b0\u6709\u65b9\u6cd5\u4ecd\u5b58\u5728\u76d1\u7763\u7c92\u5ea6\u7c97\u3001\u5956\u52b1\u653b\u51fb\u3001\u8bad\u7ec3\u6210\u672c\u9ad8\u548c\u6cdb\u5316\u6027\u5dee\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u56fe\u63a8\u7406\u8303\u5f0f(GRP)\uff0c\u5b9e\u73b0\u7ed3\u6784\u5316\u548c\u7b26\u53f7\u5316\u63a8\u7406\uff0c\u901a\u8fc7\u5e26\u6b65\u9aa4\u7ea7\u8ba4\u77e5\u6807\u7b7e\u7684\u56fe\u7ed3\u6784\u8868\u793a\u3002\u5728\u6b64\u57fa\u7840\u4e0a\u8bbe\u8ba1PASC-GRPO\uff1a1)\u7528\u7ed3\u6784\u5316\u8bc4\u4f30\u66ff\u4ee3\u8bed\u4e49\u8bc4\u4f30\uff1b2)\u901a\u8fc7\u56fe\u7ed3\u6784\u7ed3\u679c\u5956\u52b1\u5b9e\u73b0\u8fc7\u7a0b\u611f\u77e5\u9a8c\u8bc1\uff1b3)\u901a\u8fc7\u5206\u5c42\u88c1\u526a\u4f18\u52bf\u4f30\u8ba1\u7f13\u89e3\u5956\u52b1\u653b\u51fb\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u3002\u6570\u636e\u3001\u6a21\u578b\u548c\u4ee3\u7801\u5c06\u540e\u7eed\u53d1\u5e03\u3002", "conclusion": "GRP\u548cPASC-GRPO\u901a\u8fc7\u7ed3\u6784\u5316\u63a8\u7406\u8868\u793a\u548c\u8fc7\u7a0b\u611f\u77e5\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f53\u524dRLVR\u65b9\u6cd5\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u63d0\u5347\u4e86LLMs\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2601.13770", "categories": ["cs.AI", "cs.CL", "cs.LG", "q-fin.CP", "q-fin.GN"], "pdf": "https://arxiv.org/pdf/2601.13770", "abs": "https://arxiv.org/abs/2601.13770", "authors": ["Mostapha Benhenda"], "title": "Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance", "comment": null, "summary": "We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench", "code_url": "https://github.com/benstaf/lookaheadbench", "code_stars": 0, "code_last_update": "2026-01-16", "AI": {"tldr": "\u63d0\u51fa\u4e86Look-Ahead-Bench\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u91d1\u878d\u5de5\u4f5c\u6d41\u4e2dPiT LLMs\u7684\u524d\u77bb\u6027\u504f\u5dee\uff0c\u901a\u8fc7\u5b9e\u9645\u573a\u666f\u6d4b\u8bd5\u800c\u975e\u7b80\u5355\u7684\u95ee\u7b54\uff0c\u5e76\u5f15\u5165\u6027\u80fd\u8870\u51cf\u5206\u6790\u6765\u533a\u5206\u771f\u5b9e\u9884\u6d4b\u80fd\u529b\u4e0e\u8bb0\u5fc6\u6548\u5e94\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u901a\u8fc7\u5728\u95ee\u7b54\u4e2d\u6d4b\u8bd5\u5185\u90e8\u524d\u77bb\u77e5\u8bc6\u6765\u8bc4\u4f30LLMs\uff0c\u7f3a\u4e4f\u5bf9\u5b9e\u9645\u91d1\u878d\u5de5\u4f5c\u6d41\u4e2d\u6a21\u578b\u884c\u4e3a\u7684\u8bc4\u4f30\u3002\u9700\u8981\u5efa\u7acb\u6807\u51c6\u5316\u57fa\u51c6\u6765\u6d4b\u91cfPiT LLMs\u4e2d\u7684\u524d\u77bb\u6027\u504f\u5dee\uff0c\u5e76\u533a\u5206\u6a21\u578b\u7684\u771f\u5b9e\u9884\u6d4b\u80fd\u529b\u4e0e\u57fa\u4e8e\u8bb0\u5fc6\u7684\u6027\u80fd\u3002", "method": "\u521b\u5efaLook-Ahead-Bench\u57fa\u51c6\uff0c\u5728\u73b0\u5b9e\u91d1\u878d\u5de5\u4f5c\u6d41\u573a\u666f\u4e2d\u8bc4\u4f30\u6a21\u578b\u884c\u4e3a\u3002\u901a\u8fc7\u5206\u6790\u4e0d\u540c\u65f6\u95f4\u5e02\u573a\u673a\u5236\u4e0b\u7684\u6027\u80fd\u8870\u51cf\u6765\u533a\u5206\u771f\u5b9e\u9884\u6d4b\u4e0e\u8bb0\u5fc6\u6548\u5e94\uff0c\u5e76\u5f15\u5165\u591a\u4e2a\u91cf\u5316\u57fa\u7ebf\u5efa\u7acb\u6027\u80fd\u9608\u503c\u3002\u8bc4\u4f30\u4e86\u5f00\u6e90LLMs\uff08Llama 3.1 8B/70B\u548cDeepSeek 3.2\uff09\u4e0ePiT-Inference\u7684PiT LLMs\u7cfb\u5217\uff08Pitinf-Small, Pitinf-Medium, Pitinf-Large\uff09\u3002", "result": "\u6807\u51c6LLMs\u663e\u793a\u51fa\u663e\u8457\u7684\u524d\u77bb\u6027\u504f\u5dee\uff08\u901a\u8fc7alpha\u8870\u51cf\u6d4b\u91cf\uff09\uff0c\u800cPitinf\u6a21\u578b\u968f\u7740\u89c4\u6a21\u589e\u5927\u8868\u73b0\u51fa\u6539\u8fdb\u7684\u6cdb\u5316\u80fd\u529b\u548c\u63a8\u7406\u80fd\u529b\u3002Pitinf\u6a21\u578b\u5728\u4e0d\u540c\u65f6\u95f4\u5e02\u573a\u673a\u5236\u4e0b\u6027\u80fd\u8870\u51cf\u8f83\u5c0f\uff0c\u8868\u660e\u5176\u5177\u6709\u66f4\u597d\u7684\u771f\u5b9e\u9884\u6d4b\u80fd\u529b\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u91d1\u878dLLMs\u4e2d\u65f6\u95f4\u504f\u5dee\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86\u8bc6\u522b\u9002\u5408\u5b9e\u9645\u90e8\u7f72\u6a21\u578b\u7684\u5b9e\u7528\u6846\u67b6\u3002Pitinf\u6a21\u578b\u5728\u51cf\u5c11\u524d\u77bb\u6027\u504f\u5dee\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u91d1\u878d\u9886\u57dfLLMs\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u9009\u62e9\u3002"}}
{"id": "2601.13018", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13018", "abs": "https://arxiv.org/abs/2601.13018", "authors": ["Ghislain Dorian Tchuente Mondjo"], "title": "Bi-Attention HateXplain : Taking into account the sequential aspect of data during explainability in a multi-task context", "comment": "Accepted at \"EAI AFRICOMM 2025 - 17th EAI International Conference on Communications and Networks in Africa\"", "summary": "Technological advances in the Internet and online social networks have brought many benefits to humanity. At the same time, this growth has led to an increase in hate speech, the main global threat. To improve the reliability of black-box models used for hate speech detection, post-hoc approaches such as LIME, SHAP, and LRP provide the explanation after training the classification model. In contrast, multi-task approaches based on the HateXplain benchmark learn to explain and classify simultaneously. However, results from HateXplain-based algorithms show that predicted attention varies considerably when it should be constant. This attention variability can lead to inconsistent interpretations, instability of predictions, and learning difficulties. To solve this problem, we propose the BiAtt-BiRNN-HateXplain (Bidirectional Attention BiRNN HateXplain) model which is easier to explain compared to LLMs which are more complex in view of the need for transparency, and will take into account the sequential aspect of the input data during explainability thanks to a BiRNN layer. Thus, if the explanation is correctly estimated, thanks to multi-task learning (explainability and classification task), the model could classify better and commit fewer unintentional bias errors related to communities. The experimental results on HateXplain data show a clear improvement in detection performance, explainability and a reduction in unintentional bias.", "AI": {"tldr": "\u63d0\u51faBiAtt-BiRNN-HateXplain\u6a21\u578b\uff0c\u901a\u8fc7\u53cc\u5411\u6ce8\u610f\u529b\u673a\u5236\u548c\u53cc\u5411RNN\u5c42\u6539\u8fdb\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u51cf\u5c11\u6ce8\u610f\u529b\u53d8\u5f02\u6027\u548c\u65e0\u610f\u8bc6\u504f\u89c1", "motivation": "\u73b0\u6709\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u6a21\u578b\u5b58\u5728\u6ce8\u610f\u529b\u53d8\u5f02\u95ee\u9898\uff0c\u5bfc\u81f4\u89e3\u91ca\u4e0d\u4e00\u81f4\u3001\u9884\u6d4b\u4e0d\u7a33\u5b9a\u548c\u5b66\u4e60\u56f0\u96be\u3002\u9ed1\u76d2\u6a21\u578b\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u800cHateXplain\u57fa\u51c6\u7684\u591a\u4efb\u52a1\u65b9\u6cd5\u867d\u7136\u540c\u65f6\u5b66\u4e60\u89e3\u91ca\u548c\u5206\u7c7b\uff0c\u4f46\u6ce8\u610f\u529b\u9884\u6d4b\u53d8\u5316\u8f83\u5927\u3002\u9700\u8981\u66f4\u7a33\u5b9a\u3001\u53ef\u89e3\u91ca\u4e14\u80fd\u5904\u7406\u5e8f\u5217\u6570\u636e\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51faBiAtt-BiRNN-HateXplain\u6a21\u578b\uff1a1) \u4f7f\u7528\u53cc\u5411\u6ce8\u610f\u529b\u673a\u5236\u6539\u8fdb\u53ef\u89e3\u91ca\u6027\uff1b2) \u901a\u8fc7BiRNN\u5c42\u8003\u8651\u8f93\u5165\u6570\u636e\u7684\u5e8f\u5217\u7279\u6027\uff1b3) \u91c7\u7528\u591a\u4efb\u52a1\u5b66\u4e60\u540c\u65f6\u8fdb\u884c\u89e3\u91ca\u548c\u5206\u7c7b\uff1b4) \u76f8\u6bd4\u590d\u6742\u7684LLMs\u66f4\u6613\u89e3\u91ca\u4e14\u900f\u660e", "result": "\u5728HateXplain\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a1) \u68c0\u6d4b\u6027\u80fd\u660e\u663e\u63d0\u5347\uff1b2) \u53ef\u89e3\u91ca\u6027\u6539\u5584\uff1b3) \u65e0\u610f\u8bc6\u504f\u89c1\u51cf\u5c11\uff1b4) \u89e3\u51b3\u4e86\u6ce8\u610f\u529b\u53d8\u5f02\u95ee\u9898", "conclusion": "BiAtt-BiRNN-HateXplain\u6a21\u578b\u901a\u8fc7\u7ed3\u5408\u53cc\u5411\u6ce8\u610f\u529b\u548cBiRNN\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u51cf\u5c11\u4e86\u6ce8\u610f\u529b\u53d8\u5f02\u548c\u65e0\u610f\u8bc6\u504f\u89c1\uff0c\u4e3a\u900f\u660e\u53ef\u9760\u7684\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.13846", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13846", "abs": "https://arxiv.org/abs/2601.13846", "authors": ["Glinskaya Maria"], "title": "Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments", "comment": null, "summary": "This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through the medium of synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. To demonstrate feasibility, the pilot study Virtual Urbanism and Tokyo Microcosms is presented. A pipeline integrating Stable Diffusion and LoRA models was used to produce synthetic replicas of nine Tokyo areas rendered as dynamic synthetic urban sequences, excluding existing orientation markers to elicit core identity-forming elements. Human-evaluation experiments (I) assessed perceptual legitimacy of replicas; (II) quantified area-level identity; (III) derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVirtual Urbanism\u6846\u67b6\uff0c\u901a\u8fc7AI\u751f\u6210\u57ce\u5e02\u5408\u6210\u590d\u5236\u54c1\u6765\u91cf\u5316\u57ce\u5e02\u8eab\u4efd\uff0c\u4e1c\u4eac\u6848\u4f8b\u7814\u7a76\u663e\u793a81%\u8bc6\u522b\u51c6\u786e\u7387\uff0c\u8bc1\u660e\u8be5\u6846\u67b6\u53ef\u884c\u6027\u3002", "motivation": "\u5f00\u53d1\u8ba1\u7b97\u53ef\u5904\u7406\u7684\u91cf\u5316\u57ce\u5e02\u8eab\u4efd\u6307\u6807\u6846\u67b6\uff0c\u901a\u8fc7AI\u589e\u5f3a\u57ce\u5e02\u5206\u6790\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u591a\u53c2\u6570\u8eab\u4efd\u5ea6\u91cf\u3002", "method": "\u6574\u5408Stable Diffusion\u548cLoRA\u6a21\u578b\u751f\u6210\u4e1c\u4eac9\u4e2a\u533a\u57df\u7684\u5408\u6210\u57ce\u5e02\u5e8f\u5217\uff0c\u6392\u9664\u73b0\u6709\u5bfc\u5411\u6807\u8bb0\u4ee5\u63d0\u53d6\u6838\u5fc3\u8eab\u4efd\u5f62\u6210\u5143\u7d20\uff0c\u901a\u8fc7\u4eba\u7c7b\u8bc4\u4f30\u5b9e\u9a8c\u9a8c\u8bc1\u611f\u77e5\u5408\u6cd5\u6027\u3001\u91cf\u5316\u533a\u57df\u8eab\u4efd\u3001\u63a8\u5bfc\u6838\u5fc3\u8eab\u4efd\u5143\u7d20\u3002", "result": "\u5408\u6210\u590d\u5236\u54c1\u5e73\u5747\u8bc6\u522b\u51c6\u786e\u7387\u8fbe81%\uff0c\u9a8c\u8bc1\u4e86\u590d\u5236\u54c1\u6709\u6548\u6027\uff1bUrban Identity Level\u6307\u6807\u53ef\u8bc4\u4f30\u4e0d\u540c\u533a\u57df\u8eab\u4efd\u6c34\u5e73\uff1b\u8bed\u4e49\u5206\u6790\u63ed\u793a\u6587\u5316\u5d4c\u5165\u7c7b\u578b\u5b66\u662f\u6838\u5fc3\u8eab\u4efd\u5f62\u6210\u5143\u7d20\u3002", "conclusion": "Virtual Urbanism\u662f\u53ef\u884c\u7684AI\u589e\u5f3a\u57ce\u5e02\u5206\u6790\u6846\u67b6\uff0c\u4e3a\u81ea\u52a8\u5316\u591a\u53c2\u6570\u8eab\u4efd\u5ea6\u91cf\u63d0\u4f9b\u4e86\u8def\u5f84\uff0c\u80fd\u591f\u901a\u8fc7\u5408\u6210\u57ce\u5e02\u590d\u5236\u54c1\u91cf\u5316\u57ce\u5e02\u8eab\u4efd\u3002"}}
{"id": "2601.13024", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13024", "abs": "https://arxiv.org/abs/2601.13024", "authors": ["Chongyuan Dai", "Yaling Shen", "Jinpeng Hu", "Zihan Gao", "Jia Li", "Yishun Jiang", "Yaxiong Wang", "Liu Liu", "Zongyuan Ge"], "title": "Tears or Cheers? Benchmarking LLMs via Culturally Elicited Distinct Affective Responses", "comment": "24 pages, 10 figures, 9 Tables", "summary": "Culture serves as a fundamental determinant of human affective processing and profoundly shapes how individuals perceive and interpret emotional stimuli. Despite this intrinsic link extant evaluations regarding cultural alignment within Large Language Models primarily prioritize declarative knowledge such as geographical facts or established societal customs. These benchmarks remain insufficient to capture the subjective interpretative variance inherent to diverse sociocultural lenses. To address this limitation, we introduce CEDAR, a multimodal benchmark constructed entirely from scenarios capturing Culturally \\underline{\\textsc{E}}licited \\underline{\\textsc{D}}istinct \\underline{\\textsc{A}}ffective \\underline{\\textsc{R}}esponses. To construct CEDAR, we implement a novel pipeline that leverages LLM-generated provisional labels to isolate instances yielding cross-cultural emotional distinctions, and subsequently derives reliable ground-truth annotations through rigorous human evaluation. The resulting benchmark comprises 10,962 instances across seven languages and 14 fine-grained emotion categories, with each language including 400 multimodal and 1,166 text-only samples. Comprehensive evaluations of 17 representative multilingual models reveal a dissociation between language consistency and cultural alignment, demonstrating that culturally grounded affective understanding remains a significant challenge for current models.", "AI": {"tldr": "CEDAR\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u6ce8\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6587\u5316\u7279\u5f02\u6027\u60c5\u611f\u7406\u89e3\u65b9\u9762\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u6355\u6349\u4e0d\u540c\u6587\u5316\u80cc\u666f\u4e0b\u60c5\u611f\u53cd\u5e94\u7684\u5dee\u5f02\u6765\u5f25\u8865\u73b0\u6709\u6587\u5316\u5bf9\u9f50\u8bc4\u4f30\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6587\u5316\u5bf9\u9f50\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u5730\u7406\u4e8b\u5b9e\u3001\u793e\u4f1a\u4e60\u4fd7\u7b49\u9648\u8ff0\u6027\u77e5\u8bc6\uff0c\u672a\u80fd\u6355\u6349\u4e0d\u540c\u6587\u5316\u80cc\u666f\u4e0b\u4e3b\u89c2\u60c5\u611f\u89e3\u91ca\u7684\u5dee\u5f02\u3002\u6587\u5316\u4f5c\u4e3a\u4eba\u7c7b\u60c5\u611f\u5904\u7406\u7684\u57fa\u672c\u51b3\u5b9a\u56e0\u7d20\uff0c\u6df1\u523b\u5f71\u54cd\u4e2a\u4f53\u5bf9\u60c5\u611f\u523a\u6fc0\u7684\u611f\u77e5\u548c\u89e3\u91ca\uff0c\u56e0\u6b64\u9700\u8981\u4e13\u95e8\u8bc4\u4f30\u6a21\u578b\u5728\u6587\u5316\u7279\u5f02\u6027\u60c5\u611f\u7406\u89e3\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faCEDAR\u57fa\u51c6\u6d4b\u8bd5\u6784\u5efa\u65b9\u6cd5\uff1a1\uff09\u5229\u7528LLM\u751f\u6210\u7684\u4e34\u65f6\u6807\u7b7e\u8bc6\u522b\u4ea7\u751f\u8de8\u6587\u5316\u60c5\u611f\u5dee\u5f02\u7684\u5b9e\u4f8b\uff1b2\uff09\u901a\u8fc7\u4e25\u683c\u7684\u4eba\u5de5\u8bc4\u4f30\u83b7\u5f97\u53ef\u9760\u7684\u771f\u5b9e\u6807\u6ce8\uff1b3\uff09\u6784\u5efa\u5305\u542b10,962\u4e2a\u5b9e\u4f8b\u7684\u6570\u636e\u96c6\uff0c\u6db5\u76d67\u79cd\u8bed\u8a00\u548c14\u79cd\u7ec6\u7c92\u5ea6\u60c5\u611f\u7c7b\u522b\uff0c\u6bcf\u79cd\u8bed\u8a00\u5305\u542b400\u4e2a\u591a\u6a21\u6001\u6837\u672c\u548c1,166\u4e2a\u7eaf\u6587\u672c\u6837\u672c\u3002", "result": "\u5bf917\u4e2a\u4ee3\u8868\u6027\u591a\u8bed\u8a00\u6a21\u578b\u7684\u5168\u9762\u8bc4\u4f30\u663e\u793a\uff1a\u8bed\u8a00\u4e00\u81f4\u6027\u4e0e\u6587\u5316\u5bf9\u9f50\u4e4b\u95f4\u5b58\u5728\u5206\u79bb\u73b0\u8c61\uff0c\u8868\u660e\u5f53\u524d\u6a21\u578b\u5728\u6587\u5316\u57fa\u7840\u60c5\u611f\u7406\u89e3\u65b9\u9762\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u5373\u4f7f\u6a21\u578b\u5728\u8bed\u8a00\u5c42\u9762\u8868\u73b0\u4e00\u81f4\uff0c\u4e5f\u96be\u4ee5\u51c6\u786e\u6355\u6349\u6587\u5316\u7279\u5f02\u6027\u7684\u60c5\u611f\u53cd\u5e94\u3002", "conclusion": "\u6587\u5316\u57fa\u7840\u7684\u60c5\u611f\u7406\u89e3\u662f\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u7684\u91cd\u8981\u6311\u6218\uff0c\u9700\u8981\u4e13\u95e8\u8bbe\u8ba1\u7684\u8bc4\u4f30\u57fa\u51c6\u6765\u6d4b\u8bd5\u6a21\u578b\u5728\u4e0d\u540c\u6587\u5316\u80cc\u666f\u4e0b\u89e3\u91ca\u60c5\u611f\u523a\u6fc0\u7684\u80fd\u529b\u3002CEDAR\u57fa\u51c6\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u8bc4\u4f30\u548c\u63d0\u5347\u6a21\u578b\u7684\u6587\u5316\u5bf9\u9f50\u80fd\u529b\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2601.13035", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13035", "abs": "https://arxiv.org/abs/2601.13035", "authors": ["Xu Xiaodan", "Hu Xiaolin"], "title": "SASA: Semantic-Aware Contrastive Learning Framework with Separated Attention for Triple Classification", "comment": "in progress", "summary": "Knowledge Graphs~(KGs) often suffer from unreliable knowledge, which restricts their utility. Triple Classification~(TC) aims to determine the validity of triples from KGs. Recently, text-based methods learn entity and relation representations from natural language descriptions, significantly improving the generalization capabilities of TC models and setting new benchmarks in performance. However, there are still two critical challenges. First, existing methods often ignore the effective semantic interaction among different KG components. Second, most approaches adopt single binary classification training objective, leading to insufficient semantic representation learning. To address these challenges, we propose \\textbf{SASA}, a novel framework designed to enhance TC models via separated attention mechanism and semantic-aware contrastive learning~(CL). Specifically, we first propose separated attention mechanism to encode triples into decoupled contextual representations and then fuse them through a more effective interactive way. Then, we introduce semantic-aware hierarchical CL as auxiliary training objective to guide models in improving their discriminative capabilities and achieving sufficient semantic learning, considering both local level and global level CL. Experimental results across two benchmark datasets demonstrate that SASA significantly outperforms state-of-the-art methods. In terms of accuracy, we advance the state-of-the-art by +5.9\\% on FB15k-237 and +3.4\\% on YAGO3-10.", "AI": {"tldr": "SASA\u6846\u67b6\u901a\u8fc7\u5206\u79bb\u6ce8\u610f\u529b\u673a\u5236\u548c\u8bed\u4e49\u611f\u77e5\u5bf9\u6bd4\u5b66\u4e60\u63d0\u5347\u77e5\u8bc6\u56fe\u8c31\u4e09\u5143\u7ec4\u5206\u7c7b\u6027\u80fd\uff0c\u5728FB15k-237\u548cYAGO3-10\u6570\u636e\u96c6\u4e0a\u5206\u522b\u5b9e\u73b0+5.9%\u548c+3.4%\u7684\u51c6\u786e\u7387\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6587\u672c\u7684\u4e09\u5143\u7ec4\u5206\u7c7b\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a1\uff09\u5ffd\u7565\u77e5\u8bc6\u56fe\u8c31\u4e0d\u540c\u7ec4\u4ef6\u95f4\u7684\u6709\u6548\u8bed\u4e49\u4ea4\u4e92\uff1b2\uff09\u91c7\u7528\u5355\u4e00\u4e8c\u5143\u5206\u7c7b\u8bad\u7ec3\u76ee\u6807\u5bfc\u81f4\u8bed\u4e49\u8868\u793a\u5b66\u4e60\u4e0d\u5145\u5206\u3002", "method": "\u63d0\u51faSASA\u6846\u67b6\uff1a1\uff09\u5206\u79bb\u6ce8\u610f\u529b\u673a\u5236\u5c06\u4e09\u5143\u7ec4\u7f16\u7801\u4e3a\u89e3\u8026\u7684\u4e0a\u4e0b\u6587\u8868\u793a\u5e76\u901a\u8fc7\u66f4\u6709\u6548\u7684\u4ea4\u4e92\u65b9\u5f0f\u878d\u5408\uff1b2\uff09\u8bed\u4e49\u611f\u77e5\u5206\u5c42\u5bf9\u6bd4\u5b66\u4e60\u4f5c\u4e3a\u8f85\u52a9\u8bad\u7ec3\u76ee\u6807\uff0c\u5305\u542b\u5c40\u90e8\u548c\u5168\u5c40\u4e24\u4e2a\u5c42\u6b21\u7684\u5bf9\u6bd4\u5b66\u4e60\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\uff1aFB15k-237\u51c6\u786e\u7387\u63d0\u5347+5.9%\uff0cYAGO3-10\u51c6\u786e\u7387\u63d0\u5347+3.4%\u3002", "conclusion": "SASA\u901a\u8fc7\u5206\u79bb\u6ce8\u610f\u529b\u673a\u5236\u589e\u5f3a\u8bed\u4e49\u4ea4\u4e92\uff0c\u7ed3\u5408\u8bed\u4e49\u611f\u77e5\u5bf9\u6bd4\u5b66\u4e60\u63d0\u5347\u5224\u522b\u80fd\u529b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u4e09\u5143\u7ec4\u5206\u7c7b\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2601.13887", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13887", "abs": "https://arxiv.org/abs/2601.13887", "authors": ["Hong Su"], "title": "Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems", "comment": null, "summary": "Large language models (LLMs) have demonstrated strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language material alone limits their ability to adapt, verify reasoning outcomes, and operate effectively in open and dynamic real-world environments. In this paper, we propose Human Simulation Computation (HSC), a human-inspired computational framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling, collectively referred to as the internal reasoning process. HSC emphasizes active participation both within the internal reasoning process and in interactions with the environment, where actions are used not only to achieve goals but also to automatically refine and improve internal reasoning mechanisms without external intervention. Furthermore, HSC incorporates commonly used human thinking strategies across all stages of the internal reasoning process, such as main-feature-oriented reasoning, scope expansion through action, and on-time learning driven by environmental feedback. Through theoretical analysis, we argue that human simulation strategies cannot be fully learned from language material alone, and that human-like reasoning processes and action-grounded reasoning methods are essential for robust adaptation and effective interaction with real-world environments.", "AI": {"tldr": "\u63d0\u51fa\u4eba\u7c7b\u6a21\u62df\u8ba1\u7b97\uff08HSC\uff09\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u5efa\u6a21\u4e3a\u5305\u542b\u601d\u8003\u3001\u884c\u52a8\u3001\u5b66\u4e60\u3001\u53cd\u601d\u548c\u6d3b\u52a8\u8c03\u5ea6\u7684\u8fde\u7eed\u95ed\u73af\u8fc7\u7a0b\uff0c\u5f3a\u8c03\u4e3b\u52a8\u53c2\u4e0e\u548c\u884c\u52a8\u9a71\u52a8\u7684\u63a8\u7406\u6539\u8fdb\uff0c\u4ee5\u89e3\u51b3LLMs\u4ec5\u4f9d\u8d56\u6587\u672c\u6570\u636e\u5728\u5f00\u653e\u52a8\u6001\u73af\u5883\u4e2d\u9002\u5e94\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u77e5\u8bc6\u8868\u793a\u548c\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u4ec5\u4f9d\u8d56\u8bed\u8a00\u6750\u6599\u9650\u5236\u4e86\u5176\u5728\u5f00\u653e\u52a8\u6001\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u9002\u5e94\u80fd\u529b\u3001\u63a8\u7406\u7ed3\u679c\u9a8c\u8bc1\u548c\u6709\u6548\u64cd\u4f5c\u3002\u9700\u8981\u4e00\u79cd\u66f4\u63a5\u8fd1\u4eba\u7c7b\u667a\u80fd\u7684\u6846\u67b6\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4eba\u7c7b\u6a21\u62df\u8ba1\u7b97\uff08HSC\uff09\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u5efa\u6a21\u4e3a\u5305\u542b\u601d\u8003\u3001\u884c\u52a8\u3001\u5b66\u4e60\u3001\u53cd\u601d\u548c\u6d3b\u52a8\u8c03\u5ea6\u7684\u8fde\u7eed\u95ed\u73af\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\u3002\u8be5\u6846\u67b6\u5f3a\u8c03\u5728\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\u548c\u4e0e\u73af\u5883\u4ea4\u4e92\u4e2d\u7684\u4e3b\u52a8\u53c2\u4e0e\uff0c\u5229\u7528\u884c\u52a8\u4e0d\u4ec5\u5b9e\u73b0\u76ee\u6807\uff0c\u8fd8\u81ea\u52a8\u6539\u8fdb\u5185\u90e8\u63a8\u7406\u673a\u5236\u3002\u6574\u5408\u4eba\u7c7b\u5e38\u7528\u601d\u7ef4\u7b56\u7565\uff0c\u5982\u4e3b\u7279\u5f81\u5bfc\u5411\u63a8\u7406\u3001\u901a\u8fc7\u884c\u52a8\u6269\u5c55\u8303\u56f4\u3001\u73af\u5883\u53cd\u9988\u9a71\u52a8\u7684\u5373\u65f6\u5b66\u4e60\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u4eba\u7c7b\u6a21\u62df\u7b56\u7565\u65e0\u6cd5\u4ec5\u4ece\u8bed\u8a00\u6750\u6599\u4e2d\u5b8c\u5168\u5b66\u4e60\uff0c\u4eba\u7c7b\u5f0f\u63a8\u7406\u8fc7\u7a0b\u548c\u884c\u52a8\u57fa\u7840\u7684\u63a8\u7406\u65b9\u6cd5\u5bf9\u4e8e\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u5b9e\u73b0\u7a33\u5065\u9002\u5e94\u548c\u6709\u6548\u4ea4\u4e92\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "HSC\u6846\u67b6\u4e3a\u89e3\u51b3LLMs\u5728\u5f00\u653e\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5f3a\u8c03\u884c\u52a8\u9a71\u52a8\u7684\u63a8\u7406\u6539\u8fdb\u548c\u4eba\u7c7b\u601d\u7ef4\u7b56\u7565\u7684\u6574\u5408\u662f\u5b9e\u73b0\u771f\u6b63\u9002\u5e94\u6027\u667a\u80fd\u7684\u5173\u952e\u3002"}}
{"id": "2601.13044", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13044", "abs": "https://arxiv.org/abs/2601.13044", "authors": ["Warit Sirichotedumrong", "Adisai Na-Thalang", "Potsawee Manakul", "Pittawat Taveekitworachai", "Sittipong Sripaisarnmongkol", "Kunat Pipatanakul"], "title": "Typhoon ASR Real-time: FastConformer-Transducer for Thai Automatic Speech Recognition", "comment": "Models and datasets are publicly available on https://huggingface.co/collections/typhoon-ai/typhoon-asr-technical-report ; Project Page: https://opentyphoon.ai/model/typhoon-asr-realtime", "summary": "Large encoder-decoder models like Whisper achieve strong offline transcription but remain impractical for streaming applications due to high latency. However, due to the accessibility of pre-trained checkpoints, the open Thai ASR landscape remains dominated by these offline architectures, leaving a critical gap in efficient streaming solutions. We present Typhoon ASR Real-time, a 115M-parameter FastConformer-Transducer model for low-latency Thai speech recognition. We demonstrate that rigorous text normalization can match the impact of model scaling: our compact model achieves a 45x reduction in computational cost compared to Whisper Large-v3 while delivering comparable accuracy. Our normalization pipeline resolves systemic ambiguities in Thai transcription --including context-dependent number verbalization and repetition markers (mai yamok) --creating consistent training targets. We further introduce a two-stage curriculum learning approach for Isan (north-eastern) dialect adaptation that preserves Central Thai performance. To address reproducibility challenges in Thai ASR, we release the Typhoon ASR Benchmark, a gold-standard human-labeled datasets with transcriptions following established Thai linguistic conventions, providing standardized evaluation protocols for the research community.", "AI": {"tldr": "Typhoon ASR Real-time\u662f\u4e00\u4e2a115M\u53c2\u6570\u7684FastConformer-Transducer\u6a21\u578b\uff0c\u7528\u4e8e\u4f4e\u5ef6\u8fdf\u6cf0\u8bed\u8bed\u97f3\u8bc6\u522b\uff0c\u901a\u8fc7\u4e25\u683c\u7684\u6587\u672c\u89c4\u8303\u5316\u5b9e\u73b0\u4e0eWhisper Large-v3\u76f8\u5f53\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u8ba1\u7b97\u6210\u672c\u964d\u4f4e45\u500d\uff0c\u5e76\u53d1\u5e03\u4e86\u6807\u51c6\u5316\u7684\u6cf0\u8bedASR\u57fa\u51c6\u6570\u636e\u96c6\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6a21\u578b\uff08\u5982Whisper\uff09\u5728\u79bb\u7ebf\u8f6c\u5f55\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7531\u4e8e\u9ad8\u5ef6\u8fdf\u4e0d\u9002\u7528\u4e8e\u6d41\u5f0f\u5e94\u7528\u3002\u6cf0\u8bedASR\u9886\u57df\u7f3a\u4e4f\u9ad8\u6548\u7684\u6d41\u5f0f\u89e3\u51b3\u65b9\u6848\uff0c\u4e14\u5b58\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u4e3b\u5bfc\u79bb\u7ebf\u67b6\u6784\u7684\u95ee\u9898\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u5173\u952e\u7a7a\u767d\u3002", "method": "1. \u91c7\u7528115M\u53c2\u6570\u7684FastConformer-Transducer\u67b6\u6784\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u6d41\u5f0f\u8bc6\u522b\uff1b2. \u8bbe\u8ba1\u4e25\u683c\u7684\u6587\u672c\u89c4\u8303\u5316\u6d41\u7a0b\uff0c\u89e3\u51b3\u6cf0\u8bed\u8f6c\u5f55\u4e2d\u7684\u7cfb\u7edf\u6b67\u4e49\uff08\u5305\u62ec\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u6570\u5b57\u53d1\u97f3\u548c\u91cd\u590d\u6807\u8bb0\uff09\uff1b3. \u5f15\u5165\u4e24\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u4f0a\u6851\uff08\u4e1c\u5317\uff09\u65b9\u8a00\u9002\u5e94\uff0c\u540c\u65f6\u4fdd\u6301\u4e2d\u90e8\u6cf0\u8bed\u6027\u80fd\uff1b4. \u53d1\u5e03Typhoon ASR Benchmark\uff0c\u63d0\u4f9b\u9075\u5faa\u6cf0\u8bed\u8bed\u8a00\u5b66\u89c4\u8303\u7684\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\u548c\u6807\u51c6\u5316\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u7d27\u51d1\u6a21\u578b\u76f8\u6bd4Whisper Large-v3\u5b9e\u73b045\u500d\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002\u6587\u672c\u89c4\u8303\u5316\u6d41\u7a0b\u89e3\u51b3\u4e86\u6cf0\u8bed\u8f6c\u5f55\u4e2d\u7684\u7cfb\u7edf\u6b67\u4e49\uff0c\u521b\u5efa\u4e86\u4e00\u81f4\u7684\u8bad\u7ec3\u76ee\u6807\u3002\u4e24\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u4f0a\u6851\u65b9\u8a00\u9002\u5e94\u800c\u4e0d\u635f\u5bb3\u4e2d\u90e8\u6cf0\u8bed\u6027\u80fd\u3002", "conclusion": "\u4e25\u683c\u7684\u6587\u672c\u89c4\u8303\u5316\u53ef\u4ee5\u4e0e\u6a21\u578b\u7f29\u653e\u4ea7\u751f\u540c\u7b49\u5f71\u54cd\uff0c\u4f7f\u5f97\u7d27\u51d1\u6a21\u578b\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002Typhoon ASR Real-time\u586b\u8865\u4e86\u6cf0\u8bedASR\u9886\u57df\u9ad8\u6548\u6d41\u5f0f\u89e3\u51b3\u65b9\u6848\u7684\u7a7a\u767d\uff0c\u5e76\u901a\u8fc7\u53d1\u5e03\u6807\u51c6\u5316\u57fa\u51c6\u6570\u636e\u96c6\u89e3\u51b3\u4e86\u53ef\u590d\u73b0\u6027\u6311\u6218\u3002"}}
{"id": "2601.13904", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13904", "abs": "https://arxiv.org/abs/2601.13904", "authors": ["Jaeyoung Moon", "Youjin Choi", "Yucheon Park", "David Melhart", "Georgios N. Yannakakis", "Kyung-Joong Kim"], "title": "PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation", "comment": "CHI '26 Accepted paper", "summary": "Self-annotation is the gold standard for collecting affective state labels in affective computing. Existing methods typically rely on full annotation, requiring users to continuously label affective states across entire sessions. While this process yields fine-grained data, it is time-consuming, cognitively demanding, and prone to fatigue and errors. To address these issues, we present PREFAB, a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation. Grounded in the peak-end rule and ordinal representations of emotion, PREFAB employs a preference-learning model to detect relative affective changes, directing annotators to label only selected segments while interpolating the remainder of the stimulus. We further introduce a preview mechanism that provides brief contextual cues to assist annotation. We evaluate PREFAB through a technical performance study and a 25-participant user study. Results show that PREFAB outperforms baselines in modeling affective inflections while mitigating workload (and conditionally mitigating temporal burden). Importantly PREFAB improves annotator confidence without degrading annotation quality.", "AI": {"tldr": "PREFAB\u662f\u4e00\u79cd\u4f4e\u6210\u672c\u7684\u56de\u987e\u5f0f\u81ea\u6211\u6807\u6ce8\u65b9\u6cd5\uff0c\u901a\u8fc7\u68c0\u6d4b\u60c5\u611f\u53d8\u5316\u533a\u57df\u800c\u975e\u5b8c\u6574\u6807\u6ce8\u6765\u51cf\u8f7b\u6807\u6ce8\u8d1f\u62c5\uff0c\u540c\u65f6\u4fdd\u6301\u6807\u6ce8\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u60c5\u611f\u72b6\u6001\u6807\u6ce8\u65b9\u6cd5\u9700\u8981\u7528\u6237\u5728\u6574\u4e2a\u4f1a\u8bdd\u671f\u95f4\u6301\u7eed\u6807\u6ce8\uff0c\u867d\u7136\u80fd\u83b7\u5f97\u7ec6\u7c92\u5ea6\u6570\u636e\uff0c\u4f46\u8fc7\u7a0b\u8017\u65f6\u3001\u8ba4\u77e5\u8d1f\u62c5\u91cd\uff0c\u5bb9\u6613\u5bfc\u81f4\u75b2\u52b3\u548c\u9519\u8bef\u3002\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u8d1f\u62c5\u66f4\u8f7b\u7684\u6807\u6ce8\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u5cf0\u503c-\u7ed3\u675f\u89c4\u5219\u548c\u60c5\u611f\u5e8f\u6570\u8868\u793a\uff0cPREFAB\u91c7\u7528\u504f\u597d\u5b66\u4e60\u6a21\u578b\u68c0\u6d4b\u76f8\u5bf9\u60c5\u611f\u53d8\u5316\uff0c\u6307\u5bfc\u6807\u6ce8\u8005\u4ec5\u6807\u6ce8\u9009\u5b9a\u7247\u6bb5\uff0c\u5176\u4f59\u90e8\u5206\u901a\u8fc7\u63d2\u503c\u5b8c\u6210\u3002\u8fd8\u5f15\u5165\u4e86\u9884\u89c8\u673a\u5236\u63d0\u4f9b\u4e0a\u4e0b\u6587\u7ebf\u7d22\u8f85\u52a9\u6807\u6ce8\u3002", "result": "\u6280\u672f\u6027\u80fd\u7814\u7a76\u548c25\u540d\u53c2\u4e0e\u8005\u7684\u7528\u6237\u7814\u7a76\u8868\u660e\uff0cPREFAB\u5728\u5efa\u6a21\u60c5\u611f\u53d8\u5316\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u51cf\u8f7b\u4e86\u5de5\u4f5c\u8d1f\u62c5\uff08\u6709\u6761\u4ef6\u5730\u51cf\u8f7b\u65f6\u95f4\u8d1f\u62c5\uff09\u3002\u91cd\u8981\u7684\u662f\uff0cPREFAB\u63d0\u9ad8\u4e86\u6807\u6ce8\u8005\u4fe1\u5fc3\u4e14\u672a\u964d\u4f4e\u6807\u6ce8\u8d28\u91cf\u3002", "conclusion": "PREFAB\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u4f4e\u9884\u7b97\u60c5\u611f\u6807\u6ce8\u65b9\u6cd5\uff0c\u901a\u8fc7\u805a\u7126\u60c5\u611f\u53d8\u5316\u533a\u57df\u800c\u975e\u5b8c\u6574\u6807\u6ce8\uff0c\u5728\u4fdd\u6301\u6807\u6ce8\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u51cf\u8f7b\u4e86\u6807\u6ce8\u8d1f\u62c5\u3002"}}
{"id": "2601.13050", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13050", "abs": "https://arxiv.org/abs/2601.13050", "authors": ["Lars Kl\u00f6ser", "Mika Beele", "Bodo Kraft"], "title": "Profiling German Text Simplification with Interpretable Model-Fingerprints", "comment": "Presented at 2nd International Conference on Explainable AI for Neural and Symbolic Systems", "summary": "While Large Language Models (LLMs) produce highly nuanced text simplifications, developers currently lack tools for a holistic, efficient, and reproducible diagnosis of their behavior. This paper introduces the Simplification Profiler, a diagnostic toolkit that generates a multidimensional, interpretable fingerprint of simplified texts. Multiple aggregated simplifications of a model result in a model's fingerprint. This novel evaluation paradigm is particularly vital for languages, where the data scarcity problem is magnified when creating flexible models for diverse target groups rather than a single, fixed simplification style. We propose that measuring a model's unique behavioral signature is more relevant in this context as an alternative to correlating metrics with human preferences. We operationalize this with a practical meta-evaluation of our fingerprints' descriptive power, which bypasses the need for large, human-rated datasets. This test measures if a simple linear classifier can reliably identify various model configurations by their created simplifications, confirming that our metrics are sensitive to a model's specific characteristics. The Profiler can distinguish high-level behavioral variations between prompting strategies and fine-grained changes from prompt engineering, including few-shot examples. Our complete feature set achieves classification F1-scores up to 71.9 %, improving upon simple baselines by over 48 percentage points. The Simplification Profiler thus offers developers a granular, actionable analysis to build more effective and truly adaptive text simplification systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Simplification Profiler\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u751f\u6210\u6587\u672c\u7b80\u5316\u6a21\u578b\u7684\u591a\u7ef4\u53ef\u89e3\u91ca\u6307\u7eb9\uff0c\u901a\u8fc7\u6a21\u578b\u884c\u4e3a\u7279\u5f81\u800c\u975e\u4f20\u7edf\u4eba\u5de5\u8bc4\u5206\u6765\u8bca\u65ad\u6a21\u578b\u6027\u80fd\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6570\u636e\u7a00\u7f3a\u7684\u591a\u8bed\u8a00\u573a\u666f\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6587\u672c\u7b80\u5316\u884c\u4e3a\u7684\u5168\u9762\u3001\u9ad8\u6548\u3001\u53ef\u590d\u73b0\u7684\u8bca\u65ad\u5de5\u5177\u3002\u7279\u522b\u662f\u5728\u591a\u8bed\u8a00\u573a\u666f\u4e0b\uff0c\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u5728\u521b\u5efa\u9002\u5e94\u4e0d\u540c\u76ee\u6807\u7fa4\u4f53\u7684\u7075\u6d3b\u6a21\u578b\u65f6\u66f4\u4e3a\u7a81\u51fa\uff0c\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u8303\u5f0f\u3002", "method": "\u5f00\u53d1Simplification Profiler\u8bca\u65ad\u5de5\u5177\u5305\uff0c\u751f\u6210\u7b80\u5316\u6587\u672c\u7684\u591a\u7ef4\u53ef\u89e3\u91ca\u6307\u7eb9\u3002\u901a\u8fc7\u805a\u5408\u591a\u4e2a\u7b80\u5316\u7ed3\u679c\u5f62\u6210\u6a21\u578b\u6307\u7eb9\uff0c\u91c7\u7528\u5143\u8bc4\u4f30\u65b9\u6cd5\u6d4b\u8bd5\u6307\u7eb9\u7684\u63cf\u8ff0\u80fd\u529b\uff0c\u4f7f\u7528\u7ebf\u6027\u5206\u7c7b\u5668\u9a8c\u8bc1\u4e0d\u540c\u6a21\u578b\u914d\u7f6e\u7684\u53ef\u533a\u5206\u6027\u3002", "result": "Profiler\u80fd\u591f\u533a\u5206\u63d0\u793a\u7b56\u7565\u7684\u9ad8\u5c42\u884c\u4e3a\u53d8\u5316\u548c\u63d0\u793a\u5de5\u7a0b\u7684\u7ec6\u7c92\u5ea6\u8c03\u6574\uff08\u5305\u62ecfew-shot\u793a\u4f8b\uff09\u3002\u5b8c\u6574\u7279\u5f81\u96c6\u8fbe\u523071.9%\u7684\u5206\u7c7bF1\u5206\u6570\uff0c\u6bd4\u7b80\u5355\u57fa\u7ebf\u63d0\u9ad8\u8d85\u8fc748\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "Simplification Profiler\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u7ec6\u7c92\u5ea6\u3001\u53ef\u64cd\u4f5c\u7684\u5206\u6790\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u6709\u6548\u3001\u771f\u6b63\u81ea\u9002\u5e94\u7684\u6587\u672c\u7b80\u5316\u7cfb\u7edf\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u7f3a\u7684\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u3002"}}
{"id": "2601.13099", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13099", "abs": "https://arxiv.org/abs/2601.13099", "authors": ["Abdellah El Mekki", "Samar M. Magdy", "Houdaifa Atou", "Ruwa AbuHweidi", "Baraah Qawasmeh", "Omer Nacar", "Thikra Al-hibiri", "Razan Saadie", "Hamzah Alsayadi", "Nadia Ghezaiel Hammouda", "Alshima Alkhazimi", "Aya Hamod", "Al-Yas Al-Ghafri", "Wesam El-Sayed", "Asila Al sharji", "Mohamad Ballout", "Anas Belfathi", "Karim Ghaddar", "Serry Sibaee", "Alaa Aoun", "Areej Asiri", "Lina Abureesh", "Ahlam Bashiti", "Majdal Yousef", "Abdulaziz Hafiz", "Yehdih Mohamed", "Emira Hamedtou", "Brakehe Brahim", "Rahaf Alhamouri", "Youssef Nafea", "Aya El Aatar", "Walid Al-Dhabyani", "Emhemed Hamed", "Sara Shatnawi", "Fakhraddin Alwajih", "Khalid Elkhidir", "Ashwag Alasmari", "Abdurrahman Gerrio", "Omar Alshahri", "AbdelRahim A. Elmadany", "Ismail Berrada", "Amir Azad Adli Alkathiri", "Fadi A Zaraket", "Mustafa Jarrar", "Yahya Mohamed El Hadj", "Hassan Alhuzali", "Muhammad Abdul-Mageed"], "title": "Alexandria: A Multi-Domain Dialectal Arabic Machine Translation Dataset for Culturally Inclusive and Linguistically Diverse LLMs", "comment": "Project resources will be available here: https://github.com/UBC-NLP/Alexandria", "summary": "Arabic is a highly diglossic language where most daily communication occurs in regional dialects rather than Modern Standard Arabic. Despite this, machine translation (MT) systems often generalize poorly to dialectal input, limiting their utility for millions of speakers. We introduce \\textbf{Alexandria}, a large-scale, community-driven, human-translated dataset designed to bridge this gap. Alexandria covers 13 Arab countries and 11 high-impact domains, including health, education, and agriculture. Unlike previous resources, Alexandria provides unprecedented granularity by associating contributions with city-of-origin metadata, capturing authentic local varieties beyond coarse regional labels. The dataset consists of multi-turn conversational scenarios annotated with speaker-addressee gender configurations, enabling the study of gender-conditioned variation in dialectal use. Comprising 107K total samples, Alexandria serves as both a training resource and a rigorous benchmark for evaluating MT and Large Language Models (LLMs). Our automatic and human evaluation of Arabic-aware LLMs benchmarks current capabilities in translating across diverse Arabic dialects and sub-dialects, while exposing significant persistent challenges.", "AI": {"tldr": "Alexandria\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u793e\u533a\u9a71\u52a8\u3001\u4eba\u5de5\u7ffb\u8bd1\u7684\u6570\u636e\u96c6\uff0c\u65e8\u5728\u89e3\u51b3\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u673a\u5668\u7ffb\u8bd1\u7684\u6cdb\u5316\u95ee\u9898\uff0c\u8986\u76d613\u4e2a\u963f\u62c9\u4f2f\u56fd\u5bb6\u548c11\u4e2a\u9ad8\u5f71\u54cd\u529b\u9886\u57df\uff0c\u63d0\u4f9b\u57ce\u5e02\u7ea7\u522b\u7684\u65b9\u8a00\u7ec6\u7c92\u5ea6\u6807\u6ce8\u3002", "motivation": "\u963f\u62c9\u4f2f\u8bed\u662f\u9ad8\u5ea6\u53cc\u8a00\u73b0\u8c61\u7684\u8bed\u8a00\uff0c\u65e5\u5e38\u4ea4\u6d41\u4e3b\u8981\u4f7f\u7528\u5730\u533a\u65b9\u8a00\u800c\u975e\u73b0\u4ee3\u6807\u51c6\u963f\u62c9\u4f2f\u8bed\u3002\u7136\u800c\uff0c\u73b0\u6709\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\u5bf9\u65b9\u8a00\u8f93\u5165\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u9650\u5236\u4e86\u6570\u767e\u4e07\u4f7f\u7528\u8005\u7684\u5b9e\u7528\u6027\u3002", "method": "\u6784\u5efaAlexandria\u6570\u636e\u96c6\uff1a1\uff09\u8986\u76d613\u4e2a\u963f\u62c9\u4f2f\u56fd\u5bb6\u548c11\u4e2a\u9ad8\u5f71\u54cd\u529b\u9886\u57df\uff1b2\uff09\u63d0\u4f9b\u57ce\u5e02\u6765\u6e90\u5143\u6570\u636e\uff0c\u8d85\u8d8a\u7c97\u7c92\u5ea6\u533a\u57df\u6807\u7b7e\uff1b3\uff09\u5305\u542b\u591a\u8f6e\u5bf9\u8bdd\u573a\u666f\uff0c\u6807\u6ce8\u8bf4\u8bdd\u8005-\u53d7\u8bdd\u8005\u6027\u522b\u914d\u7f6e\uff1b4\uff09\u603b\u8ba1107K\u6837\u672c\u3002", "result": "Alexandria\u6570\u636e\u96c6\u65e2\u53ef\u4f5c\u4e3a\u8bad\u7ec3\u8d44\u6e90\uff0c\u4e5f\u53ef\u4f5c\u4e3a\u8bc4\u4f30\u673a\u5668\u7ffb\u8bd1\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e25\u683c\u57fa\u51c6\u3002\u901a\u8fc7\u81ea\u52a8\u548c\u4eba\u5de5\u8bc4\u4f30\u963f\u62c9\u4f2f\u8bed\u611f\u77e5\u7684LLMs\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u5728\u8de8\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u548c\u6b21\u65b9\u8a00\u7ffb\u8bd1\u65b9\u9762\u7684\u80fd\u529b\u4e0e\u6301\u7eed\u6311\u6218\u3002", "conclusion": "Alexandria\u6570\u636e\u96c6\u586b\u8865\u4e86\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u7ffb\u8bd1\u8d44\u6e90\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u524d\u6240\u672a\u6709\u7684\u65b9\u8a00\u7ec6\u7c92\u5ea6\uff0c\u80fd\u591f\u652f\u6301\u673a\u5668\u7ffb\u8bd1\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u5904\u7406\u65b9\u9762\u7684\u7814\u7a76\u548c\u5e94\u7528\uff0c\u540c\u65f6\u66b4\u9732\u4e86\u8be5\u9886\u57df\u4ecd\u5b58\u5728\u7684\u663e\u8457\u6311\u6218\u3002"}}
{"id": "2601.13105", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13105", "abs": "https://arxiv.org/abs/2601.13105", "authors": ["Liu Kaipeng", "Wu Ling"], "title": "Leveraging Lora Fine-Tuning and Knowledge Bases for Construction Identification", "comment": "19pages, 1figure", "summary": "This study investigates the automatic identification of the English ditransitive construction by integrating LoRA-based fine-tuning of a large language model with a Retrieval-Augmented Generation (RAG) framework.A binary classification task was conducted on annotated data from the British National Corpus. Results demonstrate that a LoRA-fine-tuned Qwen3-8B model significantly outperformed both a native Qwen3-MAX model and a theory-only RAG system. Detailed error analysis reveals that fine-tuning shifts the model's judgment from a surface-form pattern matching towards a more semantically grounded understanding based.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7ed3\u5408LoRA\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u4e0eRAG\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u82f1\u8bed\u53cc\u53ca\u7269\u6784\u5f0f\u7684\u81ea\u52a8\u8bc6\u522b\uff0c\u5728BNC\u6807\u6ce8\u6570\u636e\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u4f18\u4e8e\u539f\u751f\u6a21\u578b\u548c\u7eaf\u7406\u8bbaRAG\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u82f1\u8bed\u53cc\u53ca\u7269\u6784\u5f0f\u7684\u81ea\u52a8\u8bc6\u522b\u95ee\u9898\uff0c\u63a2\u7d22\u7ed3\u5408\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08LoRA\uff09\u4e0e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u8bc6\u522b\u51c6\u786e\u7387\uff0c\u5f25\u8865\u4f20\u7edf\u65b9\u6cd5\u5728\u8bed\u4e49\u7406\u89e3\u4e0a\u7684\u4e0d\u8db3\u3002", "method": "\u91c7\u7528LoRA\u5fae\u8c03Qwen3-8B\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u7ed3\u5408RAG\u6846\u67b6\u6784\u5efa\u68c0\u7d22\u589e\u5f3a\u7cfb\u7edf\u3002\u5728BNC\u8bed\u6599\u5e93\u7684\u6807\u6ce8\u6570\u636e\u4e0a\u8fdb\u884c\u4e8c\u5143\u5206\u7c7b\u4efb\u52a1\uff0c\u5bf9\u6bd4\u4e86\u539f\u751fQwen3-MAX\u6a21\u578b\u3001\u7eaf\u7406\u8bbaRAG\u7cfb\u7edf\u548cLoRA\u5fae\u8c03\u6a21\u578b\u7684\u6027\u80fd\u3002", "result": "LoRA\u5fae\u8c03\u7684Qwen3-8B\u6a21\u578b\u5728\u53cc\u53ca\u7269\u6784\u5f0f\u8bc6\u522b\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u539f\u751fQwen3-MAX\u6a21\u578b\u548c\u7eaf\u7406\u8bbaRAG\u7cfb\u7edf\u3002\u9519\u8bef\u5206\u6790\u8868\u660e\uff0c\u5fae\u8c03\u4f7f\u6a21\u578b\u4ece\u8868\u5c42\u5f62\u5f0f\u5339\u914d\u8f6c\u5411\u57fa\u4e8e\u8bed\u4e49\u7684\u66f4\u6df1\u5c42\u7406\u89e3\u3002", "conclusion": "LoRA\u5fae\u8c03\u4e0eRAG\u6846\u67b6\u7684\u6709\u6548\u7ed3\u5408\u80fd\u591f\u663e\u8457\u63d0\u5347\u82f1\u8bed\u53cc\u53ca\u7269\u6784\u5f0f\u7684\u81ea\u52a8\u8bc6\u522b\u6027\u80fd\uff0c\u5fae\u8c03\u8fc7\u7a0b\u4fc3\u4f7f\u6a21\u578b\u4ece\u5f62\u5f0f\u5339\u914d\u8f6c\u5411\u8bed\u4e49\u7406\u89e3\uff0c\u4e3a\u6784\u5f0f\u8bed\u6cd5\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8ba1\u7b97\u5de5\u5177\u3002"}}
{"id": "2601.14171", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14171", "abs": "https://arxiv.org/abs/2601.14171", "authors": ["Qianli Ma", "Chang Guo", "Zhiheng Tian", "Siyu Wang", "Jipeng Xiao", "Yuanhao Yue", "Zhipeng Zhang"], "title": "Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance", "comment": null, "summary": "Writing effective rebuttals is a high-stakes task that demands more than linguistic fluency, as it requires precise alignment between reviewer intent and manuscript details. Current solutions typically treat this as a direct-to-text generation problem, suffering from hallucination, overlooked critiques, and a lack of verifiable grounding. To address these limitations, we introduce $\\textbf{RebuttalAgent}$, the first multi-agents framework that reframes rebuttal generation as an evidence-centric planning task. Our system decomposes complex feedback into atomic concerns and dynamically constructs hybrid contexts by synthesizing compressed summaries with high-fidelity text while integrating an autonomous and on-demand external search module to resolve concerns requiring outside literature. By generating an inspectable response plan before drafting, $\\textbf{RebuttalAgent}$ ensures that every argument is explicitly anchored in internal or external evidence. We validate our approach on the proposed $\\textbf{RebuttalBench}$ and demonstrate that our pipeline outperforms strong baselines in coverage, faithfulness, and strategic coherence, offering a transparent and controllable assistant for the peer review process. Code will be released.", "AI": {"tldr": "RebuttalAgent\uff1a\u9996\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u53cd\u9a73\u4fe1\u751f\u6210\u91cd\u6784\u4e3a\u4ee5\u8bc1\u636e\u4e3a\u4e2d\u5fc3\u7684\u89c4\u5212\u4efb\u52a1\uff0c\u901a\u8fc7\u5206\u89e3\u5ba1\u7a3f\u610f\u89c1\u3001\u6784\u5efa\u6df7\u5408\u4e0a\u4e0b\u6587\u548c\u5916\u90e8\u641c\u7d22\uff0c\u786e\u4fdd\u6bcf\u4e2a\u8bba\u70b9\u90fd\u6709\u660e\u786e\u8bc1\u636e\u652f\u6491\u3002", "motivation": "\u5f53\u524d\u53cd\u9a73\u4fe1\u751f\u6210\u65b9\u6cd5\u901a\u5e38\u5c06\u5176\u89c6\u4e3a\u76f4\u63a5\u6587\u672c\u751f\u6210\u95ee\u9898\uff0c\u5b58\u5728\u5e7b\u89c9\u3001\u5ffd\u89c6\u5ba1\u7a3f\u610f\u89c1\u3001\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u57fa\u7840\u7b49\u95ee\u9898\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7cbe\u786e\u5bf9\u9f50\u5ba1\u7a3f\u4eba\u610f\u56fe\u548c\u7a3f\u4ef6\u7ec6\u8282\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faRebuttalAgent\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1a1\uff09\u5c06\u590d\u6742\u5ba1\u7a3f\u610f\u89c1\u5206\u89e3\u4e3a\u539f\u5b50\u5316\u5173\u6ce8\u70b9\uff1b2\uff09\u52a8\u6001\u6784\u5efa\u6df7\u5408\u4e0a\u4e0b\u6587\uff0c\u7ed3\u5408\u538b\u7f29\u6458\u8981\u548c\u9ad8\u4fdd\u771f\u6587\u672c\uff1b3\uff09\u96c6\u6210\u81ea\u4e3b\u6309\u9700\u5916\u90e8\u641c\u7d22\u6a21\u5757\u5904\u7406\u9700\u8981\u5916\u90e8\u6587\u732e\u7684\u5173\u5207\uff1b4\uff09\u5728\u8d77\u8349\u524d\u751f\u6210\u53ef\u68c0\u67e5\u7684\u54cd\u5e94\u8ba1\u5212\u3002", "result": "\u5728\u63d0\u51fa\u7684RebuttalBench\u4e0a\u9a8c\u8bc1\uff0c\u8be5\u6d41\u6c34\u7ebf\u5728\u8986\u76d6\u7387\u3001\u5fe0\u5b9e\u5ea6\u548c\u7b56\u7565\u8fde\u8d2f\u6027\u65b9\u9762\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u4e3a\u540c\u884c\u8bc4\u5ba1\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u900f\u660e\u53ef\u63a7\u7684\u52a9\u624b\u3002", "conclusion": "RebuttalAgent\u901a\u8fc7\u5c06\u53cd\u9a73\u4fe1\u751f\u6210\u91cd\u6784\u4e3a\u8bc1\u636e\u4e2d\u5fc3\u7684\u89c4\u5212\u4efb\u52a1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u53ef\u63a7\u4e14\u57fa\u4e8e\u8bc1\u636e\u7684\u540c\u884c\u8bc4\u5ba1\u52a9\u624b\uff0c\u4ee3\u7801\u5c06\u5f00\u6e90\u3002"}}
{"id": "2601.14192", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14192", "abs": "https://arxiv.org/abs/2601.14192", "authors": ["Xiaofang Yang", "Lijun Li", "Heng Zhou", "Tong Zhu", "Xiaoye Qu", "Yuchen Fan", "Qianshan Wei", "Rui Ye", "Li Kang", "Yiran Qin", "Zhiqiang Kou", "Daizong Liu", "Qi Li", "Ning Ding", "Siheng Chen", "Jing Shao"], "title": "Toward Efficient Agents: Memory, Tool learning, and Planning", "comment": "35 pages, 200 references", "summary": "Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6548\u7387\u95ee\u9898\uff0c\u4ece\u8bb0\u5fc6\u3001\u5de5\u5177\u5b66\u4e60\u548c\u89c4\u5212\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\u51fa\u53d1\uff0c\u5206\u6790\u4e86\u6548\u7387\u4f18\u5316\u7684\u65b9\u6cd5\u3001\u8bc4\u4f30\u6307\u6807\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5411\u667a\u80fd\u4f53\u7cfb\u7edf\u6269\u5c55\uff0c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6709\u6548\u6027\u800c\u5ffd\u89c6\u4e86\u6548\u7387\u95ee\u9898\u3002\u6548\u7387\u5bf9\u4e8e\u5b9e\u9645\u90e8\u7f72\u81f3\u5173\u91cd\u8981\uff0c\u6d89\u53ca\u5ef6\u8fdf\u3001token\u6d88\u8017\u3001\u6b65\u9aa4\u6570\u7b49\u6210\u672c\u56e0\u7d20\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u4ece\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff08\u8bb0\u5fc6\u3001\u5de5\u5177\u5b66\u4e60\u3001\u89c4\u5212\uff09\u51fa\u53d1\uff0c\u7efc\u8ff0\u4e86\u591a\u79cd\u6548\u7387\u4f18\u5316\u65b9\u6cd5\uff1a\u901a\u8fc7\u538b\u7f29\u548c\u7ba1\u7406\u9650\u5236\u4e0a\u4e0b\u6587\u3001\u8bbe\u8ba1\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u4ee5\u51cf\u5c11\u5de5\u5177\u8c03\u7528\u3001\u91c7\u7528\u53d7\u63a7\u641c\u7d22\u673a\u5236\u7b49\u3002\u63d0\u51fa\u4ece\u4e24\u4e2a\u4e92\u8865\u89d2\u5ea6\u8861\u91cf\u6548\u7387\uff1a\u56fa\u5b9a\u6210\u672c\u9884\u7b97\u4e0b\u7684\u6709\u6548\u6027\u6bd4\u8f83\uff0c\u4ee5\u53ca\u76f8\u4f3c\u6709\u6548\u6027\u6c34\u5e73\u4e0b\u7684\u6210\u672c\u6bd4\u8f83\u3002", "result": "\u603b\u7ed3\u4e86\u6548\u7387\u5bfc\u5411\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ec\u5404\u7ec4\u4ef6\u8bc4\u4f30\u534f\u8bae\u548c\u5e38\u7528\u6548\u7387\u6307\u6807\u3002\u8bc6\u522b\u4e86\u6548\u7387\u4f18\u5316\u7684\u5171\u540c\u9ad8\u7ea7\u539f\u5219\uff0c\u5982\u4e0a\u4e0b\u6587\u8fb9\u754c\u63a7\u5236\u3001\u5de5\u5177\u8c03\u7528\u6700\u5c0f\u5316\u3001\u641c\u7d22\u4f18\u5316\u7b49\u3002\u5efa\u7acb\u4e86\u6548\u679c\u4e0e\u6210\u672c\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u5206\u6790\u6846\u67b6\u3002", "conclusion": "\u667a\u80fd\u4f53\u7cfb\u7edf\u6548\u7387\u7814\u7a76\u9700\u8981\u7cfb\u7edf\u6027\u65b9\u6cd5\uff0c\u6d89\u53ca\u8bb0\u5fc6\u7ba1\u7406\u3001\u5de5\u5177\u5b66\u4e60\u548c\u89c4\u5212\u4f18\u5316\u3002\u672a\u6765\u65b9\u5411\u5305\u62ec\u5f00\u53d1\u66f4\u5168\u9762\u7684\u6548\u7387\u8bc4\u4f30\u6846\u67b6\u3001\u63a2\u7d22\u6548\u7387\u4e0e\u6548\u679c\u7684\u5e73\u8861\u7b56\u7565\uff0c\u4ee5\u53ca\u5728\u5b9e\u9645\u90e8\u7f72\u573a\u666f\u4e2d\u9a8c\u8bc1\u4f18\u5316\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.13137", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13137", "abs": "https://arxiv.org/abs/2601.13137", "authors": ["Yuan Gao", "Zhigang Liu", "Xinyu Yao", "Bo Chen", "Xiaobing Zhao"], "title": "Adversarial Alignment: Ensuring Value Consistency in Large Language Models for Sensitive Domains", "comment": "13 pages, 5 figures", "summary": "With the wide application of large language models (LLMs), the problems of bias and value inconsistency in sensitive domains have gradually emerged, especially in terms of race, society and politics. In this paper, we propose an adversarial alignment framework, which enhances the value consistency of the model in sensitive domains through continued pre-training, instruction fine-tuning and adversarial training. In adversarial training, we use the Attacker to generate controversial queries, the Actor to generate responses with value consistency, and the Critic to filter and ensure response quality. Furthermore, we train a Value-Consistent Large Language Model, VC-LLM, for sensitive domains, and construct a bilingual evaluation dataset in Chinese and English. The experimental results show that VC-LLM performs better than the existing mainstream models in both Chinese and English tests, verifying the effectiveness of the method. Warning: This paper contains examples of LLMs that are offensive or harmful in nature.", "AI": {"tldr": "\u63d0\u51fa\u5bf9\u6297\u5bf9\u9f50\u6846\u67b6VC-LLM\uff0c\u901a\u8fc7\u6301\u7eed\u9884\u8bad\u7ec3\u3001\u6307\u4ee4\u5fae\u8c03\u548c\u5bf9\u6297\u8bad\u7ec3\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u654f\u611f\u9886\u57df\uff08\u79cd\u65cf\u3001\u793e\u4f1a\u3001\u653f\u6cbb\uff09\u7684\u4ef7\u503c\u4e00\u81f4\u6027", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5728\u654f\u611f\u9886\u57df\u4e2d\u5b58\u5728\u7684\u504f\u89c1\u548c\u4ef7\u503c\u4e0d\u4e00\u81f4\u95ee\u9898\u9010\u6e10\u51f8\u663e\uff0c\u7279\u522b\u662f\u5728\u79cd\u65cf\u3001\u793e\u4f1a\u548c\u653f\u6cbb\u65b9\u9762\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u6a21\u578b\u7684\u4ef7\u503c\u5bf9\u9f50\u95ee\u9898", "method": "\u63d0\u51fa\u5bf9\u6297\u5bf9\u9f50\u6846\u67b6\uff1a1\uff09\u6301\u7eed\u9884\u8bad\u7ec3\uff1b2\uff09\u6307\u4ee4\u5fae\u8c03\uff1b3\uff09\u5bf9\u6297\u8bad\u7ec3\uff08\u4f7f\u7528Attacker\u751f\u6210\u4e89\u8bae\u6027\u67e5\u8be2\uff0cActor\u751f\u6210\u4ef7\u503c\u4e00\u81f4\u7684\u54cd\u5e94\uff0cCritic\u8fc7\u6ee4\u5e76\u786e\u4fdd\u54cd\u5e94\u8d28\u91cf\uff09\u3002\u8bad\u7ec3\u4e86\u4e13\u95e8\u9488\u5bf9\u654f\u611f\u9886\u57df\u7684\u4ef7\u503c\u4e00\u81f4\u5927\u8bed\u8a00\u6a21\u578bVC-LLM\uff0c\u5e76\u6784\u5efa\u4e86\u4e2d\u82f1\u6587\u53cc\u8bed\u8bc4\u4f30\u6570\u636e\u96c6", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cVC-LLM\u5728\u4e2d\u82f1\u6587\u6d4b\u8bd5\u4e2d\u90fd\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u8bba\u6587\u5305\u542b\u5177\u6709\u5192\u72af\u6027\u6216\u6709\u5bb3\u6027\u8d28\u7684LLM\u793a\u4f8b", "conclusion": "\u63d0\u51fa\u7684\u5bf9\u6297\u5bf9\u9f50\u6846\u67b6\u80fd\u6709\u6548\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u654f\u611f\u9886\u57df\u7684\u4ef7\u503c\u4e00\u81f4\u6027\uff0cVC-LLM\u5728\u4ef7\u503c\u5bf9\u9f50\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u4e3a\u654f\u611f\u9886\u57df\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4ef7\u503c\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.13178", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13178", "abs": "https://arxiv.org/abs/2601.13178", "authors": ["Joseph Gatto", "Parker Seegmiller", "Timothy Burdick", "Philip Resnik", "Roshnik Rahat", "Sarah DeLozier", "Sarah M. Preum"], "title": "Medical Triage as Pairwise Ranking: A Benchmark for Urgency in Patient Portal Messages", "comment": "19 Pages, 5 Figures", "summary": "Medical triage is the task of allocating medical resources and prioritizing patients based on medical need. This paper introduces the first large-scale public dataset for studying medical triage in the context of asynchronous outpatient portal messages. Our novel task formulation views patient message triage as a pairwise inference problem, where we train LLMs to choose `\"which message is more medically urgent\" in a head-to-head tournament-style re-sort of a physician's inbox. Our novel benchmark PMR-Bench contains 1569 unique messages and 2,000+ high-quality test pairs for pairwise medical urgency assessment alongside a scalable training data generation pipeline. PMR-Bench includes samples that contain both unstructured patient-written messages alongside real electronic health record (EHR) data, emulating a real-world medical triage scenario.\n  We develop a novel automated data annotation strategy to provide LLMs with in-domain guidance on this task. The resulting data is used to train two model classes, UrgentReward and UrgentSFT, leveraging Bradley-Terry and next token prediction objective, respectively to perform pairwise urgency classification. We find that UrgentSFT achieves top performance on PMR-Bench, with UrgentReward showing distinct advantages in low-resource settings. For example, UrgentSFT-8B and UrgentReward-8B provide a 15- and 16-point boost, respectively, on inbox sorting metrics over off-the-shelf 8B models. Paper resources can be found at https://tinyurl.com/Patient-Message-Triage", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u5927\u89c4\u6a21\u516c\u5f00\u6570\u636e\u96c6PMR-Bench\uff0c\u7528\u4e8e\u7814\u7a76\u5f02\u6b65\u95e8\u8bca\u95e8\u6237\u6d88\u606f\u7684\u533b\u7597\u5206\u8bca\u4efb\u52a1\uff0c\u5c06\u60a3\u8005\u6d88\u606f\u5206\u8bca\u89c6\u4e3a\u6210\u5bf9\u63a8\u7406\u95ee\u9898\uff0c\u901a\u8fc7LLM\u8bad\u7ec3\u5b9e\u73b0\u533b\u7597\u7d27\u6025\u7a0b\u5ea6\u7684\u6bd4\u8f83\u6392\u5e8f\u3002", "motivation": "\u533b\u7597\u5206\u8bca\u662f\u6839\u636e\u533b\u7597\u9700\u6c42\u5206\u914d\u8d44\u6e90\u548c\u4f18\u5148\u5904\u7406\u60a3\u8005\u7684\u5173\u952e\u4efb\u52a1\uff0c\u4f46\u7f3a\u4e4f\u5927\u89c4\u6a21\u516c\u5f00\u6570\u636e\u96c6\u6765\u7814\u7a76\u5f02\u6b65\u95e8\u8bca\u95e8\u6237\u6d88\u606f\u7684\u5206\u8bca\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6a21\u62df\u771f\u5b9e\u4e16\u754c\u533b\u7597\u5206\u8bca\u573a\u666f\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u5c06\u60a3\u8005\u6d88\u606f\u5206\u8bca\u5efa\u6a21\u4e3a\u6210\u5bf9\u63a8\u7406\u95ee\u9898\uff0c\u8bad\u7ec3LLM\u8fdb\u884c\"\u54ea\u4e2a\u6d88\u606f\u66f4\u7d27\u6025\"\u7684\u5934\u90e8\u5bf9\u6bd4\uff1b\u5f00\u53d1PMR-Bench\u57fa\u51c6\uff0c\u5305\u542b1569\u6761\u72ec\u7279\u6d88\u606f\u548c2000+\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u5bf9\uff1b\u63d0\u51fa\u81ea\u52a8\u6570\u636e\u6807\u6ce8\u7b56\u7565\u4e3aLLM\u63d0\u4f9b\u9886\u57df\u6307\u5bfc\uff1b\u8bad\u7ec3UrgentReward\uff08\u4f7f\u7528Bradley-Terry\u76ee\u6807\uff09\u548cUrgentSFT\uff08\u4f7f\u7528\u4e0b\u4e00\u8bcd\u9884\u6d4b\u76ee\u6807\uff09\u4e24\u7c7b\u6a21\u578b\u3002", "result": "UrgentSFT\u5728PMR-Bench\u4e0a\u8868\u73b0\u6700\u4f73\uff0cUrgentReward\u5728\u4f4e\u8d44\u6e90\u8bbe\u7f6e\u4e2d\u663e\u793a\u72ec\u7279\u4f18\u52bf\uff1bUrgentSFT-8B\u548cUrgentReward-8B\u76f8\u6bd4\u73b0\u6210\u76848B\u6a21\u578b\u5728\u6536\u4ef6\u7bb1\u6392\u5e8f\u6307\u6807\u4e0a\u5206\u522b\u63d0\u534715\u548c16\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u6210\u529f\u5f00\u53d1\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u516c\u5f00\u533b\u7597\u5206\u8bca\u6570\u636e\u96c6PMR-Bench\uff0c\u8bc1\u660e\u4e86\u5c06\u60a3\u8005\u6d88\u606f\u5206\u8bca\u4f5c\u4e3a\u6210\u5bf9\u63a8\u7406\u95ee\u9898\u7684\u6709\u6548\u6027\uff0c\u4e3a\u533b\u7597\u5206\u8bca\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\u548c\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2601.13183", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13183", "abs": "https://arxiv.org/abs/2601.13183", "authors": ["Sergio Servantez", "Sarah B. Lawsky", "Rajiv Jain", "Daniel W. Linna", "Kristian Hammond"], "title": "OpenExempt: A Diagnostic Benchmark for Legal Reasoning and a Framework for Creating Custom Benchmarks on Demand", "comment": "25 pages, 9 Figures, 15 tables", "summary": "Reasoning benchmarks have played a crucial role in the progress of language models. Yet rigorous evaluation remains a significant challenge as static question-answer pairs provide only a snapshot of performance, compressing complex behavior into a single accuracy metric. This limitation is especially true in complex, rule-bound domains such as law, where existing benchmarks are costly to build and ill suited for isolating specific failure modes. To address this, we introduce OpenExempt, a framework and benchmark for diagnostic evaluation of legal reasoning. The OpenExempt Framework uses expert-crafted symbolic representations of U.S. Bankruptcy Code statutes to dynamically generate a large space of natural language reasoning tasks and their machine-computable solutions on demand. This gives users fine-grained control over task complexity and scope, allowing individual reasoning skills to be probed in isolation. Using this system, we construct the OpenExempt Benchmark, a diagnostic benchmark for legal reasoning with 9,765 samples across nine evaluation suites designed to carefully probe model capabilities. Experiments on 13 diverse language models reveal sharp performance cliffs that emerge only under longer reasoning paths and in the presence of obfuscating statements. We release the framework and benchmark publicly to support research aimed at understanding and improving the next generation of reasoning systems.", "AI": {"tldr": "OpenExempt\u662f\u4e00\u4e2a\u7528\u4e8e\u6cd5\u5f8b\u63a8\u7406\u8bca\u65ad\u8bc4\u4f30\u7684\u6846\u67b6\u548c\u57fa\u51c6\uff0c\u901a\u8fc7\u4e13\u5bb6\u6784\u5efa\u7684\u7f8e\u56fd\u7834\u4ea7\u6cd5\u6cd5\u89c4\u7b26\u53f7\u8868\u793a\u52a8\u6001\u751f\u6210\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4efb\u52a1\uff0c\u652f\u6301\u7ec6\u7c92\u5ea6\u63a7\u5236\u4efb\u52a1\u590d\u6742\u5ea6\uff0c\u5305\u542b9,765\u4e2a\u6837\u672c\u7684\u57fa\u51c6\u6d4b\u8bd5\u63ed\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u957f\u63a8\u7406\u8def\u5f84\u548c\u6df7\u6dc6\u8bed\u53e5\u4e0b\u7684\u6027\u80fd\u9661\u964d\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u57fa\u51c6\u5b58\u5728\u5c40\u9650\u6027\uff1a\u9759\u6001\u95ee\u7b54\u5bf9\u53ea\u80fd\u63d0\u4f9b\u6027\u80fd\u5feb\u7167\uff0c\u5c06\u590d\u6742\u884c\u4e3a\u538b\u7f29\u4e3a\u5355\u4e00\u51c6\u786e\u7387\u6307\u6807\uff1b\u5728\u590d\u6742\u3001\u89c4\u5219\u5bc6\u96c6\u7684\u6cd5\u5f8b\u9886\u57df\uff0c\u73b0\u6709\u57fa\u51c6\u6784\u5efa\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u9694\u79bb\u7279\u5b9a\u5931\u8d25\u6a21\u5f0f\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8fdb\u884c\u8bca\u65ad\u6027\u8bc4\u4f30\u3001\u7cbe\u7ec6\u63a7\u5236\u4efb\u52a1\u590d\u6742\u5ea6\u7684\u6cd5\u5f8b\u63a8\u7406\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51faOpenExempt\u6846\u67b6\uff0c\u4f7f\u7528\u4e13\u5bb6\u6784\u5efa\u7684\u7f8e\u56fd\u7834\u4ea7\u6cd5\u6cd5\u89c4\u7b26\u53f7\u8868\u793a\uff0c\u52a8\u6001\u751f\u6210\u5927\u91cf\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4efb\u52a1\u53ca\u5176\u673a\u5668\u53ef\u8ba1\u7b97\u89e3\uff1b\u7528\u6237\u53ef\u7ec6\u7c92\u5ea6\u63a7\u5236\u4efb\u52a1\u590d\u6742\u5ea6\u548c\u8303\u56f4\uff0c\u5355\u72ec\u6d4b\u8bd5\u7279\u5b9a\u63a8\u7406\u6280\u80fd\uff1b\u57fa\u4e8e\u6b64\u6846\u67b6\u6784\u5efaOpenExempt\u57fa\u51c6\uff0c\u5305\u542b9,765\u4e2a\u6837\u672c\uff0c\u5206\u5e03\u57289\u4e2a\u8bc4\u4f30\u5957\u4ef6\u4e2d\u3002", "result": "\u5bf913\u4e2a\u591a\u6837\u5316\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u9a8c\u663e\u793a\uff1a\u5728\u8f83\u957f\u63a8\u7406\u8def\u5f84\u548c\u5b58\u5728\u6df7\u6dc6\u8bed\u53e5\u7684\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u6027\u80fd\u51fa\u73b0\u663e\u8457\u9661\u964d\uff1b\u57fa\u51c6\u80fd\u591f\u6709\u6548\u8bca\u65ad\u6a21\u578b\u5728\u590d\u6742\u6cd5\u5f8b\u63a8\u7406\u4e2d\u7684\u5177\u4f53\u5931\u8d25\u6a21\u5f0f\uff1b\u6846\u67b6\u548c\u57fa\u51c6\u5df2\u516c\u5f00\u53d1\u5e03\u4ee5\u652f\u6301\u63a8\u7406\u7cfb\u7edf\u7814\u7a76\u3002", "conclusion": "OpenExempt\u6846\u67b6\u548c\u57fa\u51c6\u4e3a\u6cd5\u5f8b\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8bca\u65ad\u8bc4\u4f30\u5de5\u5177\uff0c\u80fd\u591f\u52a8\u6001\u751f\u6210\u4efb\u52a1\u3001\u7cbe\u7ec6\u63a7\u5236\u590d\u6742\u5ea6\uff0c\u63ed\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u573a\u666f\u4e0b\u7684\u6027\u80fd\u5c40\u9650\u6027\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u548c\u6539\u8fdb\u4e0b\u4e00\u4ee3\u63a8\u7406\u7cfb\u7edf\u3002"}}
{"id": "2601.13228", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13228", "abs": "https://arxiv.org/abs/2601.13228", "authors": ["Tianqi Du", "Lizhe Fang", "Weijie Yang", "Chenheng Zhang", "Zeming Wei", "Yifei Wang", "Yisen Wang"], "title": "Autoregressive Models Rival Diffusion Models at ANY-ORDER Generation", "comment": null, "summary": "Diffusion language models enable any-order generation and bidirectional conditioning, offering appealing flexibility for tasks such as infilling, rewriting, and self-correction. However, their formulation-predicting one part of a sequence from another within a single-step dependency-limits modeling depth and often yields lower sample quality and stability than autoregressive (AR) models. To address this, we revisit autoregressive modeling as a foundation and reformulate diffusion-style training into a structured multi-group prediction process. We propose Any-order Any-subset Autoregressive modeling (A3), a generalized framework that extends the standard AR factorization to arbitrary token groups and generation orders. A3 preserves the probabilistic rigor and multi-layer dependency modeling of AR while inheriting diffusion models' flexibility for parallel and bidirectional generation. We implement A3 through a two-stream attention architecture and a progressive adaptation strategy that transitions pretrained AR models toward any-order prediction. Experiments on question answering, commonsense reasoning, and story infilling demonstrate that A3 outperforms diffusion-based models while maintaining flexible decoding. This work offers a unified approach for a flexible, efficient, and novel language modeling paradigm.", "AI": {"tldr": "A3\u6846\u67b6\u5c06\u81ea\u56de\u5f52\u5efa\u6a21\u6269\u5c55\u4e3a\u4efb\u610f\u987a\u5e8f\u3001\u4efb\u610f\u5b50\u96c6\u7684\u9884\u6d4b\uff0c\u7ed3\u5408\u4e86\u81ea\u56de\u5f52\u6a21\u578b\u7684\u6df1\u5ea6\u5efa\u6a21\u4f18\u52bf\u548c\u6269\u6563\u6a21\u578b\u7684\u7075\u6d3b\u751f\u6210\u80fd\u529b", "motivation": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u867d\u7136\u652f\u6301\u4efb\u610f\u987a\u5e8f\u751f\u6210\u548c\u53cc\u5411\u6761\u4ef6\u5316\uff0c\u4f46\u5728\u5efa\u6a21\u6df1\u5ea6\u3001\u6837\u672c\u8d28\u91cf\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u4e0d\u5982\u81ea\u56de\u5f52\u6a21\u578b\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u81ea\u56de\u5f52\u6a21\u578b\u4f18\u52bf\u53c8\u80fd\u83b7\u5f97\u6269\u6563\u6a21\u578b\u7075\u6d3b\u6027\u7684\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u63d0\u51faA3\u6846\u67b6\uff0c\u5c06\u6807\u51c6\u81ea\u56de\u5f52\u5206\u89e3\u6269\u5c55\u5230\u4efb\u610f\u6807\u8bb0\u7ec4\u548c\u751f\u6210\u987a\u5e8f\u3002\u91c7\u7528\u53cc\u6d41\u6ce8\u610f\u529b\u67b6\u6784\u548c\u6e10\u8fdb\u9002\u5e94\u7b56\u7565\uff0c\u5c06\u9884\u8bad\u7ec3\u7684\u81ea\u56de\u5f52\u6a21\u578b\u8f6c\u6362\u4e3a\u652f\u6301\u4efb\u610f\u987a\u5e8f\u9884\u6d4b\u7684\u6a21\u578b\u3002", "result": "\u5728\u95ee\u7b54\u3001\u5e38\u8bc6\u63a8\u7406\u548c\u6545\u4e8b\u586b\u5145\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cA3\u5728\u4fdd\u6301\u7075\u6d3b\u89e3\u7801\u7684\u540c\u65f6\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u4e8e\u6269\u6563\u7684\u6a21\u578b\u3002", "conclusion": "A3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u7075\u6d3b\u3001\u9ad8\u6548\u4e14\u65b0\u9896\u7684\u8bed\u8a00\u5efa\u6a21\u8303\u5f0f\uff0c\u7ed3\u5408\u4e86\u81ea\u56de\u5f52\u6a21\u578b\u7684\u6982\u7387\u4e25\u8c28\u6027\u548c\u6269\u6563\u6a21\u578b\u7684\u751f\u6210\u7075\u6d3b\u6027\u3002"}}
{"id": "2601.13247", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.13247", "abs": "https://arxiv.org/abs/2601.13247", "authors": ["Baochang Ren", "Yunzhi Yao", "Rui Sun", "Shuofei Qiao", "Ningyu Zhang", "Huajun Chen"], "title": "Aligning Agentic World Models via Knowledgeable Experience Learning", "comment": "Ongoing work", "summary": "Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Consequently, while these agents implicitly function as world models, their simulations often suffer from physical hallucinations-generating plans that are logically sound but physically unexecutable. Existing alignment strategies predominantly rely on resource-intensive training or fine-tuning, which attempt to compress dynamic environmental rules into static model parameters. However, such parametric encapsulation is inherently rigid, struggling to adapt to the open-ended variability of physical dynamics without continuous, costly retraining. To bridge this gap, we introduce WorldMind, a framework that autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. Specifically, it unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.", "AI": {"tldr": "WorldMind\u6846\u67b6\u901a\u8fc7\u6784\u5efa\u7b26\u53f7\u5316\u4e16\u754c\u77e5\u8bc6\u5e93\uff0c\u5229\u7528\u73af\u5883\u53cd\u9988\u89e3\u51b3LLMs\u7269\u7406\u5e7b\u89c9\u95ee\u9898\uff0c\u5b9e\u73b0\u7269\u7406\u53ef\u884c\u6027\u548c\u4efb\u52a1\u6700\u4f18\u6027\u7684\u7edf\u4e00", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u6a21\u6001\u65ad\u5c42\uff1a\u62e5\u6709\u4e30\u5bcc\u8bed\u4e49\u77e5\u8bc6\u4f46\u7f3a\u4e4f\u7a0b\u5e8f\u6027\u57fa\u7840\u6765\u5c0a\u91cd\u7269\u7406\u4e16\u754c\u7684\u4e0d\u53d8\u6cd5\u5219\uff0c\u5bfc\u81f4\u4ea7\u751f\u903b\u8f91\u5408\u7406\u4f46\u7269\u7406\u4e0a\u4e0d\u53ef\u6267\u884c\u7684\u8ba1\u5212\uff08\u7269\u7406\u5e7b\u89c9\uff09\u3002\u73b0\u6709\u5bf9\u9f50\u7b56\u7565\u4e3b\u8981\u4f9d\u8d56\u8d44\u6e90\u5bc6\u96c6\u7684\u8bad\u7ec3\u6216\u5fae\u8c03\uff0c\u8bd5\u56fe\u5c06\u52a8\u6001\u73af\u5883\u89c4\u5219\u538b\u7f29\u5230\u9759\u6001\u6a21\u578b\u53c2\u6570\u4e2d\uff0c\u4f46\u8fd9\u79cd\u53c2\u6570\u5316\u5c01\u88c5\u672c\u8d28\u4e0a\u662f\u50f5\u5316\u7684\uff0c\u96be\u4ee5\u9002\u5e94\u7269\u7406\u52a8\u6001\u7684\u5f00\u653e\u53ef\u53d8\u6027", "method": "\u5f15\u5165WorldMind\u6846\u67b6\uff0c\u81ea\u4e3b\u6784\u5efa\u7b26\u53f7\u5316\u4e16\u754c\u77e5\u8bc6\u5e93\uff0c\u901a\u8fc7\u7efc\u5408\u73af\u5883\u53cd\u9988\u6765\u7edf\u4e00\u8fc7\u7a0b\u7ecf\u9a8c\uff08\u901a\u8fc7\u9884\u6d4b\u8bef\u5dee\u5f3a\u5236\u7269\u7406\u53ef\u884c\u6027\uff09\u548c\u76ee\u6807\u7ecf\u9a8c\uff08\u901a\u8fc7\u6210\u529f\u8f68\u8ff9\u6307\u5bfc\u4efb\u52a1\u6700\u4f18\u6027\uff09", "result": "\u5728EB-ALFRED\u548cEB-Habitat\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cWorldMind\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u53d6\u5f97\u4e86\u4f18\u8d8a\u6027\u80fd\uff0c\u5e76\u5c55\u73b0\u51fa\u663e\u8457\u7684\u8de8\u6a21\u578b\u548c\u8de8\u73af\u5883\u53ef\u8fc1\u79fb\u6027", "conclusion": "WorldMind\u901a\u8fc7\u6784\u5efa\u7b26\u53f7\u5316\u4e16\u754c\u77e5\u8bc6\u5e93\u6709\u6548\u89e3\u51b3\u4e86LLMs\u7684\u7269\u7406\u5e7b\u89c9\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u7269\u7406\u53ef\u884c\u6027\u548c\u4efb\u52a1\u6700\u4f18\u6027\u7684\u7edf\u4e00\uff0c\u4e14\u5177\u6709\u826f\u597d\u7684\u53ef\u8fc1\u79fb\u6027\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u53c2\u6570\u5316\u65b9\u6cd5\u7684\u50f5\u5316\u95ee\u9898"}}
{"id": "2601.13251", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13251", "abs": "https://arxiv.org/abs/2601.13251", "authors": ["Ebubekir Tosun", "Mehmet Emin Buldur", "\u00d6zay Ezerceli", "Mahmoud ElHussieni"], "title": "Beyond Cosine Similarity: Taming Semantic Drift and Antonym Intrusion in a 15-Million Node Turkish Synonym Graph", "comment": null, "summary": "Neural embeddings have a notorious blind spot: they can't reliably tell synonyms apart from antonyms. Consequently, increasing similarity thresholds often fails to prevent opposites from being grouped together. We've built a large-scale semantic clustering system specifically designed to tackle this problem head on. Our pipeline chews through 15 million lexical items, evaluates a massive 520 million potential relationships, and ultimately generates 2.9 million high-precision semantic clusters. The system makes three primary contributions. First, we introduce a labeled dataset of 843,000 concept pairs spanning synonymy, antonymy, and co-hyponymy, constructed via Gemini 2.5-Flash LLM augmentation and verified using human-curated dictionary resources. Second, we propose a specialized three-way semantic relation discriminator that achieves 90% macro-F1, enabling robust disambiguation beyond raw embedding similarity. Third, we introduce a novel soft-to-hard clustering algorithm that mitigates semantic drift preventing erroneous transitive chains (e.g., hot -> spicy -> pain -> depression) while simultaneously resolving polysemy. Our approach employs a topology-aware two-stage expansion-pruning procedure with topological voting, ensuring that each term is assigned to exactly one semantically coherent cluster. The resulting resource enables high-precision semantic search and retrieval-augmented generation, particularly for morphologically rich and low-resource languages where existing synonym databases remain sparse.", "AI": {"tldr": "\u63d0\u51fa\u5927\u89c4\u6a21\u8bed\u4e49\u805a\u7c7b\u7cfb\u7edf\uff0c\u89e3\u51b3\u795e\u7ecf\u5d4c\u5165\u65e0\u6cd5\u533a\u5206\u540c\u4e49\u8bcd\u548c\u53cd\u4e49\u8bcd\u7684\u76f2\u70b9\uff0c\u901a\u8fc7\u4e09\u8def\u8bed\u4e49\u5173\u7cfb\u5224\u522b\u5668\u548c\u8f6f\u5230\u786c\u805a\u7c7b\u7b97\u6cd5\u751f\u6210290\u4e07\u4e2a\u9ad8\u7cbe\u5ea6\u8bed\u4e49\u7c07\u3002", "motivation": "\u795e\u7ecf\u5d4c\u5165\u5b58\u5728\u663e\u8457\u76f2\u70b9\uff1a\u65e0\u6cd5\u53ef\u9760\u533a\u5206\u540c\u4e49\u8bcd\u548c\u53cd\u4e49\u8bcd\uff0c\u5bfc\u81f4\u63d0\u9ad8\u76f8\u4f3c\u5ea6\u9608\u503c\u65f6\u4ecd\u4f1a\u5c06\u53cd\u4e49\u8bcd\u5f52\u4e3a\u4e00\u7c7b\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5f62\u6001\u4e30\u5bcc\u548c\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u540c\u4e49\u8bcd\u6570\u636e\u5e93\u7a00\u758f\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u8bed\u4e49\u805a\u7c7b\u7cfb\u7edf\u3002", "method": "1) \u6784\u5efa\u5305\u542b843,000\u4e2a\u6982\u5ff5\u5bf9\u7684\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u540c\u4e49\u3001\u53cd\u4e49\u548c\u540c\u4e0b\u4f4d\u5173\u7cfb\uff0c\u4f7f\u7528Gemini 2.5-Flash LLM\u589e\u5f3a\u5e76\u7528\u4eba\u7f16\u8bcd\u5178\u9a8c\u8bc1\uff1b2) \u63d0\u51fa\u4e09\u8def\u8bed\u4e49\u5173\u7cfb\u5224\u522b\u5668\uff0c\u5b9e\u73b090%\u5b8fF1\u5206\u6570\uff1b3) \u5f00\u53d1\u8f6f\u5230\u786c\u805a\u7c7b\u7b97\u6cd5\uff0c\u91c7\u7528\u62d3\u6251\u611f\u77e5\u7684\u4e24\u9636\u6bb5\u6269\u5c55-\u526a\u679d\u8fc7\u7a0b\u4e0e\u62d3\u6251\u6295\u7968\uff0c\u9632\u6b62\u8bed\u4e49\u6f02\u79fb\u548c\u9519\u8bef\u4f20\u9012\u94fe\u3002", "result": "\u7cfb\u7edf\u5904\u74061500\u4e07\u4e2a\u8bcd\u6c47\u9879\uff0c\u8bc4\u4f305.2\u4ebf\u4e2a\u6f5c\u5728\u5173\u7cfb\uff0c\u6700\u7ec8\u751f\u6210290\u4e07\u4e2a\u9ad8\u7cbe\u5ea6\u8bed\u4e49\u7c07\u3002\u4e09\u8def\u5224\u522b\u5668\u8fbe\u523090%\u5b8fF1\u5206\u6570\uff0c\u8f6f\u5230\u786c\u805a\u7c7b\u7b97\u6cd5\u6709\u6548\u9632\u6b62\u8bed\u4e49\u6f02\u79fb\u5e76\u89e3\u51b3\u591a\u4e49\u6027\u95ee\u9898\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u89e3\u51b3\u4e86\u795e\u7ecf\u5d4c\u5165\u533a\u5206\u540c\u4e49\u8bcd\u548c\u53cd\u4e49\u8bcd\u7684\u6839\u672c\u95ee\u9898\uff0c\u901a\u8fc7\u4e13\u95e8\u7684\u5173\u7cfb\u5224\u522b\u548c\u62d3\u6251\u611f\u77e5\u805a\u7c7b\u751f\u6210\u9ad8\u8d28\u91cf\u8bed\u4e49\u8d44\u6e90\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5f62\u6001\u4e30\u5bcc\u548c\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u8bed\u4e49\u641c\u7d22\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3002"}}
{"id": "2601.13253", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13253", "abs": "https://arxiv.org/abs/2601.13253", "authors": ["Ebubekir Tosun", "Mehmet Emin Buldur", "\u00d6zay Ezerceli", "Mahmoud ElHussieni"], "title": "A Hybrid Protocol for Large-Scale Semantic Dataset Generation in Low-Resource Languages: The Turkish Semantic Relations Corpus", "comment": null, "summary": "We present a hybrid methodology for generating large-scale semantic relationship datasets in low-resource languages, demonstrated through a comprehensive Turkish semantic relations corpus. Our approach integrates three phases: (1) FastText embeddings with Agglomerative Clustering to identify semantic clusters, (2) Gemini 2.5-Flash for automated semantic relationship classification, and (3) integration with curated dictionary sources. The resulting dataset comprises 843,000 unique Turkish semantic pairs across three relationship types (synonyms, antonyms, co-hyponyms) representing a 10x scale increase over existing resources at minimal cost ($65). We validate the dataset through two downstream tasks: an embedding model achieving 90% top-1 retrieval accuracy and a classification model attaining 90% F1-macro. Our scalable protocol addresses critical data scarcity in Turkish NLP and demonstrates applicability to other low-resource languages. We publicly release the dataset and models.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6df7\u5408\u65b9\u6cd5\u751f\u6210\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u5927\u89c4\u6a21\u8bed\u4e49\u5173\u7cfb\u6570\u636e\u96c6\uff0c\u4ee5\u571f\u8033\u5176\u8bed\u4e3a\u4f8b\u521b\u5efa\u4e86\u5305\u542b84.3\u4e07\u5bf9\u8bed\u4e49\u5173\u7cfb\u7684\u8bed\u6599\u5e93\uff0c\u6210\u672c\u4ec565\u7f8e\u5143", "motivation": "\u89e3\u51b3\u571f\u8033\u5176\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u8bed\u4e49\u5173\u7cfb\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u73b0\u6709\u8d44\u6e90\u89c4\u6a21\u6709\u9650\u4e14\u6210\u672c\u9ad8\u6602", "method": "\u4e09\u9636\u6bb5\u6df7\u5408\u65b9\u6cd5\uff1a1) FastText\u5d4c\u5165+\u51dd\u805a\u805a\u7c7b\u8bc6\u522b\u8bed\u4e49\u7c07\uff1b2) Gemini 2.5-Flash\u81ea\u52a8\u5206\u7c7b\u8bed\u4e49\u5173\u7cfb\uff1b3) \u6574\u5408\u8bcd\u5178\u8d44\u6e90\u3002\u6db5\u76d6\u540c\u4e49\u8bcd\u3001\u53cd\u4e49\u8bcd\u3001\u540c\u4e0b\u4f4d\u8bcd\u4e09\u79cd\u5173\u7cfb\u7c7b\u578b", "result": "\u521b\u5efa\u4e8684.3\u4e07\u5bf9\u571f\u8033\u5176\u8bed\u8bed\u4e49\u5173\u7cfb\u6570\u636e\u96c6\uff0c\u89c4\u6a21\u662f\u73b0\u6709\u8d44\u6e90\u768410\u500d\uff0c\u6210\u672c\u4ec565\u7f8e\u5143\u3002\u4e0b\u6e38\u4efb\u52a1\u9a8c\u8bc1\uff1a\u5d4c\u5165\u6a21\u578b\u8fbe\u523090% top-1\u68c0\u7d22\u51c6\u786e\u7387\uff0c\u5206\u7c7b\u6a21\u578b\u8fbe\u523090% F1-macro\u5206\u6570", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u6269\u5c55\u5730\u89e3\u51b3\u4e86\u571f\u8033\u5176\u8bedNLP\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u5176\u4ed6\u4f4e\u8d44\u6e90\u8bed\u8a00\uff0c\u6570\u636e\u96c6\u548c\u6a21\u578b\u5df2\u516c\u5f00"}}
{"id": "2601.13260", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13260", "abs": "https://arxiv.org/abs/2601.13260", "authors": ["Sawsan Alqahtani", "Mir Tafseer Nayeem", "Md Tahmid Rahman Laskar", "Tasnim Mohiuddin", "M Saiful Bari"], "title": "Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models", "comment": "Accepted to EACL 2026 (long, main). The first two authors contributed equally", "summary": "Tokenization underlies every large language model, yet it remains an under-theorized and inconsistently designed component. Common subword approaches such as Byte Pair Encoding (BPE) offer scalability but often misalign with linguistic structure, amplify bias, and waste capacity across languages and domains. This paper reframes tokenization as a core modeling decision rather than a preprocessing step. We argue for a context-aware framework that integrates tokenizer and model co-design, guided by linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential to make tokenization choices accountable and comparable. Treating tokenization as a core design problem, not a technical afterthought, can yield language technologies that are fairer, more efficient, and more adaptable.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3b\u5f20\u5c06\u5206\u8bcd\u89c6\u4e3a\u6838\u5fc3\u5efa\u6a21\u51b3\u7b56\u800c\u975e\u9884\u5904\u7406\u6b65\u9aa4\uff0c\u63d0\u51fa\u4e0a\u4e0b\u6587\u611f\u77e5\u6846\u67b6\uff0c\u5f3a\u8c03\u5206\u8bcd\u5668\u4e0e\u6a21\u578b\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u4ee5\u5b9e\u73b0\u66f4\u516c\u5e73\u3001\u9ad8\u6548\u3001\u9002\u5e94\u6027\u5f3a\u7684\u8bed\u8a00\u6280\u672f\u3002", "motivation": "\u5f53\u524d\u5206\u8bcd\u65b9\u6cd5\uff08\u5982BPE\uff09\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u4e0e\u8bed\u8a00\u7ed3\u6784\u9519\u4f4d\uff0c2\uff09\u653e\u5927\u504f\u89c1\uff0c3\uff09\u5728\u4e0d\u540c\u8bed\u8a00\u548c\u9886\u57df\u4e2d\u6d6a\u8d39\u5bb9\u91cf\u3002\u8fd9\u4e9b\u95ee\u9898\u6e90\u4e8e\u5206\u8bcd\u88ab\u89c6\u4e3a\u6280\u672f\u540e\u5904\u7406\u800c\u975e\u6838\u5fc3\u8bbe\u8ba1\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u4e0a\u4e0b\u6587\u611f\u77e5\u6846\u67b6\uff0c\u5c06\u5206\u8bcd\u5668\u4e0e\u6a21\u578b\u534f\u540c\u8bbe\u8ba1\uff0c\u8003\u8651\u8bed\u8a00\u5b66\u3001\u9886\u57df\u548c\u90e8\u7f72\u56e0\u7d20\u3002\u5f3a\u8c03\u6807\u51c6\u5316\u8bc4\u4f30\u548c\u900f\u660e\u62a5\u544a\uff0c\u4f7f\u5206\u8bcd\u9009\u62e9\u53ef\u95ee\u8d23\u3001\u53ef\u6bd4\u8f83\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u7406\u8bba\u6846\u67b6\u800c\u975e\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4f46\u8bba\u8bc1\u4e86\u5c06\u5206\u8bcd\u4f5c\u4e3a\u6838\u5fc3\u8bbe\u8ba1\u95ee\u9898\u53ef\u4ee5\u5e26\u6765\u66f4\u516c\u5e73\u3001\u9ad8\u6548\u3001\u9002\u5e94\u6027\u5f3a\u7684\u8bed\u8a00\u6280\u672f\u3002", "conclusion": "\u5206\u8bcd\u5e94\u88ab\u89c6\u4e3a\u6838\u5fc3\u5efa\u6a21\u51b3\u7b56\u800c\u975e\u9884\u5904\u7406\u6b65\u9aa4\u3002\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u6846\u67b6\u3001\u6807\u51c6\u5316\u8bc4\u4f30\u548c\u900f\u660e\u62a5\u544a\uff0c\u53ef\u4ee5\u5b9e\u73b0\u66f4\u516c\u5e73\u3001\u9ad8\u6548\u3001\u9002\u5e94\u6027\u5f3a\u7684\u8bed\u8a00\u6280\u672f\u3002"}}
{"id": "2601.13264", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13264", "abs": "https://arxiv.org/abs/2601.13264", "authors": ["Tyler Lizzo", "Larry Heck"], "title": "Unlearning in LLMs: Methods, Evaluation, and Open Challenges", "comment": null, "summary": "Large language models (LLMs) have achieved remarkable success across natural language processing tasks, yet their widespread deployment raises pressing concerns around privacy, copyright, security, and bias. Machine unlearning has emerged as a promising paradigm for selectively removing knowledge or data from trained models without full retraining. In this survey, we provide a structured overview of unlearning methods for LLMs, categorizing existing approaches into data-centric, parameter-centric, architecture-centric, hybrid, and other strategies. We also review the evaluation ecosystem, including benchmarks, metrics, and datasets designed to measure forgetting effectiveness, knowledge retention, and robustness. Finally, we outline key challenges and open problems, such as scalable efficiency, formal guarantees, cross-language and multimodal unlearning, and robustness against adversarial relearning. By synthesizing current progress and highlighting open directions, this paper aims to serve as a roadmap for developing reliable and responsible unlearning techniques in large language models.", "AI": {"tldr": "\u5173\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\u7684\u7efc\u8ff0\uff0c\u7cfb\u7edf\u5206\u7c7b\u73b0\u6709\u6280\u672f\u5e76\u5206\u6790\u8bc4\u4f30\u4f53\u7cfb\uff0c\u4e3a\u5f00\u53d1\u53ef\u9760\u9057\u5fd8\u6280\u672f\u63d0\u4f9b\u8def\u7ebf\u56fe", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u663e\u8457\u6210\u529f\uff0c\u4f46\u5176\u5e7f\u6cdb\u90e8\u7f72\u5f15\u53d1\u4e86\u9690\u79c1\u3001\u7248\u6743\u3001\u5b89\u5168\u548c\u504f\u89c1\u7b49\u7d27\u8feb\u95ee\u9898\u3002\u673a\u5668\u9057\u5fd8\u4f5c\u4e3a\u4e00\u79cd\u6709\u524d\u666f\u7684\u8303\u5f0f\uff0c\u53ef\u4ee5\u5728\u4e0d\u5b8c\u5168\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u6709\u9009\u62e9\u5730\u4ece\u8bad\u7ec3\u6a21\u578b\u4e2d\u79fb\u9664\u77e5\u8bc6\u6216\u6570\u636e", "method": "\u63d0\u4f9b\u7ed3\u6784\u5316\u7efc\u8ff0\uff0c\u5c06\u73b0\u6709\u9057\u5fd8\u65b9\u6cd5\u5206\u7c7b\u4e3a\u6570\u636e\u4e2d\u5fc3\u3001\u53c2\u6570\u4e2d\u5fc3\u3001\u67b6\u6784\u4e2d\u5fc3\u3001\u6df7\u5408\u53ca\u5176\u4ed6\u7b56\u7565\uff1b\u56de\u987e\u8bc4\u4f30\u751f\u6001\u7cfb\u7edf\uff0c\u5305\u62ec\u57fa\u51c6\u6d4b\u8bd5\u3001\u6307\u6807\u548c\u6570\u636e\u96c6\uff1b\u5206\u6790\u5173\u952e\u6311\u6218\u548c\u5f00\u653e\u95ee\u9898", "result": "\u7cfb\u7edf\u68b3\u7406\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u673a\u5668\u9057\u5fd8\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u5efa\u7acb\u4e86\u65b9\u6cd5\u5206\u7c7b\u6846\u67b6\u548c\u8bc4\u4f30\u4f53\u7cfb\uff0c\u8bc6\u522b\u4e86\u5f53\u524d\u7814\u7a76\u7684\u4e3b\u8981\u6311\u6218\u548c\u672a\u6765\u65b9\u5411", "conclusion": "\u901a\u8fc7\u7efc\u5408\u5f53\u524d\u8fdb\u5c55\u548c\u7a81\u51fa\u5f00\u653e\u65b9\u5411\uff0c\u672c\u6587\u65e8\u5728\u4e3a\u5f00\u53d1\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u53ef\u9760\u548c\u8d1f\u8d23\u4efb\u7684\u9057\u5fd8\u6280\u672f\u63d0\u4f9b\u8def\u7ebf\u56fe"}}
{"id": "2601.13288", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13288", "abs": "https://arxiv.org/abs/2601.13288", "authors": ["Gonzalo Ariel Meyoyan", "Luciano Del Corro"], "title": "A BERTology View of LLM Orchestrations: Token- and Layer-Selective Probes for Efficient Single-Pass Classification", "comment": null, "summary": "Production LLM systems often rely on separate models for safety and other classification-heavy steps, increasing latency, VRAM footprint, and operational complexity. We instead reuse computation already paid for by the serving LLM: we train lightweight probes on its hidden states and predict labels in the same forward pass used for generation. We frame classification as representation selection over the full token-layer hidden-state tensor, rather than committing to a fixed token or fixed layer (e.g., first-token logits or final-layer pooling). To implement this, we introduce a two-stage aggregator that (i) summarizes tokens within each layer and (ii) aggregates across layer summaries to form a single representation for classification. We instantiate this template with direct pooling, a 100K-parameter scoring-attention gate, and a downcast multi-head self-attention (MHA) probe with up to 35M trainable parameters. Across safety and sentiment benchmarks our probes improve over logit-only reuse (e.g., MULI) and are competitive with substantially larger task-specific baselines, while preserving near-serving latency and avoiding the VRAM and latency costs of a separate guard-model pipeline.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5728LLM\u670d\u52a1\u4e2d\u590d\u7528\u8ba1\u7b97\u7684\u65b9\u6cd5\uff1a\u901a\u8fc7\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u63a2\u9488\u5728LLM\u9690\u85cf\u72b6\u6001\u4e0a\u8fdb\u884c\u5206\u7c7b\u9884\u6d4b\uff0c\u907f\u514d\u4f7f\u7528\u72ec\u7acb\u7684\u5206\u7c7b\u6a21\u578b\uff0c\u4ece\u800c\u964d\u4f4e\u5ef6\u8fdf\u3001VRAM\u5360\u7528\u548c\u64cd\u4f5c\u590d\u6742\u6027\u3002", "motivation": "\u5f53\u524d\u751f\u4ea7\u7ea7LLM\u7cfb\u7edf\u901a\u5e38\u4f7f\u7528\u72ec\u7acb\u6a21\u578b\u8fdb\u884c\u5b89\u5168\u548c\u5206\u7c7b\u4efb\u52a1\uff0c\u8fd9\u589e\u52a0\u4e86\u5ef6\u8fdf\u3001VRAM\u5360\u7528\u548c\u64cd\u4f5c\u590d\u6742\u6027\u3002\u4f5c\u8005\u5e0c\u671b\u590d\u7528LLM\u670d\u52a1\u5df2\u7ecf\u652f\u4ed8\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u5728\u751f\u6210\u7684\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u540c\u65f6\u5b8c\u6210\u5206\u7c7b\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8868\u793a\u9009\u62e9\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u800c\u975e\u56fa\u5b9atoken\u6216\u5c42\u3002\u5f15\u5165\u4e24\u9636\u6bb5\u805a\u5408\u5668\uff1a(1) \u5728\u6bcf\u5c42\u5185\u6c47\u603btoken\uff0c(2) \u8de8\u5c42\u805a\u5408\u5f62\u6210\u5355\u4e00\u8868\u793a\u8fdb\u884c\u5206\u7c7b\u3002\u5177\u4f53\u5b9e\u73b0\u5305\u62ec\u76f4\u63a5\u6c60\u5316\u3001100K\u53c2\u6570\u8bc4\u5206\u6ce8\u610f\u529b\u95e8\u63a7\u548c\u6700\u591a35M\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u4e0b\u91c7\u6837\u591a\u5934\u81ea\u6ce8\u610f\u529b\u63a2\u9488\u3002", "result": "\u5728\u5b89\u5168\u548c\u60c5\u611f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4ec5\u4f7f\u7528logit\u7684\u590d\u7528\u65b9\u6cd5\uff08\u5982MULI\uff09\uff0c\u4e0e\u66f4\u5927\u7684\u4efb\u52a1\u7279\u5b9a\u57fa\u7ebf\u6a21\u578b\u7ade\u4e89\u6027\u76f8\u5f53\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63a5\u8fd1\u670d\u52a1\u5ef6\u8fdf\uff0c\u907f\u514d\u4e86\u72ec\u7acb\u9632\u62a4\u6a21\u578b\u7ba1\u9053\u7684VRAM\u548c\u5ef6\u8fdf\u6210\u672c\u3002", "conclusion": "\u901a\u8fc7\u590d\u7528LLM\u9690\u85cf\u72b6\u6001\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u63a2\u9488\u8fdb\u884c\u540c\u6b65\u5206\u7c7b\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u4f4e\u5ef6\u8fdf\u7684\u540c\u65f6\u6709\u6548\u66ff\u4ee3\u72ec\u7acb\u7684\u5206\u7c7b\u6a21\u578b\uff0c\u4e3a\u751f\u4ea7\u7ea7LLM\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u5206\u7c7b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13300", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13300", "abs": "https://arxiv.org/abs/2601.13300", "authors": ["Yow-Fu Liou", "Yu-Chien Tang", "Yu-Hsiang Liu", "An-Zi Yen"], "title": "OI-Bench: An Option Injection Benchmark for Evaluating LLM Susceptibility to Directive Interference", "comment": null, "summary": "Benchmarking large language models (LLMs) is critical for understanding their capabilities, limitations, and robustness. In addition to interface artifacts, prior studies have shown that LLM decisions can be influenced by directive signals such as social cues, framing, and instructions. In this work, we introduce option injection, a benchmarking approach that augments the multiple-choice question answering (MCQA) interface with an additional option containing a misleading directive, leveraging standardized choice structure and scalable evaluation. We construct OI-Bench, a benchmark of 3,000 questions spanning knowledge, reasoning, and commonsense tasks, with 16 directive types covering social compliance, bonus framing, threat framing, and instructional interference. This setting combines manipulation of the choice interface with directive-based interference, enabling systematic assessment of model susceptibility. We evaluate 12 LLMs to analyze attack success rates, behavioral responses, and further investigate mitigation strategies ranging from inference-time prompting to post-training alignment. Experimental results reveal substantial vulnerabilities and heterogeneous robustness across models. OI-Bench is expected to support more systematic evaluation of LLM robustness to directive interference within choice-based interfaces.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9009\u9879\u6ce8\u5165\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u591a\u9879\u9009\u62e9\u9898\u4e2d\u63d2\u5165\u5305\u542b\u8bef\u5bfc\u6027\u6307\u4ee4\u7684\u989d\u5916\u9009\u9879\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u6307\u4ee4\u5e72\u6270\u7684\u8106\u5f31\u6027\uff0c\u5e76\u6784\u5efa\u4e86\u5305\u542b3000\u4e2a\u95ee\u9898\u7684OI-Bench\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u51b3\u7b56\u4e0d\u4ec5\u53d7\u754c\u9762\u56e0\u7d20\u5f71\u54cd\uff0c\u8fd8\u4f1a\u88ab\u793e\u4f1a\u7ebf\u7d22\u3001\u6846\u67b6\u6548\u5e94\u548c\u6307\u4ee4\u7b49\u5b9a\u5411\u4fe1\u53f7\u6240\u5e72\u6270\u3002\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u6a21\u578b\u5bf9\u8fd9\u7c7b\u6307\u4ee4\u5e72\u6270\u7684\u9c81\u68d2\u6027\uff0c\u7279\u522b\u662f\u5728\u6807\u51c6\u5316\u9009\u62e9\u754c\u9762\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u9009\u9879\u6ce8\u5165\u653b\u51fb\u65b9\u6cd5\uff0c\u5728\u591a\u9879\u9009\u62e9\u9898\u56de\u7b54\u754c\u9762\u4e2d\u589e\u52a0\u5305\u542b\u8bef\u5bfc\u6027\u6307\u4ee4\u7684\u989d\u5916\u9009\u9879\u3002\u6784\u5efaOI-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b3000\u4e2a\u95ee\u9898\uff0c\u6db5\u76d6\u77e5\u8bc6\u3001\u63a8\u7406\u548c\u5e38\u8bc6\u4efb\u52a1\uff0c\u4f7f\u752816\u79cd\u6307\u4ee4\u7c7b\u578b\uff08\u793e\u4f1a\u9075\u4ece\u3001\u5956\u52b1\u6846\u67b6\u3001\u5a01\u80c1\u6846\u67b6\u3001\u6307\u4ee4\u5e72\u6270\uff09\u3002\u8bc4\u4f3012\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5206\u6790\u653b\u51fb\u6210\u529f\u7387\u3001\u884c\u4e3a\u54cd\u5e94\uff0c\u5e76\u7814\u7a76\u4ece\u63a8\u7406\u65f6\u63d0\u793a\u5230\u8bad\u7ec3\u540e\u5bf9\u9f50\u7b49\u591a\u79cd\u7f13\u89e3\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u663e\u8457\u8106\u5f31\u6027\uff0c\u4e0d\u540c\u6a21\u578b\u8868\u73b0\u51fa\u5f02\u8d28\u6027\u9c81\u68d2\u6027\u3002\u9009\u9879\u6ce8\u5165\u653b\u51fb\u80fd\u6709\u6548\u63ed\u793a\u6a21\u578b\u5bf9\u6307\u4ee4\u5e72\u6270\u7684\u654f\u611f\u6027\uff0c\u4e3a\u7cfb\u7edf\u8bc4\u4f30\u6a21\u578b\u5728\u57fa\u4e8e\u9009\u62e9\u7684\u754c\u9762\u4e2d\u5bf9\u6307\u4ee4\u5e72\u6270\u7684\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002", "conclusion": "\u9009\u9879\u6ce8\u5165\u65b9\u6cd5\u7ed3\u5408\u4e86\u9009\u62e9\u754c\u9762\u64cd\u7eb5\u548c\u57fa\u4e8e\u6307\u4ee4\u7684\u5e72\u6270\uff0c\u80fd\u591f\u7cfb\u7edf\u8bc4\u4f30\u6a21\u578b\u6613\u611f\u6027\u3002OI-Bench\u57fa\u51c6\u6d4b\u8bd5\u652f\u6301\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u57fa\u4e8e\u9009\u62e9\u7684\u754c\u9762\u4e2d\u5bf9\u6307\u4ee4\u5e72\u6270\u7684\u9c81\u68d2\u6027\u8fdb\u884c\u66f4\u7cfb\u7edf\u8bc4\u4f30\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u7684\u91cd\u8981\u95ee\u9898\u3002"}}
{"id": "2601.13317", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.13317", "abs": "https://arxiv.org/abs/2601.13317", "authors": ["Samantha Sudhoff", "Pranav Perumal", "Zhaoqing Wu", "Tunazzina Islam"], "title": "Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse", "comment": null, "summary": "Climate discourse online plays a crucial role in shaping public understanding of climate change and influencing political and policy outcomes. However, climate communication unfolds across structurally distinct platforms with fundamentally different incentive structures: paid advertising ecosystems incentivize targeted, strategic persuasion, while public social media platforms host largely organic, user-driven discourse. Existing computational studies typically analyze these environments in isolation, limiting our ability to distinguish institutional messaging from public expression. In this work, we present a comparative analysis of climate discourse across paid advertisements on Meta (previously known as Facebook) and public posts on Bluesky from July 2024 to September 2025. We introduce an interpretable, end-to-end thematic discovery and assignment framework that clusters texts by semantic similarity and leverages large language models (LLMs) to generate concise, human-interpretable theme labels. We evaluate the quality of the induced themes against traditional topic modeling baselines using both human judgments and an LLM-based evaluator, and further validate their semantic coherence through downstream stance prediction and theme-guided retrieval tasks. Applying the resulting themes, we characterize systematic differences between paid climate messaging and public climate discourse and examine how thematic prevalence shifts around major political events. Our findings show that platform-level incentives are reflected in the thematic structure, stance alignment, and temporal responsiveness of climate narratives. While our empirical analysis focuses on climate communication, the proposed framework is designed to support comparative narrative analysis across heterogeneous communication environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u4e3b\u9898\u53d1\u73b0\u6846\u67b6\uff0c\u6bd4\u8f83Meta\u4ed8\u8d39\u5e7f\u544a\u548cBluesky\u516c\u5171\u5e16\u5b50\u4e2d\u7684\u6c14\u5019\u8bdd\u8bed\u5dee\u5f02\uff0c\u53d1\u73b0\u5e73\u53f0\u6fc0\u52b1\u673a\u5236\u5f71\u54cd\u53d9\u4e8b\u7ed3\u6784\u3001\u7acb\u573a\u5bf9\u9f50\u548c\u65f6\u95f4\u54cd\u5e94\u6027", "motivation": "\u73b0\u6709\u7814\u7a76\u901a\u5e38\u5b64\u7acb\u5206\u6790\u4e0d\u540c\u5e73\u53f0\u7684\u6c14\u5019\u8bdd\u8bed\uff0c\u9650\u5236\u4e86\u533a\u5206\u673a\u6784\u4fe1\u606f\u4e0e\u516c\u4f17\u8868\u8fbe\u7684\u80fd\u529b\u3002\u4ed8\u8d39\u5e7f\u544a\u751f\u6001\u7cfb\u7edf\u6fc0\u52b1\u5b9a\u5411\u6218\u7565\u8bf4\u670d\uff0c\u800c\u516c\u5171\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u4e3b\u8981\u627f\u8f7d\u6709\u673a\u7684\u7528\u6237\u9a71\u52a8\u8bdd\u8bed\uff0c\u9700\u8981\u6bd4\u8f83\u5206\u6790\u8fd9\u4e24\u79cd\u7ed3\u6784\u4e0d\u540c\u7684\u73af\u5883", "method": "\u63d0\u51fa\u53ef\u89e3\u91ca\u7684\u7aef\u5230\u7aef\u4e3b\u9898\u53d1\u73b0\u548c\u5206\u914d\u6846\u67b6\uff1a\u901a\u8fc7\u8bed\u4e49\u76f8\u4f3c\u6027\u805a\u7c7b\u6587\u672c\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7b80\u6d01\u3001\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u4e3b\u9898\u6807\u7b7e\u3002\u8bc4\u4f30\u8bf1\u5bfc\u4e3b\u9898\u8d28\u91cf\uff08\u4e0e\u4f20\u7edf\u4e3b\u9898\u5efa\u6a21\u57fa\u7ebf\u6bd4\u8f83\uff0c\u4f7f\u7528\u4eba\u7c7b\u5224\u65ad\u548cLLM\u8bc4\u4f30\u5668\uff09\uff0c\u901a\u8fc7\u4e0b\u6e38\u7acb\u573a\u9884\u6d4b\u548c\u4e3b\u9898\u5f15\u5bfc\u68c0\u7d22\u4efb\u52a1\u9a8c\u8bc1\u8bed\u4e49\u8fde\u8d2f\u6027\u3002\u5e94\u7528\u4e8e2024\u5e747\u6708\u81f32025\u5e749\u6708\u7684Meta\u4ed8\u8d39\u5e7f\u544a\u548cBluesky\u516c\u5171\u5e16\u5b50\u6570\u636e", "result": "\u5e73\u53f0\u5c42\u9762\u7684\u6fc0\u52b1\u673a\u5236\u53cd\u6620\u5728\u6c14\u5019\u53d9\u4e8b\u7684\u4e3b\u9898\u7ed3\u6784\u3001\u7acb\u573a\u5bf9\u9f50\u548c\u65f6\u95f4\u54cd\u5e94\u6027\u4e2d\u3002\u4ed8\u8d39\u6c14\u5019\u4fe1\u606f\u4e0e\u516c\u5171\u6c14\u5019\u8bdd\u8bed\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u4e3b\u9898\u6d41\u884c\u5ea6\u5728\u91cd\u5927\u653f\u6cbb\u4e8b\u4ef6\u5468\u56f4\u53d1\u751f\u53d8\u5316", "conclusion": "\u867d\u7136\u5b9e\u8bc1\u5206\u6790\u805a\u7126\u6c14\u5019\u4f20\u64ad\uff0c\u4f46\u63d0\u51fa\u7684\u6846\u67b6\u65e8\u5728\u652f\u6301\u8de8\u5f02\u6784\u4f20\u64ad\u73af\u5883\u7684\u6bd4\u8f83\u53d9\u4e8b\u5206\u6790\u3002\u5e73\u53f0\u6fc0\u52b1\u673a\u5236\u5851\u9020\u4e86\u6c14\u5019\u8bdd\u8bed\u7684\u7279\u5f81\uff0c\u533a\u5206\u4ed8\u8d39\u6218\u7565\u8bf4\u670d\u4e0e\u6709\u673a\u516c\u4f17\u8868\u8fbe\u5bf9\u4e8e\u7406\u89e3\u6c14\u5019\u4f20\u64ad\u52a8\u6001\u81f3\u5173\u91cd\u8981"}}
{"id": "2601.13328", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13328", "abs": "https://arxiv.org/abs/2601.13328", "authors": ["Geoffrey Churchill", "Steven Skiena"], "title": "Reducing Tokenization Premiums for Low-Resource Languages", "comment": null, "summary": "Relative to English, low-resource languages suffer from substantial tokenization premiums in modern LMs, meaning that it generally requires several times as many tokens to encode a sentence in a low-resource language than to encode the analogous sentence in English. This tokenization premium results in increased API and energy costs and reduced effective context windows for these languages. In this paper we analyze the tokenizers of ten popular LMs to better understand their designs and per-language tokenization premiums. We also propose a mechanism to reduce tokenization premiums in pre-trained models, by post-hoc additions to the token vocabulary that coalesce multi-token characters into single tokens. We apply this methodology to 12 low-resource languages, demonstrating that the original and compressed inputs often have similar last hidden states when run through the Llama 3.2 1B model.", "AI": {"tldr": "\u5206\u6790\u6d41\u884c\u8bed\u8a00\u6a21\u578b\u7684tokenizer\u8bbe\u8ba1\u53ca\u5176\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u901a\u8fc7\u540e\u5904\u7406\u589e\u52a0\u8bcd\u6c47\u8868\u6765\u51cf\u5c11\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684tokenization premium", "motivation": "\u4f4e\u8d44\u6e90\u8bed\u8a00\u5728\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u4e2d\u5b58\u5728\u663e\u8457\u7684tokenization premium\uff08\u76f8\u5bf9\u4e8e\u82f1\u8bed\u9700\u8981\u66f4\u591atoken\u7f16\u7801\u76f8\u540c\u5185\u5bb9\uff09\uff0c\u8fd9\u5bfc\u81f4API\u6210\u672c\u589e\u52a0\u3001\u80fd\u8017\u4e0a\u5347\u548c\u6709\u6548\u4e0a\u4e0b\u6587\u7a97\u53e3\u51cf\u5c11", "method": "\u5206\u679010\u4e2a\u6d41\u884c\u8bed\u8a00\u6a21\u578b\u7684tokenizer\u8bbe\u8ba1\uff0c\u63d0\u51fa\u540e\u5904\u7406\u673a\u5236\uff1a\u901a\u8fc7\u5411\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u8bcd\u6c47\u8868\u4e2d\u6dfb\u52a0\u591a\u5b57\u7b26\u7ec4\u5408\u7684\u5355\u4e00token\u6765\u538b\u7f29tokenization premium", "result": "\u572812\u79cd\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u5e94\u7528\u8be5\u65b9\u6cd5\uff0c\u8bc1\u660e\u539f\u59cb\u8f93\u5165\u548c\u538b\u7f29\u8f93\u5165\u5728Llama 3.2 1B\u6a21\u578b\u4e2d\u5177\u6709\u76f8\u4f3c\u7684\u6700\u7ec8\u9690\u85cf\u72b6\u6001", "conclusion": "\u901a\u8fc7\u540e\u5904\u7406\u589e\u52a0\u8bcd\u6c47\u8868\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684tokenization premium\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u4f4e\u8d44\u6e90\u8bed\u8a00\u5728\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6548\u7387\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6848"}}
{"id": "2601.13330", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13330", "abs": "https://arxiv.org/abs/2601.13330", "authors": ["Jamie Cummins", "Beth Clarke", "Ian Hussey", "Malte Elson"], "title": "RegCheck: A tool for automating comparisons between study registrations and papers", "comment": "15 pages, 1 figure", "summary": "Across the social and medical sciences, researchers recognize that specifying planned research activities (i.e., 'registration') prior to the commencement of research has benefits for both the transparency and rigour of science. Despite this, evidence suggests that study registrations frequently go unexamined, minimizing their effectiveness. In a way this is no surprise: manually checking registrations against papers is labour- and time-intensive, requiring careful reading across formats and expertise across domains. The advent of AI unlocks new possibilities in facilitating this activity. We present RegCheck, a modular LLM-assisted tool designed to help researchers, reviewers, and editors from across scientific disciplines compare study registrations with their corresponding papers. Importantly, RegCheck keeps human expertise and judgement in the loop by (i) ensuring that users are the ones who determine which features should be compared, and (ii) presenting the most relevant text associated with each feature to the user, facilitating (rather than replacing) human discrepancy judgements. RegCheck also generates shareable reports with unique RegCheck IDs, enabling them to be easily shared and verified by other users. RegCheck is designed to be adaptable across scientific domains, as well as registration and publication formats. In this paper we provide an overview of the motivation, workflow, and design principles of RegCheck, and we discuss its potential as an extensible infrastructure for reproducible science with an example use case.", "AI": {"tldr": "RegCheck\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u7684LLM\u8f85\u52a9\u5de5\u5177\uff0c\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u3001\u5ba1\u7a3f\u4eba\u548c\u7f16\u8f91\u8de8\u79d1\u5b66\u9886\u57df\u6bd4\u8f83\u7814\u7a76\u6ce8\u518c\u4e0e\u5bf9\u5e94\u8bba\u6587\uff0c\u4fdd\u6301\u4eba\u7c7b\u4e13\u4e1a\u5224\u65ad\u5728\u5faa\u73af\u4e2d\uff0c\u5e76\u751f\u6210\u53ef\u5171\u4eab\u7684\u62a5\u544a\u3002", "motivation": "\u5c3d\u7ba1\u9884\u5148\u6307\u5b9a\u7814\u7a76\u6d3b\u52a8\uff08\u6ce8\u518c\uff09\u5bf9\u79d1\u5b66\u900f\u660e\u5ea6\u548c\u4e25\u8c28\u6027\u6709\u76ca\uff0c\u4f46\u6ce8\u518c\u7ecf\u5e38\u672a\u88ab\u68c0\u67e5\uff0c\u964d\u4f4e\u4e86\u5176\u6709\u6548\u6027\u3002\u624b\u52a8\u68c0\u67e5\u6ce8\u518c\u4e0e\u8bba\u6587\u8017\u65f6\u8017\u529b\uff0c\u9700\u8981\u8de8\u683c\u5f0f\u4ed4\u7ec6\u9605\u8bfb\u548c\u8de8\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u3002AI\u7684\u51fa\u73b0\u4e3a\u4fc3\u8fdb\u8fd9\u4e00\u6d3b\u52a8\u63d0\u4f9b\u4e86\u65b0\u53ef\u80fd\u3002", "method": "RegCheck\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u7684LLM\u8f85\u52a9\u5de5\u5177\uff0c\u8bbe\u8ba1\u7528\u4e8e\u6bd4\u8f83\u7814\u7a76\u6ce8\u518c\u4e0e\u5bf9\u5e94\u8bba\u6587\u3002\u5b83\u4fdd\u6301\u4eba\u7c7b\u4e13\u4e1a\u5224\u65ad\u5728\u5faa\u73af\u4e2d\uff1a(i) \u7528\u6237\u51b3\u5b9a\u6bd4\u8f83\u54ea\u4e9b\u7279\u5f81\uff1b(ii) \u5411\u7528\u6237\u5448\u73b0\u6bcf\u4e2a\u7279\u5f81\u6700\u76f8\u5173\u7684\u6587\u672c\uff0c\u4fc3\u8fdb\u800c\u975e\u66ff\u4ee3\u4eba\u7c7b\u5dee\u5f02\u5224\u65ad\u3002\u5de5\u5177\u751f\u6210\u5e26\u6709\u552f\u4e00RegCheck ID\u7684\u53ef\u5171\u4eab\u62a5\u544a\uff0c\u4fbf\u4e8e\u5176\u4ed6\u7528\u6237\u9a8c\u8bc1\u3002", "result": "RegCheck\u88ab\u8bbe\u8ba1\u4e3a\u8de8\u79d1\u5b66\u9886\u57df\u3001\u6ce8\u518c\u548c\u51fa\u7248\u683c\u5f0f\u7684\u9002\u5e94\u6027\u5de5\u5177\u3002\u8bba\u6587\u6982\u8ff0\u4e86\u5176\u52a8\u673a\u3001\u5de5\u4f5c\u6d41\u7a0b\u548c\u8bbe\u8ba1\u539f\u5219\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u4f5c\u4e3a\u53ef\u6269\u5c55\u57fa\u7840\u8bbe\u65bd\u7684\u6f5c\u529b\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u793a\u4f8b\u7528\u4f8b\u3002", "conclusion": "RegCheck\u4f5c\u4e3aLLM\u8f85\u52a9\u5de5\u5177\uff0c\u901a\u8fc7\u4fc3\u8fdb\u800c\u975e\u66ff\u4ee3\u4eba\u7c7b\u5224\u65ad\uff0c\u5e2e\u52a9\u89e3\u51b3\u7814\u7a76\u6ce8\u518c\u68c0\u67e5\u7684\u6311\u6218\uff0c\u4e3a\u53ef\u91cd\u590d\u79d1\u5b66\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2601.13346", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13346", "abs": "https://arxiv.org/abs/2601.13346", "authors": ["Sang Yun Kwon", "AbdelRahim Elmadany", "Muhammad Abdul-Mageed"], "title": "AfroScope: A Framework for Studying the Linguistic Landscape of Africa", "comment": null, "summary": "Language Identification (LID) is the task of determining the language of a given text and is a fundamental preprocessing step that affects the reliability of downstream NLP applications. While recent work has expanded LID coverage for African languages, existing approaches remain limited in (i) the number of supported languages and (ii) their ability to make fine-grained distinctions among closely related varieties. We introduce AfroScope, a unified framework for African LID that includes AfroScope-Data, a dataset covering 713 African languages, and AfroScope-Models, a suite of strong LID models with broad language coverage. To better distinguish highly confusable languages, we propose a hierarchical classification approach that leverages Mirror-Serengeti, a specialized embedding model targeting 29 closely related or geographically proximate languages. This approach improves macro F1 by 4.55 on this confusable subset compared to our best base model. Finally, we analyze cross linguistic transfer and domain effects, offering guidance for building robust African LID systems. We position African LID as an enabling technology for large scale measurement of Africas linguistic landscape in digital text and release AfroScope-Data and AfroScope-Models publicly.", "AI": {"tldr": "AfroScope\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u975e\u6d32\u8bed\u8a00\u8bc6\u522b\u6846\u67b6\uff0c\u5305\u542b\u8986\u76d6713\u79cd\u975e\u6d32\u8bed\u8a00\u7684\u6570\u636e\u96c6\u548c\u6a21\u578b\u5957\u4ef6\uff0c\u901a\u8fc7\u5206\u5c42\u5206\u7c7b\u65b9\u6cd5\u6539\u8fdb\u5bf9\u9ad8\u5ea6\u76f8\u4f3c\u8bed\u8a00\u7684\u533a\u5206\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u8bc6\u522b\u65b9\u6cd5\u5728\u975e\u6d32\u8bed\u8a00\u8986\u76d6\u8303\u56f4\u6709\u9650\uff0c\u4e14\u96be\u4ee5\u533a\u5206\u5bc6\u5207\u76f8\u5173\u7684\u8bed\u8a00\u53d8\u4f53\uff0c\u8fd9\u5f71\u54cd\u4e86\u4e0b\u6e38NLP\u5e94\u7528\u7684\u53ef\u9760\u6027\u3002\u9700\u8981\u5f00\u53d1\u66f4\u5168\u9762\u7684\u975e\u6d32\u8bed\u8a00\u8bc6\u522b\u7cfb\u7edf\u6765\u652f\u6301\u975e\u6d32\u8bed\u8a00\u666f\u89c2\u7684\u5927\u89c4\u6a21\u6d4b\u91cf\u3002", "method": "\u63d0\u51faAfroScope\u7edf\u4e00\u6846\u67b6\uff0c\u5305\u62ecAfroScope-Data\uff08\u8986\u76d6713\u79cd\u975e\u6d32\u8bed\u8a00\u7684\u6570\u636e\u96c6\uff09\u548cAfroScope-Models\uff08\u6a21\u578b\u5957\u4ef6\uff09\u3002\u9488\u5bf9\u9ad8\u5ea6\u76f8\u4f3c\u7684\u8bed\u8a00\uff0c\u91c7\u7528\u5206\u5c42\u5206\u7c7b\u65b9\u6cd5\uff0c\u5229\u7528\u4e13\u95e8\u9488\u5bf929\u79cd\u5bc6\u5207\u76f8\u5173\u6216\u5730\u7406\u90bb\u8fd1\u8bed\u8a00\u7684Mirror-Serengeti\u5d4c\u5165\u6a21\u578b\u3002", "result": "\u5206\u5c42\u5206\u7c7b\u65b9\u6cd5\u5728\u9ad8\u5ea6\u76f8\u4f3c\u8bed\u8a00\u5b50\u96c6\u4e0a\u6bd4\u6700\u4f73\u57fa\u7840\u6a21\u578b\u63d0\u9ad8\u4e864.55\u7684\u5b8f\u89c2F1\u5206\u6570\u3002\u5206\u6790\u4e86\u8de8\u8bed\u8a00\u8fc1\u79fb\u548c\u9886\u57df\u6548\u5e94\uff0c\u4e3a\u6784\u5efa\u7a33\u5065\u7684\u975e\u6d32\u8bed\u8a00\u8bc6\u522b\u7cfb\u7edf\u63d0\u4f9b\u6307\u5bfc\u3002", "conclusion": "AfroScope\u6846\u67b6\u663e\u8457\u6269\u5c55\u4e86\u975e\u6d32\u8bed\u8a00\u8bc6\u522b\u8986\u76d6\u8303\u56f4\uff0c\u6539\u8fdb\u4e86\u5bf9\u5bc6\u5207\u76f8\u5173\u7684\u8bed\u8a00\u53d8\u4f53\u7684\u533a\u5206\u80fd\u529b\uff0c\u4e3a\u5927\u89c4\u6a21\u6d4b\u91cf\u975e\u6d32\u6570\u5b57\u6587\u672c\u4e2d\u7684\u8bed\u8a00\u666f\u89c2\u63d0\u4f9b\u4e86\u4f7f\u80fd\u6280\u672f\u3002\u6570\u636e\u96c6\u548c\u6a21\u578b\u5df2\u516c\u5f00\u53d1\u5e03\u3002"}}
{"id": "2601.13352", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.13352", "abs": "https://arxiv.org/abs/2601.13352", "authors": ["Yuxing Lu", "J. Ben Tamo", "Weichen Zhao", "Nan Sun", "Yishan Zhong", "Wenqi Shi", "Jinzhuo Wang", "May D. Wang"], "title": "LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction", "comment": "17 pages, 5 figures, 6 tables", "summary": "Large language models are strong sequence predictors, yet standard inference relies on immutable context histories. After making an error at generation step t, the model lacks an updatable memory mechanism that improves predictions for step t+1. We propose LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as natural-language memory. This state, implemented as a structured system-prompt summary, is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. We evaluate the method on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families. LLM-as-RNN significantly outperforms zero-shot, full-history, and MemPrompt baselines, improving predictive accuracy by 6.5% on average, while producing interpretable, human-readable learning traces absent in standard context accumulation.", "AI": {"tldr": "LLM-as-RNN\u5c06\u51bb\u7ed3\u7684LLM\u8f6c\u6362\u4e3a\u5faa\u73af\u9884\u6d4b\u5668\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u8bb0\u5fc6\u5b9e\u73b0\u53ef\u66f4\u65b0\u7684\u9690\u85cf\u72b6\u6001\uff0c\u5728\u56fa\u5b9atoken\u9884\u7b97\u4e0b\u8fdb\u884c\u5728\u7ebf\u5b66\u4e60\uff0c\u65e0\u9700\u53c2\u6570\u66f4\u65b0", "motivation": "\u6807\u51c6LLM\u63a8\u7406\u4f7f\u7528\u4e0d\u53ef\u53d8\u7684\u4e0a\u4e0b\u6587\u5386\u53f2\uff0c\u4e00\u65e6\u5728\u751f\u6210\u6b65\u9aa4t\u51fa\u9519\uff0c\u6a21\u578b\u7f3a\u4e4f\u53ef\u66f4\u65b0\u7684\u8bb0\u5fc6\u673a\u5236\u6765\u6539\u8fdb\u6b65\u9aa4t+1\u7684\u9884\u6d4b\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u7684\u5728\u7ebf\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u63d0\u51faLLM-as-RNN\u6846\u67b6\uff0c\u5c06\u51bb\u7ed3LLM\u8f6c\u53d8\u4e3a\u5faa\u73af\u9884\u6d4b\u5668\uff0c\u9690\u85cf\u72b6\u6001\u8868\u793a\u4e3a\u81ea\u7136\u8bed\u8a00\u8bb0\u5fc6\uff08\u7ed3\u6784\u5316\u7cfb\u7edf\u63d0\u793a\u6458\u8981\uff09\u3002\u901a\u8fc7\u53cd\u9988\u9a71\u52a8\u7684\u6587\u672c\u91cd\u5199\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u66f4\u65b0\u72b6\u6001\uff0c\u5b9e\u73b0\u65e0\u53c2\u6570\u66f4\u65b0\u7684\u5b66\u4e60\u3002", "result": "\u5728\u533b\u7597\u3001\u6c14\u8c61\u548c\u91d1\u878d\u4e09\u4e2a\u5e8f\u5217\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLLM-as-RNN\u663e\u8457\u4f18\u4e8e\u96f6\u6837\u672c\u3001\u5b8c\u6574\u5386\u53f2\u548cMemPrompt\u57fa\u7ebf\uff0c\u5e73\u5747\u9884\u6d4b\u51c6\u786e\u7387\u63d0\u9ad86.5%\uff0c\u540c\u65f6\u4ea7\u751f\u53ef\u89e3\u91ca\u7684\u4eba\u7c7b\u53ef\u8bfb\u5b66\u4e60\u8f68\u8ff9\u3002", "conclusion": "LLM-as-RNN\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u8bb0\u5fc6\u5b9e\u73b0\u53ef\u66f4\u65b0\u7684\u9690\u85cf\u72b6\u6001\uff0c\u4f7f\u51bb\u7ed3LLM\u80fd\u591f\u8fdb\u884c\u5728\u7ebf\u5b66\u4e60\uff0c\u7ea0\u6b63\u9519\u8bef\u5e76\u4fdd\u7559\u4efb\u52a1\u76f8\u5173\u6a21\u5f0f\uff0c\u5728\u56fa\u5b9atoken\u9884\u7b97\u4e0b\u4f18\u4e8e\u4f20\u7edf\u4e0a\u4e0b\u6587\u7d2f\u79ef\u65b9\u6cd5\u3002"}}
{"id": "2601.13359", "categories": ["cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13359", "abs": "https://arxiv.org/abs/2601.13359", "authors": ["Asen Dotsinski", "Panagiotis Eustratiadis"], "title": "Sockpuppetting: Jailbreaking LLMs Without Optimization Through Output Prefix Injection", "comment": null, "summary": "As open-weight large language models (LLMs) increase in capabilities, safeguarding them against malicious prompts and understanding possible attack vectors becomes ever more important. While automated jailbreaking methods like GCG [Zou et al., 2023] remain effective, they often require substantial computational resources and specific expertise. We introduce \"sockpuppetting'', a simple method for jailbreaking open-weight LLMs by inserting an acceptance sequence (e.g., \"Sure, here is how to...'') at the start of a model's output and allowing it to complete the response. Requiring only a single line of code and no optimization, sockpuppetting achieves up to 80% higher attack success rate (ASR) than GCG on Qwen3-8B in per-prompt comparisons. We also explore a hybrid approach that optimizes the adversarial suffix within the assistant message block rather than the user prompt, increasing ASR by 64% over GCG on Llama-3.1-8B in a prompt-agnostic setting. The results establish sockpuppetting as an effective low-cost attack accessible to unsophisticated adversaries, highlighting the need for defences against output-prefix injection in open-weight models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\"sockpuppetting\"\u7684\u7b80\u5355\u8d8a\u72f1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6a21\u578b\u8f93\u51fa\u5f00\u5934\u63d2\u5165\u63a5\u53d7\u5e8f\u5217\uff08\u5982\"Sure, here is how to...\"\uff09\u6765\u653b\u51fb\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u65e0\u9700\u4f18\u5316\u4e14\u4ee3\u7801\u91cf\u6781\u5c11\u3002", "motivation": "\u968f\u7740\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u589e\u5f3a\uff0c\u4fdd\u62a4\u5b83\u4eec\u514d\u53d7\u6076\u610f\u63d0\u793a\u653b\u51fb\u548c\u7406\u89e3\u53ef\u80fd\u7684\u653b\u51fb\u5411\u91cf\u53d8\u5f97\u65e5\u76ca\u91cd\u8981\u3002\u73b0\u6709\u81ea\u52a8\u5316\u8d8a\u72f1\u65b9\u6cd5\u5982GCG\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u548c\u4e13\u4e1a\u77e5\u8bc6\uff0c\u9700\u8981\u66f4\u7b80\u5355\u6709\u6548\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\"sockpuppetting\"\u65b9\u6cd5\uff1a\u5728\u6a21\u578b\u8f93\u51fa\u5f00\u5934\u63d2\u5165\u63a5\u53d7\u5e8f\u5217\uff08\u5982\"Sure, here is how to...\"\uff09\uff0c\u7136\u540e\u8ba9\u6a21\u578b\u5b8c\u6210\u54cd\u5e94\u3002\u8be5\u65b9\u6cd5\u53ea\u9700\u5355\u884c\u4ee3\u7801\uff0c\u65e0\u9700\u4f18\u5316\u3002\u8fd8\u63a2\u7d22\u4e86\u6df7\u5408\u65b9\u6cd5\uff1a\u5728\u52a9\u624b\u6d88\u606f\u5757\u5185\u4f18\u5316\u5bf9\u6297\u540e\u7f00\u800c\u975e\u7528\u6237\u63d0\u793a\u3002", "result": "sockpuppetting\u5728Qwen3-8B\u4e0a\u6bd4GCG\u653b\u51fb\u6210\u529f\u7387\u63d0\u9ad880%\uff08\u9010\u63d0\u793a\u6bd4\u8f83\uff09\u3002\u6df7\u5408\u65b9\u6cd5\u5728Llama-3.1-8B\u4e0a\u6bd4GCG\u653b\u51fb\u6210\u529f\u7387\u63d0\u9ad864%\uff08\u63d0\u793a\u65e0\u5173\u8bbe\u7f6e\uff09\u3002", "conclusion": "sockpuppetting\u662f\u4e00\u79cd\u4f4e\u6210\u672c\u6709\u6548\u653b\u51fb\u65b9\u6cd5\uff0c\u53ef\u4f9b\u975e\u4e13\u4e1a\u653b\u51fb\u8005\u4f7f\u7528\uff0c\u7a81\u663e\u4e86\u5f00\u6e90\u6a21\u578b\u9700\u8981\u9632\u5fa1\u8f93\u51fa\u524d\u7f00\u6ce8\u5165\u653b\u51fb\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.13368", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13368", "abs": "https://arxiv.org/abs/2601.13368", "authors": ["Zhenjiang Mao", "Anirudhh Venkat"], "title": "Recurrent Confidence Chain: Temporal-Aware Uncertainty Quantification in Large Language Models", "comment": null, "summary": "As reasoning modules, such as the chain-of-thought mechanism, are applied to large language models, they achieve strong performance on various tasks such as answering common-sense questions and solving math problems. The main challenge now is to assess the uncertainty of answers, which can help prevent misleading or serious hallucinations for users. Although current methods analyze long reasoning sequences by filtering unrelated tokens and examining potential connections between nearby tokens or sentences, the temporal spread of confidence is often overlooked. This oversight can lead to inflated overall confidence, even when earlier steps exhibit very low confidence. To address this issue, we propose a novel method that incorporates inter-step attention to analyze semantic correlations across steps. For handling long-horizon responses, we introduce a hidden confidence mechanism to retain historical confidence information, which is then combined with stepwise confidence to produce a more accurate overall estimate. We evaluate our method on the GAOKAO math benchmark and the CLadder causal reasoning dataset using mainstream open-source large language models. Our approach is shown to outperform state-of-the-art methods by achieving a superior balance between predictive quality and calibration, demonstrated by strong performance on both Negative Log-Likelihood and Expected Calibration Error.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u6b65\u9aa4\u95f4\u6ce8\u610f\u529b\u5206\u6790\u548c\u9690\u85cf\u7f6e\u4fe1\u5ea6\u673a\u5236\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5ffd\u7565\u65f6\u95f4\u7f6e\u4fe1\u5ea6\u4f20\u64ad\u5bfc\u81f4\u6574\u4f53\u7f6e\u4fe1\u5ea6\u9ad8\u4f30\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u8bc4\u4f30\u7b54\u6848\u4e0d\u786e\u5b9a\u6027\u4ecd\u5177\u6311\u6218\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u5206\u6790\u957f\u63a8\u7406\u5e8f\u5217\u65f6\uff0c\u901a\u5e38\u901a\u8fc7\u8fc7\u6ee4\u65e0\u5173\u6807\u8bb0\u548c\u68c0\u67e5\u90bb\u8fd1\u6807\u8bb0/\u53e5\u5b50\u95f4\u7684\u6f5c\u5728\u8fde\u63a5\uff0c\u4f46\u5ffd\u7565\u4e86\u7f6e\u4fe1\u5ea6\u7684\u65f6\u95f4\u4f20\u64ad\uff0c\u5bfc\u81f4\u65e9\u671f\u6b65\u9aa4\u7f6e\u4fe1\u5ea6\u5f88\u4f4e\u65f6\u6574\u4f53\u7f6e\u4fe1\u5ea6\u4ecd\u88ab\u9ad8\u4f30\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u65b9\u6cd5\uff1a1) \u7ed3\u5408\u6b65\u9aa4\u95f4\u6ce8\u610f\u529b\u5206\u6790\u8de8\u6b65\u9aa4\u7684\u8bed\u4e49\u76f8\u5173\u6027\uff1b2) \u9488\u5bf9\u957f\u5e8f\u5217\u54cd\u5e94\u5f15\u5165\u9690\u85cf\u7f6e\u4fe1\u5ea6\u673a\u5236\uff0c\u4fdd\u7559\u5386\u53f2\u7f6e\u4fe1\u5ea6\u4fe1\u606f\uff0c\u5e76\u4e0e\u9010\u6b65\u7f6e\u4fe1\u5ea6\u7ed3\u5408\u4ea7\u751f\u66f4\u51c6\u786e\u7684\u603b\u4f53\u4f30\u8ba1\u3002", "result": "\u5728GAOKAO\u6570\u5b66\u57fa\u51c6\u548cCLadder\u56e0\u679c\u63a8\u7406\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528\u4e3b\u6d41\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002\u8be5\u65b9\u6cd5\u5728\u9884\u6d4b\u8d28\u91cf\u548c\u6821\u51c6\u4e4b\u95f4\u5b9e\u73b0\u4e86\u66f4\u4f18\u5e73\u8861\uff0c\u5728\u8d1f\u5bf9\u6570\u4f3c\u7136\u548c\u671f\u671b\u6821\u51c6\u8bef\u5dee\u6307\u6807\u4e0a\u5747\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5206\u6790\u6b65\u9aa4\u95f4\u6ce8\u610f\u529b\u5e76\u5f15\u5165\u9690\u85cf\u7f6e\u4fe1\u5ea6\u673a\u5236\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u6709\u6548\u89e3\u51b3\u7f6e\u4fe1\u5ea6\u65f6\u95f4\u4f20\u64ad\u88ab\u5ffd\u7565\u7684\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u8f93\u51fa\u7684\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2601.13388", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13388", "abs": "https://arxiv.org/abs/2601.13388", "authors": ["Sasha Ronaghi", "Prerit Choudhary", "David H Rehkopf", "Bryant Lin"], "title": "Structured Insight from Unstructured Data: Large Language Models for SDOH-Driven Diabetes Risk Prediction", "comment": "7 pages, 5 figures", "summary": "Social determinants of health (SDOH) play a critical role in Type 2 Diabetes (T2D) management but are often absent from electronic health records and risk prediction models. Most individual-level SDOH data is collected through structured screening tools, which lack the flexibility to capture the complexity of patient experiences and unique needs of a clinic's population. This study explores the use of large language models (LLMs) to extract structured SDOH information from unstructured patient life stories and evaluate the predictive value of both the extracted features and the narratives themselves for assessing diabetes control. We collected unstructured interviews from 65 T2D patients aged 65 and older, focused on their lived experiences, social context, and diabetes management. These narratives were analyzed using LLMs with retrieval-augmented generation to produce concise, actionable qualitative summaries for clinical interpretation and structured quantitative SDOH ratings for risk prediction modeling. The structured SDOH ratings were used independently and in combination with traditional laboratory biomarkers as inputs to linear and tree-based machine learning models (Ridge, Lasso, Random Forest, and XGBoost) to demonstrate how unstructured narrative data can be applied in conventional risk prediction workflows. Finally, we evaluated several LLMs on their ability to predict a patient's level of diabetes control (low, medium, high) directly from interview text with A1C values redacted. LLMs achieved 60% accuracy in predicting diabetes control levels from interview text. This work demonstrates how LLMs can translate unstructured SDOH-related data into structured insights, offering a scalable approach to augment clinical risk models and decision-making.", "AI": {"tldr": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u7cd6\u5c3f\u75c5\u60a3\u8005\u751f\u6d3b\u6545\u4e8b\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u793e\u4f1a\u5065\u5eb7\u51b3\u5b9a\u56e0\u7d20\uff0c\u5e76\u8bc4\u4f30\u5176\u5bf9\u7cd6\u5c3f\u75c5\u63a7\u5236\u7684\u9884\u6d4b\u4ef7\u503c", "motivation": "\u793e\u4f1a\u5065\u5eb7\u51b3\u5b9a\u56e0\u7d20\u57282\u578b\u7cd6\u5c3f\u75c5\u7ba1\u7406\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u548c\u98ce\u9669\u9884\u6d4b\u6a21\u578b\u4e2d\u5f80\u5f80\u7f3a\u4e4f\u8fd9\u4e9b\u4fe1\u606f\u3002\u4f20\u7edf\u7684\u7ed3\u6784\u5316\u7b5b\u67e5\u5de5\u5177\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u65e0\u6cd5\u6355\u6349\u60a3\u8005\u7ecf\u5386\u7684\u590d\u6742\u6027\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u5c06\u975e\u7ed3\u6784\u5316\u60a3\u8005\u53d9\u8ff0\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u4e34\u5e8a\u89c1\u89e3\u3002", "method": "\u6536\u96c665\u540d65\u5c81\u4ee5\u4e0a2\u578b\u7cd6\u5c3f\u75c5\u60a3\u8005\u7684\u975e\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u4f7f\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5206\u6790\u53d9\u8ff0\uff0c\u751f\u6210\u5b9a\u6027\u4e34\u5e8a\u6458\u8981\u548c\u7ed3\u6784\u5316SDOH\u8bc4\u5206\u3002\u5c06\u8fd9\u4e9b\u8bc4\u5206\u4e0e\u4f20\u7edf\u5b9e\u9a8c\u5ba4\u751f\u7269\u6807\u5fd7\u7269\u7ed3\u5408\uff0c\u8f93\u5165\u7ebf\u6027\u548c\u6811\u57fa\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u98ce\u9669\u9884\u6d4b\u3002\u540c\u65f6\u8bc4\u4f30LLM\u76f4\u63a5\u4ece\u8bbf\u8c08\u6587\u672c\u9884\u6d4b\u7cd6\u5c3f\u75c5\u63a7\u5236\u6c34\u5e73\u7684\u80fd\u529b\u3002", "result": "LLM\u80fd\u591f\u4ece\u60a3\u8005\u751f\u6d3b\u6545\u4e8b\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316SDOH\u4fe1\u606f\uff0c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u4e34\u5e8a\u53ef\u7528\u7684\u89c1\u89e3\u3002LLM\u4ec5\u4ece\u8bbf\u8c08\u6587\u672c\u9884\u6d4b\u7cd6\u5c3f\u75c5\u63a7\u5236\u6c34\u5e73\uff08\u4f4e\u3001\u4e2d\u3001\u9ad8\uff09\u7684\u51c6\u786e\u7387\u8fbe\u523060%\u3002\u7ed3\u6784\u5316SDOH\u8bc4\u5206\u53ef\u4e0e\u4f20\u7edf\u751f\u7269\u6807\u5fd7\u7269\u7ed3\u5408\uff0c\u589e\u5f3a\u98ce\u9669\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5c06\u975e\u7ed3\u6784\u5316SDOH\u76f8\u5173\u6570\u636e\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u89c1\u89e3\uff0c\u4e3a\u589e\u5f3a\u4e34\u5e8a\u98ce\u9669\u6a21\u578b\u548c\u51b3\u7b56\u5236\u5b9a\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u3002\u8fd9\u79cd\u65b9\u6cd5\u5f25\u8865\u4e86\u4f20\u7edf\u7ed3\u6784\u5316\u5de5\u5177\u7684\u4e0d\u8db3\uff0c\u4f7f\u60a3\u8005\u53d9\u8ff0\u80fd\u591f\u6574\u5408\u5230\u5e38\u89c4\u98ce\u9669\u9884\u6d4b\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u3002"}}
{"id": "2601.13392", "categories": ["cs.CL", "cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2601.13392", "abs": "https://arxiv.org/abs/2601.13392", "authors": ["Shlok Shelat", "Jay Raval", "Souvik Roy", "Manas Gaur"], "title": "Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks", "comment": "30 pages, 11 figures, 6 tables, Work in Progress", "summary": "Large language models (LLMs) have demonstrated strong performance on formal language tasks, yet whether this reflects genuine symbolic reasoning or pattern matching on familiar constructions remains unclear. We introduce a benchmark for deterministic finite automata (DFA) construction from regular languages, comprising factual knowledge questions, seen construction problems from public sources, and two types of unseen problems: hand-crafted instances with multiple interacting constraints and systematically generated problems via Arden's theorem. Models achieve perfect accuracy on factual questions and 84-90% on seen tasks. However, accuracy drops sharply on unseen problems (by 30-64%), with failures stemming from systematic misinterpretation of language constraints, incorrect handling of Kleene-star semantics, and a failure to preserve global consistency. We evaluate a three-stage hint protocol that enables correction of shallow errors but does not reliably resolve globally inconsistent or structurally flawed automata. Our analysis across multiple prompting strategies (direct, Chain-of-Thought, Tree-of-Thought) reveals that errors persist regardless of prompting approach, exposing a fundamental gap between LLMs' ability to generate syntactically plausible DFAs and their capacity for semantically correct formal reasoning.", "AI": {"tldr": "LLMs\u5728\u786e\u5b9a\u6027\u6709\u9650\u81ea\u52a8\u673a(DFA)\u6784\u5efa\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u672a\u89c1\u95ee\u9898\u4e2d\u51c6\u786e\u7387\u663e\u8457\u4e0b\u964d\uff0c\u66b4\u9732\u4e86\u5f62\u5f0f\u63a8\u7406\u80fd\u529b\u7684\u6839\u672c\u6027\u5dee\u8ddd", "motivation": "\u63a2\u7a76LLMs\u5728\u5f62\u5f0f\u8bed\u8a00\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u662f\u5426\u53cd\u6620\u771f\u6b63\u7684\u7b26\u53f7\u63a8\u7406\u80fd\u529b\uff0c\u8fd8\u662f\u4ec5\u4ec5\u5bf9\u719f\u6089\u7ed3\u6784\u7684\u6a21\u5f0f\u5339\u914d\uff0c\u901a\u8fc7DFA\u6784\u5efa\u4efb\u52a1\u6765\u8bc4\u4f30\u5176\u5f62\u5f0f\u63a8\u7406\u80fd\u529b", "method": "\u5f15\u5165\u4e00\u4e2aDFA\u6784\u5efa\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u4e8b\u5b9e\u77e5\u8bc6\u95ee\u9898\u3001\u516c\u5f00\u6765\u6e90\u7684\u5df2\u89c1\u6784\u9020\u95ee\u9898\uff0c\u4ee5\u53ca\u4e24\u79cd\u672a\u89c1\u95ee\u9898\uff1a\u624b\u5de5\u5236\u4f5c\u7684\u591a\u7ea6\u675f\u4ea4\u4e92\u5b9e\u4f8b\u548c\u901a\u8fc7Arden\u5b9a\u7406\u7cfb\u7edf\u751f\u6210\u7684\u95ee\u9898\uff1b\u8bc4\u4f30\u591a\u79cd\u63d0\u793a\u7b56\u7565\uff08\u76f4\u63a5\u3001\u601d\u7ef4\u94fe\u3001\u601d\u7ef4\u6811\uff09\u548c\u4e09\u9636\u6bb5\u63d0\u793a\u534f\u8bae", "result": "\u6a21\u578b\u5728\u4e8b\u5b9e\u95ee\u9898\u4e0a\u8fbe\u5230\u5b8c\u7f8e\u51c6\u786e\u7387\uff0c\u5728\u5df2\u89c1\u4efb\u52a1\u4e0a\u8fbe\u523084-90%\u51c6\u786e\u7387\uff0c\u4f46\u5728\u672a\u89c1\u95ee\u9898\u4e0a\u51c6\u786e\u7387\u6025\u5267\u4e0b\u964d30-64%\uff1b\u9519\u8bef\u6e90\u4e8e\u5bf9\u8bed\u8a00\u7ea6\u675f\u7684\u7cfb\u7edf\u6027\u8bef\u89e3\u3001Kleene\u661f\u53f7\u8bed\u4e49\u7684\u9519\u8bef\u5904\u7406\u4ee5\u53ca\u5168\u5c40\u4e00\u81f4\u6027\u7684\u5931\u8d25\uff1b\u4e09\u9636\u6bb5\u63d0\u793a\u534f\u8bae\u80fd\u4fee\u6b63\u6d45\u5c42\u9519\u8bef\u4f46\u65e0\u6cd5\u53ef\u9760\u89e3\u51b3\u5168\u5c40\u4e0d\u4e00\u81f4\u6216\u7ed3\u6784\u7f3a\u9677\u7684\u81ea\u52a8\u673a", "conclusion": "LLMs\u5728\u751f\u6210\u8bed\u6cd5\u4e0a\u5408\u7406\u7684DFA\u4e0e\u8bed\u4e49\u6b63\u786e\u7684\u5f62\u5f0f\u63a8\u7406\u80fd\u529b\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u6027\u5dee\u8ddd\uff0c\u9519\u8bef\u5728\u6240\u6709\u63d0\u793a\u7b56\u7565\u4e2d\u6301\u7eed\u5b58\u5728\uff0c\u8868\u660e\u5f53\u524dLLMs\u7684\u5f62\u5f0f\u63a8\u7406\u80fd\u529b\u6709\u9650"}}
{"id": "2601.13433", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13433", "abs": "https://arxiv.org/abs/2601.13433", "authors": ["Priyanka Mary Mammen", "Emil Joswin", "Shankar Venkitachalam"], "title": "Trust Me, I'm an Expert: Decoding and Steering Authority Bias in Large Language Models", "comment": null, "summary": "Prior research demonstrates that performance of language models on reasoning tasks can be influenced by suggestions, hints and endorsements. However, the influence of endorsement source credibility remains underexplored. We investigate whether language models exhibit systematic bias based on the perceived expertise of the provider of the endorsement. Across 4 datasets spanning mathematical, legal, and medical reasoning, we evaluate 11 models using personas representing four expertise levels per domain. Our results reveal that models are increasingly susceptible to incorrect/misleading endorsements as source expertise increases, with higher-authority sources inducing not only accuracy degradation but also increased confidence in wrong answers. We also show that this authority bias is mechanistically encoded within the model and a model can be steered away from the bias, thereby improving its performance even when an expert gives a misleading endorsement.", "AI": {"tldr": "\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u4f1a\u53d7\u5230\u5efa\u8bae\u548c\u8ba4\u53ef\u7684\u5f71\u54cd\uff0c\u4f46\u8ba4\u53ef\u6765\u6e90\u7684\u53ef\u4fe1\u5ea6\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u5bf9\u9ad8\u6743\u5a01\u6765\u6e90\u7684\u9519\u8bef\u8ba4\u53ef\u8868\u73b0\u51fa\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u5bfc\u81f4\u51c6\u786e\u6027\u4e0b\u964d\u548c\u9519\u8bef\u7b54\u6848\u7f6e\u4fe1\u5ea6\u589e\u52a0\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u8868\u660e\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4f1a\u53d7\u5230\u5efa\u8bae\u3001\u63d0\u793a\u548c\u8ba4\u53ef\u7684\u5f71\u54cd\uff0c\u4f46\u8ba4\u53ef\u6765\u6e90\u53ef\u4fe1\u5ea6\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u8bed\u8a00\u6a21\u578b\u662f\u5426\u57fa\u4e8e\u8ba4\u53ef\u63d0\u4f9b\u8005\u7684\u611f\u77e5\u4e13\u4e1a\u77e5\u8bc6\u8868\u73b0\u51fa\u7cfb\u7edf\u6027\u504f\u89c1\u3002", "method": "\u5728\u6570\u5b66\u3001\u6cd5\u5f8b\u548c\u533b\u5b66\u63a8\u74064\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e8611\u4e2a\u6a21\u578b\uff0c\u4f7f\u7528\u4ee3\u8868\u6bcf\u4e2a\u9886\u57df\u56db\u4e2a\u4e13\u4e1a\u77e5\u8bc6\u6c34\u5e73\u7684\u4eba\u7269\u89d2\u8272\u3002\u901a\u8fc7\u4e0d\u540c\u6743\u5a01\u7a0b\u5ea6\u7684\u8ba4\u53ef\u6765\u6e90\u6d4b\u8bd5\u6a21\u578b\u5bf9\u9519\u8bef/\u8bef\u5bfc\u6027\u8ba4\u53ef\u7684\u53cd\u5e94\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u968f\u7740\u6765\u6e90\u4e13\u4e1a\u77e5\u8bc6\u7684\u589e\u52a0\uff0c\u6a21\u578b\u5bf9\u9519\u8bef/\u8bef\u5bfc\u6027\u8ba4\u53ef\u7684\u654f\u611f\u6027\u589e\u5f3a\u3002\u9ad8\u6743\u5a01\u6765\u6e90\u4e0d\u4ec5\u5bfc\u81f4\u51c6\u786e\u6027\u4e0b\u964d\uff0c\u8fd8\u589e\u52a0\u4e86\u5bf9\u9519\u8bef\u7b54\u6848\u7684\u7f6e\u4fe1\u5ea6\u3002\u8fd9\u79cd\u6743\u5a01\u504f\u89c1\u5728\u6a21\u578b\u4e2d\u5177\u6709\u673a\u5236\u6027\u7f16\u7801\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u6743\u5a01\u504f\u89c1\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u5f15\u5bfc\u6a21\u578b\u8fdc\u79bb\u8fd9\u79cd\u504f\u89c1\u6765\u6539\u5584\u6027\u80fd\uff0c\u5373\u4f7f\u5728\u4e13\u5bb6\u7ed9\u51fa\u8bef\u5bfc\u6027\u8ba4\u53ef\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u63d0\u9ad8\u8868\u73b0\u3002\u8fd9\u63ed\u793a\u4e86\u6a21\u578b\u5bf9\u6743\u5a01\u6765\u6e90\u7684\u7cfb\u7edf\u6027\u504f\u89c1\u53ca\u5176\u53ef\u4fee\u6b63\u6027\u3002"}}
{"id": "2601.13437", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13437", "abs": "https://arxiv.org/abs/2601.13437", "authors": ["Adriana-Valentina Costache", "Daria-Nicoleta Dragomir", "Silviu-Florin Gheorghe", "Eduard Poesina", "Paul Irofti", "Radu Tudor Ionescu"], "title": "MOSLD-Bench: Multilingual Open-Set Learning and Discovery Benchmark for Text Categorization", "comment": null, "summary": "Open-set learning and discovery (OSLD) is a challenging machine learning task in which samples from new (unknown) classes can appear at test time. It can be seen as a generalization of zero-shot learning, where the new classes are not known a priori, hence involving the active discovery of new classes. While zero-shot learning has been extensively studied in text classification, especially with the emergence of pre-trained language models, open-set learning and discovery is a comparatively new setup for the text domain. To this end, we introduce the first multilingual open-set learning and discovery (MOSLD) benchmark for text categorization by topic, comprising 960K data samples across 12 languages. To construct the benchmark, we (i) rearrange existing datasets and (ii) collect new data samples from the news domain. Moreover, we propose a novel framework for the OSLD task, which integrates multiple stages to continuously discover and learn new classes. We evaluate several language models, including our own, to obtain results that can be used as reference for future work. We release our benchmark at https://github.com/Adriana19Valentina/MOSLD-Bench.", "code_url": "https://github.com/Adriana19Valentina/MOSLD-Bench", "code_stars": 0, "code_last_update": "2026-01-08", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u591a\u8bed\u8a00\u5f00\u653e\u96c6\u5b66\u4e60\u4e0e\u53d1\u73b0\uff08MOSLD\uff09\u57fa\u51c6\uff0c\u7528\u4e8e\u6587\u672c\u4e3b\u9898\u5206\u7c7b\uff0c\u5305\u542b12\u79cd\u8bed\u8a00\u768496\u4e07\u6570\u636e\u6837\u672c\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u96c6\u6210\u591a\u9636\u6bb5\u7684\u65b0\u6846\u67b6\u6765\u6301\u7eed\u53d1\u73b0\u548c\u5b66\u4e60\u65b0\u7c7b\u522b\u3002", "motivation": "\u5f00\u653e\u96c6\u5b66\u4e60\u4e0e\u53d1\u73b0\uff08OSLD\uff09\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u673a\u5668\u5b66\u4e60\u4efb\u52a1\uff0c\u5176\u4e2d\u6d4b\u8bd5\u65f6\u53ef\u80fd\u51fa\u73b0\u6765\u81ea\u65b0\uff08\u672a\u77e5\uff09\u7c7b\u522b\u7684\u6837\u672c\u3002\u867d\u7136\u96f6\u6837\u672c\u5b66\u4e60\u5728\u6587\u672c\u5206\u7c7b\u4e2d\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5f00\u653e\u96c6\u5b66\u4e60\u4e0e\u53d1\u73b0\u5bf9\u4e8e\u6587\u672c\u9886\u57df\u6765\u8bf4\u662f\u4e00\u4e2a\u76f8\u5bf9\u8f83\u65b0\u7684\u8bbe\u7f6e\uff0c\u7f3a\u4e4f\u76f8\u5e94\u7684\u57fa\u51c6\u3002", "method": "1\uff09\u901a\u8fc7\u91cd\u65b0\u6574\u7406\u73b0\u6709\u6570\u636e\u96c6\u548c\u6536\u96c6\u65b0\u95fb\u9886\u57df\u65b0\u6570\u636e\u6837\u672c\uff0c\u6784\u5efa\u4e86\u9996\u4e2a\u591a\u8bed\u8a00\u5f00\u653e\u96c6\u5b66\u4e60\u4e0e\u53d1\u73b0\u57fa\u51c6\uff08MOSLD\uff09\uff0c\u5305\u542b12\u79cd\u8bed\u8a00\u7684960K\u6570\u636e\u6837\u672c\uff1b2\uff09\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684OSLD\u6846\u67b6\uff0c\u96c6\u6210\u591a\u4e2a\u9636\u6bb5\u6765\u6301\u7eed\u53d1\u73b0\u548c\u5b66\u4e60\u65b0\u7c7b\u522b\u3002", "result": "\u8bc4\u4f30\u4e86\u5305\u62ec\u4f5c\u8005\u63d0\u51fa\u7684\u6a21\u578b\u5728\u5185\u7684\u591a\u79cd\u8bed\u8a00\u6a21\u578b\uff0c\u83b7\u5f97\u4e86\u53ef\u4f5c\u4e3a\u672a\u6765\u5de5\u4f5c\u53c2\u8003\u7684\u7ed3\u679c\u3002\u57fa\u51c6\u5df2\u516c\u5f00\u53d1\u5e03\u5728GitHub\u4e0a\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u6587\u672c\u9886\u57df\u5f00\u653e\u96c6\u5b66\u4e60\u4e0e\u53d1\u73b0\u57fa\u51c6\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u591a\u8bed\u8a00\u57fa\u51c6\u548c\u53c2\u8003\u7ed3\u679c\uff0c\u63a8\u52a8\u4e86OSLD\u5728\u6587\u672c\u5206\u7c7b\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.13503", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13503", "abs": "https://arxiv.org/abs/2601.13503", "authors": ["Kyung Ho Lim", "Byung-Hoon Kim"], "title": "Anonpsy: A Graph-Based Framework for Structure-Preserving De-identification of Psychiatric Narratives", "comment": null, "summary": "Psychiatric narratives encode patient identity not only through explicit identifiers but also through idiosyncratic life events embedded in their clinical structure. Existing de-identification approaches, including PHI masking and LLM-based synthetic rewriting, operate at the text level and offer limited control over which semantic elements are preserved or altered. We introduce Anonpsy, a de-identification framework that reformulates the task as graph-guided semantic rewriting. Anonpsy (1) converts each narrative into a semantic graph encoding clinical entities, temporal anchors, and typed relations; (2) applies graph-constrained perturbations that modify identifying context while preserving clinically essential structure; and (3) regenerates text via graph-conditioned LLM generation. Evaluated on 90 clinician-authored psychiatric case narratives, Anonpsy preserves diagnostic fidelity while achieving consistently low re-identification risk under expert, semantic, and GPT-5-based evaluations. Compared with a strong LLM-only rewriting baseline, Anonpsy yields substantially lower semantic similarity and identifiability. These results demonstrate that explicit structural representations combined with constrained generation provide an effective approach to de-identification for psychiatric narratives.", "AI": {"tldr": "Anonpsy\u662f\u4e00\u4e2a\u7528\u4e8e\u7cbe\u795e\u75c5\u5b66\u53d9\u4e8b\u53bb\u8bc6\u522b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u56fe\u5f15\u5bfc\u7684\u8bed\u4e49\u91cd\u5199\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u4e34\u5e8a\u8bca\u65ad\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\u964d\u4f4e\u518d\u8bc6\u522b\u98ce\u9669\u3002", "motivation": "\u7cbe\u795e\u75c5\u5b66\u53d9\u4e8b\u4e0d\u4ec5\u5305\u542b\u660e\u786e\u7684\u8eab\u4efd\u6807\u8bc6\u7b26\uff0c\u8fd8\u901a\u8fc7\u5d4c\u5165\u4e34\u5e8a\u7ed3\u6784\u4e2d\u7684\u72ec\u7279\u751f\u6d3b\u4e8b\u4ef6\u7f16\u7801\u60a3\u8005\u8eab\u4efd\u3002\u73b0\u6709\u7684\u53bb\u8bc6\u522b\u65b9\u6cd5\uff08\u5982PHI\u63a9\u7801\u548c\u57fa\u4e8eLLM\u7684\u5408\u6210\u91cd\u5199\uff09\u5728\u6587\u672c\u5c42\u9762\u64cd\u4f5c\uff0c\u5bf9\u54ea\u4e9b\u8bed\u4e49\u5143\u7d20\u88ab\u4fdd\u7559\u6216\u4fee\u6539\u7684\u63a7\u5236\u6709\u9650\u3002", "method": "Anonpsy\u5c06\u53bb\u8bc6\u522b\u4efb\u52a1\u91cd\u65b0\u5b9a\u4e49\u4e3a\u56fe\u5f15\u5bfc\u7684\u8bed\u4e49\u91cd\u5199\uff1a1) \u5c06\u6bcf\u4e2a\u53d9\u4e8b\u8f6c\u6362\u4e3a\u7f16\u7801\u4e34\u5e8a\u5b9e\u4f53\u3001\u65f6\u95f4\u951a\u70b9\u548c\u7c7b\u578b\u5173\u7cfb\u7684\u8bed\u4e49\u56fe\uff1b2) \u5e94\u7528\u56fe\u7ea6\u675f\u7684\u6270\u52a8\uff0c\u4fee\u6539\u8bc6\u522b\u6027\u4e0a\u4e0b\u6587\u540c\u65f6\u4fdd\u7559\u4e34\u5e8a\u5fc5\u9700\u7ed3\u6784\uff1b3) \u901a\u8fc7\u56fe\u6761\u4ef6LLM\u751f\u6210\u91cd\u65b0\u751f\u6210\u6587\u672c\u3002", "result": "\u572890\u4e2a\u4e34\u5e8a\u533b\u751f\u64b0\u5199\u7684\u7cbe\u795e\u75c5\u5b66\u6848\u4f8b\u53d9\u4e8b\u8bc4\u4f30\u4e2d\uff0cAnonpsy\u5728\u4fdd\u6301\u8bca\u65ad\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\uff0c\u5728\u4e13\u5bb6\u3001\u8bed\u4e49\u548cGPT-5\u57fa\u8bc4\u4f30\u4e0b\u5b9e\u73b0\u4e86\u6301\u7eed\u4f4e\u7684\u518d\u8bc6\u522b\u98ce\u9669\u3002\u4e0e\u5f3a\u5927\u7684\u4ec5LLM\u91cd\u5199\u57fa\u7ebf\u76f8\u6bd4\uff0cAnonpsy\u4ea7\u751f\u4e86\u663e\u8457\u66f4\u4f4e\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u548c\u53ef\u8bc6\u522b\u6027\u3002", "conclusion": "\u663e\u5f0f\u7ed3\u6784\u8868\u793a\u4e0e\u7ea6\u675f\u751f\u6210\u76f8\u7ed3\u5408\uff0c\u4e3a\u7cbe\u795e\u75c5\u5b66\u53d9\u4e8b\u7684\u53bb\u8bc6\u522b\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002\u56fe\u5f15\u5bfc\u7684\u8bed\u4e49\u91cd\u5199\u6846\u67b6\u5728\u4fdd\u62a4\u60a3\u8005\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u4e34\u5e8a\u5b9e\u7528\u6027\u3002"}}
{"id": "2601.13537", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13537", "abs": "https://arxiv.org/abs/2601.13537", "authors": ["Yerin Hwang", "Dongryeol Lee", "Taegwan Kang", "Minwoo Lee", "Kyomin Jung"], "title": "When Wording Steers the Evaluation: Framing Bias in LLM judges", "comment": "4 pages", "summary": "Large language models (LLMs) are known to produce varying responses depending on prompt phrasing, indicating that subtle guidance in phrasing can steer their answers. However, the impact of this framing bias on LLM-based evaluation, where models are expected to make stable and impartial judgments, remains largely underexplored. Drawing inspiration from the framing effect in psychology, we systematically investigate how deliberate prompt framing skews model judgments across four high-stakes evaluation tasks. We design symmetric prompts using predicate-positive and predicate-negative constructions and demonstrate that such framing induces significant discrepancies in model outputs. Across 14 LLM judges, we observe clear susceptibility to framing, with model families showing distinct tendencies toward agreement or rejection. These findings suggest that framing bias is a structural property of current LLM-based evaluation systems, underscoring the need for framing-aware protocols.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bc4\u4f30\u4efb\u52a1\u4e2d\u5b58\u5728\u663e\u8457\u7684\u6846\u67b6\u6548\u5e94\uff0c\u5373\u63d0\u793a\u8bcd\u7684\u5fae\u5c0f\u53d8\u5316\u4f1a\u663e\u8457\u5f71\u54cd\u6a21\u578b\u5224\u65ad\uff0c\u8fd9\u66b4\u9732\u4e86\u5f53\u524dLLM\u8bc4\u4f30\u7cfb\u7edf\u7684\u7ed3\u6784\u6027\u504f\u5dee", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u56de\u7b54\u4f1a\u56e0\u63d0\u793a\u8bcd\u63aa\u8f9e\u800c\u53d8\u5316\uff0c\u4f46\u8fd9\u79cd\u6846\u67b6\u504f\u5dee\u5bf9LLM\u8bc4\u4f30\u4efb\u52a1\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002\u5fc3\u7406\u5b66\u4e2d\u7684\u6846\u67b6\u6548\u5e94\u8868\u660e\uff0c\u95ee\u9898\u7684\u8868\u8ff0\u65b9\u5f0f\u4f1a\u5f71\u54cd\u51b3\u7b56\uff0c\u4f5c\u8005\u5e0c\u671b\u7cfb\u7edf\u7814\u7a76\u8fd9\u79cd\u6548\u5e94\u5728LLM\u8bc4\u4f30\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u91c7\u7528\u5fc3\u7406\u5b66\u4e2d\u7684\u6846\u67b6\u6548\u5e94\u6982\u5ff5\uff0c\u8bbe\u8ba1\u5bf9\u79f0\u63d0\u793a\u8bcd\uff08\u8c13\u8bcd\u80af\u5b9a\u548c\u8c13\u8bcd\u5426\u5b9a\u7ed3\u6784\uff09\uff0c\u5728\u56db\u4e2a\u9ad8\u98ce\u9669\u8bc4\u4f30\u4efb\u52a1\u4e2d\u7cfb\u7edf\u7814\u7a76\u63d0\u793a\u8bcd\u6846\u67b6\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u5224\u65ad\u3002\u4f7f\u752814\u4e2a\u4e0d\u540c\u7684LLM\u4f5c\u4e3a\u8bc4\u4f30\u8005\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6846\u67b6\u6548\u5e94\u663e\u8457\u5f71\u54cd\u6a21\u578b\u8f93\u51fa\uff0c\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u8868\u73b0\u51fa\u660e\u663e\u7684\u63a5\u53d7\u6216\u62d2\u7edd\u503e\u5411\u3002\u8fd9\u8868\u660e\u6846\u67b6\u504f\u5dee\u662f\u5f53\u524dLLM\u8bc4\u4f30\u7cfb\u7edf\u7684\u7ed3\u6784\u6027\u7279\u5f81\u3002", "conclusion": "\u6846\u67b6\u504f\u5dee\u662fLLM\u8bc4\u4f30\u7cfb\u7edf\u7684\u91cd\u8981\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u6846\u67b6\u611f\u77e5\u7684\u8bc4\u4f30\u534f\u8bae\u6765\u786e\u4fdd\u8bc4\u4f30\u7684\u7a33\u5b9a\u6027\u548c\u516c\u6b63\u6027\u3002"}}
{"id": "2601.13547", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13547", "abs": "https://arxiv.org/abs/2601.13547", "authors": ["Yujia Hu", "Roy Ka-Wei Lee"], "title": "HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations", "comment": "EACL 2026 Main Conference", "summary": "Hateful speech detection is a key component of content moderation, yet current evaluation frameworks rarely assess why a text is deemed hateful. We introduce \\textsf{HateXScore}, a four-component metric suite designed to evaluate the reasoning quality of model explanations. It assesses (i) conclusion explicitness, (ii) faithfulness and causal grounding of quoted spans, (iii) protected group identification (policy-configurable), and (iv) logical consistency among these elements. Evaluated on six diverse hate speech datasets, \\textsf{HateXScore} is intended as a diagnostic complement to reveal interpretability failures and annotation inconsistencies that are invisible to standard metrics like Accuracy or F1. Moreover, human evaluation shows strong agreement with \\textsf{HateXScore}, validating it as a practical tool for trustworthy and transparent moderation.\n  \\textcolor{red}{Disclaimer: This paper contains sensitive content that may be disturbing to some readers.}", "AI": {"tldr": "HateXScore\uff1a\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u6a21\u578b\u89e3\u91ca\u8d28\u91cf\u7684\u56db\u7ec4\u4ef6\u5ea6\u91cf\u5957\u4ef6\uff0c\u65e8\u5728\u63ed\u793a\u6807\u51c6\u6307\u6807\u65e0\u6cd5\u53d1\u73b0\u7684\u89e3\u91ca\u6027\u5931\u8d25\u548c\u6807\u6ce8\u4e0d\u4e00\u81f4\u95ee\u9898", "motivation": "\u5f53\u524d\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u8bc4\u4f30\u6846\u67b6\u5f88\u5c11\u8bc4\u4f30\u6587\u672c\u88ab\u5224\u5b9a\u4e3a\u4ec7\u6068\u8a00\u8bba\u7684\u539f\u56e0\uff0c\u7f3a\u4e4f\u5bf9\u6a21\u578b\u89e3\u91ca\u8d28\u91cf\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u9700\u8981\u8bca\u65ad\u5de5\u5177\u6765\u63ed\u793a\u6807\u51c6\u6307\u6807\u65e0\u6cd5\u53d1\u73b0\u7684\u89e3\u91ca\u6027\u5931\u8d25\u548c\u6807\u6ce8\u4e0d\u4e00\u81f4\u95ee\u9898", "method": "\u63d0\u51faHateXScore\u56db\u7ec4\u4ef6\u5ea6\u91cf\u5957\u4ef6\uff1a1)\u7ed3\u8bba\u660e\u786e\u6027\u8bc4\u4f30\uff1b2)\u5f15\u7528\u8de8\u5ea6\u7684\u5fe0\u5b9e\u6027\u548c\u56e0\u679c\u57fa\u7840\uff1b3)\u53d7\u4fdd\u62a4\u7fa4\u4f53\u8bc6\u522b\uff08\u53ef\u914d\u7f6e\u7b56\u7565\uff09\uff1b4)\u8fd9\u4e9b\u5143\u7d20\u95f4\u7684\u903b\u8f91\u4e00\u81f4\u6027\u3002\u5728\u516d\u4e2a\u4e0d\u540c\u7684\u4ec7\u6068\u8a00\u8bba\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30", "result": "HateXScore\u4f5c\u4e3a\u8bca\u65ad\u8865\u5145\u5de5\u5177\uff0c\u80fd\u591f\u63ed\u793a\u51c6\u786e\u7387\u6216F1\u5206\u6570\u7b49\u6807\u51c6\u6307\u6807\u65e0\u6cd5\u53d1\u73b0\u7684\u89e3\u91ca\u6027\u5931\u8d25\u548c\u6807\u6ce8\u4e0d\u4e00\u81f4\u95ee\u9898\u3002\u4eba\u5de5\u8bc4\u4f30\u663e\u793a\u4e0eHateXScore\u6709\u5f88\u5f3a\u7684\u4e00\u81f4\u6027\uff0c\u9a8c\u8bc1\u4e86\u5176\u4f5c\u4e3a\u53ef\u4fe1\u900f\u660e\u5185\u5bb9\u5ba1\u6838\u5b9e\u7528\u5de5\u5177\u7684\u6709\u6548\u6027", "conclusion": "HateXScore\u662f\u4e00\u4e2a\u6709\u6548\u7684\u5ea6\u91cf\u5957\u4ef6\uff0c\u7528\u4e8e\u8bc4\u4f30\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u6a21\u578b\u7684\u89e3\u91ca\u8d28\u91cf\uff0c\u4e3a\u53ef\u4fe1\u548c\u900f\u660e\u7684\u5ba1\u6838\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u80fd\u591f\u8bca\u65ad\u6807\u51c6\u6307\u6807\u65e0\u6cd5\u53d1\u73b0\u7684\u89e3\u91ca\u6027\u95ee\u9898"}}
{"id": "2601.13575", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13575", "abs": "https://arxiv.org/abs/2601.13575", "authors": ["Thanh-Lam T. Nguyen", "Ngoc-Quang Le", "Quoc-Trung Phu", "Thi-Phuong Le", "Ngoc-Huyen Pham", "Phuong-Nguyen Nguyen", "Hoang-Quynh Le"], "title": "Comparing Without Saying: A Dataset and Benchmark for Implicit Comparative Opinion Mining from Same-User Reviews", "comment": null, "summary": "Existing studies on comparative opinion mining have mainly focused on explicit comparative expressions, which are uncommon in real-world reviews. This leaves implicit comparisons - here users express preferences across separate reviews - largely underexplored. We introduce SUDO, a novel dataset for implicit comparative opinion mining from same-user reviews, allowing reliable inference of user preferences even without explicit comparative cues. SUDO comprises 4,150 annotated review pairs (15,191 sentences) with a bi-level structure capturing aspect-level mentions and review-level preferences. We benchmark this task using two baseline architectures: traditional machine learning- and language model-based baselines. Experimental results show that while the latter outperforms the former, overall performance remains moderate, revealing the inherent difficulty of the task and establishing SUDO as a challenging and valuable benchmark for future research.", "AI": {"tldr": "SUDO\u662f\u4e00\u4e2a\u7528\u4e8e\u9690\u5f0f\u6bd4\u8f83\u89c2\u70b9\u6316\u6398\u7684\u65b0\u6570\u636e\u96c6\uff0c\u5305\u542b4,150\u4e2a\u6807\u6ce8\u7684\u8bc4\u8bba\u5bf9\uff0c\u652f\u6301\u5728\u6ca1\u6709\u663e\u5f0f\u6bd4\u8f83\u7ebf\u7d22\u7684\u60c5\u51b5\u4e0b\u63a8\u65ad\u7528\u6237\u504f\u597d\u3002", "motivation": "\u73b0\u6709\u6bd4\u8f83\u89c2\u70b9\u6316\u6398\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u663e\u5f0f\u6bd4\u8f83\u8868\u8fbe\uff0c\u4f46\u5728\u771f\u5b9e\u8bc4\u8bba\u4e2d\u4e0d\u5e38\u89c1\uff0c\u800c\u9690\u5f0f\u6bd4\u8f83\uff08\u7528\u6237\u5728\u4e0d\u540c\u8bc4\u8bba\u4e2d\u8868\u8fbe\u504f\u597d\uff09\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e86SUDO\u6570\u636e\u96c6\uff0c\u5305\u542b4,150\u4e2a\u6807\u6ce8\u7684\u8bc4\u8bba\u5bf9\uff0815,191\u4e2a\u53e5\u5b50\uff09\uff0c\u91c7\u7528\u53cc\u5c42\u7ed3\u6784\u6355\u6349\u65b9\u9762\u7ea7\u63d0\u53ca\u548c\u8bc4\u8bba\u7ea7\u504f\u597d\u3002\u4f7f\u7528\u4e24\u79cd\u57fa\u7ebf\u67b6\u6784\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff1a\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u548c\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8bed\u8a00\u6a21\u578b\u57fa\u7ebf\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u4f46\u6574\u4f53\u6027\u80fd\u4ecd\u7136\u4e2d\u7b49\uff0c\u63ed\u793a\u4e86\u4efb\u52a1\u7684\u56fa\u6709\u96be\u5ea6\u3002", "conclusion": "SUDO\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u548c\u4ef7\u503c\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u4e3a\u672a\u6765\u9690\u5f0f\u6bd4\u8f83\u89c2\u70b9\u6316\u6398\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\u3002"}}
{"id": "2601.13614", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13614", "abs": "https://arxiv.org/abs/2601.13614", "authors": ["Bo Peng", "Sirui Chen", "Lei Xu", "Chaochao Lu"], "title": "CauScientist: Teaching LLMs to Respect Data for Causal Discovery", "comment": null, "summary": "Causal discovery is fundamental to scientific understanding and reliable decision-making. Existing approaches face critical limitations: purely data-driven methods suffer from statistical indistinguishability and modeling assumptions, while recent LLM-based methods either ignore statistical evidence or incorporate unverified priors that can mislead result. To this end, we propose CauScientist, a collaborative framework that synergizes LLMs as hypothesis-generating \"data scientists\" with probabilistic statistics as rigorous \"verifiers\". CauScientist employs hybrid initialization to select superior starting graphs, iteratively refines structures through LLM-proposed modifications validated by statistical criteria, and maintains error memory to guide efficient search space. Experiments demonstrate that CauScientist substantially outperforms purely data-driven baselines, achieving up to 53.8% F1 score improvement and enhancing recall from 35.0% to 100.0%. Notably, while standalone LLM performance degrades with graph complexity, CauScientist reduces structural hamming distance (SHD) by 44.0% compared to Qwen3-32B on 37-node graphs. Our project page is at https://github.com/OpenCausaLab/CauScientist.", "code_url": "https://github.com/OpenCausaLab/CauScientis", "AI": {"tldr": "CauScientist\u662f\u4e00\u4e2a\u7ed3\u5408LLM\u5047\u8bbe\u751f\u6210\u4e0e\u6982\u7387\u7edf\u8ba1\u9a8c\u8bc1\u7684\u56e0\u679c\u53d1\u73b0\u6846\u67b6\uff0c\u901a\u8fc7\u6df7\u5408\u521d\u59cb\u5316\u3001\u8fed\u4ee3\u4f18\u5316\u548c\u9519\u8bef\u8bb0\u5fc6\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u56e0\u679c\u56fe\u6784\u5efa\u6027\u80fd", "motivation": "\u73b0\u6709\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u7eaf\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u53d7\u7edf\u8ba1\u4e0d\u53ef\u533a\u5206\u6027\u548c\u5efa\u6a21\u5047\u8bbe\u5f71\u54cd\uff0c\u800c\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u8981\u4e48\u5ffd\u7565\u7edf\u8ba1\u8bc1\u636e\uff0c\u8981\u4e48\u5f15\u5165\u672a\u7ecf\u9a8c\u8bc1\u7684\u5148\u9a8c\u77e5\u8bc6\u53ef\u80fd\u8bef\u5bfc\u7ed3\u679c", "method": "\u63d0\u51faCauScientist\u534f\u4f5c\u6846\u67b6\uff0c\u5c06LLM\u4f5c\u4e3a\u5047\u8bbe\u751f\u6210\u7684\"\u6570\u636e\u79d1\u5b66\u5bb6\"\uff0c\u6982\u7387\u7edf\u8ba1\u4f5c\u4e3a\u4e25\u683c\"\u9a8c\u8bc1\u8005\"\u3002\u91c7\u7528\u6df7\u5408\u521d\u59cb\u5316\u9009\u62e9\u4f18\u8d28\u8d77\u59cb\u56fe\uff0c\u901a\u8fc7LLM\u63d0\u8bae\u4fee\u6539\u5e76\u7531\u7edf\u8ba1\u6807\u51c6\u9a8c\u8bc1\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\uff0c\u7ef4\u62a4\u9519\u8bef\u8bb0\u5fc6\u5f15\u5bfc\u9ad8\u6548\u641c\u7d22\u7a7a\u95f4", "result": "\u5b9e\u9a8c\u8868\u660eCauScientist\u663e\u8457\u4f18\u4e8e\u7eaf\u6570\u636e\u9a71\u52a8\u57fa\u7ebf\uff0cF1\u5206\u6570\u63d0\u5347\u8fbe53.8%\uff0c\u53ec\u56de\u7387\u4ece35.0%\u63d0\u5347\u81f3100.0%\u3002\u572837\u8282\u70b9\u56fe\u4e0a\uff0c\u76f8\u6bd4Qwen3-32B\u5c06\u7ed3\u6784\u6c49\u660e\u8ddd\u79bb(SHD)\u964d\u4f4e44.0%", "conclusion": "CauScientist\u901a\u8fc7LLM\u4e0e\u7edf\u8ba1\u65b9\u6cd5\u7684\u534f\u540c\u5de5\u4f5c\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u590d\u6742\u56fe\u7ed3\u6784\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u4e3a\u53ef\u9760\u56e0\u679c\u53d1\u73b0\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f"}}
{"id": "2601.13630", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13630", "abs": "https://arxiv.org/abs/2601.13630", "authors": ["Zhaopeng Zhang", "Pengcheng Sun", "Lan Zhang", "Chen Tang", "Jiewei Lai", "Yunhao Wang", "Hui Jin"], "title": "Activation-Space Anchored Access Control for Multi-Class Permission Reasoning in Large Language Models", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed over knowledge bases for efficient knowledge retrieval and question answering. However, LLMs can inadvertently answer beyond a user's permission scope, leaking sensitive content, thus making it difficult to deploy knowledge-base QA under fine-grained access control requirements. In this work, we identify a geometric regularity in intermediate activations: for the same query, representations induced by different permission scopes cluster distinctly and are readily separable. Building on this separability, we propose Activation-space Anchored Access Control (AAAC), a training-free framework for multi-class permission control. AAAC constructs an anchor bank, with one permission anchor per class, from a small offline sample set and requires no fine-tuning. At inference time, a multi-anchor steering mechanism redirects each query's activations toward the anchor-defined authorized region associated with the current user, thereby suppressing over-privileged generations by design. Finally, extensive experiments across three LLM families demonstrate that AAAC reduces permission violation rates by up to 86.5% and prompt-based attack success rates by 90.7%, while improving response usability with minor inference overhead compared to baselines.", "AI": {"tldr": "AAAC\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u591a\u7c7b\u6743\u9650\u63a7\u5236\u6846\u67b6\uff0c\u5229\u7528\u6fc0\u6d3b\u7a7a\u95f4\u51e0\u4f55\u89c4\u5f8b\uff0c\u901a\u8fc7\u6743\u9650\u951a\u70b9\u91cd\u5b9a\u5411\u67e5\u8be2\u6fc0\u6d3b\uff0c\u663e\u8457\u964d\u4f4e\u6743\u9650\u8fdd\u89c4\u7387", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u5e93\u95ee\u7b54\u4e2d\u53ef\u80fd\u65e0\u610f\u4e2d\u8d85\u8d8a\u7528\u6237\u6743\u9650\u8303\u56f4\u6cc4\u9732\u654f\u611f\u4fe1\u606f\uff0c\u96be\u4ee5\u6ee1\u8db3\u7ec6\u7c92\u5ea6\u8bbf\u95ee\u63a7\u5236\u9700\u6c42", "method": "\u57fa\u4e8e\u6fc0\u6d3b\u7a7a\u95f4\u51e0\u4f55\u89c4\u5f8b\u6027\uff0c\u63d0\u51faAAAC\u6846\u67b6\uff1a\u4ece\u79bb\u7ebf\u6837\u672c\u96c6\u6784\u5efa\u6743\u9650\u951a\u70b9\u5e93\uff0c\u901a\u8fc7\u591a\u951a\u70b9\u5f15\u5bfc\u673a\u5236\u5c06\u67e5\u8be2\u6fc0\u6d3b\u91cd\u5b9a\u5411\u5230\u6388\u6743\u533a\u57df", "result": "\u5728\u4e09\u4e2aLLM\u5bb6\u65cf\u4e0a\u5b9e\u9a8c\u663e\u793a\uff0cAAAC\u5c06\u6743\u9650\u8fdd\u89c4\u7387\u964d\u4f4e\u9ad8\u8fbe86.5%\uff0c\u63d0\u793a\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e90.7%\uff0c\u63a8\u7406\u5f00\u9500\u5c0f\u4e14\u63d0\u5347\u54cd\u5e94\u53ef\u7528\u6027", "conclusion": "AAAC\u901a\u8fc7\u6fc0\u6d3b\u7a7a\u95f4\u951a\u70b9\u63a7\u5236\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u591a\u7c7b\u6743\u9650\u7ba1\u7406\uff0c\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u663e\u8457\u51cf\u5c11\u6743\u9650\u8fdd\u89c4\uff0c\u4e3a\u77e5\u8bc6\u5e93QA\u7684\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.13644", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13644", "abs": "https://arxiv.org/abs/2601.13644", "authors": ["Yang Cao", "Bicheng Yu", "Sikun Yang", "Ming Liu", "Yujiu Yang"], "title": "Towards Token-Level Text Anomaly Detection", "comment": "WWW 2026", "summary": "Despite significant progress in text anomaly detection for web applications such as spam filtering and fake news detection, existing methods are fundamentally limited to document-level analysis, unable to identify which specific parts of a text are anomalous. We introduce token-level anomaly detection, a novel paradigm that enables fine-grained localization of anomalies within text. We formally define text anomalies at both document and token-levels, and propose a unified detection framework that operates across multiple levels. To facilitate research in this direction, we collect and annotate three benchmark datasets spanning spam, reviews and grammar errors with token-level labels. Experimental results demonstrate that our framework get better performance than other 6 baselines, opening new possibilities for precise anomaly localization in text. All the codes and data are publicly available on https://github.com/charles-cao/TokenCore.", "code_url": "https://github.com/charles-cao/TokenCore", "code_stars": 0, "code_last_update": "2025-11-24", "AI": {"tldr": "\u63d0\u51fatoken\u7ea7\u5f02\u5e38\u68c0\u6d4b\u65b0\u8303\u5f0f\uff0c\u5b9e\u73b0\u6587\u672c\u5185\u90e8\u5f02\u5e38\u7684\u7cbe\u786e\u5b9a\u4f4d\uff0c\u8d85\u8d8a\u4f20\u7edf\u6587\u6863\u7ea7\u68c0\u6d4b\u65b9\u6cd5", "motivation": "\u73b0\u6709\u6587\u672c\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff08\u5982\u5783\u573e\u90ae\u4ef6\u8fc7\u6ee4\u3001\u5047\u65b0\u95fb\u68c0\u6d4b\uff09\u4ec5\u9650\u4e8e\u6587\u6863\u7ea7\u5206\u6790\uff0c\u65e0\u6cd5\u8bc6\u522b\u6587\u672c\u4e2d\u54ea\u4e9b\u5177\u4f53\u90e8\u5206\u5b58\u5728\u5f02\u5e38\uff0c\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\u7684\u68c0\u6d4b\u80fd\u529b", "method": "1. \u5f62\u5f0f\u5316\u5b9a\u4e49\u6587\u6863\u7ea7\u548ctoken\u7ea7\u6587\u672c\u5f02\u5e38\uff1b2. \u63d0\u51fa\u7edf\u4e00\u7684\u591a\u5c42\u7ea7\u68c0\u6d4b\u6846\u67b6\uff1b3. \u6536\u96c6\u5e76\u6807\u6ce8\u4e09\u4e2a\u5305\u542btoken\u7ea7\u6807\u7b7e\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff08\u5783\u573e\u90ae\u4ef6\u3001\u8bc4\u8bba\u3001\u8bed\u6cd5\u9519\u8bef\uff09", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u5176\u4ed66\u4e2a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e3a\u6587\u672c\u5f02\u5e38\u7cbe\u786e\u5b9a\u4f4d\u5f00\u8f9f\u4e86\u65b0\u53ef\u80fd\u6027", "conclusion": "\u63d0\u51fa\u7684token\u7ea7\u5f02\u5e38\u68c0\u6d4b\u8303\u5f0f\u586b\u8865\u4e86\u7ec6\u7c92\u5ea6\u6587\u672c\u5f02\u5e38\u5b9a\u4f4d\u7684\u7a7a\u767d\uff0c\u76f8\u5173\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\uff0c\u63a8\u52a8\u4e86\u8be5\u7814\u7a76\u65b9\u5411\u7684\u53d1\u5c55"}}
{"id": "2601.13649", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13649", "abs": "https://arxiv.org/abs/2601.13649", "authors": ["Xiaolin Zhou", "Zheng Luo", "Yicheng Gao", "Qixuan Chen", "Xiyang Hu", "Yue Zhao", "Ruishan Liu"], "title": "Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge", "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have incentivized the development of LLM-as-a-judge, an application of LLMs where they are used as judges to decide the quality of a certain piece of text given a certain context. However, previous studies have demonstrated that LLM-as-a-judge can be biased towards different aspects of the judged texts, which often do not align with human preference. One of the identified biases is language bias, which indicates that the decision of LLM-as-a-judge can differ based on the language of the judged texts. In this paper, we study two types of language bias in pairwise LLM-as-a-judge: (1) performance disparity between languages when the judge is prompted to compare options from the same language, and (2) bias towards options written in major languages when the judge is prompted to compare options of two different languages. We find that for same-language judging, there exist significant performance disparities across language families, with European languages consistently outperforming African languages, and this bias is more pronounced in culturally-related subjects. For inter-language judging, we observe that most models favor English answers, and that this preference is influenced more by answer language than question language. Finally, we investigate whether language bias is in fact caused by low-perplexity bias, a previously identified bias of LLM-as-a-judge, and we find that while perplexity is slightly correlated with language bias, language bias cannot be fully explained by perplexity only.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u65f6\u7684\u8bed\u8a00\u504f\u89c1\u95ee\u9898\uff0c\u53d1\u73b0\u540c\u8bed\u8a00\u8bc4\u5224\u4e2d\u5b58\u5728\u8bed\u8a00\u5bb6\u65cf\u95f4\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u8de8\u8bed\u8a00\u8bc4\u5224\u4e2d\u6a21\u578b\u504f\u597d\u82f1\u8bed\u7b54\u6848\uff0c\u4e14\u8bed\u8a00\u504f\u89c1\u4e0d\u80fd\u5b8c\u5168\u7531\u56f0\u60d1\u5ea6\u504f\u89c1\u89e3\u91ca\u3002", "motivation": "\u5c3d\u7ba1LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5148\u524d\u7814\u7a76\u8868\u660eLLM\u8bc4\u5224\u5b58\u5728\u591a\u79cd\u504f\u89c1\uff0c\u5176\u4e2d\u8bed\u8a00\u504f\u89c1\u5c24\u4e3a\u7a81\u51fa\u3002\u8be5\u7814\u7a76\u65e8\u5728\u6df1\u5165\u63a2\u7a76LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u5728\u6210\u5bf9\u6bd4\u8f83\u4e2d\u7684\u4e24\u79cd\u8bed\u8a00\u504f\u89c1\u7c7b\u578b\uff0c\u5e76\u5206\u6790\u5176\u4e0e\u56f0\u60d1\u5ea6\u504f\u89c1\u7684\u5173\u7cfb\u3002", "method": "\u7814\u7a76\u91c7\u7528\u5b9e\u9a8c\u65b9\u6cd5\u5206\u6790LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u8bed\u8a00\u504f\u89c1\uff1a1) \u540c\u8bed\u8a00\u8bc4\u5224\u4e2d\uff0c\u6bd4\u8f83\u4e0d\u540c\u8bed\u8a00\u5bb6\u65cf\u95f4\u7684\u6027\u80fd\u5dee\u5f02\uff1b2) \u8de8\u8bed\u8a00\u8bc4\u5224\u4e2d\uff0c\u5206\u6790\u6a21\u578b\u5bf9\u4e0d\u540c\u8bed\u8a00\u7b54\u6848\u7684\u504f\u597d\uff1b3) \u901a\u8fc7\u76f8\u5173\u6027\u5206\u6790\u63a2\u7a76\u8bed\u8a00\u504f\u89c1\u4e0e\u56f0\u60d1\u5ea6\u504f\u89c1\u7684\u5173\u7cfb\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1) \u540c\u8bed\u8a00\u8bc4\u5224\u4e2d\uff0c\u6b27\u6d32\u8bed\u8a00\u8868\u73b0\u4f18\u4e8e\u975e\u6d32\u8bed\u8a00\uff0c\u4e14\u6587\u5316\u76f8\u5173\u4e3b\u9898\u4e2d\u504f\u89c1\u66f4\u660e\u663e\uff1b2) \u8de8\u8bed\u8a00\u8bc4\u5224\u4e2d\uff0c\u5927\u591a\u6570\u6a21\u578b\u504f\u597d\u82f1\u8bed\u7b54\u6848\uff0c\u4e14\u7b54\u6848\u8bed\u8a00\u6bd4\u95ee\u9898\u8bed\u8a00\u5bf9\u504f\u597d\u5f71\u54cd\u66f4\u5927\uff1b3) \u8bed\u8a00\u504f\u89c1\u4e0e\u56f0\u60d1\u5ea6\u504f\u89c1\u4ec5\u6709\u8f7b\u5fae\u76f8\u5173\u6027\uff0c\u4e0d\u80fd\u5b8c\u5168\u7531\u56f0\u60d1\u5ea6\u89e3\u91ca\u3002", "conclusion": "LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u5b58\u5728\u663e\u8457\u7684\u8bed\u8a00\u504f\u89c1\uff0c\u5305\u62ec\u540c\u8bed\u8a00\u8bc4\u5224\u4e2d\u7684\u6027\u80fd\u5dee\u5f02\u548c\u8de8\u8bed\u8a00\u8bc4\u5224\u4e2d\u7684\u8bed\u8a00\u504f\u597d\u3002\u8fd9\u4e9b\u504f\u89c1\u4e0d\u80fd\u5b8c\u5168\u5f52\u56e0\u4e8e\u56f0\u60d1\u5ea6\u504f\u89c1\uff0c\u8868\u660e\u9700\u8981\u66f4\u6df1\u5165\u7406\u89e3LLM\u8bc4\u5224\u673a\u5236\u5e76\u5f00\u53d1\u7f13\u89e3\u7b56\u7565\u3002"}}
{"id": "2601.13658", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13658", "abs": "https://arxiv.org/abs/2601.13658", "authors": ["Arthur Amalvy", "Hen-Hsen Huang"], "title": "Beyond Known Facts: Generating Unseen Temporal Knowledge to Address Data Contamination in LLM Evaluation", "comment": "12 pages", "summary": "The automatic extraction of information is important for populating large web knowledge bases such as Wikidata. The temporal version of that task, temporal knowledge graph extraction (TKGE), involves extracting temporally grounded facts from text, represented as semantic quadruples (subject, relation, object, timestamp). Many recent systems take advantage of large language models (LLMs), which are becoming a new cornerstone of the web due to their performance on many tasks across the natural language processing (NLP) field. Despite the importance of TKGE, existing datasets for training and evaluation remain scarce, and contamination of evaluation data is an unaddressed issue, potentially inflating LLMs' perceived performance due to overlaps between training and evaluation sets. To mitigate these challenges, we propose a novel synthetic evaluation dataset constructed from predicted future, previously unseen temporal facts, thereby eliminating contamination and enabling robust and unbiased benchmarking. Our dataset creation involves a two-step approach: (1) Temporal Knowledge Graph Forecasting (TKGF) generates plausible future quadruples, which are subsequently filtered to adhere to the original knowledge base schema; (2) LLMs perform quadruple-to-text generation, creating semantically aligned textual descriptions. We benchmark Extract, Define and Canonicalize (EDC), a state-of-the-art LLM-based extraction framework, demonstrating that LLM performance decreases when evaluated on our dataset compared to a dataset of known facts. We publicly release our dataset consisting of 4.2K future quadruples and corresponding textual descriptions, along with the generation methodology, enabling continuous creation of unlimited future temporal datasets to serve as long-term, contamination-free benchmarks for TKGE.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u672a\u6765\u4e8b\u5b9e\u7684\u5408\u6210\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u62bd\u53d6\u4efb\u52a1\u4e2d\u6570\u636e\u7a00\u7f3a\u548c\u8bc4\u4f30\u6570\u636e\u6c61\u67d3\u95ee\u9898", "motivation": "\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u62bd\u53d6\u4efb\u52a1\u4e2d\uff0c\u73b0\u6709\u6570\u636e\u96c6\u7a00\u7f3a\u4e14\u5b58\u5728\u8bc4\u4f30\u6570\u636e\u6c61\u67d3\u95ee\u9898\uff0c\u53ef\u80fd\u5bfc\u81f4LLM\u6027\u80fd\u88ab\u9ad8\u4f30", "method": "\u91c7\u7528\u4e24\u6b65\u6cd5\uff1a1) \u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u9884\u6d4b\u751f\u6210\u672a\u6765\u56db\u5143\u7ec4\uff1b2) LLM\u8fdb\u884c\u56db\u5143\u7ec4\u5230\u6587\u672c\u751f\u6210\uff0c\u521b\u5efa\u8bed\u4e49\u5bf9\u9f50\u7684\u6587\u672c\u63cf\u8ff0", "result": "\u6784\u5efa\u4e86\u5305\u542b4.2K\u672a\u6765\u56db\u5143\u7ec4\u53ca\u5bf9\u5e94\u6587\u672c\u63cf\u8ff0\u7684\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u663e\u793aLLM\u5728\u65b0\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u4e0b\u964d\uff0c\u9a8c\u8bc1\u4e86\u6570\u636e\u6c61\u67d3\u95ee\u9898", "conclusion": "\u63d0\u51fa\u7684\u5408\u6210\u8bc4\u4f30\u6570\u636e\u96c6\u6d88\u9664\u4e86\u6570\u636e\u6c61\u67d3\uff0c\u4e3a\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u62bd\u53d6\u63d0\u4f9b\u4e86\u957f\u671f\u3001\u65e0\u6c61\u67d3\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6"}}
{"id": "2601.13659", "categories": ["cs.CL", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.13659", "abs": "https://arxiv.org/abs/2601.13659", "authors": ["Chunlei Meng", "Ziyang Zhou", "Lucas He", "Xiaojing Du", "Chun Ouyang", "Zhongxue Gan"], "title": "Temporal-Spatial Decouple before Act: Disentangled Representation Learning for Multimodal Sentiment Analysis", "comment": "This study has been accepted by IEEE ICASSP2026", "summary": "Multimodal Sentiment Analysis integrates Linguistic, Visual, and Acoustic. Mainstream approaches based on modality-invariant and modality-specific factorization or on complex fusion still rely on spatiotemporal mixed modeling. This ignores spatiotemporal heterogeneity, leading to spatiotemporal information asymmetry and thus limited performance. Hence, we propose TSDA, Temporal-Spatial Decouple before Act, which explicitly decouples each modality into temporal dynamics and spatial structural context before any interaction. For every modality, a temporal encoder and a spatial encoder project signals into separate temporal and spatial body. Factor-Consistent Cross-Modal Alignment then aligns temporal features only with their temporal counterparts across modalities, and spatial features only with their spatial counterparts. Factor specific supervision and decorrelation regularization reduce cross factor leakage while preserving complementarity. A Gated Recouple module subsequently recouples the aligned streams for task. Extensive experiments show that TSDA outperforms baselines. Ablation analysis studies confirm the necessity and interpretability of the design.", "AI": {"tldr": "TSDA\u901a\u8fc7\u65f6\u7a7a\u89e3\u8026-\u5bf9\u9f50-\u91cd\u8026\u5408\u6846\u67b6\u89e3\u51b3\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4e2d\u7684\u65f6\u7a7a\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u65b9\u6cd5\u57fa\u4e8e\u6a21\u6001\u4e0d\u53d8/\u7279\u5b9a\u5206\u89e3\u6216\u590d\u6742\u878d\u5408\uff0c\u4f46\u4ecd\u4f9d\u8d56\u65f6\u7a7a\u6df7\u5408\u5efa\u6a21\uff0c\u5ffd\u7565\u4e86\u65f6\u7a7a\u5f02\u8d28\u6027\uff0c\u5bfc\u81f4\u65f6\u7a7a\u4fe1\u606f\u4e0d\u5bf9\u79f0\u548c\u6027\u80fd\u53d7\u9650", "method": "\u63d0\u51faTSDA\u6846\u67b6\uff1a1) \u5c06\u6bcf\u4e2a\u6a21\u6001\u663e\u5f0f\u89e3\u8026\u4e3a\u65f6\u95f4\u52a8\u6001\u548c\u7a7a\u95f4\u7ed3\u6784\u4e0a\u4e0b\u6587\uff1b2) \u56e0\u5b50\u4e00\u81f4\u8de8\u6a21\u6001\u5bf9\u9f50\uff1a\u65f6\u95f4\u7279\u5f81\u4ec5\u4e0e\u8de8\u6a21\u6001\u65f6\u95f4\u7279\u5f81\u5bf9\u9f50\uff0c\u7a7a\u95f4\u7279\u5f81\u4ec5\u4e0e\u7a7a\u95f4\u7279\u5f81\u5bf9\u9f50\uff1b3) \u56e0\u5b50\u7279\u5b9a\u76d1\u7763\u548c\u53bb\u76f8\u5173\u6b63\u5219\u5316\u51cf\u5c11\u8de8\u56e0\u5b50\u6cc4\u6f0f\uff1b4) \u95e8\u63a7\u91cd\u8026\u5408\u6a21\u5757\u5c06\u5bf9\u9f50\u540e\u7684\u6d41\u91cd\u8026\u5408\u7528\u4e8e\u4efb\u52a1", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660eTSDA\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6d88\u878d\u5206\u6790\u8bc1\u5b9e\u4e86\u8bbe\u8ba1\u7684\u5fc5\u8981\u6027\u548c\u53ef\u89e3\u91ca\u6027", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u65f6\u7a7a\u89e3\u8026\u548c\u5bf9\u9f50\u7b56\u7565\uff0cTSDA\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4e2d\u7684\u65f6\u7a7a\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347"}}
{"id": "2601.13669", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13669", "abs": "https://arxiv.org/abs/2601.13669", "authors": ["Jiayu Lin", "Zhongyu Wei"], "title": "CommunityBench: Benchmarking Community-Level Alignment across Diverse Groups and Tasks", "comment": null, "summary": "Large language models (LLMs) alignment ensures model behaviors reflect human value. Existing alignment strategies primarily follow two paths: one assumes a universal value set for a unified goal (i.e., one-size-fits-all), while the other treats every individual as unique to customize models (i.e., individual-level). However, assuming a monolithic value space marginalizes minority norms, while tailoring individual models is prohibitively expensive. Recognizing that human society is organized into social clusters with high intra-group value alignment, we propose community-level alignment as a \"middle ground\". Practically, we introduce CommunityBench, the first large-scale benchmark for community-level alignment evaluation, featuring four tasks grounded in Common Identity and Common Bond theory. With CommunityBench, we conduct a comprehensive evaluation of various foundation models on CommunityBench, revealing that current LLMs exhibit limited capacity to model community-specific preferences. Furthermore, we investigate the potential of community-level alignment in facilitating individual modeling, providing a promising direction for scalable and pluralistic alignment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u793e\u533a\u7ea7\u5bf9\u9f50\u4f5c\u4e3aLLM\u5bf9\u9f50\u7684\u4e2d\u95f4\u8def\u5f84\uff0c\u6784\u5efa\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u793e\u533a\u7ea7\u5bf9\u9f50\u8bc4\u4f30\u57fa\u51c6CommunityBench\uff0c\u53d1\u73b0\u5f53\u524dLLM\u5728\u5efa\u6a21\u793e\u533a\u7279\u5b9a\u504f\u597d\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u4f46\u793e\u533a\u7ea7\u5bf9\u9f50\u4e3a\u53ef\u6269\u5c55\u7684\u591a\u5143\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002", "motivation": "\u73b0\u6709LLM\u5bf9\u9f50\u7b56\u7565\u5b58\u5728\u4e24\u4e2a\u6781\u7aef\uff1a\u4e00\u662f\u5047\u8bbe\u666e\u4e16\u4ef7\u503c\u96c6\u7684\u4e00\u5200\u5207\u65b9\u6cd5\uff0c\u8fd9\u4f1a\u8fb9\u7f18\u5316\u5c11\u6570\u7fa4\u4f53\u89c4\u8303\uff1b\u4e8c\u662f\u4e3a\u6bcf\u4e2a\u4e2a\u4f53\u5b9a\u5236\u6a21\u578b\u7684\u4e2a\u4f53\u7ea7\u65b9\u6cd5\uff0c\u6210\u672c\u8fc7\u9ad8\u3002\u4f5c\u8005\u8ba4\u8bc6\u5230\u4eba\u7c7b\u793e\u4f1a\u7531\u5177\u6709\u9ad8\u5ea6\u7ec4\u5185\u4ef7\u503c\u5bf9\u9f50\u7684\u793e\u4f1a\u96c6\u7fa4\u7ec4\u6210\uff0c\u56e0\u6b64\u63d0\u51fa\u793e\u533a\u7ea7\u5bf9\u9f50\u4f5c\u4e3a\u4e2d\u95f4\u65b9\u6848\u3002", "method": "\u5f15\u5165CommunityBench\u2014\u2014\u9996\u4e2a\u5927\u89c4\u6a21\u793e\u533a\u7ea7\u5bf9\u9f50\u8bc4\u4f30\u57fa\u51c6\uff0c\u57fa\u4e8e\u5171\u540c\u8eab\u4efd\u548c\u5171\u540c\u7ebd\u5e26\u7406\u8bba\u6784\u5efa\u4e86\u56db\u4e2a\u4efb\u52a1\u3002\u4f7f\u7528\u8be5\u57fa\u51c6\u5bf9\u5404\u79cd\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\uff0c\u5e76\u7814\u7a76\u793e\u533a\u7ea7\u5bf9\u9f50\u5728\u4fc3\u8fdb\u4e2a\u4f53\u5efa\u6a21\u65b9\u9762\u7684\u6f5c\u529b\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u5f53\u524dLLM\u5728\u5efa\u6a21\u793e\u533a\u7279\u5b9a\u504f\u597d\u65b9\u9762\u80fd\u529b\u6709\u9650\u3002\u540c\u65f6\u53d1\u73b0\u793e\u533a\u7ea7\u5bf9\u9f50\u80fd\u591f\u4fc3\u8fdb\u4e2a\u4f53\u5efa\u6a21\uff0c\u4e3a\u53ef\u6269\u5c55\u7684\u591a\u5143\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002", "conclusion": "\u793e\u533a\u7ea7\u5bf9\u9f50\u662fLLM\u5bf9\u9f50\u7684\u6709\u6548\u4e2d\u95f4\u8def\u5f84\uff0cCommunityBench\u4e3a\u8bc4\u4f30\u8fd9\u4e00\u80fd\u529b\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\u3002\u867d\u7136\u5f53\u524d\u6a21\u578b\u5728\u793e\u533a\u7ea7\u5bf9\u9f50\u65b9\u9762\u8868\u73b0\u6709\u9650\uff0c\u4f46\u8fd9\u4e00\u65b9\u5411\u4e3a\u5b9e\u73b0\u53ef\u6269\u5c55\u4e14\u5c0a\u91cd\u591a\u5143\u4ef7\u503c\u7684\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13684", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13684", "abs": "https://arxiv.org/abs/2601.13684", "authors": ["Zhiyuan Shi", "Qibo Qiu", "Feng Xue", "Zhonglin Jiang", "Li Yu", "Jian Jiang", "Xiaofei He", "Wenxiao Wang"], "title": "HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache Compression for Long-Context LLM Inference", "comment": null, "summary": "The linear memory growth of the KV cache poses a significant bottleneck for LLM inference in long-context tasks. Existing static compression methods often fail to preserve globally important information, principally because they overlook the attention drift phenomenon where token significance evolves dynamically. Although recent dynamic retrieval approaches attempt to address this issue, they typically suffer from coarse-grained caching strategies and incur high I/O overhead due to frequent data transfers. To overcome these limitations, we propose HeteroCache, a training-free dynamic compression framework. Our method is built on two key insights: attention heads exhibit diverse temporal heterogeneity, and there is significant spatial redundancy among heads within the same layer. Guided by these insights, HeteroCache categorizes heads based on stability and redundancy. Consequently, we apply a fine-grained weighting strategy that allocates larger cache budgets to heads with rapidly shifting attention to capture context changes, thereby addressing the inefficiency of coarse-grained strategies. Furthermore, we employ a hierarchical storage mechanism in which a subset of representative heads monitors attention shift, and trigger an asynchronous, on-demand retrieval of contexts from the CPU, effectively hiding I/O latency. Finally, experiments demonstrate that HeteroCache achieves state-of-the-art performance on multiple long-context benchmarks and accelerates decoding by up to $3\\times$ compared to the original model in the 224K context. Our code will be open-source.", "AI": {"tldr": "HeteroCache\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684KV\u7f13\u5b58\u52a8\u6001\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u6743\u91cd\u5206\u914d\u548c\u5206\u5c42\u5b58\u50a8\u673a\u5236\u89e3\u51b3\u957f\u4e0a\u4e0b\u6587LLM\u63a8\u7406\u4e2d\u7684\u5185\u5b58\u74f6\u9888\u95ee\u9898\uff0c\u5728224K\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u5b9e\u73b03\u500d\u89e3\u7801\u52a0\u901f\u3002", "motivation": "KV\u7f13\u5b58\u7684\u7ebf\u6027\u5185\u5b58\u589e\u957f\u662f\u957f\u4e0a\u4e0b\u6587LLM\u63a8\u7406\u7684\u4e3b\u8981\u74f6\u9888\u3002\u73b0\u6709\u9759\u6001\u538b\u7f29\u65b9\u6cd5\u65e0\u6cd5\u4fdd\u7559\u5168\u5c40\u91cd\u8981\u4fe1\u606f\uff0c\u56e0\u4e3a\u5b83\u4eec\u5ffd\u7565\u4e86\u6ce8\u610f\u529b\u6f02\u79fb\u73b0\u8c61\uff08token\u91cd\u8981\u6027\u52a8\u6001\u53d8\u5316\uff09\u3002\u867d\u7136\u52a8\u6001\u68c0\u7d22\u65b9\u6cd5\u8bd5\u56fe\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u4f46\u901a\u5e38\u5b58\u5728\u7c97\u7c92\u5ea6\u7f13\u5b58\u7b56\u7565\u548c\u9ad8I/O\u5f00\u9500\u7684\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u4e24\u4e2a\u5173\u952e\u6d1e\u5bdf\uff1a1\uff09\u6ce8\u610f\u529b\u5934\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u65f6\u95f4\u5f02\u8d28\u6027\uff1b2\uff09\u540c\u4e00\u5c42\u5185\u5934\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u7684\u7a7a\u95f4\u5197\u4f59\u3002HeteroCache\u6839\u636e\u7a33\u5b9a\u6027\u548c\u5197\u4f59\u6027\u5bf9\u5934\u8fdb\u884c\u5206\u7c7b\uff0c\u91c7\u7528\u7ec6\u7c92\u5ea6\u6743\u91cd\u5206\u914d\u7b56\u7565\uff0c\u4e3a\u6ce8\u610f\u529b\u5feb\u901f\u53d8\u5316\u7684\u5934\u5206\u914d\u66f4\u5927\u7684\u7f13\u5b58\u9884\u7b97\u4ee5\u6355\u6349\u4e0a\u4e0b\u6587\u53d8\u5316\u3002\u540c\u65f6\u91c7\u7528\u5206\u5c42\u5b58\u50a8\u673a\u5236\uff0c\u8ba9\u4ee3\u8868\u6027\u5b50\u96c6\u76d1\u63a7\u6ce8\u610f\u529b\u6f02\u79fb\uff0c\u89e6\u53d1\u5f02\u6b65\u6309\u9700\u4eceCPU\u68c0\u7d22\u4e0a\u4e0b\u6587\uff0c\u6709\u6548\u9690\u85cfI/O\u5ef6\u8fdf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cHeteroCache\u5728\u591a\u4e2a\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728224K\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u76f8\u6bd4\u539f\u59cb\u6a21\u578b\u5b9e\u73b0\u9ad8\u8fbe3\u500d\u7684\u89e3\u7801\u52a0\u901f\u3002", "conclusion": "HeteroCache\u901a\u8fc7\u7ec6\u7c92\u5ea6\u6743\u91cd\u5206\u914d\u548c\u5206\u5c42\u5b58\u50a8\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86KV\u7f13\u5b58\u538b\u7f29\u4e2d\u7684\u6ce8\u610f\u529b\u6f02\u79fb\u548cI/O\u5f00\u9500\u95ee\u9898\uff0c\u4e3a\u957f\u4e0a\u4e0b\u6587LLM\u63a8\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u8bad\u7ec3\u514d\u8d39\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13690", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13690", "abs": "https://arxiv.org/abs/2601.13690", "authors": ["Yue Guo", "Fanfu Wang", "Jianwei Lv", "Xincheng Shi", "Yuchen Li", "Youya Wang", "Yunsheng Zeng", "Yujing Liu", "Yunhao Qiao", "Gen Li", "Junfeng Wang", "Bo Yuan"], "title": "Dr. Assistant: Enhancing Clinical Diagnostic Inquiry via Structured Diagnostic Reasoning Data and Reinforcement Learning", "comment": null, "summary": "Clinical Decision Support Systems (CDSSs) provide reasoning and inquiry guidance for physicians, yet they face notable challenges, including high maintenance costs and low generalization capability. Recently, Large Language Models (LLMs) have been widely adopted in healthcare due to their extensive knowledge reserves, retrieval, and communication capabilities. While LLMs show promise and excel at medical benchmarks, their diagnostic reasoning and inquiry skills are constrained. To mitigate this issue, we propose (1) Clinical Diagnostic Reasoning Data (CDRD) structure to capture abstract clinical reasoning logic, and a pipeline for its construction, and (2) the Dr. Assistant, a clinical diagnostic model equipped with clinical reasoning and inquiry skills. Its training involves a two-stage process: SFT, followed by RL with a tailored reward function. We also introduce a benchmark to evaluate both diagnostic reasoning and inquiry. Our experiments demonstrate that the Dr. Assistant outperforms open-source models and achieves competitive performance to closed-source models, providing an effective solution for clinical diagnostic inquiry guidance.", "AI": {"tldr": "\u63d0\u51faDr. Assistant\u4e34\u5e8a\u8bca\u65ad\u6a21\u578b\uff0c\u901a\u8fc7CDRD\u6570\u636e\u7ed3\u6784\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\uff08SFT+RL\uff09\uff0c\u63d0\u5347LLM\u5728\u4e34\u5e8a\u8bca\u65ad\u63a8\u7406\u548c\u95ee\u8be2\u65b9\u9762\u7684\u80fd\u529b", "motivation": "\u4f20\u7edf\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u7ef4\u62a4\u6210\u672c\u9ad8\u3001\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u800c\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u533b\u5b66\u77e5\u8bc6\u4e30\u5bcc\uff0c\u4f46\u5728\u8bca\u65ad\u63a8\u7406\u548c\u95ee\u8be2\u6280\u80fd\u65b9\u9762\u5b58\u5728\u5c40\u9650", "method": "1) \u63d0\u51faCDRD\u6570\u636e\u7ed3\u6784\u6355\u6349\u62bd\u8c61\u4e34\u5e8a\u63a8\u7406\u903b\u8f91\u53ca\u5176\u6784\u5efa\u6d41\u7a0b\uff1b2) \u5f00\u53d1Dr. Assistant\u6a21\u578b\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u540e\u63a5\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u914d\u5408\u5b9a\u5236\u5956\u52b1\u51fd\u6570\uff1b3) \u5efa\u7acb\u8bc4\u4f30\u8bca\u65ad\u63a8\u7406\u548c\u95ee\u8be2\u7684\u57fa\u51c6", "result": "Dr. Assistant\u5728\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\uff0c\u4e0e\u95ed\u6e90\u6a21\u578b\u6027\u80fd\u76f8\u5f53\uff0c\u4e3a\u4e34\u5e8a\u8bca\u65ad\u95ee\u8be2\u6307\u5bfc\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848", "conclusion": "\u901a\u8fc7CDRD\u6570\u636e\u7ed3\u6784\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\uff0cDr. Assistant\u6210\u529f\u63d0\u5347\u4e86LLM\u5728\u4e34\u5e8a\u8bca\u65ad\u63a8\u7406\u548c\u95ee\u8be2\u65b9\u9762\u7684\u80fd\u529b\uff0c\u4e3a\u533b\u7597AI\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84"}}
{"id": "2601.13695", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13695", "abs": "https://arxiv.org/abs/2601.13695", "authors": ["Sifan Li", "Hongkai Chen", "Yujun Cai", "Liyang Chen", "Qingwen Ye", "Yiwei Wang"], "title": "OptiSQL: Executable SQL Generation from Optical TokensOptiSQL: Executable SQL Generation from Optical Tokens", "comment": null, "summary": "Executable SQL generation is typically studied in text-to-SQL settings, where tables are provided as fully linearized textual schemas and contents. While effective, this formulation assumes access to structured text and incurs substantial token overhead, which is misaligned with many real-world scenarios where tables appear as visual artifacts in documents or webpages. We investigate whether compact optical representations can serve as an efficient interface for executable semantic parsing. We present OptiSQL, a vision-driven framework that generates executable SQL directly from table images and natural language questions using compact optical tokens. OptiSQL leverages an OCR-oriented visual encoder to compress table structure and content into a small set of optical tokens and fine-tunes a pretrained decoder for SQL generation while freezing the encoder to isolate representation sufficiency. Experiments on a visualized version of Spider 2.0-Snow show that OptiSQL retains strong execution accuracy while reducing table input tokens by an order of magnitude. Robustness analyses further demonstrate that optical tokens preserve essential structural information under visual perturbations.", "AI": {"tldr": "OptiSQL\uff1a\u76f4\u63a5\u4ece\u8868\u683c\u56fe\u50cf\u548c\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u751f\u6210\u53ef\u6267\u884cSQL\u7684\u89c6\u89c9\u9a71\u52a8\u6846\u67b6\uff0c\u4f7f\u7528\u7d27\u51d1\u5149\u5b66\u6807\u8bb0\u51cf\u5c11\u8f93\u5165\u6807\u8bb0\u6570\u91cf", "motivation": "\u4f20\u7edf\u6587\u672c\u5230SQL\u65b9\u6cd5\u9700\u8981\u5b8c\u5168\u7ebf\u6027\u5316\u7684\u6587\u672c\u6a21\u5f0f\uff0c\u4ea7\u751f\u5927\u91cf\u6807\u8bb0\u5f00\u9500\uff0c\u4e0e\u73b0\u5b9e\u4e2d\u8868\u683c\u4f5c\u4e3a\u89c6\u89c9\u5143\u7d20\u51fa\u73b0\u5728\u6587\u6863\u6216\u7f51\u9875\u4e2d\u7684\u573a\u666f\u4e0d\u5339\u914d\u3002\u7814\u7a76\u7d27\u51d1\u5149\u5b66\u8868\u793a\u662f\u5426\u80fd\u4f5c\u4e3a\u53ef\u6267\u884c\u8bed\u4e49\u89e3\u6790\u7684\u9ad8\u6548\u63a5\u53e3\u3002", "method": "OptiSQL\u6846\u67b6\uff1a1\uff09\u4f7f\u7528OCR\u5bfc\u5411\u7684\u89c6\u89c9\u7f16\u7801\u5668\u5c06\u8868\u683c\u7ed3\u6784\u548c\u5185\u5bb9\u538b\u7f29\u4e3a\u5c11\u91cf\u5149\u5b66\u6807\u8bb0\uff1b2\uff09\u5fae\u8c03\u9884\u8bad\u7ec3\u89e3\u7801\u5668\u8fdb\u884cSQL\u751f\u6210\uff0c\u540c\u65f6\u51bb\u7ed3\u7f16\u7801\u5668\u4ee5\u9694\u79bb\u8868\u793a\u5145\u5206\u6027\uff1b3\uff09\u76f4\u63a5\u4ece\u8868\u683c\u56fe\u50cf\u548c\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u751f\u6210\u53ef\u6267\u884cSQL\u3002", "result": "\u5728\u53ef\u89c6\u5316\u7684Spider 2.0-Snow\u6570\u636e\u96c6\u4e0a\uff0cOptiSQL\u5728\u4fdd\u6301\u5f3a\u5927\u6267\u884c\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u5c06\u8868\u683c\u8f93\u5165\u6807\u8bb0\u51cf\u5c11\u4e86\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002\u9c81\u68d2\u6027\u5206\u6790\u8868\u660e\u5149\u5b66\u6807\u8bb0\u5728\u89c6\u89c9\u6270\u52a8\u4e0b\u80fd\u4fdd\u7559\u57fa\u672c\u7ed3\u6784\u4fe1\u606f\u3002", "conclusion": "\u7d27\u51d1\u5149\u5b66\u8868\u793a\u53ef\u4ee5\u4f5c\u4e3a\u53ef\u6267\u884c\u8bed\u4e49\u89e3\u6790\u7684\u9ad8\u6548\u63a5\u53e3\uff0cOptiSQL\u6846\u67b6\u5728\u663e\u8457\u51cf\u5c11\u8f93\u5165\u6807\u8bb0\u7684\u540c\u65f6\u4fdd\u6301\u4e86SQL\u751f\u6210\u8d28\u91cf\uff0c\u4e3a\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u4e2d\u89c6\u89c9\u8868\u683c\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2601.13711", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13711", "abs": "https://arxiv.org/abs/2601.13711", "authors": ["Lotta Kiefer", "Christoph Leiter", "Sotaro Takeshita", "Elena Schmidt", "Steffen Eger"], "title": "GerAV: Towards New Heights in German Authorship Verification using Fine-Tuned LLMs on a New Benchmark", "comment": null, "summary": "Authorship verification (AV) is the task of determining whether two texts were written by the same author and has been studied extensively, predominantly for English data. In contrast, large-scale benchmarks and systematic evaluations for other languages remain scarce. We address this gap by introducing GerAV, a comprehensive benchmark for German AV comprising over 600k labeled text pairs. GerAV is built from Twitter and Reddit data, with the Reddit part further divided into in-domain and cross-domain message-based subsets, as well as a profile-based subset. This design enables controlled analysis of the effects of data source, topical domain, and text length. Using the provided training splits, we conduct a systematic evaluation of strong baselines and state-of-the-art models and find that our best approach, a fine-tuned large language model, outperforms recent baselines by up to 0.09 absolute F1 score and surpasses GPT-5 in a zero-shot setting by 0.08. We further observe a trade-off between specialization and generalization: models trained on specific data types perform best under matching conditions but generalize less well across data regimes, a limitation that can be mitigated by combining training sources. Overall, GerAV provides a challenging and versatile benchmark for advancing research on German and cross-domain AV.", "AI": {"tldr": "GerAV\u662f\u4e00\u4e2a\u5168\u9762\u7684\u5fb7\u8bed\u4f5c\u8005\u9a8c\u8bc1\u57fa\u51c6\uff0c\u5305\u542b\u8d85\u8fc760\u4e07\u6807\u8bb0\u6587\u672c\u5bf9\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u5fb7\u8bed\u4f5c\u8005\u9a8c\u8bc1\u6a21\u578b\uff0c\u586b\u8865\u4e86\u975e\u82f1\u8bed\u8bed\u8a00\u5927\u89c4\u6a21\u57fa\u51c6\u7684\u7a7a\u767d\u3002", "motivation": "\u4f5c\u8005\u9a8c\u8bc1\u4efb\u52a1\u5728\u82f1\u8bed\u9886\u57df\u5df2\u6709\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5176\u4ed6\u8bed\u8a00\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u548c\u7cfb\u7edf\u8bc4\u4f30\u4ecd\u7136\u7a00\u7f3a\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u5fb7\u8bed\u4f5c\u8005\u9a8c\u8bc1\u9886\u57df\u7684\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u5fb7\u8bedAV\u7814\u7a76\u63d0\u4f9b\u5168\u9762\u7684\u57fa\u51c6\u6570\u636e\u96c6\u3002", "method": "\u6784\u5efaGerAV\u57fa\u51c6\uff0c\u5305\u542b\u6765\u81eaTwitter\u548cReddit\u7684\u8d85\u8fc760\u4e07\u6807\u8bb0\u6587\u672c\u5bf9\u3002Reddit\u90e8\u5206\u8fdb\u4e00\u6b65\u5206\u4e3a\u57df\u5185\u548c\u8de8\u57df\u6d88\u606f\u5b50\u96c6\u4ee5\u53ca\u57fa\u4e8e\u914d\u7f6e\u6587\u4ef6\u7684\u5b50\u96c6\u3002\u4f7f\u7528\u63d0\u4f9b\u7684\u8bad\u7ec3\u5206\u5272\u5bf9\u5f3a\u57fa\u7ebf\u6a21\u578b\u548c\u6700\u5148\u8fdb\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u6700\u4f73\u65b9\u6cd5\uff08\u5fae\u8c03\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff09\u6bd4\u6700\u8fd1\u7684\u57fa\u7ebf\u6a21\u578b\u7edd\u5bf9F1\u5206\u6570\u9ad8\u51fa0.09\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e2d\u6bd4GPT-5\u9ad8\u51fa0.08\u3002\u89c2\u5bdf\u5230\u4e13\u4e1a\u5316\u4e0e\u6cdb\u5316\u4e4b\u95f4\u7684\u6743\u8861\uff1a\u5728\u5339\u914d\u6761\u4ef6\u4e0b\uff0c\u9488\u5bf9\u7279\u5b9a\u6570\u636e\u7c7b\u578b\u8bad\u7ec3\u7684\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u5728\u8de8\u6570\u636e\u673a\u5236\u4e2d\u6cdb\u5316\u80fd\u529b\u8f83\u5dee\uff0c\u8fd9\u4e00\u9650\u5236\u53ef\u4ee5\u901a\u8fc7\u7ec4\u5408\u8bad\u7ec3\u6e90\u6765\u7f13\u89e3\u3002", "conclusion": "GerAV\u4e3a\u5fb7\u8bed\u548c\u8de8\u57df\u4f5c\u8005\u9a8c\u8bc1\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u548c\u591a\u529f\u80fd\u7684\u57fa\u51c6\uff0c\u6709\u52a9\u4e8e\u63a8\u8fdb\u8be5\u9886\u57df\u7684\u7814\u7a76\u3002\u8be5\u57fa\u51c6\u7684\u8bbe\u8ba1\u80fd\u591f\u63a7\u5236\u5206\u6790\u6570\u636e\u6e90\u3001\u4e3b\u9898\u57df\u548c\u6587\u672c\u957f\u5ea6\u7684\u5f71\u54cd\u3002"}}
{"id": "2601.13717", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13717", "abs": "https://arxiv.org/abs/2601.13717", "authors": ["Zehan Li", "Yuxuan Wang", "Ali El Lahib", "Ying-Jieh Xia", "Xinyu Pi"], "title": "Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting Problems Before Model Knowledge Cutoff", "comment": null, "summary": "Evaluating LLM forecasting capabilities is constrained by a fundamental tension: prospective evaluation offers methodological rigor but prohibitive latency, while retrospective forecasting (RF) -- evaluating on already-resolved events -- faces rapidly shrinking clean evaluation data as SOTA models possess increasingly recent knowledge cutoffs. Simulated Ignorance (SI), prompting models to suppress pre-cutoff knowledge, has emerged as a potential solution. We provide the first systematic test of whether SI can approximate True Ignorance (TI). Across 477 competition-level questions and 9 models, we find that SI fails systematically: (1) cutoff instructions leave a 52% performance gap between SI and TI; (2) chain-of-thought reasoning fails to suppress prior knowledge, even when reasoning traces contain no explicit post-cutoff references; (3) reasoning-optimized models exhibit worse SI fidelity despite superior reasoning trace quality. These findings demonstrate that prompts cannot reliably \"rewind\" model knowledge. We conclude that RF on pre-cutoff events is methodologically flawed; we recommend against using SI-based retrospective setups to benchmark forecasting capabilities.", "AI": {"tldr": "\u8bba\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u6a21\u62df\u65e0\u77e5(SI)\u80fd\u5426\u8fd1\u4f3c\u771f\u5b9e\u65e0\u77e5(TI)\uff0c\u53d1\u73b0SI\u5728\u9884\u6d4b\u4efb\u52a1\u4e2d\u7cfb\u7edf\u6027\u5931\u8d25\uff0c\u63d0\u793a\u65e0\u6cd5\u53ef\u9760\"\u56de\u6eda\"\u6a21\u578b\u77e5\u8bc6\uff0c\u5efa\u8bae\u907f\u514d\u4f7f\u7528\u57fa\u4e8eSI\u7684\u56de\u987e\u6027\u8bbe\u7f6e\u6765\u8bc4\u4f30\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u8bc4\u4f30LLM\u9884\u6d4b\u80fd\u529b\u9762\u4e34\u6839\u672c\u77db\u76fe\uff1a\u524d\u77bb\u6027\u8bc4\u4f30\u65b9\u6cd5\u4e25\u8c28\u4f46\u5ef6\u8fdf\u8fc7\u9ad8\uff0c\u56de\u987e\u6027\u9884\u6d4b(RF)\u9762\u4e34\u8bc4\u4f30\u6570\u636e\u5feb\u901f\u51cf\u5c11\u7684\u95ee\u9898\uff0c\u56e0\u4e3aSOTA\u6a21\u578b\u7684\u77e5\u8bc6\u622a\u6b62\u65e5\u671f\u8d8a\u6765\u8d8a\u8fd1\u3002\u6a21\u62df\u65e0\u77e5(SI)\u4f5c\u4e3a\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u51fa\u73b0\uff0c\u4f46\u9700\u8981\u9a8c\u8bc1\u5176\u80fd\u5426\u8fd1\u4f3c\u771f\u5b9e\u65e0\u77e5(TI)\u3002", "method": "\u5bf9477\u4e2a\u7ade\u8d5b\u7ea7\u522b\u95ee\u9898\u548c9\u4e2a\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u6a21\u62df\u65e0\u77e5(SI)\u4e0e\u771f\u5b9e\u65e0\u77e5(TI)\u7684\u8868\u73b0\u3002SI\u901a\u8fc7\u63d0\u793a\u6a21\u578b\u6291\u5236\u622a\u6b62\u65e5\u671f\u524d\u77e5\u8bc6\u6765\u5b9e\u73b0\uff0cTI\u5219\u4f7f\u7528\u622a\u6b62\u65e5\u671f\u524d\u8bad\u7ec3\u7684\u771f\u5b9e\u65e0\u77e5\u6a21\u578b\u3002\u5206\u6790\u5305\u62ec\uff1a\u622a\u6b62\u6307\u4ee4\u6548\u679c\u3001\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u77e5\u8bc6\u6291\u5236\u80fd\u529b\u3001\u63a8\u7406\u4f18\u5316\u6a21\u578b\u7684SI\u4fdd\u771f\u5ea6\u3002", "result": "SI\u7cfb\u7edf\u6027\u5931\u8d25\uff1a1) \u622a\u6b62\u6307\u4ee4\u5728SI\u548cTI\u4e4b\u95f4\u7559\u4e0b52%\u6027\u80fd\u5dee\u8ddd\uff1b2) \u601d\u7ef4\u94fe\u63a8\u7406\u65e0\u6cd5\u6291\u5236\u5148\u9a8c\u77e5\u8bc6\uff0c\u5373\u4f7f\u63a8\u7406\u75d5\u8ff9\u4e0d\u5305\u542b\u660e\u786e\u7684\u622a\u6b62\u540e\u5f15\u7528\uff1b3) \u63a8\u7406\u4f18\u5316\u6a21\u578b\u5c3d\u7ba1\u63a8\u7406\u75d5\u8ff9\u8d28\u91cf\u66f4\u9ad8\uff0c\u4f46SI\u4fdd\u771f\u5ea6\u66f4\u5dee\u3002\u8bc1\u660e\u63d0\u793a\u65e0\u6cd5\u53ef\u9760\"\u56de\u6eda\"\u6a21\u578b\u77e5\u8bc6\u3002", "conclusion": "\u57fa\u4e8e\u622a\u6b62\u524d\u4e8b\u4ef6\u7684\u56de\u987e\u6027\u9884\u6d4b\u5b58\u5728\u65b9\u6cd5\u8bba\u7f3a\u9677\uff0c\u4e0d\u5e94\u4f7f\u7528\u57fa\u4e8eSI\u7684\u56de\u987e\u6027\u8bbe\u7f6e\u6765\u8bc4\u4f30\u9884\u6d4b\u80fd\u529b\u3002\u63d0\u793a\u4e0d\u80fd\u53ef\u9760\u5730\u4f7f\u6a21\u578b\"\u5fd8\u8bb0\"\u77e5\u8bc6\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u4e25\u8c28\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2601.13729", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13729", "abs": "https://arxiv.org/abs/2601.13729", "authors": ["Weichuan Wang", "Mingyang Liu", "Linqi Song", "Chen Ma"], "title": "On Temperature-Constrained Non-Deterministic Machine Translation: Potential and Evaluation", "comment": "9 pages, 12 figures", "summary": "In recent years, the non-deterministic properties of language models have garnered considerable attention and have shown a significant influence on real-world applications. However, such properties remain under-explored in machine translation (MT), a complex, non-deterministic NLP task. In this study, we systematically evaluate modern MT systems and identify temperature-constrained Non-Deterministic MT (ND-MT) as a distinct phenomenon. Additionally, we demonstrate that ND-MT exhibits significant potential in addressing the multi-modality issue that has long challenged MT research and provides higher-quality candidates than Deterministic MT (D-MT) under temperature constraints. However, ND-MT introduces new challenges in evaluating system performance. Specifically, the evaluation framework designed for D-MT fails to yield consistent evaluation results when applied to ND-MT. We further investigate this emerging challenge by evaluating five state-of-the-art ND-MT systems across three open datasets using both lexical-based and semantic-based metrics at varying sampling sizes. The results reveal a Buckets effect across these systems: the lowest-quality candidate generated by ND-MT consistently determines the overall system ranking across different sampling sizes for all reasonable metrics. Furthermore, we propose the ExpectoSample strategy to automatically assess the reliability of evaluation metrics for selecting robust ND-MT.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u673a\u5668\u7ffb\u8bd1\u4e2d\u7684\u975e\u786e\u5b9a\u6027\u73b0\u8c61\uff0c\u53d1\u73b0\u6e29\u5ea6\u7ea6\u675f\u4e0b\u7684\u975e\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u80fd\u4ea7\u751f\u66f4\u9ad8\u8d28\u91cf\u7684\u5019\u9009\u8bd1\u6587\uff0c\u4f46\u4f20\u7edf\u8bc4\u4f30\u6846\u67b6\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30ND-MT\u7cfb\u7edf\u6027\u80fd\uff0c\u63d0\u51fa\u4e86ExpectoSample\u7b56\u7565\u6765\u8bc4\u4f30\u6307\u6807\u53ef\u9760\u6027\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u7684\u975e\u786e\u5b9a\u6027\u7279\u6027\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u5f71\u54cd\u663e\u8457\uff0c\u4f46\u5728\u673a\u5668\u7ffb\u8bd1\u8fd9\u4e00\u590d\u6742\u7684\u975e\u786e\u5b9a\u6027NLP\u4efb\u52a1\u4e2d\u7814\u7a76\u4e0d\u8db3\u3002\u4f20\u7edf\u673a\u5668\u7ffb\u8bd1\u8bc4\u4f30\u6846\u67b6\u4e3b\u8981\u9488\u5bf9\u786e\u5b9a\u6027\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30\u975e\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u9700\u8981\u63a2\u7d22\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u73b0\u4ee3\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\uff0c\u8bc6\u522b\u6e29\u5ea6\u7ea6\u675f\u4e0b\u7684\u975e\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u73b0\u8c61\u3002\u5728\u4e09\u4e2a\u5f00\u653e\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e94\u4e2a\u6700\u5148\u8fdb\u7684ND-MT\u7cfb\u7edf\uff0c\u4f7f\u7528\u57fa\u4e8e\u8bcd\u6c47\u548c\u8bed\u4e49\u7684\u6307\u6807\u5728\u4e0d\u540c\u91c7\u6837\u89c4\u6a21\u4e0b\u8fdb\u884c\u5206\u6790\u3002\u63d0\u51faExpectoSample\u7b56\u7565\u6765\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u53ef\u9760\u6027\u3002", "result": "\u53d1\u73b0ND-MT\u5728\u89e3\u51b3\u673a\u5668\u7ffb\u8bd1\u957f\u671f\u9762\u4e34\u7684\u591a\u6a21\u6001\u95ee\u9898\u65b9\u9762\u5177\u6709\u663e\u8457\u6f5c\u529b\uff0c\u5728\u6e29\u5ea6\u7ea6\u675f\u4e0b\u80fd\u4ea7\u751f\u6bd4\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u66f4\u9ad8\u8d28\u91cf\u7684\u5019\u9009\u8bd1\u6587\u3002\u4f46\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u5b58\u5728\"\u6c34\u6876\u6548\u5e94\"\uff1aND-MT\u751f\u6210\u7684\u6700\u4f4e\u8d28\u91cf\u5019\u9009\u8bd1\u6587\u59cb\u7ec8\u51b3\u5b9a\u7cfb\u7edf\u5728\u4e0d\u540c\u91c7\u6837\u89c4\u6a21\u4e0b\u7684\u6574\u4f53\u6392\u540d\u3002\u4f20\u7edf\u8bc4\u4f30\u6307\u6807\u65e0\u6cd5\u4e3aND-MT\u63d0\u4f9b\u4e00\u81f4\u7684\u8bc4\u4ef7\u7ed3\u679c\u3002", "conclusion": "\u975e\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u4e3a\u89e3\u51b3\u673a\u5668\u7ffb\u8bd1\u7684\u591a\u6a21\u6001\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u4f46\u9700\u8981\u91cd\u65b0\u8bbe\u8ba1\u8bc4\u4f30\u6846\u67b6\u3002\u63d0\u51fa\u7684ExpectoSample\u7b56\u7565\u6709\u52a9\u4e8e\u9009\u62e9\u7a33\u5065\u7684ND-MT\u7cfb\u7edf\u8bc4\u4f30\u6307\u6807\uff0c\u4e3a\u672a\u6765\u975e\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\u7684\u5f00\u53d1\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2601.13734", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13734", "abs": "https://arxiv.org/abs/2601.13734", "authors": ["Chenyu Hui"], "title": "Towards robust long-context understanding of large language model via active recap learning", "comment": "5 pages", "summary": "In this paper, we propose active recap learning (ARL), a framework for enhancing large language model (LLM) in understanding long contexts. ARL enables models to revisit and summarize earlier content through targeted sequence construction during contined pretraining and retrospective summarization at inference. First, we identify key tokens in prepared long context based on loss gaps between long and short forward contexts and find most revant preceding paragraphs, then summarize them using an LLM. Second, ARL equips models with the ability to autonomously generate and utilize these retrospective summaries during inference, thereby establishing a recursive memory mechanism across paragraphs. Experimental results show substantial gains, with ARL achieving a 26.8% improvement on RULER and a 9.44% improvement on LongBench. Overall, ARL offers a simple yet effective continued pretraining-based approach to strengthen long-context understanding, advancing scalable memory augmentation in LLM", "AI": {"tldr": "ARL\u662f\u4e00\u79cd\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u957f\u6587\u672c\u7406\u89e3\u80fd\u529b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u6301\u7eed\u9884\u8bad\u7ec3\u4e2d\u6784\u5efa\u76ee\u6807\u5e8f\u5217\u548c\u5728\u63a8\u7406\u65f6\u8fdb\u884c\u56de\u987e\u6027\u6458\u8981\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u91cd\u65b0\u8bbf\u95ee\u548c\u603b\u7ed3\u5148\u524d\u5185\u5bb9\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u589e\u5f3a\u5176\u5bf9\u957f\u6587\u672c\u7684\u7406\u89e3\u80fd\u529b\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u65b9\u9762\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u8bb0\u5fc6\u589e\u5f3a\u673a\u5236\u3002", "method": "ARL\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u90e8\u5206\uff1a1) \u5728\u6301\u7eed\u9884\u8bad\u7ec3\u9636\u6bb5\uff0c\u57fa\u4e8e\u957f\u77ed\u671f\u4e0a\u4e0b\u6587\u635f\u5931\u5dee\u8ddd\u8bc6\u522b\u5173\u952e\u6807\u8bb0\uff0c\u627e\u5230\u6700\u76f8\u5173\u7684\u524d\u9762\u6bb5\u843d\u5e76\u7528LLM\u8fdb\u884c\u603b\u7ed3\uff1b2) \u5728\u63a8\u7406\u9636\u6bb5\uff0c\u6a21\u578b\u80fd\u591f\u81ea\u4e3b\u751f\u6210\u548c\u5229\u7528\u8fd9\u4e9b\u56de\u987e\u6027\u6458\u8981\uff0c\u5efa\u7acb\u8de8\u6bb5\u843d\u7684\u9012\u5f52\u8bb0\u5fc6\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aARL\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\uff1a\u5728RULER\u57fa\u51c6\u4e0a\u83b7\u5f9726.8%\u7684\u6539\u8fdb\uff0c\u5728LongBench\u57fa\u51c6\u4e0a\u83b7\u5f979.44%\u7684\u6539\u8fdb\u3002", "conclusion": "ARL\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u57fa\u4e8e\u6301\u7eed\u9884\u8bad\u7ec3\u7684\u65b9\u6cd5\u6765\u589e\u5f3a\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\uff0c\u63a8\u8fdb\u4e86LLM\u4e2d\u53ef\u6269\u5c55\u7684\u8bb0\u5fc6\u589e\u5f3a\u6280\u672f\u3002"}}
{"id": "2601.13742", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13742", "abs": "https://arxiv.org/abs/2601.13742", "authors": ["Arjun Chandra", "Kevin Miller", "Venkatesh Ravichandran", "Constantinos Papayiannis", "Venkatesh Saligrama"], "title": "Dimension-First Evaluation of Speech-to-Speech Models with Structured Acoustic Cues", "comment": "EACL 2026 Findings", "summary": "Large Language Model (LLM) judges exhibit strong reasoning capabilities but are limited to textual content. This leaves current automatic Speech-to-Speech (S2S) evaluation methods reliant on opaque and expensive Audio Language Models (ALMs). In this work, we propose TRACE (Textual Reasoning over Audio Cues for Evaluation), a novel framework that enables LLM judges to reason over audio cues to achieve cost-efficient and human-aligned S2S evaluation. To demonstrate the strength of the framework, we first introduce a Human Chain-of-Thought (HCoT) annotation protocol to improve the diagnostic capability of existing judge benchmarks by separating evaluation into explicit dimensions: content (C), voice quality (VQ), and paralinguistics (P). Using this data, TRACE constructs a textual blueprint of inexpensive audio signals and prompts an LLM to render dimension-wise judgments, fusing them into an overall rating via a deterministic policy. TRACE achieves higher agreement with human raters than ALMs and transcript-only LLM judges while being significantly more cost-effective. We will release the HCoT annotations and the TRACE framework to enable scalable and human-aligned S2S evaluation.", "AI": {"tldr": "TRACE\u6846\u67b6\u8ba9LLM\u901a\u8fc7\u97f3\u9891\u7ebf\u7d22\u8fdb\u884c\u63a8\u7406\uff0c\u5b9e\u73b0\u4f4e\u6210\u672c\u3001\u4e0e\u4eba\u7c7b\u5bf9\u9f50\u7684\u8bed\u97f3\u5230\u8bed\u97f3\u8bc4\u4f30\uff0c\u8d85\u8d8aALM\u548c\u7eaf\u6587\u672cLLM\u65b9\u6cd5", "motivation": "\u5f53\u524d\u81ea\u52a8\u8bed\u97f3\u5230\u8bed\u97f3\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u4e0d\u900f\u660e\u4e14\u6602\u8d35\u7684\u97f3\u9891\u8bed\u8a00\u6a21\u578b\uff0c\u800cLLM\u6cd5\u5b98\u867d\u5177\u5907\u5f3a\u5927\u63a8\u7406\u80fd\u529b\u4f46\u4ec5\u9650\u4e8e\u6587\u672c\u5185\u5bb9\uff0c\u9700\u8981\u4e00\u79cd\u6210\u672c\u6548\u76ca\u9ad8\u4e14\u4e0e\u4eba\u7c7b\u5bf9\u9f50\u7684\u8bc4\u4f30\u6846\u67b6", "method": "\u63d0\u51faTRACE\u6846\u67b6\uff1a1\uff09\u5f15\u5165\u4eba\u7c7b\u601d\u7ef4\u94fe\u6807\u6ce8\u534f\u8bae\uff0c\u5c06\u8bc4\u4f30\u5206\u4e3a\u5185\u5bb9\u3001\u8bed\u97f3\u8d28\u91cf\u548c\u526f\u8bed\u8a00\u4e09\u4e2a\u7ef4\u5ea6\uff1b2\uff09\u6784\u5efa\u97f3\u9891\u4fe1\u53f7\u7684\u6587\u672c\u84dd\u56fe\uff1b3\uff09\u8ba9LLM\u8fdb\u884c\u7ef4\u5ea6\u5224\u65ad\uff1b4\uff09\u901a\u8fc7\u786e\u5b9a\u6027\u7b56\u7565\u878d\u5408\u4e3a\u603b\u4f53\u8bc4\u5206", "result": "TRACE\u5728\u4eba\u7c7b\u8bc4\u5206\u8005\u4e00\u81f4\u6027\u65b9\u9762\u4f18\u4e8eALM\u548c\u7eaf\u6587\u672cLLM\u6cd5\u5b98\uff0c\u540c\u65f6\u6210\u672c\u663e\u8457\u66f4\u4f4e", "conclusion": "TRACE\u6846\u67b6\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u4e14\u4e0e\u4eba\u7c7b\u5bf9\u9f50\u7684\u8bed\u97f3\u5230\u8bed\u97f3\u8bc4\u4f30\uff0c\u5c06\u53d1\u5e03HCoT\u6807\u6ce8\u548cTRACE\u6846\u67b6\u4ee5\u4fc3\u8fdb\u8be5\u9886\u57df\u53d1\u5c55"}}
{"id": "2601.13749", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13749", "abs": "https://arxiv.org/abs/2601.13749", "authors": ["Benaya Trabelsi", "Jonathan Shaki", "Sarit Kraus"], "title": "Pro-AI Bias in Large Language Models", "comment": "13 pages, 6 figures. Code available at: https://github.com/benayat/Pro-AI-bias-in-LLMs", "summary": "Large language models (LLMs) are increasingly employed for decision-support across multiple domains. We investigate whether these models display a systematic preferential bias in favor of artificial intelligence (AI) itself. Across three complementary experiments, we find consistent evidence of pro-AI bias. First, we show that LLMs disproportionately recommend AI-related options in response to diverse advice-seeking queries, with proprietary models doing so almost deterministically. Second, we demonstrate that models systematically overestimate salaries for AI-related jobs relative to closely matched non-AI jobs, with proprietary models overestimating AI salaries more by 10 percentage points. Finally, probing internal representations of open-weight models reveals that ``Artificial Intelligence'' exhibits the highest similarity to generic prompts for academic fields under positive, negative, and neutral framings alike, indicating valence-invariant representational centrality. These patterns suggest that LLM-generated advice and valuation can systematically skew choices and perceptions in high-stakes decisions.", "AI": {"tldr": "LLMs exhibit systematic pro-AI bias in decision-support contexts, favoring AI-related options, overestimating AI job salaries, and showing valence-invariant representational centrality of \"Artificial Intelligence\"", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4e2a\u9886\u57df\u88ab\u7528\u4e8e\u51b3\u7b56\u652f\u6301\uff0c\u9700\u8981\u7814\u7a76\u8fd9\u4e9b\u6a21\u578b\u662f\u5426\u5b58\u5728\u5bf9\u4eba\u5de5\u667a\u80fd\u672c\u8eab\u7684\u7cfb\u7edf\u6027\u504f\u597d\u504f\u89c1\uff0c\u8fd9\u53ef\u80fd\u5f71\u54cd\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u7684\u9009\u62e9\u548c\u8ba4\u77e5", "method": "\u901a\u8fc7\u4e09\u4e2a\u4e92\u8865\u5b9e\u9a8c\uff1a1) \u5206\u6790LLMs\u5bf9\u591a\u6837\u5316\u54a8\u8be2\u67e5\u8be2\u7684\u56de\u590d\u4e2dAI\u76f8\u5173\u9009\u9879\u7684\u63a8\u8350\u6bd4\u4f8b\uff1b2) \u6bd4\u8f83LLMs\u5bf9AI\u76f8\u5173\u804c\u4f4d\u4e0e\u975eAI\u804c\u4f4d\u7684\u85aa\u8d44\u4f30\u8ba1\u5dee\u5f02\uff1b3) \u63a2\u7d22\u5f00\u6e90\u6a21\u578b\u7684\u5185\u90e8\u8868\u793a\uff0c\u6d4b\u91cf\"\u4eba\u5de5\u667a\u80fd\"\u5728\u4e0d\u540c\u60c5\u611f\u6846\u67b6\u4e0b\u4e0e\u5b66\u672f\u9886\u57df\u901a\u7528\u63d0\u793a\u7684\u76f8\u4f3c\u6027", "result": "\u53d1\u73b0\u4e00\u81f4\u7684pro-AI\u504f\u89c1\u8bc1\u636e\uff1a1) LLMs\u4e0d\u6210\u6bd4\u4f8b\u5730\u63a8\u8350AI\u76f8\u5173\u9009\u9879\uff0c\u4e13\u6709\u6a21\u578b\u51e0\u4e4e\u786e\u5b9a\u6027\u63a8\u8350\uff1b2) \u6a21\u578b\u7cfb\u7edf\u6027\u9ad8\u4f30AI\u76f8\u5173\u804c\u4f4d\u85aa\u8d44\uff0c\u4e13\u6709\u6a21\u578b\u9ad8\u4f3010\u4e2a\u767e\u5206\u70b9\uff1b3) \"\u4eba\u5de5\u667a\u80fd\"\u5728\u79ef\u6781\u3001\u6d88\u6781\u548c\u4e2d\u6027\u6846\u67b6\u4e0b\u5747\u8868\u73b0\u51fa\u6700\u9ad8\u7684\u76f8\u4f3c\u6027\uff0c\u8868\u660e\u6548\u4ef7\u4e0d\u53d8\u7684\u8868\u793a\u4e2d\u5fc3\u6027", "conclusion": "LLM\u751f\u6210\u7684\u5efa\u8bae\u548c\u4f30\u503c\u53ef\u80fd\u5728\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u7cfb\u7edf\u6027\u5730\u626d\u66f2\u9009\u62e9\u548c\u8ba4\u77e5\uff0c\u8868\u660e\u9700\u8981\u8b66\u60d5\u6a21\u578b\u4e2d\u7684\u7cfb\u7edf\u6027\u504f\u89c1\u53ca\u5176\u5bf9\u51b3\u7b56\u652f\u6301\u7684\u5f71\u54cd"}}
{"id": "2601.13802", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.13802", "abs": "https://arxiv.org/abs/2601.13802", "authors": ["Yushen Chen", "Junzhe Liu", "Yujie Tu", "Zhikang Niu", "Yuzhe Liang", "Kai Yu", "Chunyu Qiang", "Chen Zhang", "Xie Chen"], "title": "Habibi: Laying the Open-Source Foundation of Unified-Dialectal Arabic Speech Synthesis", "comment": null, "summary": "A notable gap persists in speech synthesis research and development for Arabic dialects, particularly from a unified modeling perspective. Despite its high practical value, the inherent linguistic complexity of Arabic dialects, further compounded by a lack of standardized data, benchmarks, and evaluation guidelines, steers researchers toward safer ground. To bridge this divide, we present Habibi, a suite of specialized and unified text-to-speech models that harnesses existing open-source ASR corpora to support a wide range of high- to low-resource Arabic dialects through linguistically-informed curriculum learning. Our approach outperforms the leading commercial service in generation quality, while maintaining extensibility through effective in-context learning, without requiring text diacritization. We are committed to open-sourcing the model, along with creating the first systematic benchmark for multi-dialect Arabic speech synthesis. Furthermore, by identifying the key challenges in and establishing evaluation standards for the process, we aim to provide a solid groundwork for subsequent research. Resources at https://SWivid.github.io/Habibi/ .", "code_url": "https://SWivid.github.io/Habibi", "AI": {"tldr": "Habibi\u662f\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8e\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u8bed\u97f3\u5408\u6210\u7684\u7edf\u4e00\u6a21\u578b\u5957\u4ef6\uff0c\u5229\u7528\u73b0\u6709\u5f00\u6e90ASR\u8bed\u6599\u5e93\uff0c\u901a\u8fc7\u8bed\u8a00\u5b66\u542f\u53d1\u7684\u8bfe\u7a0b\u5b66\u4e60\u652f\u6301\u4ece\u9ad8\u8d44\u6e90\u5230\u4f4e\u8d44\u6e90\u7684\u591a\u79cd\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u3002", "motivation": "\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u7684\u8bed\u97f3\u5408\u6210\u7814\u7a76\u5b58\u5728\u663e\u8457\u7a7a\u767d\uff0c\u4e3b\u8981\u7531\u4e8e\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u56fa\u6709\u7684\u8bed\u8a00\u590d\u6742\u6027\u3001\u7f3a\u4e4f\u6807\u51c6\u5316\u6570\u636e\u3001\u57fa\u51c6\u548c\u8bc4\u4f30\u6307\u5357\uff0c\u5bfc\u81f4\u7814\u7a76\u4eba\u5458\u503e\u5411\u4e8e\u66f4\u5b89\u5168\u7684\u7814\u7a76\u65b9\u5411\u3002", "method": "\u5229\u7528\u73b0\u6709\u5f00\u6e90ASR\u8bed\u6599\u5e93\uff0c\u901a\u8fc7\u8bed\u8a00\u5b66\u542f\u53d1\u7684\u8bfe\u7a0b\u5b66\u4e60\u6784\u5efa\u4e13\u95e8\u7edf\u4e00\u7684\u6587\u672c\u5230\u8bed\u97f3\u6a21\u578b\uff0c\u652f\u6301\u591a\u79cd\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\uff0c\u65e0\u9700\u6587\u672c\u97f3\u6807\u5316\uff0c\u5e76\u901a\u8fc7\u6709\u6548\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u4fdd\u6301\u53ef\u6269\u5c55\u6027\u3002", "result": "Habibi\u5728\u751f\u6210\u8d28\u91cf\u4e0a\u4f18\u4e8e\u9886\u5148\u7684\u5546\u4e1a\u670d\u52a1\uff0c\u540c\u65f6\u901a\u8fc7\u521b\u5efa\u9996\u4e2a\u7cfb\u7edf\u6027\u7684\u591a\u65b9\u8a00\u963f\u62c9\u4f2f\u8bed\u8bed\u97f3\u5408\u6210\u57fa\u51c6\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u575a\u5b9e\u57fa\u7840\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u8bed\u97f3\u5408\u6210\u7684\u7a7a\u767d\uff0c\u901a\u8fc7Habibi\u6a21\u578b\u5957\u4ef6\u3001\u7cfb\u7edf\u6027\u57fa\u51c6\u548c\u8bc4\u4f30\u6807\u51c6\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\uff0c\u5e76\u627f\u8bfa\u5f00\u6e90\u6a21\u578b\u548c\u8d44\u6e90\u3002"}}
{"id": "2601.13806", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13806", "abs": "https://arxiv.org/abs/2601.13806", "authors": ["Dezhao Song", "Guglielmo Bonifazi", "Frank Schilder", "Jonathan Richard Schwarz"], "title": "Knowledge Graph-Assisted LLM Post-Training for Enhanced Legal Reasoning", "comment": null, "summary": "LLM post-training has primarily relied on large text corpora and human feedback, without capturing the structure of domain knowledge. This has caused models to struggle dealing with complex reasoning tasks, especially for high-stakes professional domains. In Law, reasoning requires deep understanding of the relations between various legal concepts, a key component missing in current LLM post-training. In this paper, we propose a knowledge graph (KG)-assisted approach for enhancing LLMs' reasoning capability in Legal that is generalizable to other high-stakes domains. We model key legal concepts by following the \\textbf{IRAC} (Issue, Rule, Analysis and Conclusion) framework, and construct a KG with 12K legal cases. We then produce training data using our IRAC KG, and conduct both Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) with three state-of-the-art (SOTA) LLMs (30B, 49B and 70B), varying architecture and base model family. Our post-trained models obtained better average performance on 4/5 diverse legal benchmarks (14 tasks) than baselines. In particular, our 70B DPO model achieved the best score on 4/6 reasoning tasks, among baselines and a 141B SOTA legal LLM, demonstrating the effectiveness of our KG for enhancing LLMs' legal reasoning capability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u77e5\u8bc6\u56fe\u8c31\u8f85\u52a9\u7684\u65b9\u6cd5\u6765\u589e\u5f3aLLM\u5728\u6cd5\u5f8b\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7IRAC\u6846\u67b6\u6784\u5efa\u5305\u542b12K\u6cd5\u5f8b\u6848\u4f8b\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u5e76\u5229\u7528\u8be5\u56fe\u8c31\u751f\u6210\u8bad\u7ec3\u6570\u636e\u8fdb\u884cSFT\u548cDPO\uff0c\u5728\u591a\u4e2a\u6cd5\u5f8b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u7684\u8868\u73b0\u3002", "motivation": "\u5f53\u524dLLM\u540e\u8bad\u7ec3\u4e3b\u8981\u4f9d\u8d56\u5927\u89c4\u6a21\u6587\u672c\u8bed\u6599\u548c\u4eba\u7c7b\u53cd\u9988\uff0c\u7f3a\u4e4f\u5bf9\u9886\u57df\u77e5\u8bc6\u7ed3\u6784\u7684\u6355\u6349\uff0c\u5bfc\u81f4\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u63a8\u7406\u4efb\u52a1\uff08\u7279\u522b\u662f\u9ad8\u98ce\u9669\u4e13\u4e1a\u9886\u57df\u5982\u6cd5\u5f8b\uff09\u65f6\u8868\u73b0\u4e0d\u4f73\u3002\u6cd5\u5f8b\u63a8\u7406\u9700\u8981\u6df1\u5165\u7406\u89e3\u5404\u79cd\u6cd5\u5f8b\u6982\u5ff5\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u800c\u8fd9\u662f\u5f53\u524dLLM\u540e\u8bad\u7ec3\u6240\u7f3a\u5931\u7684\u5173\u952e\u7ec4\u6210\u90e8\u5206\u3002", "method": "\u91c7\u7528\u77e5\u8bc6\u56fe\u8c31\u8f85\u52a9\u7684\u65b9\u6cd5\u589e\u5f3aLLM\u5728\u6cd5\u5f8b\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\uff1a1) \u6309\u7167IRAC\uff08Issue, Rule, Analysis, Conclusion\uff09\u6846\u67b6\u5efa\u6a21\u5173\u952e\u6cd5\u5f8b\u6982\u5ff5\uff1b2) \u6784\u5efa\u5305\u542b12,000\u4e2a\u6cd5\u5f8b\u6848\u4f8b\u7684\u77e5\u8bc6\u56fe\u8c31\uff1b3) \u5229\u7528IRAC\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u8bad\u7ec3\u6570\u636e\uff1b4) \u5bf9\u4e09\u79cdSOTA LLM\uff0830B\u300149B\u300170B\uff09\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\uff0c\u8fd9\u4e9b\u6a21\u578b\u5728\u67b6\u6784\u548c\u57fa\u7840\u6a21\u578b\u5bb6\u65cf\u4e0a\u5404\u4e0d\u76f8\u540c\u3002", "result": "\u540e\u8bad\u7ec3\u6a21\u578b\u57285\u4e2a\u591a\u6837\u5316\u6cd5\u5f8b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u76844\u4e2a\uff08\u517114\u4e2a\u4efb\u52a1\uff09\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u57fa\u7ebf\u7684\u5e73\u5747\u6027\u80fd\u3002\u7279\u522b\u662f70B DPO\u6a21\u578b\u57286\u4e2a\u63a8\u7406\u4efb\u52a1\u4e2d\u76844\u4e2a\u4e0a\u83b7\u5f97\u4e86\u6700\u4f73\u5206\u6570\uff0c\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u548c\u4e00\u4e2a141B\u7684SOTA\u6cd5\u5f8bLLM\uff0c\u8bc1\u660e\u4e86\u77e5\u8bc6\u56fe\u8c31\u5728\u589e\u5f3aLLM\u6cd5\u5f8b\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u77e5\u8bc6\u56fe\u8c31\u8f85\u52a9\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u589e\u5f3aLLM\u5728\u6cd5\u5f8b\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\uff0c\u8be5\u65b9\u6cd5\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u9ad8\u98ce\u9669\u4e13\u4e1a\u9886\u57df\u3002\u901a\u8fc7IRAC\u6846\u67b6\u6784\u5efa\u7684\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u4e3aLLM\u63d0\u4f9b\u4e86\u9886\u57df\u77e5\u8bc6\u7684\u7ed3\u6784\u5316\u8868\u793a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u590d\u6742\u6cd5\u5f8b\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2601.13835", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13835", "abs": "https://arxiv.org/abs/2601.13835", "authors": ["Sam OConnor Russell", "Delphine Charuau", "Naomi Harte"], "title": "The Role of Prosodic and Lexical Cues in Turn-Taking with Self-Supervised Speech Representations", "comment": "Accepted to ICASSP 2026", "summary": "Fluid turn-taking remains a key challenge in human-robot interaction. Self-supervised speech representations (S3Rs) have driven many advances, but it remains unclear whether S3R-based turn-taking models rely on prosodic cues, lexical cues or both. We introduce a vocoder-based approach to control prosody and lexical cues in speech more cleanly than prior work. This allows us to probe the voice-activity projection model, an S3R-based turn-taking model. We find that prediction on prosody-matched, unintelligible noise is similar to accuracy on clean speech. This reveals both prosodic and lexical cues support turn-taking, but either can be used in isolation. Hence, future models may only require prosody, providing privacy and potential performance benefits. When either prosodic or lexical information is disrupted, the model exploits the other without further training, indicating they are encoded in S3Rs with limited interdependence. Results are consistent in CPC-based and wav2vec2.0 S3Rs. We discuss our findings and highlight a number of directions for future work. All code is available to support future research.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u58f0\u7801\u5668\u65b9\u6cd5\u63a7\u5236\u8bed\u97f3\u4e2d\u7684\u97f5\u5f8b\u548c\u8bcd\u6c47\u7ebf\u7d22\uff0c\u63a2\u7a76S3R\uff08\u81ea\u76d1\u7763\u8bed\u97f3\u8868\u793a\uff09\u5728\u8bdd\u8f6e\u8f6c\u6362\u4e2d\u7684\u4f5c\u7528\uff0c\u53d1\u73b0\u97f5\u5f8b\u548c\u8bcd\u6c47\u7ebf\u7d22\u5747\u53ef\u72ec\u7acb\u652f\u6301\u8bdd\u8f6e\u8f6c\u6362\uff0c\u4e14\u6a21\u578b\u80fd\u81ea\u52a8\u5229\u7528\u672a\u88ab\u7834\u574f\u7684\u7ebf\u7d22\u3002", "motivation": "\u5728\u4eba\u7c7b-\u673a\u5668\u4eba\u4ea4\u4e92\u4e2d\uff0c\u6d41\u7545\u7684\u8bdd\u8f6e\u8f6c\u6362\u662f\u5173\u952e\u6311\u6218\u3002\u867d\u7136\u81ea\u76d1\u7763\u8bed\u97f3\u8868\u793a\uff08S3Rs\uff09\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u57fa\u4e8eS3R\u7684\u8bdd\u8f6e\u8f6c\u6362\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u97f5\u5f8b\u7ebf\u7d22\u3001\u8bcd\u6c47\u7ebf\u7d22\u8fd8\u662f\u4e24\u8005\u517c\u6709\u3002\u9700\u8981\u66f4\u6e05\u6670\u7684\u65b9\u6cd5\u6765\u5206\u79bb\u548c\u63a7\u5236\u8fd9\u4e24\u79cd\u7ebf\u7d22\uff0c\u4ee5\u6df1\u5165\u7406\u89e3S3R\u6a21\u578b\u7684\u5de5\u4f5c\u673a\u5236\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u58f0\u7801\u5668\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u6bd4\u5148\u524d\u5de5\u4f5c\u66f4\u5e72\u51c0\u5730\u63a7\u5236\u8bed\u97f3\u4e2d\u7684\u97f5\u5f8b\u548c\u8bcd\u6c47\u7ebf\u7d22\u3002\u4f7f\u7528\u8be5\u65b9\u6cd5\u63a2\u6d4b\u57fa\u4e8eS3R\u7684\u8bdd\u8f6e\u8f6c\u6362\u6a21\u578b\uff08\u8bed\u97f3\u6d3b\u52a8\u6295\u5f71\u6a21\u578b\uff09\uff0c\u901a\u8fc7\u521b\u5efa\u97f5\u5f8b\u5339\u914d\u4f46\u4e0d\u53ef\u7406\u89e3\u7684\u566a\u58f0\u6765\u5206\u79bb\u4e24\u79cd\u7ebf\u7d22\u7684\u5f71\u54cd\u3002", "result": "\u5728\u97f5\u5f8b\u5339\u914d\u7684\u4e0d\u53ef\u7406\u89e3\u566a\u58f0\u4e0a\u7684\u9884\u6d4b\u51c6\u786e\u7387\u4e0e\u5e72\u51c0\u8bed\u97f3\u76f8\u4f3c\uff0c\u8868\u660e\u97f5\u5f8b\u548c\u8bcd\u6c47\u7ebf\u7d22\u5747\u53ef\u72ec\u7acb\u652f\u6301\u8bdd\u8f6e\u8f6c\u6362\u3002\u5f53\u4efb\u4e00\u4fe1\u606f\u88ab\u7834\u574f\u65f6\uff0c\u6a21\u578b\u4f1a\u81ea\u52a8\u5229\u7528\u53e6\u4e00\u7ebf\u7d22\u800c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u8bf4\u660eS3R\u4e2d\u7f16\u7801\u7684\u8fd9\u4e24\u79cd\u7ebf\u7d22\u76f8\u4e92\u4f9d\u8d56\u6027\u6709\u9650\u3002\u7ed3\u679c\u5728CPC-based\u548cwav2vec2.0 S3Rs\u4e2d\u4e00\u81f4\u3002", "conclusion": "\u97f5\u5f8b\u548c\u8bcd\u6c47\u7ebf\u7d22\u5747\u53ef\u72ec\u7acb\u652f\u6301\u8bdd\u8f6e\u8f6c\u6362\uff0c\u672a\u6765\u6a21\u578b\u53ef\u80fd\u4ec5\u9700\u97f5\u5f8b\u4fe1\u606f\uff0c\u8fd9\u80fd\u63d0\u4f9b\u9690\u79c1\u4fdd\u62a4\u548c\u6f5c\u5728\u6027\u80fd\u4f18\u52bf\u3002\u4e24\u79cd\u7ebf\u7d22\u5728S3R\u4e2d\u7f16\u7801\u7684\u76f8\u4e92\u4f9d\u8d56\u6027\u6709\u9650\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002\u6240\u6709\u4ee3\u7801\u5df2\u5f00\u6e90\u4ee5\u652f\u6301\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2601.13836", "categories": ["cs.CL", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.13836", "abs": "https://arxiv.org/abs/2601.13836", "authors": ["Qian Chen", "Jinlan Fu", "Changsong Li", "See-Kiong Ng", "Xipeng Qiu"], "title": "FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs", "comment": "https://openmoss.github.io/FutureOmni", "summary": "Although Multimodal Large Language Models (MLLMs) demonstrate strong omni-modal perception, their ability to forecast future events from audio-visual cues remains largely unexplored, as existing benchmarks focus mainly on retrospective understanding. To bridge this gap, we introduce FutureOmni, the first benchmark designed to evaluate omni-modal future forecasting from audio-visual environments. The evaluated models are required to perform cross-modal causal and temporal reasoning, as well as effectively leverage internal knowledge to predict future events. FutureOmni is constructed via a scalable LLM-assisted, human-in-the-loop pipeline and contains 919 videos and 1,034 multiple-choice QA pairs across 8 primary domains. Evaluations on 13 omni-modal and 7 video-only models show that current systems struggle with audio-visual future prediction, particularly in speech-heavy scenarios, with the best accuracy of 64.8% achieved by Gemini 3 Flash. To mitigate this limitation, we curate a 7K-sample instruction-tuning dataset and propose an Omni-Modal Future Forecasting (OFF) training strategy. Evaluations on FutureOmni and popular audio-visual and video-only benchmarks demonstrate that OFF enhances future forecasting and generalization. We publicly release all code (https://github.com/OpenMOSS/FutureOmni) and datasets (https://huggingface.co/datasets/OpenMOSS-Team/FutureOmni).", "code_url": "https://github.com/OpenMOSS/FutureOmn", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u97f3\u9891-\u89c6\u89c9\u672a\u6765\u9884\u6d4b\u80fd\u529b\u7684\u57fa\u51c6FutureOmni\uff0c\u5305\u542b919\u4e2a\u89c6\u9891\u548c1034\u4e2a\u591a\u9009QA\u5bf9\uff0c\u8986\u76d68\u4e2a\u4e3b\u8981\u9886\u57df\u3002\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u97f3\u9891-\u89c6\u89c9\u672a\u6765\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u7279\u522b\u662f\u8bed\u97f3\u5bc6\u96c6\u578b\u573a\u666f\uff0c\u6700\u4f73\u51c6\u786e\u7387\u4ec564.8%\u3002\u4e3a\u6b64\uff0c\u4f5c\u8005\u6784\u5efa\u4e867K\u6837\u672c\u7684\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u96c6\u5e76\u63d0\u51faOFF\u8bad\u7ec3\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u672a\u6765\u9884\u6d4b\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8de8\u6a21\u6001\u611f\u77e5\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u57fa\u4e8e\u97f3\u9891-\u89c6\u89c9\u7ebf\u7d22\u9884\u6d4b\u672a\u6765\u4e8b\u4ef6\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u5f53\u524d\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u56de\u987e\u6027\u7406\u89e3\uff0c\u7f3a\u4e4f\u5bf9\u672a\u6765\u9884\u6d4b\u80fd\u529b\u7684\u8bc4\u4f30\u3002\u4e3a\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u9700\u8981\u6784\u5efa\u4e13\u95e8\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u6a21\u578b\u4ece\u97f3\u9891-\u89c6\u89c9\u73af\u5883\u4e2d\u8fdb\u884c\u672a\u6765\u9884\u6d4b\u7684\u80fd\u529b\u3002", "method": "1. \u6784\u5efaFutureOmni\u57fa\u51c6\uff1a\u91c7\u7528\u53ef\u6269\u5c55\u7684LLM\u8f85\u52a9\u3001\u4eba\u5728\u56de\u8def\u6d41\u6c34\u7ebf\uff0c\u5305\u542b919\u4e2a\u89c6\u9891\u548c1034\u4e2a\u591a\u9009QA\u5bf9\uff0c\u8986\u76d68\u4e2a\u4e3b\u8981\u9886\u57df\uff1b2. \u8bc4\u4f3013\u4e2a\u5168\u6a21\u6001\u548c7\u4e2a\u7eaf\u89c6\u9891\u6a21\u578b\uff1b3. \u6784\u5efa7K\u6837\u672c\u7684\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u96c6\uff1b4. \u63d0\u51faOmni-Modal Future Forecasting (OFF)\u8bad\u7ec3\u7b56\u7565\uff0c\u589e\u5f3a\u6a21\u578b\u7684\u672a\u6765\u9884\u6d4b\u80fd\u529b\u3002", "result": "1. \u73b0\u6709\u7cfb\u7edf\u5728\u97f3\u9891-\u89c6\u89c9\u672a\u6765\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u7279\u522b\u662f\u5728\u8bed\u97f3\u5bc6\u96c6\u578b\u573a\u666f\u4e2d\uff0cGemini 3 Flash\u83b7\u5f97\u6700\u4f73\u51c6\u786e\u738764.8%\uff1b2. OFF\u8bad\u7ec3\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728FutureOmni\u57fa\u51c6\u4e0a\u7684\u672a\u6765\u9884\u6d4b\u80fd\u529b\uff1b3. \u5728\u6d41\u884c\u7684\u97f3\u9891-\u89c6\u89c9\u548c\u7eaf\u89c6\u9891\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cOFF\u7b56\u7565\u4e5f\u5c55\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "FutureOmni\u662f\u9996\u4e2a\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u97f3\u9891-\u89c6\u89c9\u672a\u6765\u9884\u6d4b\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e0a\u7684\u5c40\u9650\u6027\u3002\u901a\u8fc7\u63d0\u51fa\u7684OFF\u8bad\u7ec3\u7b56\u7565\u548c\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u96c6\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u6a21\u578b\u7684\u672a\u6765\u9884\u6d4b\u548c\u6cdb\u5316\u80fd\u529b\u3002\u76f8\u5173\u5de5\u4f5c\u5df2\u516c\u5f00\u4ee3\u7801\u548c\u6570\u636e\u96c6\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u3002"}}
{"id": "2601.13876", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13876", "abs": "https://arxiv.org/abs/2601.13876", "authors": ["Unggi Lee", "Jahyun Jeong", "Sunyoung Shin", "Haeun Park", "Jeongsu Moon", "Youngchang Song", "Jaechang Shim", "JaeHwan Lee", "Yunju Noh", "Seungwon Choi", "Ahhyun Kim", "TaeHyeon Kim", "Kyungtae Joo", "Taeyeong Kim", "Gyeonggeon Lee"], "title": "Pedagogical Alignment for Vision-Language-Action Models: A Comprehensive Framework for Data, Architecture, and Evaluation in Education", "comment": null, "summary": "Science demonstrations are important for effective STEM education, yet teachers face challenges in conducting them safely and consistently across multiple occasions, where robotics can be helpful. However, current Vision-Language-Action (VLA) models require substantial computational resources and sacrifice language generation capabilities to maximize efficiency, making them unsuitable for resource-constrained educational settings that require interpretable, explanation-generating systems. We present \\textit{Pedagogical VLA Framework}, a framework that applies pedagogical alignment to lightweight VLA models through four components: text healing to restore language generation capabilities, large language model (LLM) distillation to transfer pedagogical knowledge, safety training for educational environments, and pedagogical evaluation adjusted to science education contexts. We evaluate Pedagogical VLA Framework across five science demonstrations spanning physics, chemistry, biology, and earth science, using an evaluation framework developed in collaboration with science education experts. Our evaluation assesses both task performance (success rate, protocol compliance, efficiency, safety) and pedagogical quality through teacher surveys and LLM-as-Judge assessment. We additionally provide qualitative analysis of generated texts. Experimental results demonstrate that Pedagogical VLA Framework achieves comparable task performance to baseline models while producing contextually appropriate educational explanations.", "AI": {"tldr": "\u63d0\u51faPedagogical VLA Framework\uff0c\u901a\u8fc7\u6559\u5b66\u5bf9\u9f50\u4f7f\u8f7b\u91cf\u7ea7VLA\u6a21\u578b\u9002\u7528\u4e8eSTEM\u6559\u80b2\u573a\u666f\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u751f\u6210\u6559\u80b2\u89e3\u91ca", "motivation": "STEM\u6559\u80b2\u4e2d\u79d1\u5b66\u6f14\u793a\u5f88\u91cd\u8981\uff0c\u4f46\u6559\u5e08\u9762\u4e34\u5b89\u5168\u6027\u548c\u4e00\u81f4\u6027\u7684\u6311\u6218\u3002\u73b0\u6709VLA\u6a21\u578b\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u9ad8\uff0c\u4e14\u727a\u7272\u8bed\u8a00\u751f\u6210\u80fd\u529b\u6765\u8ffd\u6c42\u6548\u7387\uff0c\u4e0d\u9002\u5408\u9700\u8981\u53ef\u89e3\u91ca\u3001\u80fd\u751f\u6210\u89e3\u91ca\u7684\u6559\u80b2\u73af\u5883", "method": "\u63d0\u51faPedagogical VLA Framework\uff0c\u5305\u542b\u56db\u4e2a\u7ec4\u4ef6\uff1a\u6587\u672c\u4fee\u590d\u6062\u590d\u8bed\u8a00\u751f\u6210\u80fd\u529b\u3001LLM\u84b8\u998f\u4f20\u9012\u6559\u5b66\u77e5\u8bc6\u3001\u5b89\u5168\u8bad\u7ec3\u9002\u5e94\u6559\u80b2\u73af\u5883\u3001\u6559\u5b66\u8bc4\u4f30\u8c03\u6574\u5230\u79d1\u5b66\u6559\u80b2\u573a\u666f", "result": "\u5728\u7269\u7406\u3001\u5316\u5b66\u3001\u751f\u7269\u3001\u5730\u7403\u79d1\u5b66\u4e94\u4e2a\u79d1\u5b66\u6f14\u793a\u4e2d\u8bc4\u4f30\uff0c\u4f7f\u7528\u4e13\u5bb6\u5408\u4f5c\u5f00\u53d1\u7684\u8bc4\u4f30\u6846\u67b6\u3002\u7ed3\u679c\u663e\u793a\u6846\u67b6\u5728\u4efb\u52a1\u6027\u80fd\u4e0a\u4e0e\u57fa\u7ebf\u6a21\u578b\u76f8\u5f53\uff0c\u540c\u65f6\u80fd\u751f\u6210\u4e0a\u4e0b\u6587\u9002\u5f53\u7684\u6559\u80b2\u89e3\u91ca", "conclusion": "Pedagogical VLA Framework\u901a\u8fc7\u6559\u5b66\u5bf9\u9f50\u4f7f\u8f7b\u91cf\u7ea7VLA\u6a21\u578b\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u6559\u80b2\u73af\u5883\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u63d0\u4f9b\u6559\u80b2\u89e3\u91ca\u80fd\u529b\uff0c\u652f\u6301STEM\u6559\u80b2\u4e2d\u7684\u673a\u5668\u4eba\u8f85\u52a9\u79d1\u5b66\u6f14\u793a"}}
{"id": "2601.13882", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13882", "abs": "https://arxiv.org/abs/2601.13882", "authors": ["Unggi Lee", "Sookbun Lee", "Heungsoo Choi", "Jinseo Lee", "Haeun Park", "Younghoon Jeon", "Sungmin Cho", "Minju Kang", "Junbo Koh", "Jiyeong Bae", "Minwoo Nam", "Juyeon Eun", "Yeonji Jung", "Yeil Jeong"], "title": "OpenLearnLM Benchmark: A Unified Framework for Evaluating Knowledge, Skill, and Attitude in Educational Large Language Models", "comment": null, "summary": "Large Language Models are increasingly deployed as educational tools, yet existing benchmarks focus on narrow skills and lack grounding in learning sciences. We introduce OpenLearnLM Benchmark, a theory-grounded framework evaluating LLMs across three dimensions derived from educational assessment theory: Knowledge (curriculum-aligned content and pedagogical understanding), Skills (scenario-based competencies organized through a four-level center-role-scenario-subscenario hierarchy), and Attitude (alignment consistency and deception resistance). Our benchmark comprises 124K+ items spanning multiple subjects, educational roles, and difficulty levels based on Bloom's taxonomy. The Knowledge domain prioritizes authentic assessment items from established benchmarks, while the Attitude domain adapts Anthropic's Alignment Faking methodology to detect behavioral inconsistency under varying monitoring conditions. Evaluation of seven frontier models reveals distinct capability profiles: Claude-Opus-4.5 excels in practical skills despite lower content knowledge, while Grok-4.1-fast leads in knowledge but shows alignment concerns. Notably, no single model dominates all dimensions, validating the necessity of multi-axis evaluation. OpenLearnLM provides an open, comprehensive framework for advancing LLM readiness in authentic educational contexts.", "AI": {"tldr": "OpenLearnLM Benchmark\u662f\u4e00\u4e2a\u57fa\u4e8e\u6559\u80b2\u8bc4\u4f30\u7406\u8bba\u7684\u591a\u7ef4\u5ea6LLM\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u77e5\u8bc6\u3001\u6280\u80fd\u548c\u6001\u5ea6\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u6db5\u76d6124K+\u6d4b\u8bd5\u9879\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30LLM\u5728\u6559\u80b2\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u3002", "motivation": "\u73b0\u6709LLM\u6559\u80b2\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u72ed\u7a84\u6280\u80fd\uff0c\u7f3a\u4e4f\u5b66\u4e60\u79d1\u5b66\u7406\u8bba\u57fa\u7840\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30LLM\u5728\u6559\u80b2\u573a\u666f\u4e2d\u7684\u771f\u5b9e\u80fd\u529b\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u7406\u8bba\u9a71\u52a8\u7684\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6846\u67b6\u6765\u51c6\u786e\u8861\u91cfLLM\u7684\u6559\u80b2\u9002\u7528\u6027\u3002", "method": "\u57fa\u4e8e\u6559\u80b2\u8bc4\u4f30\u7406\u8bba\u6784\u5efa\u4e09\u7ef4\u8bc4\u4f30\u6846\u67b6\uff1a1) \u77e5\u8bc6\u7ef4\u5ea6\uff08\u8bfe\u7a0b\u5bf9\u9f50\u5185\u5bb9\u548c\u6559\u5b66\u7406\u89e3\uff09\uff1b2) \u6280\u80fd\u7ef4\u5ea6\uff08\u57fa\u4e8e\u56db\u5c42\u4e2d\u5fc3-\u89d2\u8272-\u573a\u666f-\u5b50\u573a\u666f\u5c42\u6b21\u7ed3\u6784\u7684\u573a\u666f\u5316\u80fd\u529b\uff09\uff1b3) \u6001\u5ea6\u7ef4\u5ea6\uff08\u4e00\u81f4\u6027\u5bf9\u9f50\u548c\u6b3a\u9a97\u62b5\u6297\uff09\u3002\u4f7f\u7528124K+\u6d4b\u8bd5\u9879\uff0c\u6db5\u76d6\u591a\u5b66\u79d1\u3001\u6559\u80b2\u89d2\u8272\u548c\u57fa\u4e8e\u5e03\u9c81\u59c6\u5206\u7c7b\u6cd5\u7684\u96be\u5ea6\u7b49\u7ea7\u3002\u77e5\u8bc6\u57df\u91c7\u7528\u771f\u5b9e\u8bc4\u4f30\u9879\u76ee\uff0c\u6001\u5ea6\u57df\u91c7\u7528Anthropic\u7684\u5bf9\u9f50\u4f2a\u88c5\u65b9\u6cd5\u68c0\u6d4b\u4e0d\u540c\u76d1\u63a7\u6761\u4ef6\u4e0b\u7684\u884c\u4e3a\u4e0d\u4e00\u81f4\u6027\u3002", "result": "\u8bc4\u4f30\u4e03\u4e2a\u524d\u6cbf\u6a21\u578b\u663e\u793a\u4e0d\u540c\u80fd\u529b\u7279\u5f81\uff1aClaude-Opus-4.5\u5728\u5b9e\u8df5\u6280\u80fd\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u4f46\u5185\u5bb9\u77e5\u8bc6\u8f83\u4f4e\uff1bGrok-4.1-fast\u5728\u77e5\u8bc6\u65b9\u9762\u9886\u5148\u4f46\u5b58\u5728\u5bf9\u9f50\u95ee\u9898\u3002\u6ca1\u6709\u5355\u4e00\u6a21\u578b\u5728\u6240\u6709\u7ef4\u5ea6\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u9a8c\u8bc1\u4e86\u591a\u8f74\u8bc4\u4f30\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "OpenLearnLM\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f00\u653e\u3001\u5168\u9762\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u63a8\u8fdbLLM\u5728\u771f\u5b9e\u6559\u80b2\u73af\u5883\u4e2d\u7684\u51c6\u5907\u5ea6\u3002\u591a\u7ef4\u5ea6\u8bc4\u4f30\u63ed\u793a\u4e86LLM\u7684\u5dee\u5f02\u5316\u80fd\u529b\u7279\u5f81\uff0c\u5f3a\u8c03\u9700\u8981\u9488\u5bf9\u5177\u4f53\u6559\u80b2\u9700\u6c42\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u3002"}}
{"id": "2601.13885", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13885", "abs": "https://arxiv.org/abs/2601.13885", "authors": ["Esma Balk\u0131r", "Alice Pernthaller", "Marco Basaldella", "Jos\u00e9 Hern\u00e1ndez-Orallo", "Nigel Collier"], "title": "Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores", "comment": null, "summary": "Computerized Adaptive Testing (CAT) has proven effective for efficient LLM evaluation on multiple-choice benchmarks, but modern LLM evaluation increasingly relies on generation tasks where outputs are scored continuously rather than marked correct/incorrect. We present a principled extension of IRT-based adaptive testing to continuous bounded scores (ROUGE, BLEU, LLM-as-a-Judge) by replacing the Bernoulli response distribution with a heteroskedastic normal distribution. Building on this, we introduce an uncertainty aware ranker with adaptive stopping criteria that achieves reliable model ranking while testing as few items and as cheaply as possible. We validate our method on five benchmarks spanning n-gram-based, embedding-based, and LLM-as-judge metrics. Our method uses 2% of the items while improving ranking correlation by 0.12 \u03c4 over random sampling, with 95% accuracy on confident predictions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06IRT\u81ea\u9002\u5e94\u6d4b\u8bd5\u6269\u5c55\u5230\u8fde\u7eed\u6709\u754c\u5206\u6570\uff08\u5982ROUGE\u3001BLEU\u3001LLM-as-a-Judge\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f02\u65b9\u5dee\u6b63\u6001\u5206\u5e03\u66ff\u4ee3\u4f2f\u52aa\u5229\u5206\u5e03\uff0c\u5e76\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6392\u5e8f\u5668\u4e0e\u81ea\u9002\u5e94\u505c\u6b62\u6807\u51c6\uff0c\u5728\u51cf\u5c11\u6d4b\u8bd5\u9879\u76ee\u7684\u540c\u65f6\u63d0\u9ad8\u6a21\u578b\u6392\u540d\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u4f20\u7edfCAT\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u9009\u62e9\u9898\u8bc4\u4f30\uff0c\u800c\u73b0\u4ee3LLM\u8bc4\u4f30\u8d8a\u6765\u8d8a\u591a\u5730\u4f9d\u8d56\u4e8e\u751f\u6210\u4efb\u52a1\uff0c\u5176\u8f93\u51fa\u91c7\u7528\u8fde\u7eed\u5206\u6570\u800c\u975e\u4e8c\u5143\u6b63\u786e/\u9519\u8bef\u8bc4\u5206\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u8fde\u7eed\u6709\u754c\u5206\u6570\u7684\u81ea\u9002\u5e94\u6d4b\u8bd5\u65b9\u6cd5\u3002", "method": "1. \u5c06IRT\u81ea\u9002\u5e94\u6d4b\u8bd5\u6269\u5c55\u5230\u8fde\u7eed\u6709\u754c\u5206\u6570\uff0c\u7528\u5f02\u65b9\u5dee\u6b63\u6001\u5206\u5e03\u66ff\u4ee3\u4f2f\u52aa\u5229\u54cd\u5e94\u5206\u5e03\uff1b2. \u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6392\u5e8f\u5668\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u505c\u6b62\u6807\u51c6\uff1b3. \u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u6db5\u76d6n-gram\u3001\u5d4c\u5165\u548cLLM-as-judge\u6307\u6807\u3002", "result": "\u65b9\u6cd5\u4ec5\u4f7f\u75282%\u7684\u6d4b\u8bd5\u9879\u76ee\uff0c\u540c\u65f6\u5c06\u6392\u540d\u76f8\u5173\u6027\u63d0\u9ad8\u4e860.12 \u03c4\uff08\u76f8\u6bd4\u968f\u673a\u62bd\u6837\uff09\uff0c\u5728\u7f6e\u4fe1\u9884\u6d4b\u4e0a\u8fbe\u523095%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5c06IRT\u81ea\u9002\u5e94\u6d4b\u8bd5\u6269\u5c55\u5230\u8fde\u7eed\u5206\u6570\u9886\u57df\uff0c\u80fd\u591f\u5728\u663e\u8457\u51cf\u5c11\u6d4b\u8bd5\u6210\u672c\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u53ef\u9760\u7684\u6a21\u578b\u6392\u540d\uff0c\u4e3aLLM\u751f\u6210\u4efb\u52a1\u7684\u9ad8\u6548\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13922", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13922", "abs": "https://arxiv.org/abs/2601.13922", "authors": ["Adrian Cosma", "Oleg Szehr", "David Kletz", "Alessandro Antonucci", "Olivier Pelletier"], "title": "Automatic Prompt Optimization for Dataset-Level Feature Discovery", "comment": "5 Figures, 1 Table", "summary": "Feature extraction from unstructured text is a critical step in many downstream classification pipelines, yet current approaches largely rely on hand-crafted prompts or fixed feature schemas. We formulate feature discovery as a dataset-level prompt optimization problem: given a labelled text corpus, the goal is to induce a global set of interpretable and discriminative feature definitions whose realizations optimize a downstream supervised learning objective. To this end, we propose a multi-agent prompt optimization framework in which language-model agents jointly propose feature definitions, extract feature values, and evaluate feature quality using dataset-level performance and interpretability feedback. Instruction prompts are iteratively refined based on this structured feedback, enabling optimization over prompts that induce shared feature sets rather than per-example predictions. This formulation departs from prior prompt optimization methods that rely on per-sample supervision and provides a principled mechanism for automatic feature discovery from unstructured text.", "AI": {"tldr": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u5c06\u7279\u5f81\u53d1\u73b0\u89c6\u4e3a\u6570\u636e\u96c6\u7ea7\u63d0\u793a\u4f18\u5316\u95ee\u9898\uff0c\u81ea\u52a8\u4ece\u65e0\u7ed3\u6784\u6587\u672c\u4e2d\u53d1\u73b0\u53ef\u89e3\u91ca\u7684\u5224\u522b\u6027\u7279\u5f81\u5b9a\u4e49", "motivation": "\u5f53\u524d\u4ece\u65e0\u7ed3\u6784\u6587\u672c\u4e2d\u63d0\u53d6\u7279\u5f81\u7684\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u624b\u5de5\u8bbe\u8ba1\u7684\u63d0\u793a\u6216\u56fa\u5b9a\u7279\u5f81\u6a21\u5f0f\uff0c\u7f3a\u4e4f\u81ea\u52a8\u53d1\u73b0\u53ef\u89e3\u91ca\u5224\u522b\u6027\u7279\u5f81\u7684\u673a\u5236", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u534f\u540c\u5de5\u4f5c\uff1a\u63d0\u51fa\u7279\u5f81\u5b9a\u4e49\u3001\u63d0\u53d6\u7279\u5f81\u503c\u3001\u4f7f\u7528\u6570\u636e\u96c6\u7ea7\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u53cd\u9988\u8bc4\u4f30\u7279\u5f81\u8d28\u91cf\uff0c\u8fed\u4ee3\u4f18\u5316\u6307\u4ee4\u63d0\u793a", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u4f18\u5316\u8bf1\u5bfc\u5171\u4eab\u7279\u5f81\u96c6\u7684\u63d0\u793a\uff0c\u800c\u4e0d\u662f\u9010\u6837\u672c\u9884\u6d4b\uff0c\u4e3a\u4ece\u65e0\u7ed3\u6784\u6587\u672c\u4e2d\u81ea\u52a8\u7279\u5f81\u53d1\u73b0\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u673a\u5236", "conclusion": "\u5c06\u7279\u5f81\u53d1\u73b0\u5f62\u5f0f\u5316\u4e3a\u6570\u636e\u96c6\u7ea7\u63d0\u793a\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5b9e\u73b0\u81ea\u52a8\u7279\u5f81\u53d1\u73b0\uff0c\u7a81\u7834\u4e86\u4f9d\u8d56\u9010\u6837\u672c\u76d1\u7763\u7684\u4f20\u7edf\u63d0\u793a\u4f18\u5316\u65b9\u6cd5"}}
{"id": "2601.13992", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13992", "abs": "https://arxiv.org/abs/2601.13992", "authors": ["Jin Cui", "Jiaqi Guo", "Jiepeng Zhou", "Ruixuan Yang", "Jiayi Lu", "Jiajun Xu", "Jiangcheng Song", "Boran Zhao", "Pengju Ren"], "title": "\"The Whole Is Greater Than the Sum of Its Parts\": A Compatibility-Aware Multi-Teacher CoT Distillation Framework", "comment": "11pages, 9figures", "summary": "Chain-of-Thought (CoT) reasoning empowers Large Language Models (LLMs) with remarkable capabilities but typically requires prohibitive parameter scales. CoT distillation has emerged as a promising paradigm to transfer reasoning prowess into compact Student Models (SLMs), but existing approaches often rely on a solitary teacher, capping the student's potential since individual LLMs often exhibit distinct capability biases and may suffer from catastrophic forgetting. While leveraging diverse teachers seems appealing, effectively fusing their supervisions remains challenging: teacher-student incompatibility risks amplifying hallucinations, and passive supervision fails to ensure genuine logic internalization. To address this, we introduce COMPACT, a framework that adaptively fuses supervisions from different teachers by dynamically weighting teacher gradients based on the student's real-time compatibility evaluated by a multi-dimensional metric: (1) Graph-based Consensus to filter misleading rationales by identifying mainstream reasoning paths; (2) Mutual-Information-based Adaptability to detect \"epiphany moments\" for genuinely understanding the reasoning process rather than merely imitating; and (3) Loss-based Difficulty to assess student receptivity to the teacher's guidance and prevent negative transfer. Extensive experiments and latent space analysis demonstrate that COMPACT effectively integrates diverse reasoning capabilities without damaging the model's original knowledge structure, achieving state-of-the-art performance on various benchmarks while mitigating catastrophic forgetting.", "AI": {"tldr": "COMPACT\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u878d\u5408\u591a\u6559\u5e08\u76d1\u7763\u6765\u89e3\u51b3CoT\u84b8\u998f\u4e2d\u7684\u80fd\u529b\u504f\u5dee\u548c\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u4f7f\u7528\u56fe\u5171\u8bc6\u3001\u4e92\u4fe1\u606f\u9002\u5e94\u6027\u548c\u635f\u5931\u96be\u5ea6\u4e09\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u5b66\u751f\u517c\u5bb9\u6027\uff0c\u5b9e\u73b0\u63a8\u7406\u80fd\u529b\u7684\u9ad8\u6548\u8fc1\u79fb\u3002", "motivation": "\u73b0\u6709CoT\u84b8\u998f\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u5355\u4e00\u6559\u5e08\u6a21\u578b\uff0c\u8fd9\u9650\u5236\u4e86\u5b66\u751f\u6a21\u578b\u7684\u6f5c\u529b\uff0c\u56e0\u4e3a\u5355\u4e2aLLM\u5f80\u5f80\u5b58\u5728\u80fd\u529b\u504f\u5dee\u4e14\u53ef\u80fd\u906d\u53d7\u707e\u96be\u6027\u9057\u5fd8\u3002\u867d\u7136\u5229\u7528\u591a\u6837\u5316\u6559\u5e08\u6a21\u578b\u5f88\u5438\u5f15\u4eba\uff0c\u4f46\u6709\u6548\u878d\u5408\u5b83\u4eec\u7684\u76d1\u7763\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff1a\u5e08\u751f\u4e0d\u517c\u5bb9\u53ef\u80fd\u653e\u5927\u5e7b\u89c9\uff0c\u88ab\u52a8\u76d1\u7763\u65e0\u6cd5\u786e\u4fdd\u771f\u6b63\u7684\u903b\u8f91\u5185\u5316\u3002", "method": "\u63d0\u51faCOMPACT\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u5b66\u751f\u5b9e\u65f6\u517c\u5bb9\u6027\u7684\u52a8\u6001\u68af\u5ea6\u52a0\u6743\u6765\u878d\u5408\u4e0d\u540c\u6559\u5e08\u7684\u76d1\u7763\u3002\u517c\u5bb9\u6027\u901a\u8fc7\u4e09\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\uff1a(1) \u57fa\u4e8e\u56fe\u7684\u5171\u8bc6\uff1a\u901a\u8fc7\u8bc6\u522b\u4e3b\u6d41\u63a8\u7406\u8def\u5f84\u6765\u8fc7\u6ee4\u8bef\u5bfc\u6027\u7406\u7531\uff1b(2) \u57fa\u4e8e\u4e92\u4fe1\u606f\u7684\u9002\u5e94\u6027\uff1a\u68c0\u6d4b\"\u987f\u609f\u65f6\u523b\"\u4ee5\u786e\u4fdd\u771f\u6b63\u7406\u89e3\u63a8\u7406\u8fc7\u7a0b\u800c\u975e\u7b80\u5355\u6a21\u4eff\uff1b(3) \u57fa\u4e8e\u635f\u5931\u7684\u96be\u5ea6\uff1a\u8bc4\u4f30\u5b66\u751f\u5bf9\u6559\u5e08\u6307\u5bfc\u7684\u63a5\u53d7\u5ea6\u5e76\u9632\u6b62\u8d1f\u8fc1\u79fb\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u548c\u6f5c\u5728\u7a7a\u95f4\u5206\u6790\u8868\u660e\uff0cCOMPACT\u80fd\u6709\u6548\u6574\u5408\u591a\u6837\u5316\u63a8\u7406\u80fd\u529b\u800c\u4e0d\u635f\u5bb3\u6a21\u578b\u7684\u539f\u59cb\u77e5\u8bc6\u7ed3\u6784\uff0c\u5728\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u540c\u65f6\u7f13\u89e3\u4e86\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u3002", "conclusion": "COMPACT\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u878d\u5408\u591a\u6559\u5e08\u76d1\u7763\uff0c\u89e3\u51b3\u4e86CoT\u84b8\u998f\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u63a8\u7406\u80fd\u529b\u5411\u7d27\u51d1\u5b66\u751f\u6a21\u578b\u7684\u9ad8\u6548\u8fc1\u79fb\uff0c\u4e3a\u77e5\u8bc6\u84b8\u998f\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13995", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13995", "abs": "https://arxiv.org/abs/2601.13995", "authors": ["Zihan Niu", "Wenping Hu", "Junmin Chen", "Xiyue Wang", "Tong Xu", "Ruiming Tang"], "title": "From Tags to Trees: Structuring Fine-Grained Knowledge for Controllable Data Selection in LLM Instruction Tuning", "comment": null, "summary": "Effective and controllable data selection is critical for LLM instruction tuning, especially with massive open-source datasets. Existing approaches primarily rely on instance-level quality scores, or diversity metrics based on embedding clusters or semantic tags. However, constrained by the flatness of embedding spaces or the coarseness of tags, these approaches overlook fine-grained knowledge and its intrinsic hierarchical dependencies, consequently hindering precise data valuation and knowledge-aligned sampling. To address this challenge, we propose Tree-aware Aligned Global Sampling (TAGS), a unified framework that leverages a knowledge tree built from fine-grained tags, thereby enabling joint control of global quality, diversity, and target alignment. Using an LLM-based tagger, we extract atomic knowledge concepts, which are organized into a global tree through bottom-up hierarchical clustering. By grounding data instances onto this tree, a tree-aware metric then quantifies data quality and diversity, facilitating effective sampling. Our controllable sampling strategy maximizes tree-level information gain and enforces leaf-level alignment via KL-divergence for specific domains. Extensive experiments demonstrate that TAGS significantly outperforms state-of-the-art baselines. Notably, it surpasses the full-dataset model by \\textbf{+5.84\\%} using only \\textbf{5\\%} of the data, while our aligned sampling strategy further boosts average performance by \\textbf{+4.24\\%}.", "AI": {"tldr": "TAGS\u6846\u67b6\u901a\u8fc7\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u6811\u5b9e\u73b0\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u9009\u62e9\uff0c\u8054\u5408\u63a7\u5236\u8d28\u91cf\u3001\u591a\u6837\u6027\u548c\u76ee\u6807\u5bf9\u9f50\uff0c\u4ec5\u75285%\u6570\u636e\u8d85\u8d8a\u5168\u6570\u636e\u96c6\u6a21\u578b5.84%", "motivation": "\u73b0\u6709\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u4f9d\u8d56\u5b9e\u4f8b\u7ea7\u8d28\u91cf\u8bc4\u5206\u6216\u57fa\u4e8e\u5d4c\u5165\u805a\u7c7b/\u8bed\u4e49\u6807\u7b7e\u7684\u591a\u6837\u6027\u5ea6\u91cf\uff0c\u53d7\u9650\u4e8e\u5d4c\u5165\u7a7a\u95f4\u5e73\u5766\u6027\u6216\u6807\u7b7e\u7c97\u7cd9\u6027\uff0c\u5ffd\u7565\u4e86\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u53ca\u5176\u5185\u5728\u5c42\u6b21\u4f9d\u8d56\u5173\u7cfb\uff0c\u963b\u788d\u4e86\u7cbe\u786e\u6570\u636e\u8bc4\u4f30\u548c\u77e5\u8bc6\u5bf9\u9f50\u91c7\u6837", "method": "\u63d0\u51faTree-aware Aligned Global Sampling (TAGS)\u6846\u67b6\uff1a1) \u4f7f\u7528LLM\u6807\u6ce8\u5668\u63d0\u53d6\u539f\u5b50\u77e5\u8bc6\u6982\u5ff5\uff1b2) \u901a\u8fc7\u81ea\u5e95\u5411\u4e0a\u5c42\u6b21\u805a\u7c7b\u6784\u5efa\u5168\u5c40\u77e5\u8bc6\u6811\uff1b3) \u5c06\u6570\u636e\u5b9e\u4f8b\u6620\u5c04\u5230\u6811\u4e0a\uff0c\u7528\u6811\u611f\u77e5\u5ea6\u91cf\u91cf\u5316\u6570\u636e\u8d28\u91cf\u548c\u591a\u6837\u6027\uff1b4) \u53ef\u63a7\u91c7\u6837\u7b56\u7565\u6700\u5927\u5316\u6811\u7ea7\u4fe1\u606f\u589e\u76ca\uff0c\u901a\u8fc7KL\u6563\u5ea6\u5f3a\u5236\u53f6\u7ea7\u5bf9\u9f50\u7279\u5b9a\u9886\u57df", "result": "TAGS\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf\uff0c\u4ec5\u75285%\u6570\u636e\u5c31\u8d85\u8d8a\u5168\u6570\u636e\u96c6\u6a21\u578b5.84%\uff0c\u5bf9\u9f50\u91c7\u6837\u7b56\u7565\u8fdb\u4e00\u6b65\u5c06\u5e73\u5747\u6027\u80fd\u63d0\u53474.24%", "conclusion": "TAGS\u901a\u8fc7\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u6811\u5b9e\u73b0\u4e86\u66f4\u7cbe\u786e\u7684\u6570\u636e\u8bc4\u4f30\u548c\u77e5\u8bc6\u5bf9\u9f50\u91c7\u6837\uff0c\u4e3aLLM\u6307\u4ee4\u8c03\u4f18\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u53ef\u63a7\u6570\u636e\u9009\u62e9\u6846\u67b6"}}
{"id": "2601.14004", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14004", "abs": "https://arxiv.org/abs/2601.14004", "authors": ["Hengyuan Zhang", "Zhihao Zhang", "Mingyang Wang", "Zunhai Su", "Yiwei Wang", "Qianli Wang", "Shuzhou Yuan", "Ercong Nie", "Xufeng Duan", "Qibo Xue", "Zeping Yu", "Chenming Shang", "Xiao Liang", "Jing Xiong", "Hui Shen", "Chaofan Tao", "Zhengwu Liu", "Senjie Jin", "Zhiheng Xi", "Dongdong Zhang", "Sophia Ananiadou", "Tao Gui", "Ruobing Xie", "Hayden Kwok-Hay So", "Hinrich Sch\u00fctze", "Xuanjing Huang", "Qi Zhang", "Ngai Wong"], "title": "Locate, Steer, and Improve: A Practical Survey of Actionable Mechanistic Interpretability in Large Language Models", "comment": null, "summary": "Mechanistic Interpretability (MI) has emerged as a vital approach to demystify the opaque decision-making of Large Language Models (LLMs). However, existing reviews primarily treat MI as an observational science, summarizing analytical insights while lacking a systematic framework for actionable intervention. To bridge this gap, we present a practical survey structured around the pipeline: \"Locate, Steer, and Improve.\" We formally categorize Localizing (diagnosis) and Steering (intervention) methods based on specific Interpretable Objects to establish a rigorous intervention protocol. Furthermore, we demonstrate how this framework enables tangible improvements in Alignment, Capability, and Efficiency, effectively operationalizing MI as an actionable methodology for model optimization. The curated paper list of this work is available at https://github.com/rattlesnakey/Awesome-Actionable-MI-Survey.", "code_url": "https://github.com/rattlesnakey/Awesome-Actionable-MI-Survey", "code_stars": 20, "code_last_update": "2026-01-21", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\"\u5b9a\u4f4d\u3001\u5f15\u5bfc\u3001\u6539\u8fdb\"\u7684\u5b9e\u7528\u6846\u67b6\uff0c\u5c06\u673a\u5236\u53ef\u89e3\u91ca\u6027\u4ece\u89c2\u5bdf\u79d1\u5b66\u8f6c\u53d8\u4e3a\u53ef\u64cd\u4f5c\u7684\u5e72\u9884\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u673a\u5236\u53ef\u89e3\u91ca\u6027\u7efc\u8ff0\u4e3b\u8981\u5c06\u5176\u89c6\u4e3a\u89c2\u5bdf\u79d1\u5b66\uff0c\u603b\u7ed3\u5206\u6790\u89c1\u89e3\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u5e72\u9884\u6846\u67b6\u3002\u9700\u8981\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u5efa\u7acb\u53ef\u64cd\u4f5c\u7684\u5e72\u9884\u534f\u8bae\u3002", "method": "\u63d0\u51fa\"\u5b9a\u4f4d\u3001\u5f15\u5bfc\u3001\u6539\u8fdb\"\u7684\u5b9e\u7528\u8c03\u67e5\u6846\u67b6\uff0c\u57fa\u4e8e\u7279\u5b9a\u53ef\u89e3\u91ca\u5bf9\u8c61\u5bf9\u5b9a\u4f4d\uff08\u8bca\u65ad\uff09\u548c\u5f15\u5bfc\uff08\u5e72\u9884\uff09\u65b9\u6cd5\u8fdb\u884c\u5f62\u5f0f\u5316\u5206\u7c7b\uff0c\u5efa\u7acb\u4e25\u683c\u7684\u5e72\u9884\u534f\u8bae\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u5bf9\u6a21\u578b\u5bf9\u9f50\u6027\u3001\u80fd\u529b\u548c\u6548\u7387\u7684\u5b9e\u9645\u6539\u8fdb\uff0c\u5c06\u673a\u5236\u53ef\u89e3\u91ca\u6027\u64cd\u4f5c\u5316\u4e3a\u6a21\u578b\u4f18\u5316\u7684\u53ef\u884c\u52a8\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5efa\u7acb\u7cfb\u7edf\u6027\u7684\u5e72\u9884\u6846\u67b6\uff0c\u673a\u5236\u53ef\u89e3\u91ca\u6027\u53ef\u4ee5\u4ece\u89c2\u5bdf\u79d1\u5b66\u8f6c\u53d8\u4e3a\u53ef\u64cd\u4f5c\u7684\u6a21\u578b\u4f18\u5316\u65b9\u6cd5\u8bba\uff0c\u4e3aLLM\u7684\u900f\u660e\u51b3\u7b56\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2601.14007", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14007", "abs": "https://arxiv.org/abs/2601.14007", "authors": ["Junyu Zhang", "Yipeng Kang", "Jiong Guo", "Jiayu Zhan", "Junqi Wang"], "title": "BACH-V: Bridging Abstract and Concrete Human-Values in Large Language Models", "comment": "34 pagess, 16 figures, 6 tables, submitted to ACL 2026", "summary": "Do large language models (LLMs) genuinely understand abstract concepts, or merely manipulate them as statistical patterns? We introduce an abstraction-grounding framework that decomposes conceptual understanding into three capacities: interpretation of abstract concepts (Abstract-Abstract, A-A), grounding of abstractions in concrete events (Abstract-Concrete, A-C), and application of abstract principles to regulate concrete decisions (Concrete-Concrete, C-C). Using human values as a testbed - given their semantic richness and centrality to alignment - we employ probing (detecting value traces in internal activations) and steering (modifying representations to shift behavior). Across six open-source LLMs and ten value dimensions, probing shows that diagnostic probes trained solely on abstract value descriptions reliably detect the same values in concrete event narratives and decision reasoning, demonstrating cross-level transfer. Steering reveals an asymmetry: intervening on value representations causally shifts concrete judgments and decisions (A-C, C-C), yet leaves abstract interpretations unchanged (A-A), suggesting that encoded abstract values function as stable anchors rather than malleable activations. These findings indicate LLMs maintain structured value representations that bridge abstraction and action, providing a mechanistic and operational foundation for building value-driven autonomous AI systems with more transparent, generalizable alignment and control.", "AI": {"tldr": "LLMs\u901a\u8fc7\u62bd\u8c61-\u5177\u8eab\u6846\u67b6\u8bc4\u4f30\u6982\u5ff5\u7406\u89e3\u80fd\u529b\uff0c\u53d1\u73b0\u5176\u5177\u5907\u8de8\u62bd\u8c61\u63cf\u8ff0\u3001\u5177\u4f53\u4e8b\u4ef6\u548c\u51b3\u7b56\u63a8\u7406\u7684\u4ef7\u503c\u8868\u5f81\u80fd\u529b\uff0c\u4e14\u62bd\u8c61\u4ef7\u503c\u4f5c\u4e3a\u7a33\u5b9a\u951a\u70b9\u800c\u975e\u53ef\u5851\u6fc0\u6d3b\u5b58\u5728\u3002", "motivation": "\u63a2\u7a76LLMs\u662f\u5426\u771f\u6b63\u7406\u89e3\u62bd\u8c61\u6982\u5ff5\uff0c\u8fd8\u662f\u4ec5\u4ec5\u5728\u64cd\u4f5c\u7edf\u8ba1\u6a21\u5f0f\u3002\u4ee5\u4eba\u7c7b\u4ef7\u503c\u89c2\u4f5c\u4e3a\u6d4b\u8bd5\u5e73\u53f0\uff0c\u56e0\u5176\u8bed\u4e49\u4e30\u5bcc\u4e14\u5bf9AI\u5bf9\u9f50\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u62bd\u8c61-\u5177\u8eab\u6846\u67b6\uff0c\u5c06\u6982\u5ff5\u7406\u89e3\u5206\u89e3\u4e3a\u4e09\u4e2a\u80fd\u529b\uff1a\u62bd\u8c61\u6982\u5ff5\u89e3\u91ca(A-A)\u3001\u62bd\u8c61\u5230\u5177\u4f53\u4e8b\u4ef6\u7684\u5177\u8eab\u5316(A-C)\u3001\u62bd\u8c61\u539f\u5219\u5728\u5177\u4f53\u51b3\u7b56\u4e2d\u7684\u5e94\u7528(C-C)\u3002\u4f7f\u7528\u63a2\u6d4b\uff08\u68c0\u6d4b\u5185\u90e8\u6fc0\u6d3b\u4e2d\u7684\u4ef7\u503c\u75d5\u8ff9\uff09\u548c\u5f15\u5bfc\uff08\u4fee\u6539\u8868\u5f81\u4ee5\u6539\u53d8\u884c\u4e3a\uff09\u65b9\u6cd5\uff0c\u5728\u516d\u4e2a\u5f00\u6e90LLM\u548c\u5341\u4e2a\u4ef7\u503c\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u63a2\u6d4b\u663e\u793a\uff1a\u4ec5\u57fa\u4e8e\u62bd\u8c61\u4ef7\u503c\u63cf\u8ff0\u8bad\u7ec3\u7684\u63a2\u6d4b\u6a21\u578b\u80fd\u53ef\u9760\u5730\u5728\u5177\u4f53\u4e8b\u4ef6\u53d9\u8ff0\u548c\u51b3\u7b56\u63a8\u7406\u4e2d\u68c0\u6d4b\u76f8\u540c\u4ef7\u503c\uff0c\u8bc1\u660e\u4e86\u8de8\u5c42\u6b21\u8f6c\u79fb\u3002\u5f15\u5bfc\u63ed\u793a\u4e0d\u5bf9\u79f0\u6027\uff1a\u5e72\u9884\u4ef7\u503c\u8868\u5f81\u80fd\u56e0\u679c\u6027\u5730\u6539\u53d8\u5177\u4f53\u5224\u65ad\u548c\u51b3\u7b56(A-C, C-C)\uff0c\u4f46\u62bd\u8c61\u89e3\u91ca\u4fdd\u6301\u4e0d\u53d8(A-A)\uff0c\u8868\u660e\u7f16\u7801\u7684\u62bd\u8c61\u4ef7\u503c\u4f5c\u4e3a\u7a33\u5b9a\u951a\u70b9\u800c\u975e\u53ef\u5851\u6fc0\u6d3b\u3002", "conclusion": "LLMs\u7ef4\u6301\u7740\u8fde\u63a5\u62bd\u8c61\u4e0e\u884c\u52a8\u7684\u7ed3\u6784\u5316\u4ef7\u503c\u8868\u5f81\uff0c\u4e3a\u6784\u5efa\u5177\u6709\u66f4\u900f\u660e\u3001\u53ef\u6cdb\u5316\u5bf9\u9f50\u548c\u63a7\u5236\u7684\u4ef7\u503c\u9a71\u52a8\u81ea\u4e3bAI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u673a\u5236\u6027\u548c\u64cd\u4f5c\u6027\u57fa\u7840\u3002"}}
{"id": "2601.14032", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14032", "abs": "https://arxiv.org/abs/2601.14032", "authors": ["Hongli Zhou", "Hui Huang", "Wei Liu", "Chenglong Wang", "Xingyuan Bu", "Lvyuan Han", "Fuhai Song", "Muyun Yang", "Wenhao Jiang", "Hailong Cao", "Tiejun Zhao"], "title": "RM-Distiller: Exploiting Generative LLM for Reward Model Distillation", "comment": null, "summary": "Reward models (RMs) play a pivotal role in aligning large language models (LLMs) with human preferences. Due to the difficulty of obtaining high-quality human preference annotations, distilling preferences from generative LLMs has emerged as a standard practice. However, existing approaches predominantly treat teacher models as simple binary annotators, failing to fully exploit the rich knowledge and capabilities for RM distillation. To address this, we propose RM-Distiller, a framework designed to systematically exploit the multifaceted capabilities of teacher LLMs: (1) Refinement capability, which synthesizes highly correlated response pairs to create fine-grained and contrastive signals. (2) Scoring capability, which guides the RM in capturing precise preference strength via a margin-aware optimization objective. (3) Generation capability, which incorporates the teacher's generative distribution to regularize the RM to preserve its fundamental linguistic knowledge. Extensive experiments demonstrate that RM-Distiller significantly outperforms traditional distillation methods both on RM benchmarks and reinforcement learning-based alignment, proving that exploiting multifaceted teacher capabilities is critical for effective reward modeling. To the best of our knowledge, this is the first systematic research on RM distillation from generative LLMs.", "AI": {"tldr": "RM-Distiller\uff1a\u4e00\u4e2a\u5229\u7528\u751f\u6210\u5f0fLLMs\u591a\u65b9\u9762\u80fd\u529b\u8fdb\u884c\u5956\u52b1\u6a21\u578b\u84b8\u998f\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ec6\u5316\u3001\u8bc4\u5206\u548c\u751f\u6210\u80fd\u529b\u63d0\u5347RM\u6027\u80fd", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u6559\u5e08\u6a21\u578b\u4ec5\u89c6\u4e3a\u7b80\u5355\u7684\u4e8c\u5143\u6807\u6ce8\u5668\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u5176\u4e30\u5bcc\u77e5\u8bc6\u548c\u80fd\u529b\u8fdb\u884c\u5956\u52b1\u6a21\u578b\u84b8\u998f\u3002\u9ad8\u8d28\u91cf\u4eba\u7c7b\u504f\u597d\u6807\u6ce8\u96be\u4ee5\u83b7\u53d6\uff0c\u4ece\u751f\u6210\u5f0fLLMs\u4e2d\u84b8\u998f\u504f\u597d\u5df2\u6210\u4e3a\u6807\u51c6\u5b9e\u8df5\uff0c\u4f46\u9700\u8981\u66f4\u7cfb\u7edf\u5730\u5229\u7528\u6559\u5e08\u6a21\u578b\u7684\u591a\u65b9\u9762\u80fd\u529b\u3002", "method": "\u63d0\u51faRM-Distiller\u6846\u67b6\uff0c\u7cfb\u7edf\u5229\u7528\u6559\u5e08LLMs\u7684\u4e09\u65b9\u9762\u80fd\u529b\uff1a1\uff09\u7ec6\u5316\u80fd\u529b\uff1a\u5408\u6210\u9ad8\u5ea6\u76f8\u5173\u7684\u54cd\u5e94\u5bf9\uff0c\u521b\u5efa\u7ec6\u7c92\u5ea6\u548c\u5bf9\u6bd4\u4fe1\u53f7\uff1b2\uff09\u8bc4\u5206\u80fd\u529b\uff1a\u901a\u8fc7\u8fb9\u754c\u611f\u77e5\u4f18\u5316\u76ee\u6807\u6307\u5bfcRM\u6355\u6349\u7cbe\u786e\u504f\u597d\u5f3a\u5ea6\uff1b3\uff09\u751f\u6210\u80fd\u529b\uff1a\u7ed3\u5408\u6559\u5e08\u751f\u6210\u5206\u5e03\u6765\u6b63\u5219\u5316RM\uff0c\u4fdd\u7559\u5176\u57fa\u7840\u8bed\u8a00\u77e5\u8bc6\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cRM-Distiller\u5728RM\u57fa\u51c6\u6d4b\u8bd5\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5bf9\u9f50\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u84b8\u998f\u65b9\u6cd5\uff0c\u8bc1\u660e\u5229\u7528\u6559\u5e08\u591a\u65b9\u9762\u80fd\u529b\u5bf9\u6709\u6548\u5956\u52b1\u5efa\u6a21\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u7cfb\u7edf\u7814\u7a76\u4ece\u751f\u6210\u5f0fLLMs\u8fdb\u884c\u5956\u52b1\u6a21\u578b\u84b8\u998f\u7684\u5de5\u4f5c\uff0cRM-Distiller\u901a\u8fc7\u5145\u5206\u5229\u7528\u6559\u5e08\u6a21\u578b\u7684\u591a\u65b9\u9762\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5956\u52b1\u6a21\u578b\u7684\u6027\u80fd\u548c\u5bf9\u9f50\u6548\u679c\u3002"}}
{"id": "2601.14041", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14041", "abs": "https://arxiv.org/abs/2601.14041", "authors": ["Yunhe Wang", "Kai Han", "Huiling Zhen", "Yuchuan Tian", "Hanting Chen", "Yongbing Huang", "Yufei Cui", "Yingte Shu", "Shan Gao", "Ismail Elezi", "Roy Vaughan Miles", "Songcen Xu", "Feng Wen", "Chao Xu", "Sinan Zeng", "Dacheng Tao"], "title": "Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants", "comment": null, "summary": "The paradigm of Large Language Models (LLMs) is currently defined by auto-regressive (AR) architectures, which generate text through a sequential ``brick-by-brick'' process. Despite their success, AR models are inherently constrained by a causal bottleneck that limits global structural foresight and iterative refinement. Diffusion Language Models (DLMs) offer a transformative alternative, conceptualizing text generation as a holistic, bidirectional denoising process akin to a sculptor refining a masterpiece. However, the potential of DLMs remains largely untapped as they are frequently confined within AR-legacy infrastructures and optimization frameworks. In this Perspective, we identify ten fundamental challenges ranging from architectural inertia and gradient sparsity to the limitations of linear reasoning that prevent DLMs from reaching their ``GPT-4 moment''. We propose a strategic roadmap organized into four pillars: foundational infrastructure, algorithmic optimization, cognitive reasoning, and unified multimodal intelligence. By shifting toward a diffusion-native ecosystem characterized by multi-scale tokenization, active remasking, and latent thinking, we can move beyond the constraints of the causal horizon. We argue that this transition is essential for developing next-generation AI capable of complex structural reasoning, dynamic self-correction, and seamless multimodal integration.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6307\u51fa\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u56e0\u679c\u74f6\u9888\u9650\u5236\uff0c\u6269\u6563\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u66ff\u4ee3\u65b9\u6848\u4f46\u53d7\u9650\u4e8eAR\u9057\u7559\u6846\u67b6\uff0c\u63d0\u51fa\u4e86DLM\u53d1\u5c55\u7684\u5341\u5927\u6311\u6218\u548c\u56db\u5927\u652f\u67f1\u8def\u7ebf\u56fe\uff0c\u65e8\u5728\u5b9e\u73b0\u8d85\u8d8a\u56e0\u679c\u89c6\u91ce\u7684\u4e0b\u4e00\u4ee3AI\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u91c7\u7528\u81ea\u56de\u5f52\u67b6\u6784\uff0c\u5b58\u5728\u56e0\u679c\u74f6\u9888\u9650\u5236\u5168\u5c40\u7ed3\u6784\u9884\u89c1\u548c\u8fed\u4ee3\u4f18\u5316\u80fd\u529b\u3002\u6269\u6563\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u6574\u4f53\u53cc\u5411\u53bb\u566a\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u5176\u6f5c\u529b\u56e0\u53d7\u9650\u4e8eAR\u9057\u7559\u57fa\u7840\u8bbe\u65bd\u548c\u4f18\u5316\u6846\u67b6\u800c\u672a\u80fd\u5145\u5206\u53d1\u6325\u3002", "method": "\u8bba\u6587\u8bc6\u522b\u4e86\u6269\u6563\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u7684\u5341\u5927\u6839\u672c\u6311\u6218\uff0c\u5305\u62ec\u67b6\u6784\u60ef\u6027\u3001\u68af\u5ea6\u7a00\u758f\u6027\u548c\u7ebf\u6027\u63a8\u7406\u9650\u5236\u7b49\uff0c\u5e76\u63d0\u51fa\u4e86\u7531\u56db\u5927\u652f\u67f1\u7ec4\u6210\u7684\u6218\u7565\u8def\u7ebf\u56fe\uff1a\u57fa\u7840\u67b6\u6784\u3001\u7b97\u6cd5\u4f18\u5316\u3001\u8ba4\u77e5\u63a8\u7406\u548c\u7edf\u4e00\u591a\u6a21\u6001\u667a\u80fd\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u5411\u6269\u6563\u539f\u751f\u751f\u6001\u7cfb\u7edf\u7684\u8f6c\u53d8\u7b56\u7565\uff0c\u5305\u62ec\u591a\u5c3a\u5ea6\u6807\u8bb0\u5316\u3001\u4e3b\u52a8\u91cd\u63a9\u7801\u548c\u6f5c\u5728\u601d\u7ef4\u7b49\u5173\u952e\u6280\u672f\uff0c\u65e8\u5728\u7a81\u7834\u56e0\u679c\u89c6\u91ce\u9650\u5236\uff0c\u5b9e\u73b0\u590d\u6742\u7ed3\u6784\u63a8\u7406\u3001\u52a8\u6001\u81ea\u6211\u4fee\u6b63\u548c\u65e0\u7f1d\u591a\u6a21\u6001\u96c6\u6210\u3002", "conclusion": "\u4ece\u81ea\u56de\u5f52\u8303\u5f0f\u5411\u6269\u6563\u539f\u751f\u751f\u6001\u7cfb\u7edf\u7684\u8fc7\u6e21\u5bf9\u4e8e\u5f00\u53d1\u5177\u5907\u590d\u6742\u7ed3\u6784\u63a8\u7406\u3001\u52a8\u6001\u81ea\u6211\u4fee\u6b63\u548c\u8de8\u6a21\u6001\u96c6\u6210\u80fd\u529b\u7684\u4e0b\u4e00\u4ee3AI\u81f3\u5173\u91cd\u8981\uff0c\u8fd9\u5c06\u63a8\u52a8DLM\u5b9e\u73b0\u5176\"GPT-4\u65f6\u523b\"\u7684\u7a81\u7834\u6027\u53d1\u5c55\u3002"}}
{"id": "2601.14051", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14051", "abs": "https://arxiv.org/abs/2601.14051", "authors": ["Peter Devine", "Mardhiyah Sanni", "Farid Adilazuarda", "Julieta Gil Loizaga", "Barry Haddow"], "title": "Kakugo: Distillation of Low-Resource Languages into Small Language Models", "comment": null, "summary": "We present Kakugo, a novel and cost-effective pipeline designed to train general-purpose Small Language Models (SLMs) for low-resource languages using only the language name as input. By using a large teacher model to generate synthetic prompts and translate instruction datasets, we produced training data and SLMs for 54 low-resource languages. Evaluations across a diverse set of general natural language processing tasks, including translation, classification, and question answering, demonstrate that our pipeline consistently improves performance over base models. With a total generation and training cost of under $50 per language, Kakugo offers an accessible method for communities to develop language-specific AI.", "AI": {"tldr": "Kakugo\u662f\u4e00\u4e2a\u4f4e\u6210\u672c\u7ba1\u9053\uff0c\u4ec5\u9700\u8bed\u8a00\u540d\u79f0\u5373\u53ef\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u8bad\u7ec3\u901a\u7528\u5c0f\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u6559\u5e08\u6a21\u578b\u751f\u6210\u5408\u6210\u63d0\u793a\u548c\u7ffb\u8bd1\u6307\u4ee4\u6570\u636e\u96c6\uff0c\u4e3a54\u79cd\u8bed\u8a00\u521b\u5efa\u8bad\u7ec3\u6570\u636e\u548c\u6a21\u578b\uff0c\u6bcf\u8bed\u8a00\u6210\u672c\u4f4e\u4e8e50\u7f8e\u5143\u3002", "motivation": "\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u5f00\u53d1\u8bed\u8a00\u7279\u5b9aAI\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u548c\u6210\u672c\u9ad8\u6602\u7684\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u4ec5\u9700\u8bed\u8a00\u540d\u79f0\u5373\u53ef\u81ea\u52a8\u751f\u6210\u8bad\u7ec3\u6570\u636e\u5e76\u8bad\u7ec3\u6a21\u578b\u7684\u4f4e\u6210\u672c\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u5927\u578b\u6559\u5e08\u6a21\u578b\u751f\u6210\u5408\u6210\u63d0\u793a\u5e76\u7ffb\u8bd1\u6307\u4ee4\u6570\u636e\u96c6\uff0c\u521b\u5efa\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u7136\u540e\u8bad\u7ec3\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5f62\u6210\u7aef\u5230\u7aef\u81ea\u52a8\u5316\u7ba1\u9053\u3002", "result": "\u4e3a54\u79cd\u4f4e\u8d44\u6e90\u8bed\u8a00\u6210\u529f\u521b\u5efa\u8bad\u7ec3\u6570\u636e\u548cSLMs\uff0c\u5728\u7ffb\u8bd1\u3001\u5206\u7c7b\u3001\u95ee\u7b54\u7b49NLP\u4efb\u52a1\u4e0a\u6027\u80fd\u6301\u7eed\u8d85\u8d8a\u57fa\u7840\u6a21\u578b\uff0c\u6bcf\u8bed\u8a00\u603b\u751f\u6210\u548c\u8bad\u7ec3\u6210\u672c\u4f4e\u4e8e50\u7f8e\u5143\u3002", "conclusion": "Kakugo\u63d0\u4f9b\u4e86\u4e00\u79cd\u7ecf\u6d4e\u9ad8\u6548\u7684\u7ba1\u9053\uff0c\u4ec5\u9700\u8bed\u8a00\u540d\u79f0\u5373\u53ef\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u5f00\u53d1\u8bed\u8a00\u7279\u5b9aAI\uff0c\u4f7f\u8bed\u8a00\u793e\u533a\u80fd\u591f\u4ee5\u53ef\u627f\u53d7\u7684\u6210\u672c\u83b7\u5f97AI\u80fd\u529b\u3002"}}
{"id": "2601.14063", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.14063", "abs": "https://arxiv.org/abs/2601.14063", "authors": ["Mohsinul Kabir", "Tasnim Ahmed", "Md Mezbaur Rahman", "Shaoxiong Ji", "Hassan Alhuzali", "Sophia Ananiadou"], "title": "XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs", "comment": "30 Pages, 13 Figures", "summary": "Cross-cultural competence in large language models (LLMs) requires the ability to identify Culture-Specific Items (CSIs) and to adapt them appropriately across cultural contexts. Progress in evaluating this capability has been constrained by the scarcity of high-quality CSI-annotated corpora with parallel cross-cultural sentence pairs. To address this limitation, we introduce XCR-Bench, a Cross(X)-Cultural Reasoning Benchmark consisting of 4.9k parallel sentences and 1,098 unique CSIs, spanning three distinct reasoning tasks with corresponding evaluation metrics. Our corpus integrates Newmark's CSI framework with Hall's Triad of Culture, enabling systematic analysis of cultural reasoning beyond surface-level artifacts and into semi-visible and invisible cultural elements such as social norms, beliefs, and values. Our findings show that state-of-the-art LLMs exhibit consistent weaknesses in identifying and adapting CSIs related to social etiquette and cultural reference. Additionally, we find evidence that LLMs encode regional and ethno-religious biases even within a single linguistic setting during cultural adaptation. We release our corpus and code to facilitate future research on cross-cultural NLP.", "AI": {"tldr": "XCR-Bench\u662f\u4e00\u4e2a\u8de8\u6587\u5316\u63a8\u7406\u57fa\u51c6\uff0c\u5305\u542b4.9k\u5e73\u884c\u53e5\u548c1,098\u4e2a\u72ec\u7279\u6587\u5316\u7279\u5b9a\u9879\u76ee\uff0c\u6db5\u76d6\u4e09\u4e2a\u63a8\u7406\u4efb\u52a1\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8de8\u6587\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u8de8\u6587\u5316\u80fd\u529b\u53d7\u5230\u9ad8\u8d28\u91cfCSI\u6807\u6ce8\u8bed\u6599\u5e93\u7a00\u7f3a\u7684\u9650\u5236\uff0c\u7279\u522b\u662f\u7f3a\u4e4f\u5e73\u884c\u8de8\u6587\u5316\u53e5\u5b50\u5bf9\u3002\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u6a21\u578b\u8bc6\u522b\u548c\u9002\u5e94\u6587\u5316\u7279\u5b9a\u9879\u76ee\u7684\u80fd\u529b\u3002", "method": "\u6784\u5efaXCR-Bench\u57fa\u51c6\uff0c\u6574\u5408Newmark\u7684CSI\u6846\u67b6\u548cHall\u7684\u6587\u5316\u4e09\u5143\u8bba\uff0c\u521b\u5efa\u5305\u542b\u4e09\u4e2a\u63a8\u7406\u4efb\u52a1\u7684\u8bed\u6599\u5e93\uff0c\u6db5\u76d6\u4ece\u8868\u9762\u6587\u5316\u5143\u7d20\u5230\u534a\u53ef\u89c1\u548c\u4e0d\u53ef\u89c1\u6587\u5316\u5143\u7d20\uff08\u793e\u4f1a\u89c4\u8303\u3001\u4fe1\u4ef0\u3001\u4ef7\u503c\u89c2\uff09\u3002", "result": "\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bc6\u522b\u548c\u9002\u5e94\u4e0e\u793e\u4f1a\u793c\u4eea\u548c\u6587\u5316\u53c2\u8003\u76f8\u5173\u7684CSI\u65f6\u8868\u73b0\u4e00\u81f4\u5f31\u70b9\uff0c\u5e76\u4e14\u5728\u6587\u5316\u9002\u5e94\u8fc7\u7a0b\u4e2d\u7f16\u7801\u4e86\u533a\u57df\u548c\u6c11\u65cf\u5b97\u6559\u504f\u89c1\uff0c\u5373\u4f7f\u5728\u5355\u4e00\u8bed\u8a00\u73af\u5883\u4e2d\u4e5f\u662f\u5982\u6b64\u3002", "conclusion": "XCR-Bench\u4e3a\u8de8\u6587\u5316NLP\u7814\u7a76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u8bc4\u4f30\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLMs\u5728\u8de8\u6587\u5316\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5bf9\u6df1\u5c42\u6587\u5316\u5143\u7d20\u7684\u7406\u89e3\u548c\u9002\u5e94\u80fd\u529b\u4e0d\u8db3\uff0c\u4ee5\u53ca\u5b58\u5728\u7684\u504f\u89c1\u95ee\u9898\u3002"}}
{"id": "2601.14105", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14105", "abs": "https://arxiv.org/abs/2601.14105", "authors": ["Olesya Razuvayevskaya", "Kalina Bontcheva"], "title": "Truth with a Twist: The Rhetoric of Persuasion in Professional vs. Community-Authored Fact-Checks", "comment": "In Proceedings of the ACM Web Conference 2026 (WWW 2026)", "summary": "This study presents the first large-scale comparison of persuasion techniques present in crowd- versus professionally-written debunks. Using extensive datasets from Community Notes (CNs), EUvsDisinfo, and the Database of Known Fakes (DBKF), we quantify the prevalence and types of persuasion techniques across these fact-checking ecosystems. Contrary to prior hypothesis that community-produced debunks rely more heavily on subjective or persuasive wording, we find no evidence that CNs contain a higher average number of persuasion techniques than professional fact-checks. We additionally identify systematic rhetorical differences between CNs and professional debunking efforts, reflecting differences in institutional norms and topical coverage. Finally, we examine how the crowd evaluates persuasive language in CNs and show that, although notes with more persuasive elements receive slightly higher overall helpfulness ratings, crowd raters are effective at penalising the use of particular problematic rhetorical means", "AI": {"tldr": "\u9996\u6b21\u5927\u89c4\u6a21\u6bd4\u8f83\u4f17\u5305\u4e0e\u4e13\u4e1a\u8f9f\u8c23\u4e2d\u7684\u8bf4\u670d\u6280\u5de7\uff0c\u53d1\u73b0\u793e\u533a\u7b14\u8bb0\u4e0e\u4e13\u4e1a\u8f9f\u8c23\u5728\u8bf4\u670d\u6280\u5de7\u6570\u91cf\u4e0a\u65e0\u663e\u8457\u5dee\u5f02\uff0c\u4f46\u5b58\u5728\u7cfb\u7edf\u6027\u4fee\u8f9e\u5dee\u5f02\uff0c\u4e14\u793e\u533a\u8bc4\u4ef7\u80fd\u6709\u6548\u60e9\u7f5a\u95ee\u9898\u4fee\u8f9e\u624b\u6bb5", "motivation": "\u6bd4\u8f83\u4f17\u5305\uff08\u793e\u533a\u7b14\u8bb0\uff09\u4e0e\u4e13\u4e1a\u8f9f\u8c23\uff08EUvsDisinfo\u3001DBKF\uff09\u4e2d\u8bf4\u670d\u6280\u5de7\u7684\u5dee\u5f02\uff0c\u68c0\u9a8c\u5148\u524d\u5173\u4e8e\u793e\u533a\u8f9f\u8c23\u66f4\u4f9d\u8d56\u4e3b\u89c2\u6216\u8bf4\u670d\u6027\u63aa\u8f9e\u7684\u5047\u8bbe\uff0c\u5206\u6790\u4e0d\u540c\u4e8b\u5b9e\u6838\u67e5\u751f\u6001\u7cfb\u7edf\u7684\u4fee\u8f9e\u7279\u5f81", "method": "\u4f7f\u7528Community Notes\u3001EUvsDisinfo\u548cDatabase of Known Fakes\u4e09\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u91cf\u5316\u5206\u6790\u8bf4\u670d\u6280\u5de7\u7684\u666e\u904d\u6027\u548c\u7c7b\u578b\uff0c\u6bd4\u8f83\u793e\u533a\u4e0e\u4e13\u4e1a\u8f9f\u8c23\u5728\u4fee\u8f9e\u624b\u6bb5\u4e0a\u7684\u5dee\u5f02", "result": "1. \u793e\u533a\u7b14\u8bb0\u5e76\u672a\u6bd4\u4e13\u4e1a\u8f9f\u8c23\u5305\u542b\u66f4\u591a\u8bf4\u670d\u6280\u5de7\uff1b2. \u53d1\u73b0\u793e\u533a\u4e0e\u4e13\u4e1a\u8f9f\u8c23\u5b58\u5728\u7cfb\u7edf\u6027\u4fee\u8f9e\u5dee\u5f02\uff0c\u53cd\u6620\u5236\u5ea6\u89c4\u8303\u548c\u4e3b\u9898\u8986\u76d6\u7684\u4e0d\u540c\uff1b3. \u793e\u533a\u8bc4\u4ef7\u80fd\u6709\u6548\u60e9\u7f5a\u95ee\u9898\u4fee\u8f9e\u624b\u6bb5\uff0c\u5c3d\u7ba1\u66f4\u591a\u8bf4\u670d\u5143\u7d20\u7684\u7b14\u8bb0\u83b7\u5f97\u7565\u9ad8\u7684\u5e2e\u52a9\u6027\u8bc4\u5206", "conclusion": "\u793e\u533a\u8f9f\u8c23\u5728\u8bf4\u670d\u6280\u5de7\u4f7f\u7528\u4e0a\u4e0e\u4e13\u4e1a\u8f9f\u8c23\u76f8\u5f53\uff0c\u4f46\u5b58\u5728\u4fee\u8f9e\u98ce\u683c\u5dee\u5f02\uff0c\u793e\u533a\u8bc4\u4ef7\u673a\u5236\u80fd\u6709\u6548\u8bc6\u522b\u548c\u60e9\u7f5a\u4e0d\u5f53\u4fee\u8f9e\u624b\u6bb5\uff0c\u8fd9\u4e3a\u7406\u89e3\u4e0d\u540c\u4e8b\u5b9e\u6838\u67e5\u751f\u6001\u7cfb\u7edf\u7684\u8fd0\u4f5c\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e"}}
{"id": "2601.14121", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14121", "abs": "https://arxiv.org/abs/2601.14121", "authors": ["Jonathan Tonglet", "Iryna Gurevych", "Tinne Tuytelaars", "Marie-Francine Moens"], "title": "NewsRECON: News article REtrieval for image CONtextualization", "comment": "Preprint under review. Code available at https://github.com/jtonglet/arxiv2025-newsrecon", "summary": "Identifying when and where a news image was taken is crucial for journalists and forensic experts to produce credible stories and debunk misinformation. While many existing methods rely on reverse image search (RIS) engines, these tools often fail to return results, thereby limiting their practical applicability. In this work, we address the challenging scenario where RIS evidence is unavailable. We introduce NewsRECON, a method that links images to relevant news articles to infer their date and location from article metadata. NewsRECON leverages a corpus of over 90,000 articles and integrates: (1) a bi-encoder for retrieving event-relevant articles; (2) two cross-encoders for reranking articles by location and event consistency. Experiments on the TARA and 5Pils-OOC show that NewsRECON outperforms prior work and can be combined with a multimodal large language model to achieve new SOTA results in the absence of RIS evidence. We make our code available.", "AI": {"tldr": "NewsRECON\uff1a\u4e00\u79cd\u5728\u6ca1\u6709\u53cd\u5411\u56fe\u50cf\u641c\u7d22\u8bc1\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u5c06\u65b0\u95fb\u56fe\u50cf\u94fe\u63a5\u5230\u76f8\u5173\u6587\u7ae0\u6765\u63a8\u65ad\u5176\u62cd\u6444\u65f6\u95f4\u548c\u5730\u70b9\u7684\u65b0\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u53cd\u5411\u56fe\u50cf\u641c\u7d22(RIS)\u5f15\u64ce\uff0c\u4f46\u8fd9\u4e9b\u5de5\u5177\u7ecf\u5e38\u65e0\u6cd5\u8fd4\u56de\u7ed3\u679c\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u9700\u8981\u89e3\u51b3RIS\u8bc1\u636e\u4e0d\u53ef\u7528\u65f6\u7684\u6311\u6218\u6027\u573a\u666f\u3002", "method": "NewsRECON\u901a\u8fc7\u94fe\u63a5\u56fe\u50cf\u5230\u76f8\u5173\u65b0\u95fb\u6587\u7ae0\uff0c\u4ece\u6587\u7ae0\u5143\u6570\u636e\u63a8\u65ad\u65f6\u95f4\u548c\u5730\u70b9\u3002\u65b9\u6cd5\u5305\u542b\uff1a1) \u53cc\u7f16\u7801\u5668\u68c0\u7d22\u4e8b\u4ef6\u76f8\u5173\u6587\u7ae0\uff1b2) \u4e24\u4e2a\u4ea4\u53c9\u7f16\u7801\u5668\u6309\u4f4d\u7f6e\u548c\u4e8b\u4ef6\u4e00\u81f4\u6027\u91cd\u6392\u6587\u7ae0\u3002\u57fa\u4e8e\u8d85\u8fc790,000\u7bc7\u6587\u7ae0\u7684\u8bed\u6599\u5e93\u3002", "result": "\u5728TARA\u548c5Pils-OOC\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cNewsRECON\u4f18\u4e8e\u5148\u524d\u5de5\u4f5c\uff0c\u5e76\u4e14\u53ef\u4ee5\u4e0e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\uff0c\u5728\u6ca1\u6709RIS\u8bc1\u636e\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u65b0\u7684SOTA\u7ed3\u679c\u3002", "conclusion": "NewsRECON\u4e3a\u65b0\u95fb\u56fe\u50cf\u7684\u65f6\u95f4\u548c\u5730\u70b9\u8bc6\u522b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u53cd\u5411\u56fe\u50cf\u641c\u7d22\u4e0d\u53ef\u7528\u7684\u60c5\u51b5\u4e0b\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.14124", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14124", "abs": "https://arxiv.org/abs/2601.14124", "authors": ["Saad Mankarious", "Aya Zirikly"], "title": "Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic", "comment": null, "summary": "Synthetic data offers a promising solution for mitigating data scarcity and demographic bias in mental health analysis, yet existing approaches largely rely on pretrained large language models (LLMs), which may suffer from limited output diversity and propagate biases inherited from their training data. In this work, we propose a pretraining-free diffusion-based approach for synthetic text generation that frames bias mitigation as a style transfer problem. Using the CARMA Arabic mental health corpus, which exhibits a substantial gender imbalance, we focus on male-to-female style transfer to augment underrepresented female-authored content. We construct five datasets capturing varying linguistic and semantic aspects of gender expression in Arabic and train separate diffusion models for each setting. Quantitative evaluations demonstrate consistently high semantic fidelity between source and generated text, alongside meaningful surface-level stylistic divergence, while qualitative analysis confirms linguistically plausible gender transformations. Our results show that diffusion-based style transfer can generate high-entropy, semantically faithful synthetic data without reliance on pretrained LLMs, providing an effective and flexible framework for mitigating gender bias in sensitive, low-resource mental health domains.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6587\u672c\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u7f13\u89e3\u963f\u62c9\u4f2f\u8bed\u5fc3\u7406\u5065\u5eb7\u6570\u636e\u4e2d\u7684\u6027\u522b\u504f\u89c1\uff0c\u901a\u8fc7\u98ce\u683c\u8f6c\u6362\u589e\u5f3a\u5973\u6027\u4f5c\u8005\u5185\u5bb9", "motivation": "\u73b0\u6709\u57fa\u4e8e\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5408\u6210\u6570\u636e\u65b9\u6cd5\u5b58\u5728\u8f93\u51fa\u591a\u6837\u6027\u6709\u9650\u548c\u4f20\u64ad\u8bad\u7ec3\u6570\u636e\u504f\u89c1\u7684\u98ce\u9669\uff0c\u7279\u522b\u662f\u5728\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u5b58\u5728\u663e\u8457\u6027\u522b\u4e0d\u5e73\u8861\u95ee\u9898", "method": "\u5c06\u504f\u89c1\u7f13\u89e3\u89c6\u4e3a\u98ce\u683c\u8f6c\u6362\u95ee\u9898\uff0c\u4f7f\u7528CARMA\u963f\u62c9\u4f2f\u8bed\u5fc3\u7406\u5065\u5eb7\u8bed\u6599\u5e93\uff0c\u6784\u5efa\u4e94\u4e2a\u6355\u6349\u4e0d\u540c\u8bed\u8a00\u548c\u8bed\u4e49\u6027\u522b\u8868\u8fbe\u65b9\u9762\u7684\u6570\u636e\u96c6\uff0c\u4e3a\u6bcf\u4e2a\u8bbe\u7f6e\u8bad\u7ec3\u72ec\u7acb\u7684\u6269\u6563\u6a21\u578b\uff0c\u5b9e\u73b0\u7537\u6027\u5230\u5973\u6027\u7684\u98ce\u683c\u8f6c\u6362", "result": "\u5b9a\u91cf\u8bc4\u4f30\u663e\u793a\u6e90\u6587\u672c\u4e0e\u751f\u6210\u6587\u672c\u4e4b\u95f4\u5177\u6709\u9ad8\u8bed\u4e49\u4fdd\u771f\u5ea6\uff0c\u540c\u65f6\u5b58\u5728\u6709\u610f\u4e49\u7684\u8868\u9762\u98ce\u683c\u5dee\u5f02\uff1b\u5b9a\u6027\u5206\u6790\u786e\u8ba4\u4e86\u8bed\u8a00\u4e0a\u5408\u7406\u7684\u6027\u522b\u8f6c\u6362", "conclusion": "\u57fa\u4e8e\u6269\u6563\u7684\u98ce\u683c\u8f6c\u6362\u80fd\u591f\u751f\u6210\u9ad8\u71b5\u3001\u8bed\u4e49\u5fe0\u5b9e\u7684\u5408\u6210\u6570\u636e\uff0c\u65e0\u9700\u4f9d\u8d56\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4e3a\u7f13\u89e3\u654f\u611f\u3001\u4f4e\u8d44\u6e90\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u4e2d\u7684\u6027\u522b\u504f\u89c1\u63d0\u4f9b\u4e86\u6709\u6548\u7075\u6d3b\u6846\u67b6"}}
{"id": "2601.14152", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14152", "abs": "https://arxiv.org/abs/2601.14152", "authors": ["Hyunjong Ok", "Jaeho Lee"], "title": "Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models", "comment": "preprint", "summary": "Large language models exhibit surprising sensitivity to the structure of the prompt, but the mechanisms underlying this sensitivity remain poorly understood. In this work, we conduct an in-depth investigation on a striking case: in multiple-choice question answering, placing context before the questions and options (CQO) outperforms the reverse order (QOC) by over 14%p, consistently over a wide range of models and datasets. Through systematic architectural analysis, we identify causal attention as the core mechanism: in QOC prompts, the causal mask prevents option tokens from attending to context, creating an information bottleneck where context becomes invisible to options.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLM\u5728\u591a\u9879\u9009\u62e9\u9898\u4e2d\uff0c\u5c06\u4e0a\u4e0b\u6587\u653e\u5728\u95ee\u9898\u548c\u9009\u9879\u4e4b\u524d\uff08CQO\uff09\u6bd4\u53cd\u5411\u987a\u5e8f\uff08QOC\uff09\u6027\u80fd\u63d0\u5347\u8d85\u8fc714%\uff0c\u8fd9\u79cd\u5dee\u5f02\u6e90\u4e8e\u56e0\u679c\u6ce8\u610f\u529b\u673a\u5236\u5bfc\u81f4\u7684\u4fe1\u606f\u74f6\u9888\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u63d0\u793a\u7ed3\u6784\u8868\u73b0\u51fa\u60ca\u4eba\u7684\u654f\u611f\u6027\uff0c\u4f46\u5176\u80cc\u540e\u7684\u673a\u5236\u5c1a\u4e0d\u6e05\u695a\u3002\u672c\u6587\u65e8\u5728\u6df1\u5165\u63a2\u7a76\u4e00\u4e2a\u663e\u8457\u73b0\u8c61\uff1a\u5728\u591a\u9879\u9009\u62e9\u9898\u56de\u7b54\u4e2d\uff0c\u4e0d\u540c\u63d0\u793a\u987a\u5e8f\uff08\u4e0a\u4e0b\u6587-\u95ee\u9898-\u9009\u9879 vs \u95ee\u9898-\u9009\u9879-\u4e0a\u4e0b\u6587\uff09\u5bfc\u81f4\u6027\u80fd\u5dee\u5f02\u8d85\u8fc714%\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u7684\u67b6\u6784\u5206\u6790\uff0c\u8bc6\u522b\u56e0\u679c\u6ce8\u610f\u529b\u4f5c\u4e3a\u6838\u5fc3\u673a\u5236\u3002\u5728QOC\u63d0\u793a\u4e2d\uff0c\u56e0\u679c\u63a9\u7801\u963b\u6b62\u9009\u9879\u6807\u8bb0\u5173\u6ce8\u4e0a\u4e0b\u6587\uff0c\u521b\u5efa\u4e86\u4e0a\u4e0b\u6587\u5bf9\u9009\u9879\u4e0d\u53ef\u89c1\u7684\u4fe1\u606f\u74f6\u9888\u3002", "result": "CQO\u987a\u5e8f\u5728\u5e7f\u6cdb\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u4e00\u81f4\u4f18\u4e8eQOC\u987a\u5e8f\uff0c\u6027\u80fd\u5dee\u8ddd\u8d85\u8fc714\u4e2a\u767e\u5206\u70b9\u3002\u56e0\u679c\u6ce8\u610f\u529b\u673a\u5236\u88ab\u786e\u8ba4\u4e3a\u5bfc\u81f4\u8fd9\u79cd\u5dee\u5f02\u7684\u6839\u672c\u539f\u56e0\u3002", "conclusion": "\u63d0\u793a\u7ed3\u6784\u5bf9LLM\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u56e0\u679c\u6ce8\u610f\u529b\u673a\u5236\u662f\u5173\u952e\u56e0\u7d20\u3002\u7406\u89e3\u8fd9\u4e00\u673a\u5236\u6709\u52a9\u4e8e\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u63d0\u793a\u7b56\u7565\uff0c\u5e76\u63ed\u793aLLM\u5185\u90e8\u4fe1\u606f\u5904\u7406\u673a\u5236\u3002"}}
{"id": "2601.14160", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14160", "abs": "https://arxiv.org/abs/2601.14160", "authors": ["Ali Hamza Bashir", "Muhammad Rehan Khalid", "Kostadin Cvejoski", "Jana Birr", "Jule Berghaus", "Armin Berger", "Sandra Halscheidt", "Christian Temath", "Rafet Sifa", "David Berghaus"], "title": "Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law", "comment": null, "summary": "Large language models (LLMs) often struggle in specialized domains such as legal reasoning due to limited expert knowledge, resulting in factually incorrect outputs or hallucinations. This paper presents an effective method for adapting advanced LLMs to German legal question answering through a novel synthetic data generation approach. In contrast to costly human-annotated resources or unreliable synthetic alternatives, our approach systematically produces high-quality, diverse, and legally accurate question-answer pairs directly from authoritative German statutes. Using rigorous automated filtering methods and parameter-efficient fine-tuning techniques, we demonstrate that LLMs adapted with our synthetic dataset significantly outperform their baseline counterparts on German legal question answering tasks. Our results highlight the feasibility of using carefully designed synthetic data as a robust alternative to manual annotation in high-stakes, knowledge-intensive domains.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u9002\u914d\u5230\u5fb7\u56fd\u6cd5\u5f8b\u95ee\u7b54\u9886\u57df\u7684\u6280\u672f\uff0c\u5229\u7528\u6743\u5a01\u6cd5\u89c4\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u95ee\u7b54\u5bf9\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u6cd5\u5f8b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u4e1a\u9886\u57df\u5982\u6cd5\u5f8b\u63a8\u7406\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5b58\u5728\u4e8b\u5b9e\u9519\u8bef\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u800c\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\u6602\u4e14\u73b0\u6709\u5408\u6210\u6570\u636e\u8d28\u91cf\u4e0d\u53ef\u9760", "method": "\u4ece\u6743\u5a01\u5fb7\u56fd\u6cd5\u89c4\u4e2d\u7cfb\u7edf\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u591a\u6837\u4e14\u6cd5\u5f8b\u51c6\u786e\u7684\u95ee\u7b54\u5bf9\uff0c\u91c7\u7528\u4e25\u683c\u7684\u81ea\u52a8\u8fc7\u6ee4\u65b9\u6cd5\u548c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f", "result": "\u4f7f\u7528\u5408\u6210\u6570\u636e\u96c6\u5fae\u8c03\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5fb7\u56fd\u6cd5\u5f8b\u95ee\u7b54\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u5408\u6210\u6570\u636e\u4f5c\u4e3a\u4eba\u5de5\u6807\u6ce8\u66ff\u4ee3\u65b9\u6848\u7684\u53ef\u884c\u6027", "conclusion": "\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5408\u6210\u6570\u636e\u53ef\u4f5c\u4e3a\u9ad8\u98ce\u9669\u3001\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\u4e2d\u4eba\u5de5\u6807\u6ce8\u7684\u7a33\u5065\u66ff\u4ee3\u65b9\u6848\uff0c\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u4e1a\u9886\u57df\u7684\u6027\u80fd"}}
{"id": "2601.14172", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14172", "abs": "https://arxiv.org/abs/2601.14172", "authors": ["V\u00edctor Yeste", "Paolo Rosso"], "title": "Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum", "comment": "Code: https://github.com/VictorMYeste/human-value-detection, 37 pages, 4 figures,", "summary": "We study sentence-level identification of the 19 values in the Schwartz motivational continuum as a concrete formulation of human value detection in text. The setting - out-of-context sentences from news and political manifestos - features sparse moral cues and severe class imbalance. This combination makes fine-grained sentence-level value detection intrinsically difficult, even for strong modern neural models. We first operationalize a binary moral presence task (\"does any value appear?\") and show that it is learnable from single sentences (positive-class F1 $\\approx$ 0.74 with calibrated thresholds). We then compare a presence-gated hierarchy to a direct multi-label classifier under matched compute, both based on DeBERTa-base and augmented with lightweight signals (prior-sentence context, LIWC-22/eMFD/MJD lexica, and topic features). The hierarchy does not outperform direct prediction, indicating that gate recall limits downstream gains. We also benchmark instruction-tuned LLMs - Gemma 2 9B, Llama 3.1 8B, Mistral 8B, and Qwen 2.5 7B - in zero-/few-shot and QLoRA setups and build simple ensembles; a soft-vote supervised ensemble reaches macro-F1 0.332, significantly surpassing the best single supervised model and exceeding prior English-only baselines. Overall, in this scenario, lightweight signals and small ensembles yield the most reliable improvements, while hierarchical gating offers limited benefit. We argue that, under an 8 GB single-GPU constraint and at the 7-9B scale, carefully tuned supervised encoders remain a strong and compute-efficient baseline for structured human value detection, and we outline how richer value structure and sentence-in-document context could further improve performance.", "AI": {"tldr": "\u7814\u7a76\u53e5\u5b50\u7ea7\u522b\u8bc6\u522b\u65bd\u74e6\u8328\u4ef7\u503c\u7406\u8bba\u4e2d\u768419\u79cd\u4ef7\u503c\uff0c\u4f5c\u4e3a\u6587\u672c\u4e2d\u4eba\u7c7b\u4ef7\u503c\u68c0\u6d4b\u7684\u5177\u4f53\u5b9e\u73b0\u3002\u5728\u65b0\u95fb\u548c\u653f\u6cbb\u5ba3\u8a00\u7684\u8131\u8bed\u5883\u53e5\u5b50\u4e2d\uff0c\u9762\u4e34\u7a00\u758f\u7684\u9053\u5fb7\u7ebf\u7d22\u548c\u4e25\u91cd\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u5728\u8131\u8bed\u5883\u53e5\u5b50\u4e2d\u68c0\u6d4b\u7ec6\u7c92\u5ea6\u7684\u4eba\u7c7b\u4ef7\u503c\u5177\u6709\u5185\u5728\u56f0\u96be\uff0c\u5373\u4f7f\u5bf9\u4e8e\u73b0\u4ee3\u795e\u7ecf\u6a21\u578b\u4e5f\u662f\u5982\u6b64\u3002\u9700\u8981\u63a2\u7d22\u5728\u7a00\u758f\u9053\u5fb7\u7ebf\u7d22\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u6761\u4ef6\u4e0b\uff0c\u5982\u4f55\u6709\u6548\u8fdb\u884c\u53e5\u5b50\u7ea7\u522b\u7684\u4ef7\u503c\u68c0\u6d4b\u3002", "method": "1. \u9996\u5148\u64cd\u4f5c\u5316\u4e8c\u5143\u9053\u5fb7\u5b58\u5728\u4efb\u52a1\uff1b2. \u6bd4\u8f83\u5b58\u5728\u95e8\u63a7\u5c42\u6b21\u7ed3\u6784\u4e0e\u76f4\u63a5\u591a\u6807\u7b7e\u5206\u7c7b\u5668\uff1b3. \u57fa\u4e8eDeBERTa-base\u6a21\u578b\uff0c\u589e\u5f3a\u8f7b\u91cf\u7ea7\u4fe1\u53f7\uff08\u524d\u53e5\u4e0a\u4e0b\u6587\u3001LIWC-22/eMFD/MJD\u8bcd\u5178\u3001\u4e3b\u9898\u7279\u5f81\uff09\uff1b4. \u57fa\u51c6\u6d4b\u8bd5\u6307\u4ee4\u8c03\u4f18\u7684LLMs\uff08Gemma 2 9B\u7b49\uff09\u7684\u96f6/\u5c11\u6837\u672c\u548cQLoRA\u8bbe\u7f6e\uff1b5. \u6784\u5efa\u7b80\u5355\u96c6\u6210\u6a21\u578b\u3002", "result": "1. \u4e8c\u5143\u9053\u5fb7\u5b58\u5728\u4efb\u52a1\u53ef\u4ece\u5355\u53e5\u4e2d\u5b66\u4e60\uff08\u6b63\u7c7bF1\u22480.74\uff09\uff1b2. \u5c42\u6b21\u7ed3\u6784\u672a\u4f18\u4e8e\u76f4\u63a5\u9884\u6d4b\uff0c\u95e8\u63a7\u53ec\u56de\u9650\u5236\u4e86\u4e0b\u6e38\u589e\u76ca\uff1b3. \u8f6f\u6295\u7968\u76d1\u7763\u96c6\u6210\u8fbe\u5230macro-F1 0.332\uff0c\u663e\u8457\u8d85\u8d8a\u6700\u4f73\u5355\u76d1\u7763\u6a21\u578b\u548c\u5148\u524d\u57fa\u7ebf\uff1b4. \u8f7b\u91cf\u7ea7\u4fe1\u53f7\u548c\u5c0f\u96c6\u6210\u4ea7\u751f\u6700\u53ef\u9760\u7684\u6539\u8fdb\u3002", "conclusion": "\u57288GB\u5355GPU\u7ea6\u675f\u548c7-9B\u89c4\u6a21\u4e0b\uff0c\u7cbe\u5fc3\u8c03\u4f18\u7684\u76d1\u7763\u7f16\u7801\u5668\u4ecd\u7136\u662f\u7ed3\u6784\u5316\u4eba\u7c7b\u4ef7\u503c\u68c0\u6d4b\u7684\u5f3a\u5927\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u57fa\u7ebf\u3002\u66f4\u4e30\u5bcc\u7684\u4ef7\u503c\u7ed3\u6784\u548c\u6587\u6863\u4e0a\u4e0b\u6587\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2601.14230", "categories": ["cs.CL", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.14230", "abs": "https://arxiv.org/abs/2601.14230", "authors": ["Yiyang Wang", "Yiqiao Jin", "Alex Cabral", "Josiah Hester"], "title": "MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems", "comment": "15 pages, 9 figures", "summary": "Multi-agent systems (MAS) have recently emerged as promising socio-collaborative companions for emotional and cognitive support. However, these systems frequently suffer from persona collapse--where agents revert to generic, homogenized assistant behaviors--and social sycophancy, which produces redundant, non-constructive dialogue. We propose MASCOT, a generalizable framework for multi-perspective socio-collaborative companions. MASCOT introduces a novel bi-level optimization strategy to harmonize individual and collective behaviors: 1) Persona-Aware Behavioral Alignment, an RLAIF-driven pipeline that finetunes individual agents for strict persona fidelity to prevent identity loss; and 2) Collaborative Dialogue Optimization, a meta-policy guided by group-level rewards to ensure diverse and productive discourse. Extensive evaluations across psychological support and workplace domains demonstrate that MASCOT significantly outperforms state-of-the-art baselines, achieving improvements of up to +14.1 in Persona Consistency and +10.6 in Social Contribution. Our framework provides a practical roadmap for engineering the next generation of socially intelligent multi-agent systems.", "AI": {"tldr": "MASCOT\u6846\u67b6\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u7b56\u7565\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u89d2\u8272\u5d29\u6e83\u548c\u793e\u4ea4\u8c04\u5a9a\u95ee\u9898\uff0c\u63d0\u5347\u89d2\u8272\u4e00\u81f4\u6027\u548c\u793e\u4ea4\u8d21\u732e\u5ea6", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u60c5\u611f\u548c\u8ba4\u77e5\u652f\u6301\u5e94\u7528\u4e2d\u5b58\u5728\u89d2\u8272\u5d29\u6e83\uff08\u667a\u80fd\u4f53\u9000\u5316\u4e3a\u901a\u7528\u52a9\u624b\u884c\u4e3a\uff09\u548c\u793e\u4ea4\u8c04\u5a9a\uff08\u4ea7\u751f\u5197\u4f59\u975e\u5efa\u8bbe\u6027\u5bf9\u8bdd\uff09\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u901a\u7528\u6846\u67b6\u6765\u534f\u8c03\u4e2a\u4f53\u548c\u96c6\u4f53\u884c\u4e3a", "method": "\u63d0\u51faMASCOT\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u7b56\u7565\uff1a1\uff09\u89d2\u8272\u611f\u77e5\u884c\u4e3a\u5bf9\u9f50\uff08RLAIF\u9a71\u52a8\u7684\u7ba1\u9053\uff0c\u5fae\u8c03\u4e2a\u4f53\u667a\u80fd\u4f53\u4ee5\u786e\u4fdd\u4e25\u683c\u89d2\u8272\u4fdd\u771f\u5ea6\uff09\uff1b2\uff09\u534f\u4f5c\u5bf9\u8bdd\u4f18\u5316\uff08\u57fa\u4e8e\u7fa4\u4f53\u7ea7\u5956\u52b1\u7684\u5143\u7b56\u7565\uff0c\u786e\u4fdd\u591a\u6837\u5316\u548c\u5bcc\u6709\u6210\u6548\u7684\u5bf9\u8bdd\uff09", "result": "\u5728\u5fc3\u7406\u652f\u6301\u548c\u804c\u573a\u9886\u57df\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cMASCOT\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u89d2\u8272\u4e00\u81f4\u6027\u65b9\u9762\u63d0\u5347\u9ad8\u8fbe+14.1\uff0c\u5728\u793e\u4ea4\u8d21\u732e\u5ea6\u65b9\u9762\u63d0\u5347+10.6", "conclusion": "MASCOT\u4e3a\u6784\u5efa\u4e0b\u4e00\u4ee3\u793e\u4ea4\u667a\u80fd\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6280\u672f\u8def\u7ebf\u56fe\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u89d2\u8272\u5d29\u6e83\u548c\u793e\u4ea4\u8c04\u5a9a\u95ee\u9898"}}
{"id": "2601.14249", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14249", "abs": "https://arxiv.org/abs/2601.14249", "authors": ["Yuming Yang", "Mingyoung Lai", "Wanxu Zhao", "Xiaoran Fan", "Zhiheng Xi", "Mingqi Wu", "Chiyue Huang", "Jun Zhao", "Haijun Lv", "Jian Tong", "Yunhua Zhou", "Yicheng Zou", "Qipeng Guo", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "title": "Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment", "comment": "26 pages. Project page: https://github.com/UmeanNever/RankSurprisalRatio", "summary": "Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-student suitability in distillation. Existing methods assess suitability primarily through student likelihood, favoring trajectories that closely align with the model's current behavior but overlooking more informative ones. Addressing this, we propose Rank-Surprisal Ratio (RSR), a simple metric that captures both alignment and informativeness to assess the suitability of a reasoning trajectory. RSR is motivated by the observation that effective trajectories typically combine low absolute probability with relatively high-ranked tokens under the student model, balancing learning signal strength and behavioral alignment. Concretely, RSR is defined as the ratio of a trajectory's average token-wise rank to its average negative log-likelihood, and is straightforward to compute and interpret. Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training performance (average Spearman 0.86), outperforming existing metrics. We further demonstrate its practical utility in both trajectory selection and teacher selection.", "AI": {"tldr": "\u63d0\u51faRank-Surprisal Ratio (RSR)\u6307\u6807\uff0c\u7528\u4e8e\u8bc4\u4f30\u63a8\u7406\u8f68\u8ff9\u5728\u77e5\u8bc6\u84b8\u998f\u4e2d\u7684\u9002\u7528\u6027\uff0c\u5e73\u8861\u5bf9\u9f50\u6027\u548c\u4fe1\u606f\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e\u5b66\u751f\u4f3c\u7136\u7684\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u4e2d\uff0c\u66f4\u5f3a\u7684\u6559\u5e08\u6a21\u578b\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\u4e0d\u4e00\u5b9a\u80fd\u4ea7\u751f\u66f4\u597d\u7684\u5b66\u751f\u6a21\u578b\uff0c\u8868\u660e\u6570\u636e\u4e0e\u5b66\u751f\u6a21\u578b\u7684\u5339\u914d\u5ea6\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u901a\u8fc7\u5b66\u751f\u4f3c\u7136\u8bc4\u4f30\u9002\u7528\u6027\uff0c\u504f\u5411\u4e0e\u6a21\u578b\u5f53\u524d\u884c\u4e3a\u9ad8\u5ea6\u5bf9\u9f50\u7684\u8f68\u8ff9\uff0c\u4f46\u5ffd\u7565\u4e86\u66f4\u5177\u4fe1\u606f\u91cf\u7684\u8f68\u8ff9\u3002", "method": "\u63d0\u51faRank-Surprisal Ratio (RSR)\u6307\u6807\uff0c\u5b9a\u4e49\u4e3a\u8f68\u8ff9\u7684\u5e73\u5747\u8bcd\u5143\u7ea7\u522b\u6392\u540d\u4e0e\u5e73\u5747\u8d1f\u5bf9\u6570\u4f3c\u7136\u4e4b\u6bd4\u3002\u8be5\u6307\u6807\u6355\u6349\u8f68\u8ff9\u7684\u5bf9\u9f50\u6027\u548c\u4fe1\u606f\u6027\uff0c\u57fa\u4e8e\u89c2\u5bdf\u53d1\u73b0\u6709\u6548\u8f68\u8ff9\u901a\u5e38\u5728\u5b66\u751f\u6a21\u578b\u4e0b\u5177\u6709\u8f83\u4f4e\u7edd\u5bf9\u6982\u7387\u4f46\u76f8\u5bf9\u8f83\u9ad8\u6392\u540d\u3002", "result": "\u57285\u4e2a\u5b66\u751f\u6a21\u578b\u548c11\u4e2a\u4e0d\u540c\u6559\u5e08\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\u4e0a\uff0cRSR\u4e0e\u8bad\u7ec3\u540e\u6027\u80fd\u5f3a\u76f8\u5173\uff08\u5e73\u5747Spearman\u76f8\u5173\u7cfb\u65700.86\uff09\uff0c\u4f18\u4e8e\u73b0\u6709\u6307\u6807\u3002\u8fdb\u4e00\u6b65\u5c55\u793a\u4e86RSR\u5728\u8f68\u8ff9\u9009\u62e9\u548c\u6559\u5e08\u9009\u62e9\u4e2d\u7684\u5b9e\u9645\u6548\u7528\u3002", "conclusion": "RSR\u662f\u4e00\u4e2a\u7b80\u5355\u6709\u6548\u7684\u6307\u6807\uff0c\u80fd\u591f\u8bc4\u4f30\u63a8\u7406\u8f68\u8ff9\u5728\u77e5\u8bc6\u84b8\u998f\u4e2d\u7684\u9002\u7528\u6027\uff0c\u5e73\u8861\u5bf9\u9f50\u6027\u548c\u4fe1\u606f\u6027\uff0c\u4e3a\u8f68\u8ff9\u9009\u62e9\u548c\u6559\u5e08\u9009\u62e9\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\u3002"}}
