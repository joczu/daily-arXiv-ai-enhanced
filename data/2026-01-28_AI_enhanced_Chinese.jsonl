{"id": "2601.17057", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.17057", "abs": "https://arxiv.org/abs/2601.17057", "authors": ["Zhikai Wang", "Weihua Zhang"], "title": "Frequency-aware Adaptive Contrastive Learning for Sequential Recommendation", "comment": "10 pages, 6 figures", "summary": "In this paper, we revisited the role of data augmentation in contrastive learning for sequential recommendation, revealing its inherent bias against low-frequency items and sparse user behaviors. To address this limitation, we proposed FACL, a frequency-aware adaptive contrastive learning framework that introduces micro-level adaptive perturbation to protect the integrity of rare items, as well as macro-level reweighting to amplify the influence of sparse and rare-interaction sequences during training. Comprehensive experiments on five public benchmark datasets demonstrated that FACL consistently outperforms state-of-the-art data augmentation and model augmentation-based methods, achieving up to 3.8% improvement in recommendation accuracy. Moreover, fine-grained analyses confirm that FACL significantly alleviates the performance drop on low-frequency items and users, highlighting its robust intent-preserving ability and its superior applicability to real-world, long-tail recommendation scenarios.", "AI": {"tldr": "FACL\u6846\u67b6\u901a\u8fc7\u9891\u7387\u611f\u77e5\u7684\u81ea\u9002\u5e94\u5bf9\u6bd4\u5b66\u4e60\uff0c\u89e3\u51b3\u5e8f\u5217\u63a8\u8350\u4e2d\u6570\u636e\u589e\u5f3a\u5bf9\u4f4e\u9891\u7269\u54c1\u548c\u7a00\u758f\u7528\u6237\u884c\u4e3a\u7684\u504f\u89c1\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\u3002", "motivation": "\u7814\u7a76\u53d1\u73b0\u4f20\u7edf\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u5b58\u5728\u56fa\u6709\u504f\u89c1\uff0c\u4f1a\u635f\u5bb3\u4f4e\u9891\u7269\u54c1\u548c\u7a00\u758f\u7528\u6237\u884c\u4e3a\u7684\u5b8c\u6574\u6027\uff0c\u5bfc\u81f4\u63a8\u8350\u7cfb\u7edf\u5728\u957f\u5c3e\u573a\u666f\u4e0b\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51faFACL\u6846\u67b6\uff0c\u5305\u542b\u5fae\u89c2\u5c42\u9762\u7684\u81ea\u9002\u5e94\u6270\u52a8\u4fdd\u62a4\u7a00\u6709\u7269\u54c1\u5b8c\u6574\u6027\uff0c\u4ee5\u53ca\u5b8f\u89c2\u5c42\u9762\u7684\u91cd\u52a0\u6743\u673a\u5236\u653e\u5927\u7a00\u758f\u548c\u7a00\u6709\u4ea4\u4e92\u5e8f\u5217\u5728\u8bad\u7ec3\u4e2d\u7684\u5f71\u54cd\u3002", "result": "\u5728\u4e94\u4e2a\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cFACL\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6570\u636e\u589e\u5f3a\u548c\u6a21\u578b\u589e\u5f3a\u65b9\u6cd5\uff0c\u63a8\u8350\u51c6\u786e\u7387\u63d0\u5347\u6700\u9ad8\u8fbe3.8%\uff0c\u663e\u8457\u7f13\u89e3\u4e86\u4f4e\u9891\u7269\u54c1\u548c\u7528\u6237\u7684\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "FACL\u6846\u67b6\u5177\u6709\u5f3a\u5927\u7684\u610f\u56fe\u4fdd\u6301\u80fd\u529b\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u957f\u5c3e\u63a8\u8350\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u9002\u7528\u6027\uff0c\u4e3a\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u5bf9\u6bd4\u5b66\u4e60\u63d0\u4f9b\u4e86\u9891\u7387\u611f\u77e5\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17218", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17218", "abs": "https://arxiv.org/abs/2601.17218", "authors": ["Zihan Huang", "Rohan Surana", "Zhouhang Xie", "Junda Wu", "Yu Xia", "Julian McAuley"], "title": "Evaluation on Entity Matching in Recommender Systems", "comment": null, "summary": "Entity matching is a crucial component in various recommender systems, including conversational recommender systems (CRS) and knowledge-based recommender systems. However, the lack of rigorous evaluation frameworks for cross-dataset entity matching impedes progress in areas such as LLM-driven conversational recommendations and knowledge-grounded dataset construction.\n  In this paper, we introduce Reddit-Amazon-EM, a novel dataset comprising naturally occurring items from Reddit and the Amazon '23 dataset. Through careful manual annotation, we identify corresponding movies across Reddit-Movies and Amazon'23, two existing recommender system datasets with inherently overlapping catalogs. Leveraging Reddit-Amazon-EM, we conduct a comprehensive evaluation of state-of-the-art entity matching methods, including rule-based, graph-based, lexical-based, embedding-based, and LLM-based approaches.\n  For reproducible research, we release our manually annotated entity matching gold set and provide the mapping between the two datasets using the best-performing method from our experiments. This serves as a valuable resource for advancing future work on entity matching in recommender systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Reddit-Amazon-EM\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u8de8\u6570\u636e\u96c6\u5b9e\u4f53\u5339\u914d\u65b9\u6cd5\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7f3a\u4e4f\u4e25\u8c28\u8bc4\u4f30\u6846\u67b6\u7684\u7a7a\u767d\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\uff08\u5982\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u548c\u57fa\u4e8e\u77e5\u8bc6\u7684\u63a8\u8350\u7cfb\u7edf\uff09\u4e2d\u7684\u5b9e\u4f53\u5339\u914d\u7f3a\u4e4f\u8de8\u6570\u636e\u96c6\u7684\u4e25\u8c28\u8bc4\u4f30\u6846\u67b6\uff0c\u8fd9\u963b\u788d\u4e86LLM\u9a71\u52a8\u7684\u5bf9\u8bdd\u63a8\u8350\u548c\u57fa\u4e8e\u77e5\u8bc6\u7684\u63a8\u8350\u7cfb\u7edf\u6570\u636e\u96c6\u6784\u5efa\u7b49\u9886\u57df\u7684\u8fdb\u5c55\u3002", "method": "\u901a\u8fc7\u624b\u52a8\u6807\u6ce8Reddit-Movies\u548cAmazon'23\u4e24\u4e2a\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u6570\u636e\u96c6\u4e2d\u7684\u91cd\u53e0\u9879\u76ee\uff0c\u6784\u5efa\u4e86Reddit-Amazon-EM\u6570\u636e\u96c6\uff0c\u5e76\u5229\u7528\u8be5\u6570\u636e\u96c6\u5168\u9762\u8bc4\u4f30\u4e86\u57fa\u4e8e\u89c4\u5219\u3001\u56fe\u3001\u8bcd\u6c47\u3001\u5d4c\u5165\u548cLLM\u7684\u5b9e\u4f53\u5339\u914d\u65b9\u6cd5\u3002", "result": "\u521b\u5efa\u4e86\u624b\u52a8\u6807\u6ce8\u7684\u5b9e\u4f53\u5339\u914d\u9ec4\u91d1\u96c6\uff0c\u5e76\u57fa\u4e8e\u5b9e\u9a8c\u4e2d\u6700\u4f18\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e24\u4e2a\u6570\u636e\u96c6\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u5b9e\u4f53\u5339\u914d\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8d44\u6e90\u3002", "conclusion": "Reddit-Amazon-EM\u6570\u636e\u96c6\u586b\u8865\u4e86\u63a8\u8350\u7cfb\u7edf\u5b9e\u4f53\u5339\u914d\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u591a\u79cd\u5b9e\u4f53\u5339\u914d\u65b9\u6cd5\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u7840\u548c\u5b9e\u7528\u8d44\u6e90\u3002"}}
{"id": "2601.17333", "categories": ["cs.IR", "cs.AI", "cs.CE", "cs.DB"], "pdf": "https://arxiv.org/pdf/2601.17333", "abs": "https://arxiv.org/abs/2601.17333", "authors": ["Lalit Pant", "Shivang Nagar"], "title": "FinMetaMind: A Tech Blueprint on NLQ Systems for Financial Knowledge Search", "comment": "8 pages, 8 figures, Information Retrieval, Natural Language Query, Vector Search, Embeddings, Named Entity Recognition, Large Language Models", "summary": "Natural Language Query (NLQ) allows users to search and interact with information systems using plain, human language instead of structured query syntax. This paper presents a technical blueprint on the design of a modern NLQ system tailored to financial knowledge search. The introduction of NLQ not only enhances the precision and recall of the knowledge search compared to traditional methods, but also facilitates deeper insights by efficiently linking disparate financial objects, events, and relationships. Using core constructs from natural language processing, search engineering, and vector data models, the proposed system aims to address key challenges in discovering, relevance ranking, data freshness, and entity recognition intrinsic to financial data retrieval. In this work, we detail the unique requirements of NLQ for financial datasets and documents, outline the architectural components for offline indexing and online retrieval, and discuss the real-world use cases of enhanced knowledge search in financial services. We delve into the theoretical underpinnings and experimental evidence supporting our proposed architecture, ultimately providing a comprehensive analysis on the subject matter. We also provide a detailed elaboration of our experimental methodology, the data used, the results and future optimizations in this study.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u91d1\u878d\u77e5\u8bc6\u641c\u7d22\u7684\u73b0\u4ee3\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u7cfb\u7edf\u6280\u672f\u84dd\u56fe\uff0c\u901a\u8fc7\u7ed3\u5408NLP\u3001\u641c\u7d22\u5de5\u7a0b\u548c\u5411\u91cf\u6570\u636e\u6a21\u578b\uff0c\u63d0\u5347\u91d1\u878d\u6570\u636e\u68c0\u7d22\u7684\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u548c\u6d1e\u5bdf\u6df1\u5ea6\u3002", "motivation": "\u4f20\u7edf\u91d1\u878d\u77e5\u8bc6\u641c\u7d22\u65b9\u6cd5\u5b58\u5728\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u96be\u4ee5\u6709\u6548\u8fde\u63a5\u5206\u6563\u7684\u91d1\u878d\u5bf9\u8c61\u3001\u4e8b\u4ef6\u548c\u5173\u7cfb\u3002\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u80fd\u591f\u4f7f\u7528\u6237\u4ee5\u81ea\u7136\u8bed\u8a00\u4e0e\u4fe1\u606f\u7cfb\u7edf\u4ea4\u4e92\uff0c\u4ece\u800c\u63d0\u5347\u641c\u7d22\u6548\u679c\u5e76\u4fc3\u8fdb\u66f4\u6df1\u5c42\u6b21\u7684\u91d1\u878d\u6d1e\u5bdf\u3002", "method": "\u91c7\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u641c\u7d22\u5de5\u7a0b\u548c\u5411\u91cf\u6570\u636e\u6a21\u578b\u7684\u6838\u5fc3\u6784\u5efa\u6a21\u5757\uff0c\u8bbe\u8ba1\u4e86\u5305\u542b\u79bb\u7ebf\u7d22\u5f15\u548c\u5728\u7ebf\u68c0\u7d22\u7684\u67b6\u6784\u7ec4\u4ef6\u3002\u7cfb\u7edf\u4e13\u95e8\u9488\u5bf9\u91d1\u878d\u6570\u636e\u96c6\u548c\u6587\u6863\u7684\u72ec\u7279\u9700\u6c42\uff0c\u89e3\u51b3\u4e86\u53d1\u73b0\u3001\u76f8\u5173\u6027\u6392\u5e8f\u3001\u6570\u636e\u65b0\u9c9c\u5ea6\u548c\u5b9e\u4f53\u8bc6\u522b\u7b49\u5173\u952e\u6311\u6218\u3002", "result": "\u63d0\u51fa\u7684NLQ\u7cfb\u7edf\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5728\u91d1\u878d\u77e5\u8bc6\u641c\u7d22\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\uff0c\u80fd\u591f\u6709\u6548\u8fde\u63a5\u5206\u6563\u7684\u91d1\u878d\u5b9e\u4f53\u3001\u4e8b\u4ef6\u548c\u5173\u7cfb\uff0c\u4e3a\u91d1\u878d\u670d\u52a1\u4e2d\u7684\u589e\u5f3a\u77e5\u8bc6\u641c\u7d22\u63d0\u4f9b\u4e86\u5b9e\u9645\u5e94\u7528\u6848\u4f8b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u91d1\u878d\u9886\u57df\u7684\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u6280\u672f\u84dd\u56fe\u548c\u7406\u8bba\u652f\u6301\uff0c\u901a\u8fc7\u8be6\u7ec6\u7684\u5b9e\u9a8c\u65b9\u6cd5\u548c\u6570\u636e\u5206\u6790\u9a8c\u8bc1\u4e86\u67b6\u6784\u7684\u6709\u6548\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u4f18\u5316\u7684\u65b9\u5411\uff0c\u5bf9\u91d1\u878d\u77e5\u8bc6\u641c\u7d22\u7684\u73b0\u4ee3\u5316\u5177\u6709\u91cd\u8981\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2601.17339", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.17339", "abs": "https://arxiv.org/abs/2601.17339", "authors": ["Payel Santra", "Partha Basuchowdhuri", "Debasis Ganguly"], "title": "Beyond Correlations: A Downstream Evaluation Framework for Query Performance Prediction", "comment": null, "summary": "The standard practice of query performance prediction (QPP) evaluation is to measure a set-level correlation between the estimated retrieval qualities and the true ones. However, neither this correlation-based evaluation measure quantifies QPP effectiveness at the level of individual queries, nor does this connect to a downstream application, meaning that QPP methods yielding high correlation values may not find a practical application in query-specific decisions in an IR pipeline. In this paper, we propose a downstream-focussed evaluation framework where a distribution of QPP estimates across a list of top-documents retrieved with several rankers is used as priors for IR fusion. While on the one hand, a distribution of these estimates closely matching that of the true retrieval qualities indicates the quality of the predictor, their usage as priors on the other hand indicates a predictor's ability to make informed choices in an IR pipeline. Our experiments firstly establish the importance of QPP estimates in weighted IR fusion, yielding substantial improvements of over 4.5% over unweighted CombSUM and RRF fusion strategies, and secondly, reveal new insights that the downstream effectiveness of QPP does not correlate well with the standard correlation-based QPP evaluation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u4e0b\u6e38\u5e94\u7528\u7684QPP\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u7528QPP\u4f30\u8ba1\u503c\u4f5c\u4e3aIR\u878d\u5408\u7684\u5148\u9a8c\uff0c\u53d1\u73b0\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u6807\u51c6QPP\u8bc4\u4f30\u4e0e\u4e0b\u6e38\u5b9e\u9645\u6548\u679c\u76f8\u5173\u6027\u4e0d\u5f3a\u3002", "motivation": "\u4f20\u7edf\u7684\u67e5\u8be2\u6027\u80fd\u9884\u6d4b\u8bc4\u4f30\u91c7\u7528\u96c6\u5408\u5c42\u9762\u7684\u76f8\u5173\u6027\u5ea6\u91cf\uff0c\u65e2\u65e0\u6cd5\u91cf\u5316\u5355\u4e2a\u67e5\u8be2\u7ea7\u522b\u7684QPP\u6548\u679c\uff0c\u4e5f\u65e0\u6cd5\u4e0e\u4e0b\u6e38\u5e94\u7528\u8fde\u63a5\uff0c\u5bfc\u81f4\u9ad8\u76f8\u5173\u6027\u503c\u7684QPP\u65b9\u6cd5\u5728\u5b9e\u9645IR\u7ba1\u9053\u4e2d\u53ef\u80fd\u65e0\u6cd5\u6709\u6548\u652f\u6301\u67e5\u8be2\u7279\u5b9a\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u4e0b\u6e38\u805a\u7126\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u591a\u4e2a\u6392\u5e8f\u5668\u68c0\u7d22\u5230\u7684top\u6587\u6863\u5217\u8868\u4e2d\u7684QPP\u4f30\u8ba1\u503c\u5206\u5e03\u4f5c\u4e3aIR\u878d\u5408\u7684\u5148\u9a8c\u3002\u4e00\u65b9\u9762\uff0c\u8fd9\u4e9b\u4f30\u8ba1\u503c\u5206\u5e03\u4e0e\u771f\u5b9e\u68c0\u7d22\u8d28\u91cf\u5206\u5e03\u7684\u5339\u914d\u7a0b\u5ea6\u53cd\u6620\u9884\u6d4b\u5668\u8d28\u91cf\uff1b\u53e6\u4e00\u65b9\u9762\uff0c\u5c06\u5b83\u4eec\u4f5c\u4e3a\u5148\u9a8c\u4f7f\u7528\u53cd\u6620\u9884\u6d4b\u5668\u5728IR\u7ba1\u9053\u4e2d\u505a\u51fa\u660e\u667a\u9009\u62e9\u7684\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1) QPP\u4f30\u8ba1\u503c\u5728\u52a0\u6743IR\u878d\u5408\u4e2d\u5177\u6709\u91cd\u8981\u6027\uff0c\u76f8\u6bd4\u672a\u52a0\u6743\u7684CombSUM\u548cRRF\u878d\u5408\u7b56\u7565\u83b7\u5f97\u8d85\u8fc74.5%\u7684\u663e\u8457\u6539\u8fdb\uff1b2) QPP\u7684\u4e0b\u6e38\u6548\u679c\u4e0e\u6807\u51c6\u7684\u57fa\u4e8e\u76f8\u5173\u6027\u7684QPP\u8bc4\u4f30\u76f8\u5173\u6027\u4e0d\u5f3a\uff0c\u63ed\u793a\u4e86\u65b0\u7684\u89c1\u89e3\u3002", "conclusion": "\u9700\u8981\u91cd\u65b0\u601d\u8003QPP\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5c06\u4e0b\u6e38\u5e94\u7528\u6548\u679c\u7eb3\u5165\u8003\u91cf\uff0c\u56e0\u4e3a\u4f20\u7edf\u7684\u76f8\u5173\u6027\u8bc4\u4f30\u65e0\u6cd5\u51c6\u786e\u53cd\u6620QPP\u65b9\u6cd5\u5728\u5b9e\u9645IR\u7ba1\u9053\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.16986", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.16986", "abs": "https://arxiv.org/abs/2601.16986", "authors": ["Zihan Wang", "Cheng Tang", "Lei Gong", "Cheng Li", "Chao Wang", "teng wang", "Wenqi Lou", "Xuehai Zhou"], "title": "Crystal-KV: Efficient KV Cache Management for Chain-of-Thought LLMs via Answer-First Principle", "comment": null, "summary": "Chain-of-Thought (CoT) reasoning in large language models (LLMs) significantly improves accuracy on complex tasks, yet incurs excessive memory overhead due to the long think-stage sequences stored in the Key-Value (KV) cache. Unlike traditional generation tasks where all tokens are uniformly important, CoT emphasizes the final answer, rendering conventional KV compression strategies ineffective. In this paper, we present Crystal-KV, an efficient KV cache management framework tailored for CoT reasoning. Our key insight is the answer-first principle. By mapping answer preferences into think-stage attention map, we distinguish between SlipKV, which mainly maintains the reasoning flow but may occasionally introduce misleading context, and CrystalKV, which truly contributes to the correctness of the final answer. Next, we propose an attention-based Least Recently Frequently Used algorithm. It precisely identifies when a SlipKV entry's utility expires and evicts it, retaining CrystalKV without disrupting reasoning flow. Finally, we introduce an adaptive cache budget allocation algorithm. Based on the dynamic proportion of CrystalKV, it estimates the importance of each layer/head and adjusts the KV cache budget during inference, amplifying critical components to improve budget utilization. Results show that Crystal-KV achieves state-of-the-art KV cache compression, significantly improves throughput, and enables faster response time, while maintaining, or even improving, answer accuracy for CoT reasoning.", "AI": {"tldr": "Crystal-KV\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3aCoT\u63a8\u7406\u8bbe\u8ba1\u7684KV\u7f13\u5b58\u7ba1\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u7b54\u6848\u4f18\u5148\u539f\u5219\u533a\u5206SlipKV\u548cCrystalKV\uff0c\u91c7\u7528\u57fa\u4e8e\u6ce8\u610f\u529b\u7684LRFU\u7b97\u6cd5\u548c\u81ea\u9002\u5e94\u7f13\u5b58\u9884\u7b97\u5206\u914d\uff0c\u5728\u4fdd\u6301\u751a\u81f3\u63d0\u9ad8CoT\u63a8\u7406\u51c6\u786e\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u7684KV\u7f13\u5b58\u538b\u7f29\u3002", "motivation": "CoT\u63a8\u7406\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u6027\uff0c\u4f46\u4f1a\u5bfc\u81f4\u8fc7\u9ad8\u7684\u5185\u5b58\u5f00\u9500\uff0c\u56e0\u4e3a\u957f\u601d\u8003\u5e8f\u5217\u9700\u8981\u5b58\u50a8\u5728KV\u7f13\u5b58\u4e2d\u3002\u4f20\u7edf\u7684KV\u538b\u7f29\u7b56\u7565\u5bf9CoT\u63a8\u7406\u65e0\u6548\uff0c\u56e0\u4e3aCoT\u5f3a\u8c03\u6700\u7ec8\u7b54\u6848\u800c\u975e\u6240\u6709token\u7684\u5747\u5300\u91cd\u8981\u6027\u3002", "method": "1. \u7b54\u6848\u4f18\u5148\u539f\u5219\uff1a\u5c06\u7b54\u6848\u504f\u597d\u6620\u5c04\u5230\u601d\u8003\u9636\u6bb5\u6ce8\u610f\u529b\u56fe\uff0c\u533a\u5206SlipKV\uff08\u4e3b\u8981\u7ef4\u6301\u63a8\u7406\u6d41\u7a0b\u4f46\u53ef\u80fd\u5f15\u5165\u8bef\u5bfc\uff09\u548cCrystalKV\uff08\u771f\u6b63\u8d21\u732e\u4e8e\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\uff09\u30022. \u57fa\u4e8e\u6ce8\u610f\u529b\u7684LRFU\u7b97\u6cd5\uff1a\u7cbe\u786e\u8bc6\u522bSlipKV\u6761\u76ee\u6548\u7528\u4f55\u65f6\u8fc7\u671f\u5e76\u9a71\u9010\uff0c\u4fdd\u7559CrystalKV\u800c\u4e0d\u7834\u574f\u63a8\u7406\u6d41\u7a0b\u30023. \u81ea\u9002\u5e94\u7f13\u5b58\u9884\u7b97\u5206\u914d\u7b97\u6cd5\uff1a\u57fa\u4e8eCrystalKV\u7684\u52a8\u6001\u6bd4\u4f8b\u4f30\u8ba1\u6bcf\u5c42/\u5934\u7684\u91cd\u8981\u6027\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u8c03\u6574KV\u7f13\u5b58\u9884\u7b97\uff0c\u653e\u5927\u5173\u952e\u7ec4\u4ef6\u4ee5\u63d0\u9ad8\u9884\u7b97\u5229\u7528\u7387\u3002", "result": "Crystal-KV\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684KV\u7f13\u5b58\u538b\u7f29\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\uff0c\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u54cd\u5e94\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u9ad8\u4e86CoT\u63a8\u7406\u7684\u7b54\u6848\u51c6\u786e\u6027\u3002", "conclusion": "Crystal-KV\u901a\u8fc7\u9488\u5bf9CoT\u63a8\u7406\u7279\u70b9\u8bbe\u8ba1\u7684KV\u7f13\u5b58\u7ba1\u7406\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfKV\u538b\u7f29\u7b56\u7565\u5728CoT\u573a\u666f\u4e0b\u7684\u4e0d\u8db3\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6548\u7387\u3002"}}
{"id": "2601.17009", "categories": ["cs.AI", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.17009", "abs": "https://arxiv.org/abs/2601.17009", "authors": ["Yanhua Zhao"], "title": "Online parameter estimation for the Crazyflie quadcopter through an EM algorithm", "comment": "20 pages, 37 figures", "summary": "Drones are becoming more and more popular nowadays. They are small in size, low in cost, and reliable in operation. They contain a variety of sensors and can perform a variety of flight tasks, reaching places that are difficult or inaccessible for humans. Earthquakes damage a lot of infrastructure, making it impossible for rescuers to reach some areas. But drones can help. Many amateur and professional photographers like to use drones for aerial photography. Drones play a non-negligible role in agriculture and transportation too. Drones can be used to spray pesticides, and they can also transport supplies. A quadcopter is a four-rotor drone and has been studied in this paper. In this paper, random noise is added to the quadcopter system and its effects on the drone system are studied. An extended Kalman filter has been used to estimate the state based on noisy observations from the sensor. Based on a SDE system, a linear quadratic Gaussian controller has been implemented. The expectation maximization algorithm has been applied for parameter estimation of the quadcopter. The results of offline parameter estimation and online parameter estimation are presented. The results show that the online parameter estimation has a slightly larger range of convergence values than the offline parameter estimation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u7cfb\u7edf\u4e2d\u6dfb\u52a0\u968f\u673a\u566a\u58f0\u7684\u5f71\u54cd\uff0c\u4f7f\u7528\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u8fdb\u884c\u72b6\u6001\u4f30\u8ba1\uff0c\u57fa\u4e8eSDE\u7cfb\u7edf\u5b9e\u73b0\u7ebf\u6027\u4e8c\u6b21\u9ad8\u65af\u63a7\u5236\u5668\uff0c\u5e76\u5e94\u7528\u671f\u671b\u6700\u5927\u5316\u7b97\u6cd5\u8fdb\u884c\u53c2\u6570\u4f30\u8ba1\uff0c\u6bd4\u8f83\u4e86\u79bb\u7ebf\u548c\u5728\u7ebf\u53c2\u6570\u4f30\u8ba1\u7684\u6027\u80fd\u3002", "motivation": "\u65e0\u4eba\u673a\u56e0\u5176\u5c3a\u5bf8\u5c0f\u3001\u6210\u672c\u4f4e\u3001\u53ef\u9760\u6027\u9ad8\u4e14\u914d\u5907\u591a\u79cd\u4f20\u611f\u5668\uff0c\u5728\u6551\u63f4\u3001\u6444\u5f71\u3001\u519c\u4e1a\u548c\u8fd0\u8f93\u7b49\u9886\u57df\u5e94\u7528\u5e7f\u6cdb\u3002\u5730\u9707\u7b49\u707e\u5bb3\u4f1a\u7834\u574f\u57fa\u7840\u8bbe\u65bd\uff0c\u963b\u788d\u6551\u63f4\u4eba\u5458\u8fdb\u5165\uff0c\u800c\u65e0\u4eba\u673a\u53ef\u4ee5\u5230\u8fbe\u4eba\u7c7b\u96be\u4ee5\u8fdb\u5165\u7684\u533a\u57df\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u968f\u673a\u566a\u58f0\u5bf9\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u5e76\u5f00\u53d1\u6709\u6548\u7684\u72b6\u6001\u4f30\u8ba1\u548c\u63a7\u5236\u65b9\u6cd5\u3002", "method": "1. \u5728\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u7cfb\u7edf\u4e2d\u6dfb\u52a0\u968f\u673a\u566a\u58f0\uff1b2. \u4f7f\u7528\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u57fa\u4e8e\u4f20\u611f\u5668\u7684\u566a\u58f0\u89c2\u6d4b\u8fdb\u884c\u72b6\u6001\u4f30\u8ba1\uff1b3. \u57fa\u4e8e\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u7cfb\u7edf\u5b9e\u73b0\u7ebf\u6027\u4e8c\u6b21\u9ad8\u65af\u63a7\u5236\u5668\uff1b4. \u5e94\u7528\u671f\u671b\u6700\u5927\u5316\u7b97\u6cd5\u8fdb\u884c\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u7684\u53c2\u6570\u4f30\u8ba1\uff1b5. \u6bd4\u8f83\u79bb\u7ebf\u548c\u5728\u7ebf\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728\u7ebf\u53c2\u6570\u4f30\u8ba1\u7684\u6536\u655b\u503c\u8303\u56f4\u7565\u5927\u4e8e\u79bb\u7ebf\u53c2\u6570\u4f30\u8ba1\u3002\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u80fd\u6709\u6548\u5904\u7406\u566a\u58f0\u89c2\u6d4b\uff0c\u7ebf\u6027\u4e8c\u6b21\u9ad8\u65af\u63a7\u5236\u5668\u5728\u968f\u673a\u566a\u58f0\u73af\u5883\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u671f\u671b\u6700\u5927\u5316\u7b97\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u53c2\u6570\u4f30\u8ba1\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u5728\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u7cfb\u7edf\u4e2d\u5904\u7406\u968f\u673a\u566a\u58f0\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u548c\u7ebf\u6027\u4e8c\u6b21\u9ad8\u65af\u63a7\u5236\u5668\u7684\u7ed3\u5408\u4e3a\u65e0\u4eba\u673a\u5728\u566a\u58f0\u73af\u5883\u4e0b\u7684\u7a33\u5b9a\u8fd0\u884c\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002\u5728\u7ebf\u53c2\u6570\u4f30\u8ba1\u76f8\u6bd4\u79bb\u7ebf\u65b9\u6cd5\u5177\u6709\u66f4\u5e7f\u7684\u6536\u655b\u8303\u56f4\uff0c\u4e3a\u65e0\u4eba\u673a\u7cfb\u7edf\u7684\u81ea\u9002\u5e94\u63a7\u5236\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u57fa\u7840\u3002"}}
{"id": "2601.17359", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.17359", "abs": "https://arxiv.org/abs/2601.17359", "authors": ["Payel Santra", "Partha Basuchowdhuri", "Debasis Ganguly"], "title": "Breaking Flat: A Generalised Query Performance Prediction Evaluation Framework", "comment": null, "summary": "The traditional use-case of query performance prediction (QPP) is to identify which queries perform well and which perform poorly for a given ranking model. A more fine-grained and arguably more challenging extension of this task is to determine which ranking models are most effective for a given query. In this work, we generalize the QPP task and its evaluation into three settings: (i) SingleRanker MultiQuery (SRMQ-PP), corresponding to the standard use case; (ii) MultiRanker SingleQuery (MRSQ-PP), which evaluates a QPP model's ability to select the most effective ranker for a query; and (iii) MultiRanker MultiQuery (MRMQ-PP), which considers predictions jointly across all query ranker pairs. Our results show that (a) the relative effectiveness of QPP models varies substantially across tasks (SRMQ-PP vs. MRSQ-PP), and (b) predicting the best ranker for a query is considerably more difficult than predicting the relative difficulty of queries for a given ranker.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u67e5\u8be2\u6027\u80fd\u9884\u6d4b\u4efb\u52a1\u6cdb\u5316\u4e3a\u4e09\u79cd\u8bbe\u7f6e\uff1a\u5355\u6392\u5e8f\u5668\u591a\u67e5\u8be2\u3001\u591a\u6392\u5e8f\u5668\u5355\u67e5\u8be2\u548c\u591a\u6392\u5e8f\u5668\u591a\u67e5\u8be2\uff0c\u53d1\u73b0\u4e0d\u540c\u4efb\u52a1\u4e2dQPP\u6a21\u578b\u6548\u679c\u5dee\u5f02\u663e\u8457\uff0c\u4e14\u9884\u6d4b\u6700\u4f73\u6392\u5e8f\u5668\u6bd4\u9884\u6d4b\u67e5\u8be2\u96be\u5ea6\u66f4\u5177\u6311\u6218\u6027\u3002", "motivation": "\u4f20\u7edf\u67e5\u8be2\u6027\u80fd\u9884\u6d4b\u4e3b\u8981\u5173\u6ce8\u5355\u4e2a\u6392\u5e8f\u5668\u4e0b\u4e0d\u540c\u67e5\u8be2\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u4f46\u66f4\u7ec6\u7c92\u5ea6\u7684\u6311\u6218\u662f\u786e\u5b9a\u7279\u5b9a\u67e5\u8be2\u4e0b\u54ea\u4e2a\u6392\u5e8f\u5668\u6700\u6709\u6548\u3002\u672c\u7814\u7a76\u65e8\u5728\u5c06QPP\u4efb\u52a1\u53ca\u5176\u8bc4\u4f30\u6cdb\u5316\u5230\u66f4\u5168\u9762\u7684\u6846\u67b6\u4e2d\u3002", "method": "\u63d0\u51fa\u4e09\u79cdQPP\u4efb\u52a1\u8bbe\u7f6e\uff1aSRMQ-PP\uff08\u4f20\u7edf\u5355\u6392\u5e8f\u5668\u591a\u67e5\u8be2\uff09\u3001MRSQ-PP\uff08\u591a\u6392\u5e8f\u5668\u5355\u67e5\u8be2\uff0c\u9884\u6d4b\u6700\u4f73\u6392\u5e8f\u5668\uff09\u548cMRMQ-PP\uff08\u591a\u6392\u5e8f\u5668\u591a\u67e5\u8be2\uff0c\u8054\u5408\u9884\u6d4b\u6240\u6709\u67e5\u8be2-\u6392\u5e8f\u5668\u5bf9\uff09\u3002\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540cQPP\u6a21\u578b\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a(a) QPP\u6a21\u578b\u7684\u76f8\u5bf9\u6709\u6548\u6027\u5728\u4e0d\u540c\u4efb\u52a1\u95f4\u5dee\u5f02\u663e\u8457\uff08SRMQ-PP vs MRSQ-PP\uff09\uff1b(b) \u9884\u6d4b\u67e5\u8be2\u7684\u6700\u4f73\u6392\u5e8f\u5668\u6bd4\u9884\u6d4b\u7279\u5b9a\u6392\u5e8f\u5668\u4e0b\u67e5\u8be2\u7684\u76f8\u5bf9\u96be\u5ea6\u8981\u56f0\u96be\u5f97\u591a\u3002", "conclusion": "QPP\u4efb\u52a1\u9700\u8981\u6839\u636e\u5177\u4f53\u5e94\u7528\u573a\u666f\u9009\u62e9\u5408\u9002\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u591a\u6392\u5e8f\u5668\u73af\u5883\u4e0b\u7684\u6027\u80fd\u9884\u6d4b\u66f4\u5177\u6311\u6218\u6027\uff0c\u4e3a\u672a\u6765QPP\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u89c6\u89d2\u3002"}}
{"id": "2601.16987", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16987", "abs": "https://arxiv.org/abs/2601.16987", "authors": ["Shunyang Luo", "Peibei Cao", "Zhihui Zhu", "Kehua Feng", "Zhihua Wang", "Keyan Ding"], "title": "Evaluating Reward Model Generalization via Pairwise Maximum Discrepancy Competitions", "comment": "17 pages, 6 figures, 2 tables", "summary": "Reward models (RMs) are central to aligning large language models, yet their practical effectiveness hinges on generalization to unseen prompts and shifting distributions. Most existing RM evaluations rely on static, pre-annotated preference datasets, which provide limited coverage and often fail to faithfully assess generalization in open-world settings. We introduce Pairwise Maximum Discrepancy Competition (PMDC), a dynamic and annotation-efficient framework for evaluating RM generalization using a large, unlabeled, open-domain prompt pool. PMDC actively selects prompt--response pairs that maximize disagreement between two RMs, yielding a compact set of highly contentious test cases. These cases are adjudicated by an oracle, and the resulting outcomes are aggregated via a Bradley--Terry model to produce a global ranking and pairwise win-rate landscape of RMs. We apply PMDC to re-evaluate 10 representative RMs and observe substantial rank reshuffling compared with conventional benchmarks. Qualitative analyses further uncover systematic generalization failures, providing valuable insights for improving reward modeling.", "AI": {"tldr": "PMDC\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u5956\u52b1\u6a21\u578b\u95f4\u6700\u5927\u5206\u6b67\u7684\u63d0\u793a-\u54cd\u5e94\u5bf9\uff0c\u4f7f\u7528\u672a\u6807\u6ce8\u7684\u5f00\u653e\u57df\u63d0\u793a\u6c60\u9ad8\u6548\u8bc4\u4f30\u5956\u52b1\u6a21\u578b\u6cdb\u5316\u80fd\u529b\uff0c\u76f8\u6bd4\u4f20\u7edf\u9759\u6001\u57fa\u51c6\u80fd\u66f4\u771f\u5b9e\u53cd\u6620\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u9759\u6001\u9884\u6807\u6ce8\u504f\u597d\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b\u6570\u636e\u96c6\u8986\u76d6\u6709\u9650\u4e14\u96be\u4ee5\u771f\u5b9e\u8bc4\u4f30\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u9700\u8981\u66f4\u52a8\u6001\u3001\u9ad8\u6548\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u51c6\u786e\u8861\u91cf\u5956\u52b1\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51faPairwise Maximum Discrepancy Competition (PMDC)\u6846\u67b6\uff1a1) \u4f7f\u7528\u5927\u578b\u672a\u6807\u6ce8\u5f00\u653e\u57df\u63d0\u793a\u6c60\uff1b2) \u4e3b\u52a8\u9009\u62e9\u4f7f\u4e24\u4e2a\u5956\u52b1\u6a21\u578b\u4ea7\u751f\u6700\u5927\u5206\u6b67\u7684\u63d0\u793a-\u54cd\u5e94\u5bf9\uff1b3) \u901a\u8fc7oracle\u88c1\u51b3\u4e89\u8bae\u6848\u4f8b\uff1b4) \u4f7f\u7528Bradley-Terry\u6a21\u578b\u805a\u5408\u7ed3\u679c\u751f\u6210\u5168\u5c40\u6392\u540d\u548c\u6210\u5bf9\u80dc\u7387\u5206\u5e03\u3002", "result": "\u5bf910\u4e2a\u4ee3\u8868\u6027\u5956\u52b1\u6a21\u578b\u91cd\u65b0\u8bc4\u4f30\u53d1\u73b0\uff0c\u4e0e\u4f20\u7edf\u57fa\u51c6\u76f8\u6bd4\u6392\u540d\u53d1\u751f\u663e\u8457\u53d8\u5316\u3002\u5b9a\u6027\u5206\u6790\u63ed\u793a\u4e86\u7cfb\u7edf\u6027\u7684\u6cdb\u5316\u5931\u8d25\u6a21\u5f0f\uff0c\u4e3a\u6539\u8fdb\u5956\u52b1\u5efa\u6a21\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002", "conclusion": "PMDC\u63d0\u4f9b\u4e86\u4e00\u79cd\u52a8\u6001\u3001\u6807\u6ce8\u9ad8\u6548\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u66f4\u771f\u5b9e\u5730\u8bc4\u4f30\u5956\u52b1\u6a21\u578b\u5728\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u4f20\u7edf\u9759\u6001\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u5956\u52b1\u6a21\u578b\u7684\u6539\u8fdb\u65b9\u5411\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2601.17168", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.17168", "abs": "https://arxiv.org/abs/2601.17168", "authors": ["Judy Zhu", "Dhari Gandhi", "Himanshu Joshi", "Ahmad Rezaie Mianroodi", "Sedef Akinli Kocak", "Dhanesh Ramachandran"], "title": "Interpreting Agentic Systems: Beyond Model Explanations to System-Level Accountability", "comment": null, "summary": "Agentic systems have transformed how Large Language Models (LLMs) can be leveraged to create autonomous systems with goal-directed behaviors, consisting of multi-step planning and the ability to interact with different environments. These systems differ fundamentally from traditional machine learning models, both in architecture and deployment, introducing unique AI safety challenges, including goal misalignment, compounding decision errors, and coordination risks among interacting agents, that necessitate embedding interpretability and explainability by design to ensure traceability and accountability across their autonomous behaviors. Current interpretability techniques, developed primarily for static models, show limitations when applied to agentic systems. The temporal dynamics, compounding decisions, and context-dependent behaviors of agentic systems demand new analytical approaches. This paper assesses the suitability and limitations of existing interpretability methods in the context of agentic systems, identifying gaps in their capacity to provide meaningful insight into agent decision-making. We propose future directions for developing interpretability techniques specifically designed for agentic systems, pinpointing where interpretability is required to embed oversight mechanisms across the agent lifecycle from goal formation, through environmental interaction, to outcome evaluation. These advances are essential to ensure the safe and accountable deployment of agentic AI systems.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u73b0\u6709\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5728\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u5c40\u9650\uff0c\u63d0\u51fa\u9700\u5f00\u53d1\u4e13\u95e8\u9488\u5bf9\u667a\u80fd\u4f53\u7cfb\u7edf\u7279\u6027\u7684\u65b0\u53ef\u89e3\u91ca\u6027\u6280\u672f\uff0c\u4ee5\u4fdd\u969cAI\u7cfb\u7edf\u7684\u5b89\u5168\u90e8\u7f72\u3002", "motivation": "\u667a\u80fd\u4f53\u7cfb\u7edf\u4e0e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u67b6\u6784\u548c\u90e8\u7f72\u4e0a\u5b58\u5728\u6839\u672c\u5dee\u5f02\uff0c\u5f15\u5165\u4e86\u72ec\u7279\u7684\u5b89\u5168\u6311\u6218\uff08\u5982\u76ee\u6807\u9519\u4f4d\u3001\u51b3\u7b56\u9519\u8bef\u7d2f\u79ef\u3001\u591a\u667a\u80fd\u4f53\u534f\u8c03\u98ce\u9669\uff09\uff0c\u800c\u73b0\u6709\u4e3b\u8981\u4e3a\u9759\u6001\u6a21\u578b\u8bbe\u8ba1\u7684\u53ef\u89e3\u91ca\u6027\u6280\u672f\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u667a\u80fd\u4f53\u7cfb\u7edf\u5f00\u53d1\u65b0\u7684\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u3002", "method": "\u8bc4\u4f30\u73b0\u6709\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5728\u667a\u80fd\u4f53\u7cfb\u7edf\u80cc\u666f\u4e0b\u7684\u9002\u7528\u6027\u548c\u5c40\u9650\u6027\uff0c\u8bc6\u522b\u5176\u5728\u63d0\u4f9b\u667a\u80fd\u4f53\u51b3\u7b56\u6d1e\u5bdf\u65b9\u9762\u7684\u80fd\u529b\u5dee\u8ddd\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u5f00\u53d1\u4e13\u95e8\u9488\u5bf9\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u6280\u672f\u65b9\u5411\u3002", "result": "\u53d1\u73b0\u73b0\u6709\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5728\u5e94\u7528\u4e8e\u667a\u80fd\u4f53\u7cfb\u7edf\u65f6\u5b58\u5728\u663e\u8457\u5c40\u9650\uff0c\u65e0\u6cd5\u5145\u5206\u5e94\u5bf9\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u65f6\u5e8f\u52a8\u6001\u6027\u3001\u51b3\u7b56\u7d2f\u79ef\u6548\u5e94\u548c\u4e0a\u4e0b\u6587\u4f9d\u8d56\u884c\u4e3a\u7b49\u7279\u6027\uff0c\u9700\u8981\u65b0\u7684\u5206\u6790\u65b9\u6cd5\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u9488\u5bf9\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u7684\u53ef\u89e3\u91ca\u6027\u6280\u672f\uff0c\u5728\u667a\u80fd\u4f53\u751f\u547d\u5468\u671f\u7684\u5404\u4e2a\u9636\u6bb5\uff08\u76ee\u6807\u5f62\u6210\u3001\u73af\u5883\u4ea4\u4e92\u3001\u7ed3\u679c\u8bc4\u4f30\uff09\u5d4c\u5165\u53ef\u89e3\u91ca\u6027\u673a\u5236\uff0c\u8fd9\u5bf9\u4e8e\u786e\u4fdd\u667a\u80fd\u4f53AI\u7cfb\u7edf\u7684\u5b89\u5168\u548c\u53ef\u95ee\u8d23\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2601.17438", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17438", "abs": "https://arxiv.org/abs/2601.17438", "authors": ["Jialei Li", "Yang Zhang", "Yimeng Bai", "Shuai Zhu", "Ziqi Xue", "Xiaoyan Zhao", "Dingxian Wang", "Frank Yang", "Andrew Rabinovich", "Xiangnan He"], "title": "UniGRec: Unified Generative Recommendation with Soft Identifiers for End-to-End Optimization", "comment": "11 pages, 6 figures", "summary": "Generative recommendation has recently emerged as a transformative paradigm that directly generates target items, surpassing traditional cascaded approaches. It typically involves two components: a tokenizer that learns item identifiers and a recommender trained on them. Existing methods often decouple tokenization from recommendation or rely on asynchronous alternating optimization, limiting full end-to-end alignment. To address this, we unify the tokenizer and recommender under the ultimate recommendation objective via differentiable soft item identifiers, enabling joint end-to-end training. However, this introduces three challenges: training-inference discrepancy due to soft-to-hard mismatch, item identifier collapse from codeword usage imbalance, and collaborative signal deficiency due to an overemphasis on fine-grained token-level semantics.\n  To tackle these challenges, we propose UniGRec, a unified generative recommendation framework that addresses them from three perspectives. UniGRec employs Annealed Inference Alignment during tokenization to smoothly bridge soft training and hard inference, a Codeword Uniformity Regularization to prevent identifier collapse and encourage codebook diversity, and a Dual Collaborative Distillation mechanism that distills collaborative priors from a lightweight teacher model to jointly guide both the tokenizer and the recommender. Extensive experiments on real-world datasets demonstrate that UniGRec consistently outperforms state-of-the-art baseline methods. Our codes are available at https://github.com/Jialei-03/UniGRec.", "code_url": "https://github.com/Jialei-03/UniGRec", "code_stars": 0, "code_last_update": "2026-01-27", "AI": {"tldr": "UniGRec\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u751f\u6210\u5f0f\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u8f6f\u9879\u76ee\u6807\u8bc6\u7b26\u5c06\u5206\u8bcd\u5668\u548c\u63a8\u8350\u5668\u7edf\u4e00\u5728\u6700\u7ec8\u63a8\u8350\u76ee\u6807\u4e0b\uff0c\u89e3\u51b3\u4e86\u8bad\u7ec3-\u63a8\u7406\u5dee\u5f02\u3001\u9879\u76ee\u6807\u8bc6\u7b26\u5d29\u6e83\u548c\u534f\u4f5c\u4fe1\u53f7\u4e0d\u8db3\u4e09\u5927\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u63a8\u8350\u65b9\u6cd5\u901a\u5e38\u5c06\u5206\u8bcd\u5668\u4e0e\u63a8\u8350\u5668\u89e3\u8026\u6216\u4f9d\u8d56\u5f02\u6b65\u4ea4\u66ff\u4f18\u5316\uff0c\u9650\u5236\u4e86\u7aef\u5230\u7aef\u5bf9\u9f50\u3002\u4e3a\u4e86\u7edf\u4e00\u5206\u8bcd\u5668\u548c\u63a8\u8350\u5668\u5728\u6700\u7ec8\u63a8\u8350\u76ee\u6807\u4e0b\u8fdb\u884c\u8054\u5408\u7aef\u5230\u7aef\u8bad\u7ec3\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5f15\u5165\u4e86\u4e09\u4e2a\u6311\u6218\uff1a\u8f6f\u786c\u4e0d\u5339\u914d\u5bfc\u81f4\u7684\u8bad\u7ec3-\u63a8\u7406\u5dee\u5f02\u3001\u7801\u5b57\u4f7f\u7528\u4e0d\u5e73\u8861\u5bfc\u81f4\u7684\u6807\u8bc6\u7b26\u5d29\u6e83\u3001\u4ee5\u53ca\u8fc7\u5ea6\u5173\u6ce8\u7ec6\u7c92\u5ea6\u8bed\u4e49\u5bfc\u81f4\u7684\u534f\u4f5c\u4fe1\u53f7\u4e0d\u8db3\u3002", "method": "UniGRec\u91c7\u7528\u4e09\u65b9\u9762\u7b56\u7565\uff1a1) \u9000\u706b\u63a8\u7406\u5bf9\u9f50\uff1a\u5728\u5206\u8bcd\u8fc7\u7a0b\u4e2d\u5e73\u6ed1\u8fde\u63a5\u8f6f\u8bad\u7ec3\u548c\u786c\u63a8\u7406\uff1b2) \u7801\u5b57\u5747\u5300\u6027\u6b63\u5219\u5316\uff1a\u9632\u6b62\u6807\u8bc6\u7b26\u5d29\u6e83\u5e76\u9f13\u52b1\u7801\u672c\u591a\u6837\u6027\uff1b3) \u53cc\u91cd\u534f\u4f5c\u84b8\u998f\uff1a\u4ece\u8f7b\u91cf\u7ea7\u6559\u5e08\u6a21\u578b\u4e2d\u84b8\u998f\u534f\u4f5c\u5148\u9a8c\uff0c\u5171\u540c\u6307\u5bfc\u5206\u8bcd\u5668\u548c\u63a8\u8350\u5668\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cUniGRec\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "UniGRec\u901a\u8fc7\u7edf\u4e00\u6846\u67b6\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u5206\u8bcd\u5668\u548c\u63a8\u8350\u5668\u7684\u7aef\u5230\u7aef\u8054\u5408\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2601.16999", "categories": ["cs.CL", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.16999", "abs": "https://arxiv.org/abs/2601.16999", "authors": ["Matthew Singer", "Srijan Sengupta", "Karl Pazdernik"], "title": "Uncertainty Quantification for Named Entity Recognition via Full-Sequence and Subsequence Conformal Prediction", "comment": null, "summary": "Named Entity Recognition (NER) serves as a foundational component in many natural language processing (NLP) pipelines. However, current NER models typically output a single predicted label sequence without any accompanying measure of uncertainty, leaving downstream applications vulnerable to cascading errors. In this paper, we introduce a general framework for adapting sequence-labeling-based NER models to produce uncertainty-aware prediction sets. These prediction sets are collections of full-sentence labelings that are guaranteed to contain the correct labeling with a user-specified confidence level. This approach serves a role analogous to confidence intervals in classical statistics by providing formal guarantees about the reliability of model predictions. Our method builds on conformal prediction, which offers finite-sample coverage guarantees under minimal assumptions. We design efficient nonconformity scoring functions to construct efficient, well-calibrated prediction sets that support both unconditional and class-conditional coverage. This framework accounts for heterogeneity across sentence length, language, entity type, and number of entities within a sentence. Empirical experiments on four NER models across three benchmark datasets demonstrate the broad applicability, validity, and efficiency of the proposed methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u5e8f\u5217\u6807\u6ce8\u7684NER\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u9884\u6d4b\u96c6\u6846\u67b6\uff0c\u901a\u8fc7\u4fdd\u5f62\u9884\u6d4b\u63d0\u4f9b\u6709\u9650\u6837\u672c\u8986\u76d6\u4fdd\u8bc1\uff0c\u751f\u6210\u5305\u542b\u6b63\u786e\u6807\u6ce8\u7684\u9884\u6d4b\u96c6\u5408", "motivation": "\u5f53\u524dNER\u6a21\u578b\u901a\u5e38\u53ea\u8f93\u51fa\u5355\u4e00\u9884\u6d4b\u6807\u7b7e\u5e8f\u5217\uff0c\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\uff0c\u5bfc\u81f4\u4e0b\u6e38\u5e94\u7528\u5bb9\u6613\u53d7\u5230\u7ea7\u8054\u9519\u8bef\u5f71\u54cd\uff0c\u9700\u8981\u63d0\u4f9b\u7c7b\u4f3c\u7f6e\u4fe1\u533a\u95f4\u7684\u53ef\u9760\u6027\u4fdd\u8bc1", "method": "\u57fa\u4e8e\u4fdd\u5f62\u9884\u6d4b\u6846\u67b6\uff0c\u8bbe\u8ba1\u9ad8\u6548\u7684\u975e\u4fdd\u5f62\u6027\u8bc4\u5206\u51fd\u6570\uff0c\u6784\u5efa\u652f\u6301\u65e0\u6761\u4ef6\u8986\u76d6\u548c\u7c7b\u522b\u6761\u4ef6\u8986\u76d6\u7684\u6821\u51c6\u9884\u6d4b\u96c6\uff0c\u8003\u8651\u53e5\u5b50\u957f\u5ea6\u3001\u8bed\u8a00\u3001\u5b9e\u4f53\u7c7b\u578b\u548c\u5b9e\u4f53\u6570\u91cf\u7b49\u5f02\u8d28\u6027\u56e0\u7d20", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u56db\u4e2aNER\u6a21\u578b\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3001\u6709\u6548\u6027\u548c\u9ad8\u6548\u6027\uff0c\u80fd\u591f\u63d0\u4f9b\u53ef\u9760\u7684\u8986\u76d6\u4fdd\u8bc1", "conclusion": "\u8be5\u6846\u67b6\u4e3aNER\u6a21\u578b\u63d0\u4f9b\u4e86\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u9884\u6d4b\u96c6\uff0c\u7c7b\u4f3c\u4e8e\u4f20\u7edf\u7edf\u8ba1\u4e2d\u7684\u7f6e\u4fe1\u533a\u95f4\uff0c\u4e3a\u4e0b\u6e38\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u6027\u4fdd\u8bc1\uff0c\u89e3\u51b3\u4e86\u5f53\u524dNER\u6a21\u578b\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u7684\u95ee\u9898"}}
{"id": "2601.17472", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.17472", "abs": "https://arxiv.org/abs/2601.17472", "authors": ["Junyou He", "Lixi Deng", "Huichao Guo", "Ye Tang", "Yong Li", "Sulong Xu"], "title": "Adversarial Alignment and Disentanglement for Cross-Domain CTR Prediction with Domain-Encompassing Features", "comment": "Accepted to ICDM 2025", "summary": "Cross-domain recommendation (CDR) has been increasingly explored to address data sparsity and cold-start issues. However, recent approaches typically disentangle domain-invariant features shared between source and target domains, as well as domain-specific features for each domain. However, they often rely solely on domain-invariant features combined with target domain-specific features, which can lead to suboptimal performance. To overcome the limitations, this paper presents the Adversarial Alignment and Disentanglement Cross-Domain Recommendation ($A^2DCDR$ ) model, an innovative approach designed to capture a comprehensive range of cross-domain information, including both domain-invariant and valuable non-aligned features. The $A^2DCDR$ model enhances cross-domain recommendation through three key components: refining MMD with adversarial training for better generalization, employing a feature disentangler and reconstruction mechanism for intra-domain disentanglement, and introducing a novel fused representation combining domain-invariant, non-aligned features with original contextual data. Experiments on real-world datasets and online A/B testing show that $A^2DCDR$ outperforms existing methods, confirming its effectiveness and practical applicability. The code is provided at https://github.com/youzi0925/A-2DCDR/tree/main.", "code_url": "https://github.com/youzi0925/A-2DCDR", "code_stars": 0, "code_last_update": "2025-09-22", "AI": {"tldr": "A\u00b2DCDR\u6a21\u578b\u901a\u8fc7\u5bf9\u6297\u5bf9\u9f50\u548c\u7279\u5f81\u89e3\u8026\u6539\u8fdb\u8de8\u57df\u63a8\u8350\uff0c\u7ed3\u5408\u57df\u4e0d\u53d8\u7279\u5f81\u3001\u975e\u5bf9\u9f50\u7279\u5f81\u548c\u539f\u59cb\u4e0a\u4e0b\u6587\u6570\u636e\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u57df\u4e0d\u53d8\u7279\u5f81\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u8de8\u57df\u63a8\u8350\u65b9\u6cd5\u901a\u5e38\u4ec5\u89e3\u8026\u57df\u4e0d\u53d8\u7279\u5f81\u548c\u57df\u7279\u5b9a\u7279\u5f81\uff0c\u5e76\u4e3b\u8981\u4f9d\u8d56\u57df\u4e0d\u53d8\u7279\u5f81\u7ed3\u5408\u76ee\u6807\u57df\u7279\u5b9a\u7279\u5f81\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6b21\u4f18\u6027\u80fd\u3002\u9700\u8981\u66f4\u5168\u9762\u5730\u6355\u6349\u8de8\u57df\u4fe1\u606f\uff0c\u5305\u62ec\u57df\u4e0d\u53d8\u7279\u5f81\u548c\u6709\u4ef7\u503c\u7684\u975e\u5bf9\u9f50\u7279\u5f81\u3002", "method": "\u63d0\u51faA\u00b2DCDR\u6a21\u578b\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1) \u901a\u8fc7\u5bf9\u6297\u8bad\u7ec3\u6539\u8fdbMMD\u4ee5\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\uff1b2) \u4f7f\u7528\u7279\u5f81\u89e3\u8026\u5668\u548c\u91cd\u6784\u673a\u5236\u5b9e\u73b0\u57df\u5185\u89e3\u8026\uff1b3) \u5f15\u5165\u878d\u5408\u8868\u793a\uff0c\u7ed3\u5408\u57df\u4e0d\u53d8\u7279\u5f81\u3001\u975e\u5bf9\u9f50\u7279\u5f81\u548c\u539f\u59cb\u4e0a\u4e0b\u6587\u6570\u636e\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\uff0cA\u00b2DCDR\u6a21\u578b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8bc1\u5b9e\u4e86\u5176\u6709\u6548\u6027\u548c\u5b9e\u9645\u9002\u7528\u6027\u3002", "conclusion": "A\u00b2DCDR\u6a21\u578b\u901a\u8fc7\u5bf9\u6297\u5bf9\u9f50\u548c\u7279\u5f81\u89e3\u8026\uff0c\u80fd\u591f\u66f4\u5168\u9762\u5730\u6355\u6349\u8de8\u57df\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u8de8\u57df\u63a8\u8350\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u6570\u636e\u7a00\u758f\u548c\u51b7\u542f\u52a8\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2601.17002", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17002", "abs": "https://arxiv.org/abs/2601.17002", "authors": ["Ziyang Zhou", "Ziqi Liu", "Yan Wang", "Yiming Lin", "Yangbin Chen"], "title": "RAM-SD: Retrieval-Augmented Multi-agent framework for Sarcasm Detection", "comment": "12 pages, 4 figures, 6 tables, preprint", "summary": "Sarcasm detection remains a significant challenge due to its reliance on nuanced contextual understanding, world knowledge, and multi-faceted linguistic cues that vary substantially across different sarcastic expressions. Existing approaches, from fine-tuned transformers to large language models, apply a uniform reasoning strategy to all inputs, struggling to address the diverse analytical demands of sarcasm. These demands range from modeling contextual expectation violations to requiring external knowledge grounding or recognizing specific rhetorical patterns. To address this limitation, we introduce RAM-SD, a Retrieval-Augmented Multi-Agent framework for Sarcasm Detection. The framework operates through four stages: (1) contextual retrieval grounds the query in both sarcastic and non-sarcastic exemplars; (2) a meta-planner classifies the sarcasm type and selects an optimal reasoning plan from a predefined set; (3) an ensemble of specialized agents performs complementary, multi-view analysis; and (4) an integrator synthesizes these analyses into a final, interpretable judgment with a natural language explanation. Evaluated on four standard benchmarks, RAM-SD achieves a state-of-the-art Macro-F1 of 77.74%, outperforming the strong GPT-4o+CoC baseline by 7.01 points. Our framework not only sets a new performance benchmark but also provides transparent and interpretable reasoning traces, illuminating the cognitive processes behind sarcasm comprehension.", "AI": {"tldr": "RAM-SD\uff1a\u4e00\u4e2a\u7528\u4e8e\u8bbd\u523a\u68c0\u6d4b\u7684\u68c0\u7d22\u589e\u5f3a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u56db\u9636\u6bb5\u6d41\u7a0b\u5b9e\u73b0SOTA\u6027\u80fd\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8fc7\u7a0b", "motivation": "\u73b0\u6709\u8bbd\u523a\u68c0\u6d4b\u65b9\u6cd5\u91c7\u7528\u7edf\u4e00\u7684\u63a8\u7406\u7b56\u7565\u5904\u7406\u6240\u6709\u8f93\u5165\uff0c\u96be\u4ee5\u5e94\u5bf9\u8bbd\u523a\u8868\u8fbe\u4e2d\u591a\u6837\u7684\u5206\u6790\u9700\u6c42\uff0c\u5305\u62ec\u4e0a\u4e0b\u6587\u671f\u671b\u8fdd\u53cd\u5efa\u6a21\u3001\u5916\u90e8\u77e5\u8bc6\u57fa\u7840\u3001\u7279\u5b9a\u4fee\u8f9e\u6a21\u5f0f\u8bc6\u522b\u7b49", "method": "\u63d0\u51faRAM-SD\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u9636\u6bb5\uff1a(1)\u4e0a\u4e0b\u6587\u68c0\u7d22\uff1a\u57fa\u4e8e\u8bbd\u523a\u548c\u975e\u8bbd\u523a\u8303\u4f8b\u8fdb\u884c\u67e5\u8be2\uff1b(2)\u5143\u89c4\u5212\u5668\uff1a\u5206\u7c7b\u8bbd\u523a\u7c7b\u578b\u5e76\u9009\u62e9\u6700\u4f18\u63a8\u7406\u8ba1\u5212\uff1b(3)\u4e13\u4e1a\u5316\u667a\u80fd\u4f53\u96c6\u6210\uff1a\u6267\u884c\u4e92\u8865\u7684\u591a\u89c6\u89d2\u5206\u6790\uff1b(4)\u96c6\u6210\u5668\uff1a\u7efc\u5408\u5206\u6790\u751f\u6210\u6700\u7ec8\u53ef\u89e3\u91ca\u5224\u65ad\u548c\u81ea\u7136\u8bed\u8a00\u89e3\u91ca", "result": "\u5728\u56db\u4e2a\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRAM-SD\u5b9e\u73b0\u4e8677.74%\u7684Macro-F1\u5206\u6570\uff0c\u6bd4\u5f3a\u5927\u7684GPT-4o+CoC\u57fa\u7ebf\u9ad8\u51fa7.01\u4e2a\u767e\u5206\u70b9\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd", "conclusion": "RAM-SD\u4e0d\u4ec5\u8bbe\u5b9a\u4e86\u65b0\u7684\u6027\u80fd\u57fa\u51c6\uff0c\u8fd8\u63d0\u4f9b\u4e86\u900f\u660e\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u63ed\u793a\u4e86\u8bbd\u523a\u7406\u89e3\u80cc\u540e\u7684\u8ba4\u77e5\u8fc7\u7a0b\uff0c\u4e3a\u590d\u6742\u8bed\u8a00\u7406\u89e3\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u8303\u4f8b"}}
{"id": "2601.17310", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17310", "abs": "https://arxiv.org/abs/2601.17310", "authors": ["Yu Akagi", "Tomohisa Seki", "Hiromasa Ito", "Toru Takiguchi", "Kazuhiko Ohe", "Yoshimasa Kawazoe"], "title": "High-Fidelity Longitudinal Patient Simulation Using Real-World Data", "comment": null, "summary": "Simulation is a powerful tool for exploring uncertainty. Its potential in clinical medicine is transformative and includes personalized treatment planning and virtual clinical trials. However, simulating patient trajectories is challenging because of complex biological and sociocultural influences. Here, we show that real-world clinical records can be leveraged to empirically model patient timelines. We developed a generative simulator model that takes a patient's history as input and synthesizes fine-grained, realistic future trajectories. The model was pretrained on more than 200 million clinical records. It produced high-fidelity future timelines, closely matching event occurrence rates, laboratory test results, and temporal dynamics in real patient future data. It also accurately estimated future event probabilities, with observed-to-expected ratios consistently near 1.0 across diverse outcomes and time horizons. Our results reveal the untapped value of real-world data in electronic health records and introduce a scalable framework for in silico modeling of clinical care.", "AI": {"tldr": "\u5229\u7528\u771f\u5b9e\u4e16\u754c\u4e34\u5e8a\u8bb0\u5f55\u6784\u5efa\u751f\u6210\u5f0f\u6a21\u62df\u5668\u6a21\u578b\uff0c\u80fd\u591f\u57fa\u4e8e\u60a3\u8005\u5386\u53f2\u751f\u6210\u9ad8\u4fdd\u771f\u7684\u672a\u6765\u4e34\u5e8a\u8f68\u8ff9\uff0c\u4e3a\u4e2a\u6027\u5316\u6cbb\u7597\u89c4\u5212\u548c\u865a\u62df\u4e34\u5e8a\u8bd5\u9a8c\u63d0\u4f9b\u652f\u6301\u3002", "motivation": "\u4e34\u5e8a\u533b\u5b66\u4e2d\u6a21\u62df\u60a3\u8005\u8f68\u8ff9\u5177\u6709\u53d8\u9769\u6027\u6f5c\u529b\uff0c\u53ef\u7528\u4e8e\u4e2a\u6027\u5316\u6cbb\u7597\u89c4\u5212\u548c\u865a\u62df\u4e34\u5e8a\u8bd5\u9a8c\u3002\u7136\u800c\uff0c\u7531\u4e8e\u590d\u6742\u7684\u751f\u7269\u548c\u793e\u4f1a\u6587\u5316\u5f71\u54cd\uff0c\u6a21\u62df\u60a3\u8005\u8f68\u8ff9\u5177\u6709\u6311\u6218\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528\u771f\u5b9e\u4e16\u754c\u4e34\u5e8a\u8bb0\u5f55\u7ecf\u9a8c\u6027\u5730\u5efa\u6a21\u60a3\u8005\u65f6\u95f4\u7ebf\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u751f\u6210\u5f0f\u6a21\u62df\u5668\u6a21\u578b\uff0c\u4ee5\u60a3\u8005\u5386\u53f2\u4e3a\u8f93\u5165\uff0c\u5408\u6210\u7ec6\u7c92\u5ea6\u3001\u771f\u5b9e\u7684\u672a\u6765\u8f68\u8ff9\u3002\u8be5\u6a21\u578b\u5728\u8d85\u8fc72\u4ebf\u6761\u4e34\u5e8a\u8bb0\u5f55\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\u3002", "result": "\u6a21\u578b\u751f\u6210\u4e86\u9ad8\u4fdd\u771f\u7684\u672a\u6765\u65f6\u95f4\u7ebf\uff0c\u4e0e\u771f\u5b9e\u60a3\u8005\u672a\u6765\u6570\u636e\u4e2d\u7684\u4e8b\u4ef6\u53d1\u751f\u7387\u3001\u5b9e\u9a8c\u5ba4\u68c0\u6d4b\u7ed3\u679c\u548c\u65f6\u95f4\u52a8\u6001\u5bc6\u5207\u5339\u914d\u3002\u51c6\u786e\u4f30\u8ba1\u4e86\u672a\u6765\u4e8b\u4ef6\u6982\u7387\uff0c\u5728\u4e0d\u540c\u7ed3\u679c\u548c\u65f6\u95f4\u8303\u56f4\u5185\u89c2\u5bdf\u5230\u4e0e\u9884\u671f\u6bd4\u7387\u59cb\u7ec8\u63a5\u8fd11.0\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u771f\u5b9e\u4e16\u754c\u6570\u636e\u7684\u672a\u5f00\u53d1\u4ef7\u503c\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u4e34\u5e8a\u62a4\u7406\u8ba1\u7b97\u673a\u6a21\u62df\u6846\u67b6\u3002"}}
{"id": "2601.17492", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.17492", "abs": "https://arxiv.org/abs/2601.17492", "authors": ["Jin Li", "Huilin Gu", "Shoujin Wang", "Qi Zhang", "Shui Yu", "Chen Wang", "Xiwei Xu", "Fang Chen"], "title": "Towards Fair Large Language Model-based Recommender Systems without Costly Retraining", "comment": "Accepted by WWW 2026", "summary": "Large Language Models (LLMs) have revolutionized Recommender Systems (RS) through advanced generative user modeling. However, LLM-based RS (LLM-RS) often inadvertently perpetuates bias present in the training data, leading to severe fairness issues. Addressing these fairness problems in LLM-RS faces two significant challenges. 1) Existing debiasing methods, designed for specific bias types, lack the generality to handle diverse or emerging biases in real-world applications. 2) Debiasing methods relying on retraining are computationally infeasible given the massive parameter scale of LLMs. To overcome these challenges, we propose FUDLR (Fast Unified Debiasing for LLM-RS). The core idea is to reformulate the debiasing problem as an efficient machine unlearning task with two stages. First, FUDLR identifies bias-inducing samples to unlearn through a novel bias-agnostic mask, optimized to balance fairness improvement with accuracy preservation. Its bias-agnostic design allows adaptability to various or co-existing biases simply by incorporating different fairness metrics. Second, FUDLR performs efficient debiasing by estimating and removing the influence of identified samples on model parameters. Extensive experiments demonstrate that FUDLR effectively and efficiently improves fairness while preserving recommendation accuracy, offering a practical path toward socially responsible LLM-RS. The code and data are available at https://github.com/JinLi-i/FUDLR.", "code_url": "https://github.com/JinLi-i/FUDLR", "code_stars": 0, "code_last_update": "2026-01-20", "AI": {"tldr": "FUDLR\u63d0\u51fa\u4e86\u4e00\u79cd\u5feb\u901f\u7edf\u4e00\u7684LLM\u63a8\u8350\u7cfb\u7edf\u53bb\u504f\u65b9\u6cd5\uff0c\u5c06\u53bb\u504f\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u9ad8\u6548\u673a\u5668\u9057\u5fd8\u4efb\u52a1\uff0c\u901a\u8fc7\u504f\u7f6e\u65e0\u5173\u63a9\u7801\u8bc6\u522b\u504f\u7f6e\u6837\u672c\u5e76\u8fdb\u884c\u9ad8\u6548\u53bb\u504f", "motivation": "LLM\u63a8\u8350\u7cfb\u7edf\u5bb9\u6613\u65e0\u610f\u4e2d\u5ef6\u7eed\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u504f\u7f6e\uff0c\u5bfc\u81f4\u4e25\u91cd\u7684\u516c\u5e73\u6027\u95ee\u9898\u3002\u73b0\u6709\u53bb\u504f\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a1) \u9488\u5bf9\u7279\u5b9a\u504f\u7f6e\u7c7b\u578b\u8bbe\u8ba1\uff0c\u7f3a\u4e4f\u5904\u7406\u591a\u6837\u6216\u65b0\u5174\u504f\u7f6e\u7684\u901a\u7528\u6027\uff1b2) \u4f9d\u8d56\u91cd\u65b0\u8bad\u7ec3\u7684\u65b9\u6cd5\u5728LLM\u5de8\u5927\u53c2\u6570\u91cf\u4e0b\u8ba1\u7b97\u4e0d\u53ef\u884c", "method": "FUDLR\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u901a\u8fc7\u65b0\u9896\u7684\u504f\u7f6e\u65e0\u5173\u63a9\u7801\u8bc6\u522b\u9700\u8981\u9057\u5fd8\u7684\u504f\u7f6e\u8bf1\u5bfc\u6837\u672c\uff0c\u4f18\u5316\u516c\u5e73\u6027\u6539\u8fdb\u4e0e\u51c6\u786e\u6027\u4fdd\u6301\u7684\u5e73\u8861\uff1b2) \u901a\u8fc7\u4f30\u8ba1\u5e76\u79fb\u9664\u5df2\u8bc6\u522b\u6837\u672c\u5bf9\u6a21\u578b\u53c2\u6570\u7684\u5f71\u54cd\u8fdb\u884c\u9ad8\u6548\u53bb\u504f\u3002\u504f\u7f6e\u65e0\u5173\u8bbe\u8ba1\u5141\u8bb8\u901a\u8fc7\u7eb3\u5165\u4e0d\u540c\u516c\u5e73\u6027\u6307\u6807\u9002\u5e94\u5404\u79cd\u6216\u5171\u5b58\u7684\u504f\u7f6e", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cFUDLR\u80fd\u6709\u6548\u4e14\u9ad8\u6548\u5730\u63d0\u9ad8\u516c\u5e73\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u8350\u51c6\u786e\u6027\uff0c\u4e3a\u6784\u5efa\u793e\u4f1a\u8d23\u4efb\u7684LLM\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84", "conclusion": "FUDLR\u4e3a\u89e3\u51b3LLM\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u3001\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5c06\u53bb\u504f\u91cd\u65b0\u5b9a\u4e49\u4e3a\u673a\u5668\u9057\u5fd8\u4efb\u52a1\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u6539\u5584\u516c\u5e73\u6027\u7684\u76ee\u6807"}}
{"id": "2601.17132", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17132", "abs": "https://arxiv.org/abs/2601.17132", "authors": ["Vigneshwaran Shankaran", "Gabriella Lapesa", "Claudia Wagner"], "title": "From Emotion to Expression: Theoretical Foundations and Resources for Fear Speech", "comment": "Paper accepted to EACL Mains 2026", "summary": "Few forces rival fear in their ability to mobilize societies, distort communication, and reshape collective behavior. In computational linguistics, fear is primarily studied as an emotion, but not as a distinct form of speech. Fear speech content is widespread and growing, and often outperforms hate-speech content in reach and engagement because it appears \"civiler\" and evades moderation. Yet the computational study of fear speech remains fragmented and under-resourced. This can be understood by recognizing that fear speech is a phenomenon shaped by contributions from multiple disciplines. In this paper, we bridge cross-disciplinary perspectives by comparing theories of fear from Psychology, Political science, Communication science, and Linguistics. Building on this, we review existing definitions. We follow up with a survey of datasets from related research areas and propose a taxonomy that consolidates different dimensions of fear for studying fear speech. By reviewing current datasets and defining core concepts, our work offers both theoretical and practical guidance for creating datasets and advancing fear speech research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u6574\u5408\u5fc3\u7406\u5b66\u3001\u653f\u6cbb\u5b66\u3001\u4f20\u64ad\u5b66\u548c\u8bed\u8a00\u5b66\u7b49\u591a\u5b66\u79d1\u89c6\u89d2\uff0c\u7cfb\u7edf\u6027\u5730\u7814\u7a76\u4e86\u6050\u60e7\u8a00\u8bba\u8fd9\u4e00\u73b0\u8c61\uff0c\u63d0\u51fa\u4e86\u5206\u7c7b\u6846\u67b6\u5e76\u56de\u987e\u4e86\u73b0\u6709\u6570\u636e\u96c6\uff0c\u4e3a\u6050\u60e7\u8a00\u8bba\u7814\u7a76\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u6307\u5bfc\u3002", "motivation": "\u6050\u60e7\u8a00\u8bba\u4f5c\u4e3a\u4e00\u79cd\u72ec\u7279\u7684\u8a00\u8bba\u5f62\u5f0f\uff0c\u5728\u793e\u4ea4\u5a92\u4f53\u4e2d\u5e7f\u6cdb\u4f20\u64ad\u4e14\u5f71\u54cd\u529b\u5e38\u8d85\u8fc7\u4ec7\u6068\u8a00\u8bba\uff0c\u4f46\u7531\u4e8e\u5176\"\u770b\u4f3c\u6587\u660e\"\u7684\u7279\u70b9\u5f80\u5f80\u9003\u907f\u5185\u5bb9\u5ba1\u6838\u3002\u76ee\u524d\u8ba1\u7b97\u8bed\u8a00\u5b66\u9886\u57df\u5bf9\u6050\u60e7\u8a00\u8bba\u7684\u7814\u7a76\u4ecd\u5904\u4e8e\u788e\u7247\u5316\u548c\u8d44\u6e90\u4e0d\u8db3\u7684\u72b6\u6001\uff0c\u9700\u8981\u8de8\u5b66\u79d1\u6574\u5408\u6765\u5efa\u7acb\u7cfb\u7edf\u7684\u7814\u7a76\u6846\u67b6\u3002", "method": "1. \u6bd4\u8f83\u5fc3\u7406\u5b66\u3001\u653f\u6cbb\u5b66\u3001\u4f20\u64ad\u5b66\u548c\u8bed\u8a00\u5b66\u4e2d\u5173\u4e8e\u6050\u60e7\u7684\u7406\u8bba\uff1b2. \u56de\u987e\u73b0\u6709\u6050\u60e7\u8a00\u8bba\u5b9a\u4e49\uff1b3. \u8c03\u67e5\u76f8\u5173\u7814\u7a76\u9886\u57df\u7684\u6570\u636e\u96c6\uff1b4. \u63d0\u51fa\u6574\u5408\u6050\u60e7\u4e0d\u540c\u7ef4\u5ea6\u7684\u5206\u7c7b\u5b66\u6846\u67b6\u3002", "result": "\u5efa\u7acb\u4e86\u8de8\u5b66\u79d1\u7684\u6050\u60e7\u8a00\u8bba\u7814\u7a76\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u7cfb\u7edf\u6027\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u4e3a\u521b\u5efa\u6570\u636e\u96c6\u548c\u63a8\u8fdb\u6050\u60e7\u8a00\u8bba\u7814\u7a76\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6307\u5bfc\u3002\u901a\u8fc7\u6574\u5408\u591a\u5b66\u79d1\u89c6\u89d2\uff0c\u6f84\u6e05\u4e86\u6050\u60e7\u8a00\u8bba\u7684\u6838\u5fc3\u6982\u5ff5\u548c\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u6050\u60e7\u8a00\u8bba\u662f\u4e00\u79cd\u72ec\u7279\u4e14\u5177\u6709\u91cd\u8981\u793e\u4f1a\u5f71\u54cd\u7684\u8a00\u8bba\u5f62\u5f0f\uff0c\u9700\u8981\u8de8\u5b66\u79d1\u7684\u7cfb\u7edf\u7814\u7a76\u3002\u672c\u6587\u901a\u8fc7\u6574\u5408\u591a\u5b66\u79d1\u7406\u8bba\u3001\u5b9a\u4e49\u6838\u5fc3\u6982\u5ff5\u548c\u63d0\u51fa\u5206\u7c7b\u6846\u67b6\uff0c\u4e3a\u6050\u60e7\u8a00\u8bba\u7684\u8ba1\u7b97\u7814\u7a76\u5960\u5b9a\u4e86\u91cd\u8981\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u672a\u6765\u6570\u636e\u96c6\u6784\u5efa\u548c\u66f4\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u5f00\u53d1\u3002"}}
{"id": "2601.17311", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17311", "abs": "https://arxiv.org/abs/2601.17311", "authors": ["Bang Liu", "Linglong Kong", "Jian Pei"], "title": "Phase Transition for Budgeted Multi-Agent Synergy", "comment": "55 pages, 12 figures", "summary": "Multi-agent systems can improve reliability, yet under a fixed inference budget they often help, saturate, or even collapse. We develop a minimal and calibratable theory that predicts these regimes from three binding constraints of modern agent stacks: finite context windows, lossy inter-agent communication, and shared failures among similar agents. Each leaf agent is summarized by a compute-performance scaling exponent $\u03b2$; communication is captured by a message-length fidelity curve $\u03b3(m)$; dependence is captured by an effective shared-error correlation $\u03c1$; and a context window $W$ imposes hard fan-in limits that make hierarchy necessary. For binary success/failure tasks with majority aggregation, we prove a sharp phase transition for deep $b$-ary trees with correlated inputs and lossy communication: a single scalar $\u03b1_\u03c1$ (combining $\u03b3(m)$, $\u03c1$, and fan-in $b$) determines whether weak signal is amplified to a nontrivial fixed point or washed out to chance. In the amplifying regime, we derive an organization exponent $s$ and show that budgeted synergy, i.e., outperforming the best single agent under the same total budget, occurs exactly when $s>\u03b2$, yielding closed-form compute allocation rules and explicit budget thresholds. We further characterize saturation via a mixing depth and provide a conservative clipped predictor that remains accurate across growth and saturation. A continuous-performance warm-up gives closed-form risks for star, chain, and tree organizations, making correlation- and communication-induced floors explicit and exposing the core design trade-offs in a smooth setting. Finally, we validate the predicted phase boundaries in controlled synthetic simulations and show how the same mechanisms explain the dominant bottlenecks reported in recent large-scale matched-budget studies of LLM agent-system scaling.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u6821\u51c6\u7684\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u6709\u9650\u63a8\u7406\u9884\u7b97\u4e0b\u7684\u6027\u80fd\u8868\u73b0\uff0c\u8bc6\u522b\u51fa\u5e2e\u52a9\u3001\u9971\u548c\u548c\u5d29\u6e83\u4e09\u79cd\u673a\u5236\uff0c\u5e76\u63ed\u793a\u4e86\u4e0a\u4e0b\u6587\u7a97\u53e3\u3001\u901a\u4fe1\u635f\u5931\u548c\u667a\u80fd\u4f53\u76f8\u5173\u6027\u7b49\u7ea6\u675f\u6761\u4ef6\u5982\u4f55\u5f71\u54cd\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u56fa\u5b9a\u63a8\u7406\u9884\u7b97\u4e0b\u5e38\u5e38\u8868\u73b0\u51fa\u5e2e\u52a9\u3001\u9971\u548c\u751a\u81f3\u5d29\u6e83\u7684\u73b0\u8c61\uff0c\u73b0\u6709\u7406\u8bba\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u73b0\u8c61\u7684\u5b9a\u91cf\u9884\u6d4b\u80fd\u529b\u3002\u7814\u7a76\u8005\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u6700\u5c0f\u5316\u4e14\u53ef\u6821\u51c6\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4ece\u73b0\u4ee3\u667a\u80fd\u4f53\u5806\u6808\u7684\u4e09\u4e2a\u5173\u952e\u7ea6\u675f\uff08\u6709\u9650\u4e0a\u4e0b\u6587\u7a97\u53e3\u3001\u6709\u635f\u901a\u4fe1\u3001\u76f8\u4f3c\u667a\u80fd\u4f53\u95f4\u7684\u5171\u4eab\u6545\u969c\uff09\u51fa\u53d1\uff0c\u9884\u6d4b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u6bcf\u4e2a\u53f6\u5b50\u667a\u80fd\u4f53\u7528\u8ba1\u7b97-\u6027\u80fd\u7f29\u653e\u6307\u6570\u03b2\u63cf\u8ff0\uff0c\u901a\u4fe1\u7528\u6d88\u606f\u957f\u5ea6\u4fdd\u771f\u5ea6\u66f2\u7ebf\u03b3(m)\u63cf\u8ff0\uff0c\u76f8\u5173\u6027\u7528\u6709\u6548\u5171\u4eab\u8bef\u5dee\u76f8\u5173\u7cfb\u6570\u03c1\u63cf\u8ff0\uff0c\u4e0a\u4e0b\u6587\u7a97\u53e3W\u65bd\u52a0\u786c\u6027\u6247\u5165\u9650\u5236\u3002\u901a\u8fc7\u5206\u6790\u4e8c\u8fdb\u5236\u6210\u529f/\u5931\u8d25\u4efb\u52a1\u4e2d\u7684\u591a\u6570\u805a\u5408\uff0c\u8bc1\u660e\u4e86\u6df1\u5ea6b\u53c9\u6811\u5728\u76f8\u5173\u8f93\u5165\u548c\u6709\u635f\u901a\u4fe1\u4e0b\u7684\u5c16\u9510\u76f8\u53d8\u3002\u63a8\u5bfc\u4e86\u7ec4\u7ec7\u6307\u6570s\uff0c\u5e76\u7ed9\u51fa\u4e86\u8ba1\u7b97\u5206\u914d\u89c4\u5219\u548c\u9884\u7b97\u9608\u503c\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff1a\u5355\u4e2a\u6807\u91cf\u03b1\u03c1\uff08\u7ed3\u5408\u03b3(m)\u3001\u03c1\u548c\u6247\u5165b\uff09\u51b3\u5b9a\u4e86\u5f31\u4fe1\u53f7\u662f\u88ab\u653e\u5927\u5230\u975e\u5e73\u51e1\u56fa\u5b9a\u70b9\u8fd8\u662f\u88ab\u6d17\u724c\u5230\u968f\u673a\u6c34\u5e73\u3002\u5728\u653e\u5927\u673a\u5236\u4e2d\uff0c\u5f53s>\u03b2\u65f6\u51fa\u73b0\u9884\u7b97\u534f\u540c\u6548\u5e94\uff08\u5373\u4f18\u4e8e\u76f8\u540c\u603b\u9884\u7b97\u4e0b\u7684\u6700\u4f73\u5355\u4e2a\u667a\u80fd\u4f53\uff09\u3002\u901a\u8fc7\u6df7\u5408\u6df1\u5ea6\u8868\u5f81\u9971\u548c\u73b0\u8c61\uff0c\u5e76\u63d0\u4f9b\u4e86\u4fdd\u5b88\u7684\u88c1\u526a\u9884\u6d4b\u5668\u3002\u8fde\u7eed\u6027\u80fd\u70ed\u8eab\u7ed9\u51fa\u4e86\u661f\u578b\u3001\u94fe\u5f0f\u548c\u6811\u5f62\u7ec4\u7ec7\u7684\u95ed\u5f0f\u98ce\u9669\u516c\u5f0f\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u80fd\u591f\u9884\u6d4b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u6709\u9650\u9884\u7b97\u4e0b\u7684\u6027\u80fd\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u4e0a\u4e0b\u6587\u7a97\u53e3\u3001\u901a\u4fe1\u635f\u5931\u548c\u667a\u80fd\u4f53\u76f8\u5173\u6027\u4e4b\u95f4\u7684\u6838\u5fc3\u8bbe\u8ba1\u6743\u8861\u3002\u7406\u8bba\u9884\u6d4b\u5728\u5408\u6210\u6a21\u62df\u4e2d\u5f97\u5230\u9a8c\u8bc1\uff0c\u5e76\u80fd\u89e3\u91ca\u6700\u8fd1\u5927\u89c4\u6a21\u5339\u914d\u9884\u7b97\u7814\u7a76\u4e2d\u62a5\u544a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u7cfb\u7edf\u7f29\u653e\u7684\u4e3b\u8981\u74f6\u9888\u3002"}}
{"id": "2601.17500", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17500", "abs": "https://arxiv.org/abs/2601.17500", "authors": ["Emmanouil Georgios Lionis", "Jia-Huei Ju", "Angelos Nalmpantis", "Casper Thuis", "Sean MacAvaney", "Andrew Yates"], "title": "To Case or Not to Case: An Empirical Study in Learned Sparse Retrieval", "comment": "This preprint has not undergone peer review (when applicable) or any post-submission improvements or corrections. The Version of Record of this contribution is published in ECIR2026 (Part I) Advances in Information Retrieval", "summary": "Learned Sparse Retrieval (LSR) methods construct sparse lexical representations of queries and documents that can be efficiently searched using inverted indexes. Existing LSR approaches have relied almost exclusively on uncased backbone models, whose vocabularies exclude case-sensitive distinctions, thereby reducing vocabulary mismatch. However, the most recent state-of-the-art language models are only available in cased versions. Despite this shift, the impact of backbone model casing on LSR has not been studied, potentially posing a risk to the viability of the method going forward. To fill this gap, we systematically evaluate paired cased and uncased versions of the same backbone models across multiple datasets to assess their suitability for LSR. Our findings show that LSR models with cased backbone models by default perform substantially worse than their uncased counterparts; however, this gap can be eliminated by pre-processing the text to lowercase. Moreover, our token-level analysis reveals that, under lowercasing, cased models almost entirely suppress cased vocabulary items and behave effectively as uncased models, explaining their restored performance. This result broadens the applicability of recent cased models to the LSR setting and facilitates the integration of stronger backbone architectures into sparse retrieval. The complete code and implementation for this project are available at: https://github.com/lionisakis/Uncased-vs-cased-models-in-LSR", "code_url": "https://github.com/lionisakis/Uncased-vs-cased-models-in-LSR", "code_stars": 1, "code_last_update": "2025-10-03", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u5728\u7a00\u758f\u68c0\u7d22\u4e2d\u4f7f\u7528\u5927\u5c0f\u5199\u654f\u611f\u4e0e\u4e0d\u654f\u611f\u57fa\u7840\u6a21\u578b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5927\u5c0f\u5199\u654f\u611f\u6a21\u578b\u9ed8\u8ba4\u8868\u73b0\u8f83\u5dee\uff0c\u4f46\u901a\u8fc7\u6587\u672c\u5c0f\u5199\u5316\u9884\u5904\u7406\u53ef\u4ee5\u6d88\u9664\u6027\u80fd\u5dee\u8ddd\u3002", "motivation": "\u5f53\u524d\u6700\u5148\u8fdb\u7684LSR\u65b9\u6cd5\u51e0\u4e4e\u5b8c\u5168\u4f9d\u8d56\u5927\u5c0f\u5199\u4e0d\u654f\u611f\u7684\u57fa\u7840\u6a21\u578b\uff0c\u4f46\u6700\u65b0\u7684SOTA\u8bed\u8a00\u6a21\u578b\u53ea\u6709\u5927\u5c0f\u5199\u654f\u611f\u7248\u672c\u3002\u57fa\u7840\u6a21\u578b\u7684\u5927\u5c0f\u5199\u654f\u611f\u6027\u5bf9LSR\u7684\u5f71\u54cd\u5c1a\u672a\u88ab\u7814\u7a76\uff0c\u8fd9\u53ef\u80fd\u5a01\u80c1\u5230\u8be5\u65b9\u6cd5\u7684\u672a\u6765\u53d1\u5c55\u53ef\u884c\u6027\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u4e86\u76f8\u540c\u57fa\u7840\u6a21\u578b\u7684\u5927\u5c0f\u5199\u654f\u611f\u548c\u4e0d\u654f\u611f\u7248\u672c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u6587\u672c\u5c0f\u5199\u5316\u9884\u5904\u7406\u6765\u6d88\u9664\u6027\u80fd\u5dee\u8ddd\uff0c\u5e76\u8fdb\u884c\u8bcd\u5143\u7ea7\u522b\u7684\u5206\u6790\u6765\u7406\u89e3\u6a21\u578b\u884c\u4e3a\u3002", "result": "\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528\u5927\u5c0f\u5199\u654f\u611f\u57fa\u7840\u6a21\u578b\u7684LSR\u6a21\u578b\u8868\u73b0\u663e\u8457\u5dee\u4e8e\u5927\u5c0f\u5199\u4e0d\u654f\u611f\u7248\u672c\uff1b\u4f46\u901a\u8fc7\u6587\u672c\u5c0f\u5199\u5316\u9884\u5904\u7406\u53ef\u4ee5\u5b8c\u5168\u6d88\u9664\u8fd9\u4e00\u6027\u80fd\u5dee\u8ddd\u3002\u8bcd\u5143\u7ea7\u522b\u5206\u6790\u663e\u793a\uff0c\u5728\u5c0f\u5199\u5316\u5904\u7406\u540e\uff0c\u5927\u5c0f\u5199\u654f\u611f\u6a21\u578b\u51e0\u4e4e\u5b8c\u5168\u6291\u5236\u4e86\u5927\u5c0f\u5199\u654f\u611f\u8bcd\u6c47\u9879\uff0c\u884c\u4e3a\u5b9e\u9645\u4e0a\u7b49\u540c\u4e8e\u5927\u5c0f\u5199\u4e0d\u654f\u611f\u6a21\u578b\u3002", "conclusion": "\u8fd9\u4e00\u53d1\u73b0\u6269\u5c55\u4e86\u6700\u65b0\u5927\u5c0f\u5199\u654f\u611f\u6a21\u578b\u5728LSR\u8bbe\u7f6e\u4e2d\u7684\u9002\u7528\u6027\uff0c\u4fc3\u8fdb\u4e86\u66f4\u5f3a\u57fa\u7840\u67b6\u6784\u4e0e\u7a00\u758f\u68c0\u7d22\u7684\u96c6\u6210\u3002\u901a\u8fc7\u7b80\u5355\u7684\u6587\u672c\u9884\u5904\u7406\uff0c\u5927\u5c0f\u5199\u654f\u611f\u6a21\u578b\u53ef\u4ee5\u5728LSR\u4e2d\u8fbe\u5230\u4e0e\u5927\u5c0f\u5199\u4e0d\u654f\u611f\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u3002"}}
{"id": "2601.17152", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17152", "abs": "https://arxiv.org/abs/2601.17152", "authors": ["Miao Zhang", "Junsik Kim", "Siyuan Xiang", "Jian Gao", "Cheng Cao"], "title": "Dynamic Role Assignment for Multi-Agent Debate", "comment": null, "summary": "Multi-agent large language model (LLM) and vision-language model (VLM) debate systems employ specialized roles for complex problem-solving, yet model specializations are not leveraged to decide which model should fill which role. We propose dynamic role assignment, a framework that runs a Meta-Debate to select suitable agents before the actual debate. The meta-debate has two stages: (1) proposal, where candidates provide role-tailored arguments, and (2) peer review, where proposals are scored with data and role-specific criteria to choose the best agent for each position. We evaluate our method on LLM problem solving benchmarks. Applied on top of existing debate systems, our approach consistently outperforms uniform assignments (filling all roles with the same model) by up to 74.8% and random assignments (assigning models to roles without considering their suitability) by up to 29.7%, depending on the task and the specific assignment. This work establishes a new paradigm for multi-agent system design, shifting from static agent deployment to dynamic and capability-aware selection.", "AI": {"tldr": "\u63d0\u51fa\u52a8\u6001\u89d2\u8272\u5206\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u5143\u8fa9\u8bba\u9009\u62e9\u6700\u9002\u5408\u7684\u667a\u80fd\u4f53\u62c5\u4efb\u7279\u5b9a\u89d2\u8272\uff0c\u63d0\u5347\u591a\u667a\u80fd\u4f53\u5927\u8bed\u8a00\u6a21\u578b\u8fa9\u8bba\u7cfb\u7edf\u7684\u6027\u80fd", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53LLM/VLM\u8fa9\u8bba\u7cfb\u7edf\u867d\u7136\u4f7f\u7528\u4e13\u95e8\u89d2\u8272\u89e3\u51b3\u590d\u6742\u95ee\u9898\uff0c\u4f46\u672a\u80fd\u6839\u636e\u6a21\u578b\u7279\u6027\u51b3\u5b9a\u54ea\u4e2a\u6a21\u578b\u9002\u5408\u54ea\u4e2a\u89d2\u8272\uff0c\u5bfc\u81f4\u89d2\u8272\u5206\u914d\u4e0d\u591f\u4f18\u5316", "method": "\u63d0\u51fa\u52a8\u6001\u89d2\u8272\u5206\u914d\u6846\u67b6\uff0c\u5305\u542b\u5143\u8fa9\u8bba\u8fc7\u7a0b\uff1a1)\u63d0\u6848\u9636\u6bb5-\u5019\u9009\u667a\u80fd\u4f53\u63d0\u4f9b\u89d2\u8272\u5b9a\u5236\u5316\u8bba\u8bc1\uff1b2)\u540c\u884c\u8bc4\u5ba1\u9636\u6bb5-\u4f7f\u7528\u6570\u636e\u548c\u89d2\u8272\u7279\u5b9a\u6807\u51c6\u5bf9\u63d0\u6848\u8bc4\u5206\uff0c\u9009\u62e9\u6700\u9002\u5408\u6bcf\u4e2a\u89d2\u8272\u7684\u667a\u80fd\u4f53", "result": "\u5728LLM\u95ee\u9898\u89e3\u51b3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u5747\u5300\u5206\u914d\uff08\u6240\u6709\u89d2\u8272\u4f7f\u7528\u76f8\u540c\u6a21\u578b\uff09\u6700\u9ad8\u8fbe74.8%\uff0c\u4f18\u4e8e\u968f\u673a\u5206\u914d\u6700\u9ad8\u8fbe29.7%\uff0c\u5177\u4f53\u63d0\u5347\u53d6\u51b3\u4e8e\u4efb\u52a1\u548c\u7279\u5b9a\u5206\u914d", "conclusion": "\u5efa\u7acb\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u65b0\u8303\u5f0f\uff0c\u4ece\u9759\u6001\u667a\u80fd\u4f53\u90e8\u7f72\u8f6c\u5411\u52a8\u6001\u3001\u80fd\u529b\u611f\u77e5\u7684\u9009\u62e9\uff0c\u663e\u8457\u63d0\u5347\u8fa9\u8bba\u7cfb\u7edf\u6027\u80fd"}}
{"id": "2601.17332", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17332", "abs": "https://arxiv.org/abs/2601.17332", "authors": ["Yicheng Tao", "Hongteng Xu"], "title": "TheoremForge: Scaling up Formal Data Synthesis with Low-Budget Agentic Workflow", "comment": null, "summary": "The high cost of agentic workflows in formal mathematics hinders large-scale data synthesis, exacerbating the scarcity of open-source corpora. To address this, we introduce \\textbf{TheoremForge}, a cost-effective formal data synthesis pipeline that decomposes the formalization process into five sub-tasks, which are \\textit{statement formalization}, \\textit{proof generation}, \\textit{premise selection}, \\textit{proof correction} and \\textit{proof sketching}. By implementing a \\textit{Decoupled Extraction Strategy}, the workflow recovers valid training signals from globally failed trajectories, effectively utilizing wasted computation. Experiments on a 2,000-problem benchmark demonstrate that TheoremForge achieves a Verified Rate of 12.6\\%, surpassing the 8.6\\% baseline, at an average cost of only \\textbf{\\$0.481} per successful trajectory using Gemini-3-Flash. Crucially, our strategy increases data yield by \\textbf{1.6$\\times$} for proof generation compared to standard filtering. These results establish TheoremForge as a scalable framework for constructing a data flywheel to train future expert models. Our code is available \\href{https://github.com/timechess/TheoremForge}{here}.", "code_url": "https://github.com/timechess/TheoremForge", "code_stars": 4, "code_last_update": "2026-01-27", "AI": {"tldr": "TheoremForge\u662f\u4e00\u4e2a\u4f4e\u6210\u672c\u7684\u5f62\u5f0f\u5316\u6570\u5b66\u6570\u636e\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u4efb\u52a1\u5206\u89e3\u548c\u89e3\u8026\u63d0\u53d6\u7b56\u7565\u63d0\u9ad8\u6570\u636e\u751f\u6210\u6548\u7387\uff0c\u76f8\u6bd4\u57fa\u7ebf\u5c06\u9a8c\u8bc1\u7387\u4ece8.6%\u63d0\u5347\u523012.6%\uff0c\u6bcf\u4e2a\u6210\u529f\u8f68\u8ff9\u6210\u672c\u4ec50.481\u7f8e\u5143\u3002", "motivation": "\u5f62\u5f0f\u5316\u6570\u5b66\u4e2d\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u9ad8\u6210\u672c\u963b\u788d\u4e86\u5927\u89c4\u6a21\u6570\u636e\u5408\u6210\uff0c\u52a0\u5267\u4e86\u5f00\u6e90\u8bed\u6599\u5e93\u7684\u7a00\u7f3a\u6027\u3002\u9700\u8981\u4e00\u79cd\u6210\u672c\u6548\u76ca\u9ad8\u7684\u65b9\u6cd5\u6765\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u5f62\u5f0f\u5316\u6570\u5b66\u6570\u636e\u3002", "method": "\u5c06\u5f62\u5f0f\u5316\u8fc7\u7a0b\u5206\u89e3\u4e3a\u4e94\u4e2a\u5b50\u4efb\u52a1\uff1a\u9648\u8ff0\u5f62\u5f0f\u5316\u3001\u8bc1\u660e\u751f\u6210\u3001\u524d\u63d0\u9009\u62e9\u3001\u8bc1\u660e\u4fee\u6b63\u548c\u8bc1\u660e\u8349\u56fe\u3002\u91c7\u7528\u89e3\u8026\u63d0\u53d6\u7b56\u7565\u4ece\u5168\u5c40\u5931\u8d25\u7684\u8f68\u8ff9\u4e2d\u6062\u590d\u6709\u6548\u8bad\u7ec3\u4fe1\u53f7\uff0c\u6709\u6548\u5229\u7528\u6d6a\u8d39\u7684\u8ba1\u7b97\u8d44\u6e90\u3002", "result": "\u57282000\u4e2a\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTheoremForge\u8fbe\u523012.6%\u7684\u9a8c\u8bc1\u7387\uff0c\u8d85\u8fc78.6%\u7684\u57fa\u7ebf\uff0c\u6bcf\u4e2a\u6210\u529f\u8f68\u8ff9\u5e73\u5747\u6210\u672c\u4ec50.481\u7f8e\u5143\uff08\u4f7f\u7528Gemini-3-Flash\uff09\u3002\u89e3\u8026\u63d0\u53d6\u7b56\u7565\u4f7f\u8bc1\u660e\u751f\u6210\u7684\u6570\u636e\u4ea7\u91cf\u76f8\u6bd4\u6807\u51c6\u8fc7\u6ee4\u63d0\u9ad81.6\u500d\u3002", "conclusion": "TheoremForge\u4e3a\u6784\u5efa\u6570\u636e\u98de\u8f6e\u4ee5\u8bad\u7ec3\u672a\u6765\u4e13\u5bb6\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5f62\u5f0f\u5316\u6570\u5b66\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002"}}
{"id": "2601.17335", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17335", "abs": "https://arxiv.org/abs/2601.17335", "authors": ["Angshul Majumdar"], "title": "The Relativity of AGI: Distributional Axioms, Fragility, and Undecidability", "comment": null, "summary": "We study whether Artificial General Intelligence (AGI) admits a coherent theoretical definition that supports absolute claims of existence, robustness, or self-verification. We formalize AGI axiomatically as a distributional, resource-bounded semantic predicate, indexed by a task family, a task distribution, a performance functional, and explicit resource budgets. Under this framework, we derive four classes of results. First, we show that generality is inherently relational: there is no distribution-independent notion of AGI. Second, we prove non-invariance results demonstrating that arbitrarily small perturbations of the task distribution can invalidate AGI properties via cliff sets, precluding universal robustness. Third, we establish bounded transfer guarantees, ruling out unbounded generalization across task families under finite resources. Fourth, invoking Rice-style and G\u00f6del--Tarski arguments, we prove that AGI is a nontrivial semantic property and therefore cannot be soundly and completely certified by any computable procedure, including procedures implemented by the agent itself. Consequently, recursive self-improvement schemes that rely on internal self-certification of AGI are ill-posed. Taken together, our results show that strong, distribution-independent claims of AGI are not false but undefined without explicit formal indexing, and that empirical progress in AI does not imply the attainability of self-certifying general intelligence.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u516c\u7406\u5316\u6846\u67b6\u8bc1\u660eAGI\u65e0\u6cd5\u83b7\u5f97\u72ec\u7acb\u4e8e\u5206\u5e03\u7684\u7edf\u4e00\u5b9a\u4e49\uff0c\u7f3a\u4e4f\u901a\u7528\u9c81\u68d2\u6027\uff0c\u5b58\u5728\u6709\u754c\u8fc1\u79fb\u9650\u5236\uff0c\u4e14\u65e0\u6cd5\u901a\u8fc7\u53ef\u8ba1\u7b97\u7a0b\u5e8f\uff08\u5305\u62ec\u81ea\u6211\u8ba4\u8bc1\uff09\u8fdb\u884c\u5b8c\u5907\u9a8c\u8bc1\uff0c\u4ece\u800c\u8d28\u7591AGI\u7684\u7edd\u5bf9\u5b58\u5728\u6027\u58f0\u660e\u3002", "motivation": "\u7814\u7a76\u4eba\u5de5\u667a\u80fd\u901a\u7528\u667a\u80fd\uff08AGI\uff09\u662f\u5426\u5177\u6709\u652f\u6301\u7edd\u5bf9\u5b58\u5728\u6027\u3001\u9c81\u68d2\u6027\u6216\u81ea\u6211\u9a8c\u8bc1\u7684\u8fde\u8d2f\u7406\u8bba\u5b9a\u4e49\uff0c\u8d28\u7591\u5f53\u524dAGI\u58f0\u660e\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u5c06AGI\u516c\u7406\u5316\u4e3a\u5206\u5e03\u6027\u3001\u8d44\u6e90\u53d7\u9650\u7684\u8bed\u4e49\u8c13\u8bcd\uff0c\u901a\u8fc7\u4efb\u52a1\u65cf\u3001\u4efb\u52a1\u5206\u5e03\u3001\u6027\u80fd\u51fd\u6570\u548c\u663e\u5f0f\u8d44\u6e90\u9884\u7b97\u8fdb\u884c\u7d22\u5f15\uff0c\u5728\u6b64\u57fa\u7840\u4e0a\u63a8\u5bfc\u56db\u7c7b\u5f62\u5f0f\u5316\u7ed3\u679c\u3002", "result": "1. \u901a\u7528\u6027\u672c\u8d28\u4e0a\u662f\u5173\u7cfb\u6027\u7684\uff0c\u4e0d\u5b58\u5728\u72ec\u7acb\u4e8e\u5206\u5e03\u7684AGI\u6982\u5ff5\uff1b2. \u4efb\u52a1\u5206\u5e03\u7684\u5fae\u5c0f\u6270\u52a8\u53ef\u901a\u8fc7\u60ac\u5d16\u96c6\u4f7fAGI\u5c5e\u6027\u5931\u6548\uff1b3. \u6709\u9650\u8d44\u6e90\u4e0b\u65e0\u6cd5\u5b9e\u73b0\u8de8\u4efb\u52a1\u65cf\u7684\u65e0\u9650\u6cdb\u5316\uff1b4. AGI\u4f5c\u4e3a\u975e\u5e73\u51e1\u8bed\u4e49\u5c5e\u6027\u65e0\u6cd5\u901a\u8fc7\u4efb\u4f55\u53ef\u8ba1\u7b97\u7a0b\u5e8f\uff08\u5305\u62ec\u81ea\u6211\u8ba4\u8bc1\uff09\u8fdb\u884c\u5b8c\u5907\u9a8c\u8bc1\u3002", "conclusion": "\u5f3a\u5206\u5e03\u72ec\u7acb\u7684AGI\u58f0\u660e\u5728\u6ca1\u6709\u663e\u5f0f\u5f62\u5f0f\u5316\u7d22\u5f15\u7684\u60c5\u51b5\u4e0b\u662f\u672a\u5b9a\u4e49\u7684\uff0cAI\u7684\u7ecf\u9a8c\u8fdb\u5c55\u5e76\u4e0d\u610f\u5473\u7740\u53ef\u5b9e\u73b0\u81ea\u6211\u8ba4\u8bc1\u7684\u901a\u7528\u667a\u80fd\uff0c\u4f9d\u8d56\u5185\u90e8\u81ea\u6211\u8ba4\u8bc1\u7684\u9012\u5f52\u81ea\u6211\u6539\u8fdb\u65b9\u6848\u5b58\u5728\u6839\u672c\u7f3a\u9677\u3002"}}
{"id": "2601.17567", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17567", "abs": "https://arxiv.org/abs/2601.17567", "authors": ["Zijing Hui", "Wenhan Lyu", "Shusen Wang", "Li Chen", "Chu Wang"], "title": "Real-Time Trend Prediction via Continually-Aligned LLM Query Generation", "comment": null, "summary": "Trending news detection in low-traffic search environments faces a fundamental cold-start problem, where a lack of query volume prevents systems from identifying emerging or long-tail trends. Existing methods relying on keyword frequency or query spikes are inherently slow and ineffective in these sparse settings, lagging behind real-world shifts in attention. We introduce RTTP, a novel Real-Time Trending Prediction framework that generates search queries directly from news content instead of waiting for users to issue them. RTTP leverages a continual learning LLM (CL-LLM) that converts posts into search-style queries and scores them using engagement strength + creator authority, enabling early trend surfacing before search volume forms. To ensure adaptation without degrading reasoning, we propose Mix-Policy DPO, a new preference-based continual learning approach that combines on-policy stability with off-policy novelty to mitigate catastrophic forgetting during model upgrades. Deployed at production scale on Facebook and Meta AI products, RTTP delivers +91.4% improvement in tail-trend detection precision@500 and +19% query generation accuracy over industry baselines, while sustaining stable performance after multi-week online training. This work demonstrates that LLM-generated synthetic search signals, when aligned and continually updated, unlock timely trend understanding in low-traffic search environments.", "AI": {"tldr": "RTTP\u6846\u67b6\u901a\u8fc7\u6301\u7eed\u5b66\u4e60LLM\u76f4\u63a5\u4ece\u65b0\u95fb\u5185\u5bb9\u751f\u6210\u641c\u7d22\u67e5\u8be2\uff0c\u89e3\u51b3\u4f4e\u6d41\u91cf\u641c\u7d22\u73af\u5883\u4e2d\u7684\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u5b9e\u73b0\u65e9\u671f\u8d8b\u52bf\u53d1\u73b0", "motivation": "\u4f4e\u6d41\u91cf\u641c\u7d22\u73af\u5883\u4e2d\u5b58\u5728\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u4f20\u7edf\u57fa\u4e8e\u5173\u952e\u8bcd\u9891\u7387\u6216\u67e5\u8be2\u5cf0\u503c\u7684\u65b9\u6cd5\u5728\u7a00\u758f\u8bbe\u7f6e\u4e0b\u6548\u679c\u5dee\u3001\u54cd\u5e94\u6162\uff0c\u65e0\u6cd5\u53ca\u65f6\u8bc6\u522b\u65b0\u5174\u6216\u957f\u5c3e\u8d8b\u52bf", "method": "RTTP\u6846\u67b6\u4f7f\u7528\u6301\u7eed\u5b66\u4e60LLM\u5c06\u65b0\u95fb\u5e16\u5b50\u8f6c\u6362\u4e3a\u641c\u7d22\u5f0f\u67e5\u8be2\uff0c\u901a\u8fc7\u53c2\u4e0e\u5f3a\u5ea6+\u521b\u4f5c\u8005\u6743\u5a01\u6027\u8fdb\u884c\u8bc4\u5206\uff1b\u63d0\u51faMix-Policy DPO\u65b9\u6cd5\uff0c\u7ed3\u5408on-policy\u7a33\u5b9a\u6027\u548coff-policy\u65b0\u9896\u6027\uff0c\u9632\u6b62\u6a21\u578b\u5347\u7ea7\u65f6\u7684\u707e\u96be\u6027\u9057\u5fd8", "result": "\u5728Facebook\u548cMeta AI\u4ea7\u54c1\u4e2d\u90e8\u7f72\uff0c\u957f\u5c3e\u8d8b\u52bf\u68c0\u6d4b\u7cbe\u5ea6@500\u63d0\u534791.4%\uff0c\u67e5\u8be2\u751f\u6210\u51c6\u786e\u7387\u6bd4\u884c\u4e1a\u57fa\u7ebf\u63d0\u9ad819%\uff0c\u591a\u5468\u5728\u7ebf\u8bad\u7ec3\u540e\u4fdd\u6301\u7a33\u5b9a\u6027\u80fd", "conclusion": "LLM\u751f\u6210\u7684\u5408\u6210\u641c\u7d22\u4fe1\u53f7\u7ecf\u8fc7\u5bf9\u9f50\u548c\u6301\u7eed\u66f4\u65b0\uff0c\u80fd\u591f\u5728\u4f4e\u6d41\u91cf\u641c\u7d22\u73af\u5883\u4e2d\u5b9e\u73b0\u53ca\u65f6\u7684\u8d8b\u52bf\u7406\u89e3\uff0c\u89e3\u51b3\u4e86\u51b7\u542f\u52a8\u95ee\u9898"}}
{"id": "2601.17172", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17172", "abs": "https://arxiv.org/abs/2601.17172", "authors": ["Tunazzina Islam"], "title": "Who Gets Which Message? Auditing Demographic Bias in LLM-Generated Targeted Text", "comment": null, "summary": "Large language models (LLMs) are increasingly capable of generating personalized, persuasive text at scale, raising new questions about bias and fairness in automated communication. This paper presents the first systematic analysis of how LLMs behave when tasked with demographic-conditioned targeted messaging. We introduce a controlled evaluation framework using three leading models -- GPT-4o, Llama-3.3, and Mistral-Large 2.1 -- across two generation settings: Standalone Generation, which isolates intrinsic demographic effects, and Context-Rich Generation, which incorporates thematic and regional context to emulate realistic targeting. We evaluate generated messages along three dimensions: lexical content, language style, and persuasive framing. We instantiate this framework on climate communication and find consistent age- and gender-based asymmetries across models: male- and youth-targeted messages emphasize agency, innovation, and assertiveness, while female- and senior-targeted messages stress warmth, care, and tradition. Contextual prompts systematically amplify these disparities, with persuasion scores significantly higher for messages tailored to younger or male audiences. Our findings demonstrate how demographic stereotypes can surface and intensify in LLM-generated targeted communication, underscoring the need for bias-aware generation pipelines and transparent auditing frameworks that explicitly account for demographic conditioning in socially sensitive applications.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u5206\u6790\u4e86LLM\u5728\u751f\u6210\u4eba\u53e3\u7edf\u8ba1\u6761\u4ef6\u5b9a\u5411\u4fe1\u606f\u65f6\u7684\u884c\u4e3a\uff0c\u53d1\u73b0GPT-4o\u3001Llama-3.3\u548cMistral-Large 2.1\u5728\u6c14\u5019\u6c9f\u901a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u5e74\u9f84\u548c\u6027\u522b\u504f\u89c1\uff1a\u9488\u5bf9\u7537\u6027\u548c\u5e74\u8f7b\u4eba\u7684\u4fe1\u606f\u5f3a\u8c03\u80fd\u52a8\u6027\u3001\u521b\u65b0\u548c\u81ea\u4fe1\uff0c\u800c\u9488\u5bf9\u5973\u6027\u548c\u8001\u5e74\u4eba\u7684\u4fe1\u606f\u5219\u5f3a\u8c03\u6e29\u6696\u3001\u5173\u6000\u548c\u4f20\u7edf\u3002", "motivation": "\u968f\u7740LLM\u80fd\u591f\u5927\u89c4\u6a21\u751f\u6210\u4e2a\u6027\u5316\u3001\u6709\u8bf4\u670d\u529b\u7684\u6587\u672c\uff0c\u81ea\u52a8\u901a\u4fe1\u4e2d\u7684\u504f\u89c1\u548c\u516c\u5e73\u6027\u95ee\u9898\u65e5\u76ca\u51f8\u663e\u3002\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u5206\u6790LLM\u5728\u4eba\u53e3\u7edf\u8ba1\u6761\u4ef6\u5b9a\u5411\u4fe1\u606f\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u884c\u4e3a\uff0c\u63ed\u793a\u6f5c\u5728\u7684\u504f\u89c1\u6a21\u5f0f\u3002", "method": "\u5f15\u5165\u53d7\u63a7\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u7528GPT-4o\u3001Llama-3.3\u548cMistral-Large 2.1\u4e09\u4e2a\u9886\u5148\u6a21\u578b\uff0c\u5728\u4e24\u79cd\u751f\u6210\u8bbe\u7f6e\u4e0b\u8bc4\u4f30\uff1a\u72ec\u7acb\u751f\u6210\uff08\u9694\u79bb\u5185\u5728\u4eba\u53e3\u7edf\u8ba1\u6548\u5e94\uff09\u548c\u4e0a\u4e0b\u6587\u4e30\u5bcc\u751f\u6210\uff08\u7eb3\u5165\u4e3b\u9898\u548c\u533a\u57df\u80cc\u666f\u4ee5\u6a21\u62df\u73b0\u5b9e\u5b9a\u5411\uff09\u3002\u4ece\u8bcd\u6c47\u5185\u5bb9\u3001\u8bed\u8a00\u98ce\u683c\u548c\u8bf4\u670d\u6846\u67b6\u4e09\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u751f\u6210\u4fe1\u606f\uff0c\u5e76\u5728\u6c14\u5019\u6c9f\u901a\u4efb\u52a1\u4e2d\u5b9e\u4f8b\u5316\u8be5\u6846\u67b6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e09\u4e2a\u6a21\u578b\u5728\u5e74\u9f84\u548c\u6027\u522b\u7ef4\u5ea6\u4e0a\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u504f\u89c1\u6a21\u5f0f\uff1a\u9488\u5bf9\u7537\u6027\u548c\u5e74\u8f7b\u4eba\u7684\u4fe1\u606f\u5f3a\u8c03\u80fd\u52a8\u6027\u3001\u521b\u65b0\u548c\u81ea\u4fe1\uff0c\u800c\u9488\u5bf9\u5973\u6027\u548c\u8001\u5e74\u4eba\u7684\u4fe1\u606f\u5219\u5f3a\u8c03\u6e29\u6696\u3001\u5173\u6000\u548c\u4f20\u7edf\u3002\u4e0a\u4e0b\u6587\u63d0\u793a\u4f1a\u7cfb\u7edf\u6027\u653e\u5927\u8fd9\u4e9b\u5dee\u5f02\uff0c\u9488\u5bf9\u5e74\u8f7b\u6216\u7537\u6027\u53d7\u4f17\u7684\u5b9a\u5411\u4fe1\u606f\u7684\u8bf4\u670d\u529b\u5f97\u5206\u663e\u8457\u66f4\u9ad8\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\u4eba\u53e3\u7edf\u8ba1\u523b\u677f\u5370\u8c61\u4f1a\u5728LLM\u751f\u6210\u7684\u5b9a\u5411\u901a\u4fe1\u4e2d\u6d6e\u73b0\u5e76\u5f3a\u5316\uff0c\u5f3a\u8c03\u4e86\u5728\u793e\u4f1a\u654f\u611f\u5e94\u7528\u4e2d\u9700\u8981\u5f00\u53d1\u504f\u89c1\u611f\u77e5\u7684\u751f\u6210\u6d41\u7a0b\u548c\u900f\u660e\u7684\u5ba1\u8ba1\u6846\u67b6\uff0c\u660e\u786e\u8003\u8651\u4eba\u53e3\u7edf\u8ba1\u6761\u4ef6\u7684\u5f71\u54cd\u3002"}}
{"id": "2601.17343", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17343", "abs": "https://arxiv.org/abs/2601.17343", "authors": ["Wei Liu", "Haomei Xu", "Hongkai Liu", "Zhiying Deng", "Ruixuan Li", "Heng Huang", "Yee Whye Teh", "Wee Sun Lee"], "title": "Are We Evaluating the Edit Locality of LLM Model Editing Properly?", "comment": null, "summary": "Model editing has recently emerged as a popular paradigm for efficiently updating knowledge in LLMs. A central desideratum of updating knowledge is to balance editing efficacy, i.e., the successful injection of target knowledge, and specificity (also known as edit locality), i.e., the preservation of existing non-target knowledge. However, we find that existing specificity evaluation protocols are inadequate for this purpose. We systematically elaborated on the three fundamental issues it faces. Beyond the conceptual issues, we further empirically demonstrate that existing specificity metrics are weakly correlated with the strength of specificity regularizers. We also find that current metrics lack sufficient sensitivity, rendering them ineffective at distinguishing the specificity performance of different methods. Finally, we propose a constructive evaluation protocol. Under this protocol, the conflict between open-ended LLMs and the assumption of determined answers is eliminated, query-independent fluency biases are avoided, and the evaluation strictness can be smoothly adjusted within a near-continuous space. Experiments across various LLMs, datasets, and editing methods show that metrics derived from the proposed protocol are more sensitive to changes in the strength of specificity regularizers and exhibit strong correlation with them, enabling more fine-grained discrimination of different methods' knowledge preservation capabilities.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u73b0\u6709\u6a21\u578b\u7f16\u8f91\u7279\u5f02\u6027\u8bc4\u4f30\u534f\u8bae\u5b58\u5728\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u8be5\u534f\u8bae\u80fd\u66f4\u654f\u611f\u5730\u53cd\u6620\u7279\u5f02\u6027\u6b63\u5219\u5316\u5f3a\u5ea6\u53d8\u5316\uff0c\u5e76\u66f4\u597d\u5730\u533a\u5206\u4e0d\u540c\u65b9\u6cd5\u7684\u77e5\u8bc6\u4fdd\u7559\u80fd\u529b\u3002", "motivation": "\u6a21\u578b\u7f16\u8f91\u9700\u8981\u5e73\u8861\u7f16\u8f91\u6548\u679c\uff08\u6210\u529f\u6ce8\u5165\u76ee\u6807\u77e5\u8bc6\uff09\u548c\u7279\u5f02\u6027\uff08\u4fdd\u7559\u73b0\u6709\u975e\u76ee\u6807\u77e5\u8bc6\uff09\uff0c\u4f46\u73b0\u6709\u7279\u5f02\u6027\u8bc4\u4f30\u534f\u8bae\u5b58\u5728\u4e0d\u8db3\uff0c\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30\u8fd9\u4e00\u5e73\u8861\u3002", "method": "\u7cfb\u7edf\u5206\u6790\u4e86\u73b0\u6709\u7279\u5f02\u6027\u8bc4\u4f30\u534f\u8bae\u7684\u4e09\u4e2a\u57fa\u672c\u95ee\u9898\uff0c\u5b9e\u8bc1\u8868\u660e\u73b0\u6709\u6307\u6807\u4e0e\u7279\u5f02\u6027\u6b63\u5219\u5316\u5f3a\u5ea6\u76f8\u5173\u6027\u5f31\u4e14\u654f\u611f\u6027\u4e0d\u8db3\u3002\u63d0\u51fa\u4e86\u65b0\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u6d88\u9664\u4e86\u5f00\u653e\u57dfLLM\u4e0e\u786e\u5b9a\u7b54\u6848\u5047\u8bbe\u7684\u51b2\u7a81\uff0c\u907f\u514d\u4e86\u67e5\u8be2\u65e0\u5173\u7684\u6d41\u7545\u6027\u504f\u5dee\uff0c\u5e76\u80fd\u5728\u63a5\u8fd1\u8fde\u7eed\u7684\u7a7a\u95f4\u4e2d\u5e73\u6ed1\u8c03\u6574\u8bc4\u4f30\u4e25\u683c\u5ea6\u3002", "result": "\u5728\u4e0d\u540cLLM\u3001\u6570\u636e\u96c6\u548c\u7f16\u8f91\u65b9\u6cd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u65b0\u534f\u8bae\u7684\u6307\u6807\u5bf9\u7279\u5f02\u6027\u6b63\u5219\u5316\u5f3a\u5ea6\u53d8\u5316\u66f4\u654f\u611f\uff0c\u4e0e\u6b63\u5219\u5316\u5f3a\u5ea6\u5f3a\u76f8\u5173\uff0c\u80fd\u66f4\u7cbe\u7ec6\u5730\u533a\u5206\u4e0d\u540c\u65b9\u6cd5\u7684\u77e5\u8bc6\u4fdd\u7559\u80fd\u529b\u3002", "conclusion": "\u73b0\u6709\u6a21\u578b\u7f16\u8f91\u7279\u5f02\u6027\u8bc4\u4f30\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff0c\u63d0\u51fa\u7684\u65b0\u8bc4\u4f30\u534f\u8bae\u80fd\u66f4\u51c6\u786e\u3001\u654f\u611f\u5730\u8bc4\u4f30\u77e5\u8bc6\u4fdd\u7559\u80fd\u529b\uff0c\u4e3a\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u7684\u6bd4\u8f83\u548c\u6539\u8fdb\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2601.17601", "categories": ["cs.IR", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.17601", "abs": "https://arxiv.org/abs/2601.17601", "authors": ["Fangping Lan", "Abdullah Aljebreen", "Eduard C. Dragut"], "title": "Why They Link: An Intent Taxonomy for Including Hyperlinks in Social Posts", "comment": "10 pages including references, 5 figures,", "summary": "URLs serve as bridges between social media platforms and the broader web, linking user-generated content to external information resources. On Twitter (X), approximately one in five tweets contains at least one URL, underscoring their central role in information dissemination. While prior studies have examined the motivations of authors who share URLs, such author-centered intentions are difficult to observe in practice. To enable broader downstream use, this work investigates reader-centered interpretations, i.e., how users perceive the intentions behind hyperlinks included in posts. We develop an intent taxonomy for including hyperlinks in social posts through a hybrid approach that begins with a bottom-up, data-driven process using large-scale crowdsourced annotations, and is then refined using large language model assistance to generate descriptive category names and precise definitions. The final taxonomy comprises 6 top-level categories and 26 fine-grained intention classes, capturing diverse communicative purposes. Applying this taxonomy, we annotate and analyze 1000 user posts, revealing that advertising, arguing, and sharing are the most prevalent intentions. This resulting taxonomy provides a foundation for intent-aware information retrieval and NLP applications, enabling more accurate retrieval, recommendation, and understanding of social media content.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u793e\u4ea4\u5a92\u4f53\u8d85\u94fe\u63a5\u610f\u56fe\u5206\u7c7b\u4f53\u7cfb\uff0c\u901a\u8fc7\u4f17\u5305\u6807\u6ce8\u548cLLM\u8f85\u52a9\u6784\u5efa\u4e86\u5305\u542b6\u4e2a\u9876\u5c42\u7c7b\u522b\u548c26\u4e2a\u7ec6\u7c92\u5ea6\u610f\u56fe\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u5e94\u7528\u4e8e1000\u6761\u7528\u6237\u5e16\u5b50\u5206\u6790", "motivation": "URL\u5728\u793e\u4ea4\u5a92\u4f53\u4fe1\u606f\u4f20\u64ad\u4e2d\u626e\u6f14\u6838\u5fc3\u89d2\u8272\uff08Twitter\u4e0a\u7ea620%\u63a8\u6587\u5305\u542bURL\uff09\uff0c\u4f46\u4ee5\u5f80\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4f5c\u8005\u5206\u4eabURL\u7684\u52a8\u673a\uff0c\u8fd9\u4e9b\u4f5c\u8005\u4e2d\u5fc3\u610f\u56fe\u5728\u5b9e\u8df5\u4e2d\u96be\u4ee5\u89c2\u5bdf\u3002\u4e3a\u652f\u6301\u66f4\u5e7f\u6cdb\u7684\u4e0b\u6e38\u5e94\u7528\uff0c\u672c\u7814\u7a76\u8f6c\u5411\u8bfb\u8005\u4e2d\u5fc3\u89c6\u89d2\uff0c\u63a2\u7a76\u7528\u6237\u5982\u4f55\u7406\u89e3\u5e16\u5b50\u4e2d\u5d4c\u5165\u8d85\u94fe\u63a5\u7684\u610f\u56fe", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u5f00\u53d1\u8d85\u94fe\u63a5\u610f\u56fe\u5206\u7c7b\u4f53\u7cfb\uff1a1\uff09\u81ea\u4e0b\u800c\u4e0a\u7684\u6570\u636e\u9a71\u52a8\u8fc7\u7a0b\uff0c\u4f7f\u7528\u5927\u89c4\u6a21\u4f17\u5305\u6807\u6ce8\uff1b2\uff09\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u751f\u6210\u63cf\u8ff0\u6027\u7c7b\u522b\u540d\u79f0\u548c\u7cbe\u786e\u5b9a\u4e49\u3002\u6700\u7ec8\u6784\u5efa\u5305\u542b6\u4e2a\u9876\u5c42\u7c7b\u522b\u548c26\u4e2a\u7ec6\u7c92\u5ea6\u610f\u56fe\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u5e94\u7528\u4e8e1000\u6761\u7528\u6237\u5e16\u5b50\u7684\u6807\u6ce8\u5206\u6790", "result": "\u6700\u7ec8\u5206\u7c7b\u6cd5\u5305\u542b6\u4e2a\u9876\u5c42\u7c7b\u522b\u548c26\u4e2a\u7ec6\u7c92\u5ea6\u610f\u56fe\u7c7b\u522b\uff0c\u8986\u76d6\u591a\u6837\u5316\u7684\u4ea4\u9645\u76ee\u7684\u3002\u5bf91000\u6761\u7528\u6237\u5e16\u5b50\u7684\u5206\u6790\u663e\u793a\uff0c\u5e7f\u544a\u3001\u4e89\u8bba\u548c\u5206\u4eab\u662f\u6700\u666e\u904d\u7684\u610f\u56fe\u3002\u8be5\u5206\u7c7b\u6cd5\u4e3a\u610f\u56fe\u611f\u77e5\u7684\u4fe1\u606f\u68c0\u7d22\u548cNLP\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840", "conclusion": "\u672c\u7814\u7a76\u5f00\u53d1\u7684\u793e\u4ea4\u5a92\u4f53\u8d85\u94fe\u63a5\u610f\u56fe\u5206\u7c7b\u4f53\u7cfb\u80fd\u591f\u66f4\u51c6\u786e\u5730\u6355\u6349\u7528\u6237\u5bf9\u8d85\u94fe\u63a5\u610f\u56fe\u7684\u611f\u77e5\uff0c\u4e3a\u610f\u56fe\u611f\u77e5\u7684\u4fe1\u606f\u68c0\u7d22\u3001\u63a8\u8350\u7cfb\u7edf\u548c\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\u7406\u89e3\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\u7684\u68c0\u7d22\u51c6\u786e\u6027\u548c\u7406\u89e3\u6df1\u5ea6"}}
{"id": "2601.17173", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17173", "abs": "https://arxiv.org/abs/2601.17173", "authors": ["Parth Bhalerao", "Diola Dsouza", "Ruiwen Guan", "Oana Ignat"], "title": "Beyond Factual QA: Mentorship-Oriented Question Answering over Long-Form Multilingual Content", "comment": null, "summary": "Question answering systems are typically evaluated on factual correctness, yet many real-world applications-such as education and career guidance-require mentorship: responses that provide reflection and guidance. Existing QA benchmarks rarely capture this distinction, particularly in multilingual and long-form settings. We introduce MentorQA, the first multilingual dataset and evaluation framework for mentorship-focused question answering from long-form videos, comprising nearly 9,000 QA pairs from 180 hours of content across four languages. We define mentorship-focused evaluation dimensions that go beyond factual accuracy, capturing clarity, alignment, and learning value. Using MentorQA, we compare Single-Agent, Dual-Agent, RAG, and Multi-Agent QA architectures under controlled conditions. Multi-Agent pipelines consistently produce higher-quality mentorship responses, with especially strong gains for complex topics and lower-resource languages. We further analyze the reliability of automated LLM-based evaluation, observing substantial variation in alignment with human judgments. Overall, this work establishes mentorship-focused QA as a distinct research problem and provides a multilingual benchmark for studying agentic architectures and evaluation design in educational AI. The dataset and evaluation framework are released at https://github.com/AIM-SCU/MentorQA.", "code_url": "https://github.com/AIM-SCU/MentorQA", "code_stars": 0, "code_last_update": "2026-01-06", "AI": {"tldr": "MentorQA\uff1a\u9996\u4e2a\u591a\u8bed\u8a00\u957f\u89c6\u9891\u95ee\u7b54\u6570\u636e\u96c6\u4e0e\u8bc4\u4f30\u6846\u67b6\uff0c\u4e13\u6ce8\u4e8e\u6307\u5bfc\u6027\u56de\u7b54\u800c\u975e\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u5305\u542b\u8fd19000\u4e2aQA\u5bf9\uff0c\u6bd4\u8f83\u4e86\u591a\u79cd\u95ee\u7b54\u67b6\u6784\uff0c\u53d1\u73b0\u591a\u667a\u80fd\u4f53\u7ba1\u9053\u5728\u6307\u5bfc\u6027\u56de\u7b54\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u73b0\u6709\u95ee\u7b54\u7cfb\u7edf\u4e3b\u8981\u8bc4\u4f30\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u4f46\u6559\u80b2\u3001\u804c\u4e1a\u6307\u5bfc\u7b49\u5b9e\u9645\u5e94\u7528\u9700\u8981\u6307\u5bfc\u6027\u56de\u7b54\uff08\u63d0\u4f9b\u53cd\u601d\u548c\u6307\u5bfc\uff09\u3002\u73b0\u6709QA\u57fa\u51c6\u5f88\u5c11\u6355\u6349\u8fd9\u79cd\u533a\u522b\uff0c\u7279\u522b\u662f\u5728\u591a\u8bed\u8a00\u548c\u957f\u6587\u672c\u573a\u666f\u4e2d\u3002", "method": "\u5f15\u5165MentorQA\u6570\u636e\u96c6\uff0c\u5305\u542b\u8fd19000\u4e2aQA\u5bf9\uff0c\u6765\u81ea180\u5c0f\u65f6\u7684\u56db\u8bed\u8a00\u89c6\u9891\u5185\u5bb9\u3002\u5b9a\u4e49\u4e86\u8d85\u8d8a\u4e8b\u5b9e\u51c6\u786e\u6027\u7684\u6307\u5bfc\u6027\u8bc4\u4f30\u7ef4\u5ea6\uff08\u6e05\u6670\u5ea6\u3001\u4e00\u81f4\u6027\u3001\u5b66\u4e60\u4ef7\u503c\uff09\u3002\u5728\u53d7\u63a7\u6761\u4ef6\u4e0b\u6bd4\u8f83\u4e86\u5355\u667a\u80fd\u4f53\u3001\u53cc\u667a\u80fd\u4f53\u3001RAG\u548c\u591a\u667a\u80fd\u4f53QA\u67b6\u6784\u3002", "result": "\u591a\u667a\u80fd\u4f53\u7ba1\u9053\u59cb\u7ec8\u4ea7\u751f\u66f4\u9ad8\u8d28\u91cf\u7684\u6307\u5bfc\u6027\u56de\u7b54\uff0c\u5728\u590d\u6742\u4e3b\u9898\u548c\u4f4e\u8d44\u6e90\u8bed\u8a00\u65b9\u9762\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\u3002\u540c\u65f6\u5206\u6790\u4e86\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u8bc4\u4f30\u7684\u53ef\u9760\u6027\uff0c\u53d1\u73b0\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u4e00\u81f4\u6027\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u786e\u7acb\u4e86\u6307\u5bfc\u6027\u95ee\u7b54\u4f5c\u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u7814\u7a76\u95ee\u9898\uff0c\u5e76\u4e3a\u6559\u80b2AI\u4e2d\u7684\u667a\u80fd\u4f53\u67b6\u6784\u548c\u8bc4\u4f30\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u591a\u8bed\u8a00\u57fa\u51c6\u3002\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6846\u67b6\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.17346", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17346", "abs": "https://arxiv.org/abs/2601.17346", "authors": ["Haoxin Xu", "Changyong Qi", "Tong Liu", "Bohao Zhang", "Anna He", "Bingqian Jiang", "Longwei Zheng", "Xiaoqing Gu"], "title": "Multi-Agent Learning Path Planning via LLMs", "comment": null, "summary": "The integration of large language models (LLMs) into intelligent tutoring systems offers transformative potential for personalized learning in higher education. However, most existing learning path planning approaches lack transparency, adaptability, and learner-centered explainability. To address these challenges, this study proposes a novel Multi-Agent Learning Path Planning (MALPP) framework that leverages a role- and rule-based collaboration mechanism among intelligent agents, each powered by LLMs. The framework includes three task-specific agents: a learner analytics agent, a path planning agent, and a reflection agent. These agents collaborate via structured prompts and predefined rules to analyze learning profiles, generate tailored learning paths, and iteratively refine them with interpretable feedback. Grounded in Cognitive Load Theory and Zone of Proximal Development, the system ensures that recommended paths are cognitively aligned and pedagogically meaningful. Experiments conducted on the MOOCCubeX dataset using seven LLMs show that MALPP significantly outperforms baseline models in path quality, knowledge sequence consistency, and cognitive load alignment. Ablation studies further validate the effectiveness of the collaborative mechanism and theoretical constraints. This research contributes to the development of trustworthy, explainable AI in education and demonstrates a scalable approach to learner-centered adaptive instruction powered by LLMs.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u8def\u5f84\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7\u89d2\u8272\u5316\u667a\u80fd\u4f53\u534f\u4f5c\u5b9e\u73b0\u900f\u660e\u3001\u81ea\u9002\u5e94\u3001\u53ef\u89e3\u91ca\u7684\u4e2a\u6027\u5316\u5b66\u4e60\u8def\u5f84\u89c4\u5212", "motivation": "\u73b0\u6709\u667a\u80fd\u5bfc\u5b66\u7cfb\u7edf\u4e2d\u7684\u5b66\u4e60\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u7f3a\u4e4f\u900f\u660e\u5ea6\u3001\u9002\u5e94\u6027\u548c\u4ee5\u5b66\u4e60\u8005\u4e3a\u4e2d\u5fc3\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u53ef\u4fe1\u3001\u53ef\u89e3\u91ca\u7684\u6559\u80b2AI\u7cfb\u7edf", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u8def\u5f84\u89c4\u5212\u6846\u67b6\uff0c\u5305\u542b\u5b66\u4e60\u8005\u5206\u6790\u3001\u8def\u5f84\u89c4\u5212\u548c\u53cd\u601d\u4e09\u4e2a\u4efb\u52a1\u7279\u5b9a\u667a\u80fd\u4f53\uff0c\u57fa\u4e8e\u89d2\u8272\u548c\u89c4\u5219\u534f\u4f5c\u673a\u5236\uff0c\u4f7f\u7528\u7ed3\u6784\u5316\u63d0\u793a\u548c\u9884\u5b9a\u4e49\u89c4\u5219\uff0c\u57fa\u4e8e\u8ba4\u77e5\u8d1f\u8377\u7406\u8bba\u548c\u6700\u8fd1\u53d1\u5c55\u533a\u7406\u8bba\u8fdb\u884c\u7ea6\u675f", "result": "\u5728MOOCCubeX\u6570\u636e\u96c6\u4e0a\u4f7f\u75287\u4e2aLLM\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMALPP\u5728\u8def\u5f84\u8d28\u91cf\u3001\u77e5\u8bc6\u5e8f\u5217\u4e00\u81f4\u6027\u548c\u8ba4\u77e5\u8d1f\u8377\u5bf9\u9f50\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u534f\u4f5c\u673a\u5236\u548c\u7406\u8bba\u7ea6\u675f\u7684\u6709\u6548\u6027", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u53ef\u4fe1\u3001\u53ef\u89e3\u91ca\u7684\u6559\u80b2AI\u53d1\u5c55\u505a\u51fa\u8d21\u732e\uff0c\u5c55\u793a\u4e86\u57fa\u4e8eLLM\u7684\u4ee5\u5b66\u4e60\u8005\u4e3a\u4e2d\u5fc3\u7684\u81ea\u9002\u5e94\u6559\u5b66\u7684\u89c4\u6a21\u5316\u65b9\u6cd5\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2601.17181", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17181", "abs": "https://arxiv.org/abs/2601.17181", "authors": ["Doreen Osmelak", "Yang Xu", "Michael Hahn", "Kate McCurdy"], "title": "Systematicity between Forms and Meanings across Languages Supports Efficient Communication", "comment": null, "summary": "Languages vary widely in how meanings map to word forms. These mappings have been found to support efficient communication; however, this theory does not account for systematic relations within word forms. We examine how a restricted set of grammatical meanings (e.g. person, number) are expressed on verbs and pronouns across typologically diverse languages. Consistent with prior work, we find that verb and pronoun forms are shaped by competing communicative pressures for simplicity (minimizing the inventory of grammatical distinctions) and accuracy (enabling recovery of intended meanings). Crucially, our proposed model uses a novel measure of complexity (inverse of simplicity) based on the learnability of meaning-to-form mappings. This innovation captures fine-grained regularities in linguistic form, allowing better discrimination between attested and unattested systems, and establishes a new connection from efficient communication theory to systematicity in natural language.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u5b66\u4e60\u6027\u7684\u590d\u6742\u5ea6\u5ea6\u91cf\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u91ca\u52a8\u8bcd\u548c\u4ee3\u8bcd\u5f62\u5f0f\u4e2d\u8bed\u6cd5\u610f\u4e49\u6620\u5c04\u7684\u7cfb\u7edf\u6027\u89c4\u5f8b\uff0c\u5c06\u9ad8\u6548\u4ea4\u9645\u7406\u8bba\u4e0e\u81ea\u7136\u8bed\u8a00\u7684\u7cfb\u7edf\u6027\u8054\u7cfb\u8d77\u6765\u3002", "motivation": "\u73b0\u6709\u9ad8\u6548\u4ea4\u9645\u7406\u8bba\u672a\u80fd\u5145\u5206\u89e3\u91ca\u8bcd\u5f62\u5185\u90e8\u7684\u7cfb\u7edf\u6027\u5173\u7cfb\u3002\u4e0d\u540c\u8bed\u8a00\u4e2d\u8bed\u6cd5\u610f\u4e49\uff08\u5982\u4eba\u79f0\u3001\u6570\uff09\u5230\u8bcd\u5f62\u7684\u6620\u5c04\u5b58\u5728\u89c4\u5f8b\u6027\u53d8\u5316\uff0c\u9700\u8981\u65b0\u7684\u7406\u8bba\u6846\u67b6\u6765\u89e3\u91ca\u8fd9\u4e9b\u7cfb\u7edf\u6027\u7684\u5f62\u5f0f\u5173\u7cfb\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u53ef\u5b66\u4e60\u6027\u7684\u590d\u6742\u5ea6\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5206\u6790\u8de8\u8bed\u8a00\u7c7b\u578b\u5b66\u4e0a\u591a\u6837\u5316\u7684\u8bed\u8a00\u4e2d\u52a8\u8bcd\u548c\u4ee3\u8bcd\u5f62\u5f0f\u7684\u8bed\u6cd5\u610f\u4e49\u6620\u5c04\u3002\u6a21\u578b\u8003\u8651\u7b80\u6d01\u6027\uff08\u6700\u5c0f\u5316\u8bed\u6cd5\u533a\u5206\uff09\u548c\u51c6\u786e\u6027\uff08\u6062\u590d\u610f\u56fe\u610f\u4e49\uff09\u4e4b\u95f4\u7684\u7ade\u4e89\u538b\u529b\u3002", "result": "\u65b0\u6a21\u578b\u80fd\u591f\u6355\u6349\u8bed\u8a00\u5f62\u5f0f\u4e2d\u7684\u7ec6\u7c92\u5ea6\u89c4\u5f8b\u6027\uff0c\u66f4\u597d\u5730\u533a\u5206\u5b9e\u9645\u5b58\u5728\u7684\u8bed\u8a00\u7cfb\u7edf\u548c\u7406\u8bba\u4e0a\u53ef\u80fd\u4f46\u672a\u51fa\u73b0\u7684\u7cfb\u7edf\uff0c\u9a8c\u8bc1\u4e86\u52a8\u8bcd\u548c\u4ee3\u8bcd\u5f62\u5f0f\u786e\u5b9e\u53d7\u5230\u7b80\u6d01\u6027\u548c\u51c6\u786e\u6027\u7ade\u4e89\u538b\u529b\u7684\u5f71\u54cd\u3002", "conclusion": "\u57fa\u4e8e\u53ef\u5b66\u4e60\u6027\u7684\u590d\u6742\u5ea6\u5ea6\u91cf\u4e3a\u7406\u89e3\u8bed\u8a00\u5f62\u5f0f\u7684\u7cfb\u7edf\u6027\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5efa\u7acb\u4e86\u9ad8\u6548\u4ea4\u9645\u7406\u8bba\u4e0e\u81ea\u7136\u8bed\u8a00\u7cfb\u7edf\u6027\u4e4b\u95f4\u7684\u65b0\u8054\u7cfb\uff0c\u89e3\u91ca\u4e86\u8bed\u6cd5\u610f\u4e49\u6620\u5c04\u4e2d\u7684\u89c4\u5f8b\u6027\u6a21\u5f0f\u3002"}}
{"id": "2601.17348", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17348", "abs": "https://arxiv.org/abs/2601.17348", "authors": ["Srikant Panda", "Sourabh Singh Yadav", "Palkesh Malviya"], "title": "Auditing Disability Representation in Vision-Language Models", "comment": null, "summary": "Vision-language models (VLMs) are increasingly deployed in socially sensitive applications, yet their behavior with respect to disability remains underexplored. We study disability aware descriptions for person centric images, where models often transition from evidence grounded factual description to interpretation shift including introduction of unsupported inferences beyond observable visual evidence. To systematically analyze this phenomenon, we introduce a benchmark based on paired Neutral Prompts (NP) and Disability-Contextualised Prompts (DP) and evaluate 15 state-of-the-art open- and closed-source VLMs under a zero-shot setting across 9 disability categories. Our evaluation framework treats interpretive fidelity as core objective and combines standard text-based metrics capturing affective degradation through shifts in sentiment, social regard and response length with an LLM-as-judge protocol, validated by annotators with lived experience of disability. We find that introducing disability context consistently degrades interpretive fidelity, inducing interpretation shifts characterised by speculative inference, narrative elaboration, affective degradation and deficit oriented framing. These effects are further amplified along race and gender dimension. Finally, we demonstrate targeted prompting and preference fine-tuning effectively improves interpretive fidelity and reduces substantially interpretation shifts.", "AI": {"tldr": "\u7814\u7a76\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u6b8b\u75be\u76f8\u5173\u63cf\u8ff0\u4e2d\u7684\u89e3\u91ca\u504f\u79fb\u95ee\u9898\uff0c\u53d1\u73b0\u5f15\u5165\u6b8b\u75be\u4e0a\u4e0b\u6587\u4f1a\u964d\u4f4e\u89e3\u91ca\u4fdd\u771f\u5ea6\uff0c\u5bfc\u81f4\u63a8\u6d4b\u6027\u63a8\u65ad\u3001\u53d9\u4e8b\u6269\u5c55\u3001\u60c5\u611f\u964d\u7ea7\u548c\u7f3a\u9677\u5bfc\u5411\u6846\u67b6\u7b49\u504f\u5dee\uff0c\u8fd9\u4e9b\u6548\u5e94\u5728\u79cd\u65cf\u548c\u6027\u522b\u7ef4\u5ea6\u4e0a\u8fdb\u4e00\u6b65\u653e\u5927\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u5e94\u7528\u4e8e\u793e\u4f1a\u654f\u611f\u9886\u57df\uff0c\u4f46\u5b83\u4eec\u5728\u6b8b\u75be\u76f8\u5173\u884c\u4e3a\u65b9\u9762\u7684\u8868\u73b0\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u6a21\u578b\u5728\u4eba\u7269\u4e2d\u5fc3\u56fe\u50cf\u63cf\u8ff0\u4e2d\u7ecf\u5e38\u4ece\u57fa\u4e8e\u8bc1\u636e\u7684\u4e8b\u5b9e\u63cf\u8ff0\u8f6c\u5411\u89e3\u91ca\u504f\u79fb\uff0c\u5f15\u5165\u8d85\u51fa\u53ef\u89c2\u5bdf\u89c6\u89c9\u8bc1\u636e\u7684\u4e0d\u652f\u6301\u63a8\u65ad\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u4e2d\u6027\u63d0\u793a\u548c\u6b8b\u75be\u60c5\u5883\u5316\u63d0\u793a\u914d\u5bf9\u7684\u57fa\u51c6\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u8bc4\u4f3015\u4e2a\u6700\u5148\u8fdb\u7684\u5f00\u653e\u548c\u95ed\u6e90\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u6db5\u76d69\u4e2a\u6b8b\u75be\u7c7b\u522b\u3002\u8bc4\u4f30\u6846\u67b6\u5c06\u89e3\u91ca\u4fdd\u771f\u5ea6\u4f5c\u4e3a\u6838\u5fc3\u76ee\u6807\uff0c\u7ed3\u5408\u6807\u51c6\u6587\u672c\u6307\u6807\uff08\u6355\u6349\u60c5\u611f\u964d\u7ea7\u3001\u793e\u4f1a\u5173\u6ce8\u548c\u54cd\u5e94\u957f\u5ea6\u53d8\u5316\uff09\u548c\u7ecf\u8fc7\u6b8b\u75be\u751f\u6d3b\u7ecf\u9a8c\u6807\u6ce8\u8005\u9a8c\u8bc1\u7684LLM-as-judge\u534f\u8bae\u3002", "result": "\u5f15\u5165\u6b8b\u75be\u4e0a\u4e0b\u6587\u4f1a\u6301\u7eed\u964d\u4f4e\u89e3\u91ca\u4fdd\u771f\u5ea6\uff0c\u5bfc\u81f4\u89e3\u91ca\u504f\u79fb\uff0c\u8868\u73b0\u4e3a\u63a8\u6d4b\u6027\u63a8\u65ad\u3001\u53d9\u4e8b\u6269\u5c55\u3001\u60c5\u611f\u964d\u7ea7\u548c\u7f3a\u9677\u5bfc\u5411\u6846\u67b6\u3002\u8fd9\u4e9b\u6548\u5e94\u5728\u79cd\u65cf\u548c\u6027\u522b\u7ef4\u5ea6\u4e0a\u8fdb\u4e00\u6b65\u653e\u5927\u3002\u9488\u5bf9\u6027\u63d0\u793a\u548c\u504f\u597d\u5fae\u8c03\u80fd\u6709\u6548\u63d0\u9ad8\u89e3\u91ca\u4fdd\u771f\u5ea6\u5e76\u663e\u8457\u51cf\u5c11\u89e3\u91ca\u504f\u79fb\u3002", "conclusion": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u6b8b\u75be\u76f8\u5173\u63cf\u8ff0\u4e2d\u5b58\u5728\u7cfb\u7edf\u6027\u89e3\u91ca\u504f\u79fb\u95ee\u9898\uff0c\u9700\u8981\u66f4\u4e25\u683c\u7684\u8bc4\u4f30\u548c\u5e72\u9884\u7b56\u7565\u3002\u9488\u5bf9\u6027\u63d0\u793a\u548c\u504f\u597d\u5fae\u8c03\u662f\u6539\u5584\u6a21\u578b\u89e3\u91ca\u4fdd\u771f\u5ea6\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u786e\u4fdd\u6a21\u578b\u5728\u793e\u4f1a\u654f\u611f\u5e94\u7528\u4e2d\u7684\u516c\u5e73\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2601.17692", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17692", "abs": "https://arxiv.org/abs/2601.17692", "authors": ["Yunhan Li", "Mingjie Xie", "Gaoli Kang", "Zihan Gong", "Gengshen Wu", "Min Yang"], "title": "LegalMALR:Multi-Agent Query Understanding and LLM-Based Reranking for Chinese Statute Retrieval", "comment": "31pages, 4 figures", "summary": "Statute retrieval is essential for legal assistance and judicial decision support, yet real-world legal queries are often implicit, multi-issue, and expressed in colloquial or underspecified forms. These characteristics make it difficult for conventional retrieval-augmented generation pipelines to recover the statutory elements required for accurate retrieval. Dense retrievers focus primarily on the literal surface form of the query, whereas lightweight rerankers lack the legal-reasoning capacity needed to assess statutory applicability. We present LegalMALR, a retrieval framework that integrates a Multi-Agent Query Understanding System (MAS) with a zero-shot large-language-model-based reranking module (LLM Reranker). MAS generates diverse, legally grounded reformulations and conducts iterative dense retrieval to broaden candidate coverage. To stabilise the stochastic behaviour of LLM-generated rewrites, we optimise a unified MAS policy using Generalized Reinforcement Policy Optimization(GRPO). The accumulated candidate set is subsequently evaluated by the LLM Reranker, which performs natural-language legal reasoning to produce the final ranking. We further construct CSAID, a dataset of 118 difficult Chinese legal queries annotated with multiple statutory labels, and evaluate LegalMALR on both CSAID and the public STARD benchmark. Experiments show that LegalMALR substantially outperforms strong Retrieval-augmented generation(RAG) baselines in both in-distribution and out-of-distribution settings, demonstrating the effectiveness of combining multi-perspective query interpretation, reinforcement-based policy optimisation, and large-model reranking for statute retrieval.", "AI": {"tldr": "LegalMALR\uff1a\u4e00\u4e2a\u96c6\u6210\u591a\u667a\u80fd\u4f53\u67e5\u8be2\u7406\u89e3\u7cfb\u7edf\u4e0e\u96f6\u6837\u672c\u5927\u8bed\u8a00\u6a21\u578b\u91cd\u6392\u6a21\u5757\u7684\u6cd5\u5f8b\u6cd5\u89c4\u68c0\u7d22\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u5bf9\u9690\u542b\u3001\u591a\u8bae\u9898\u3001\u53e3\u8bed\u5316\u6cd5\u5f8b\u67e5\u8be2\u7684\u68c0\u7d22\u6548\u679c", "motivation": "\u73b0\u5b9e\u4e2d\u7684\u6cd5\u5f8b\u67e5\u8be2\u901a\u5e38\u5177\u6709\u9690\u542b\u6027\u3001\u591a\u8bae\u9898\u6027\u548c\u53e3\u8bed\u5316\u7279\u5f81\uff0c\u8fd9\u4f7f\u5f97\u4f20\u7edf\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7ba1\u9053\u96be\u4ee5\u51c6\u786e\u6062\u590d\u6cd5\u89c4\u8981\u7d20\u3002\u5bc6\u96c6\u68c0\u7d22\u5668\u4e3b\u8981\u5173\u6ce8\u67e5\u8be2\u7684\u5b57\u9762\u5f62\u5f0f\uff0c\u800c\u8f7b\u91cf\u7ea7\u91cd\u6392\u5668\u7f3a\u4e4f\u8bc4\u4f30\u6cd5\u89c4\u9002\u7528\u6027\u6240\u9700\u7684\u6cd5\u5f8b\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faLegalMALR\u6846\u67b6\uff1a1\uff09\u591a\u667a\u80fd\u4f53\u67e5\u8be2\u7406\u89e3\u7cfb\u7edf\u751f\u6210\u591a\u6837\u5316\u7684\u6cd5\u5f8b\u57fa\u7840\u91cd\u8ff0\u5e76\u8fdb\u884c\u8fed\u4ee3\u5bc6\u96c6\u68c0\u7d22\u4ee5\u6269\u5927\u5019\u9009\u8986\u76d6\uff1b2\uff09\u4f7f\u7528\u5e7f\u4e49\u5f3a\u5316\u7b56\u7565\u4f18\u5316\u7edf\u4e00MAS\u7b56\u7565\u4ee5\u7a33\u5b9aLLM\u751f\u6210\u91cd\u8ff0\u7684\u968f\u673a\u884c\u4e3a\uff1b3\uff09LLM\u91cd\u6392\u6a21\u5757\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6cd5\u5f8b\u63a8\u7406\u5bf9\u7d2f\u79ef\u5019\u9009\u96c6\u8fdb\u884c\u6700\u7ec8\u6392\u5e8f\u3002\u6784\u5efa\u4e86\u5305\u542b118\u4e2a\u56f0\u96be\u4e2d\u6587\u6cd5\u5f8b\u67e5\u8be2\u7684CSAID\u6570\u636e\u96c6\u3002", "result": "\u5728CSAID\u6570\u636e\u96c6\u548c\u516c\u5f00STARD\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLegalMALR\u5728\u5206\u5e03\u5185\u548c\u5206\u5e03\u5916\u8bbe\u7f6e\u4e0b\u5747\u663e\u8457\u4f18\u4e8e\u5f3a\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u57fa\u7ebf\uff0c\u8bc1\u660e\u4e86\u7ed3\u5408\u591a\u89c6\u89d2\u67e5\u8be2\u89e3\u91ca\u3001\u57fa\u4e8e\u5f3a\u5316\u7684\u7b56\u7565\u4f18\u5316\u548c\u5927\u6a21\u578b\u91cd\u6392\u5bf9\u6cd5\u89c4\u68c0\u7d22\u7684\u6709\u6548\u6027\u3002", "conclusion": "LegalMALR\u901a\u8fc7\u96c6\u6210\u591a\u667a\u80fd\u4f53\u67e5\u8be2\u7406\u89e3\u3001\u5f3a\u5316\u7b56\u7565\u4f18\u5316\u548cLLM\u91cd\u6392\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6cd5\u5f8b\u67e5\u8be2\u7684\u9690\u542b\u6027\u3001\u591a\u8bae\u9898\u6027\u548c\u53e3\u8bed\u5316\u7279\u5f81\u5e26\u6765\u7684\u68c0\u7d22\u6311\u6218\uff0c\u4e3a\u6cd5\u5f8b\u8f85\u52a9\u548c\u53f8\u6cd5\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u6cd5\u898f\u68c0\u7d22\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17197", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17197", "abs": "https://arxiv.org/abs/2601.17197", "authors": ["Seyyed Saeid Cheshmi", "Hahnemann Ortiz", "James Mooney", "Dongyeop Kang"], "title": "Reasoning Beyond Literal: Cross-style Multimodal Reasoning for Figurative Language Understanding", "comment": null, "summary": "Vision-language models (VLMs) have demonstrated strong reasoning abilities in literal multimodal tasks such as visual mathematics and science question answering. However, figurative language, such as sarcasm, humor, and metaphor, remains a significant challenge, as it conveys intent and emotion through subtle incongruities between expressed and intended meanings. In multimodal settings, accompanying images can amplify or invert textual meaning, demanding models that reason across modalities and account for subjectivity. We propose a three-step framework for developing efficient multimodal reasoning models that can (i) interpret multimodal figurative language, (ii) provide transparent reasoning traces, and (iii) generalize across multiple figurative styles. Experiments across four styles show that (1) incorporating reasoning traces substantially improves multimodal figurative understanding, (2) reasoning learned in one style can transfer to others, especially between related styles like sarcasm and humor, and (3) training jointly across styles yields a generalized reasoning VLM that outperforms much larger open- and closed-source models. Our findings show that lightweight VLMs with verifiable reasoning achieve robust cross-style generalization while providing inspectable reasoning traces for multimodal tasks. The code and implementation are available at https://github.com/scheshmi/CrossStyle-MMR.", "code_url": "https://github.com/scheshmi/CrossStyle-MMR", "code_stars": 1, "code_last_update": "2026-01-19", "AI": {"tldr": "\u63d0\u51fa\u4e09\u6b65\u9aa4\u6846\u67b6\u5f00\u53d1\u9ad8\u6548\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578b\uff0c\u89e3\u51b3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u7406\u89e3\u591a\u6a21\u6001\u6bd4\u55bb\u8bed\u8a00\uff08\u5982\u8bbd\u523a\u3001\u5e7d\u9ed8\u3001\u9690\u55bb\uff09\u65b9\u9762\u7684\u6311\u6218\uff0c\u901a\u8fc7\u63a8\u7406\u8f68\u8ff9\u63d0\u5347\u7406\u89e3\u80fd\u529b\u5e76\u5b9e\u73b0\u8de8\u98ce\u683c\u6cdb\u5316\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u5b57\u9762\u591a\u6a21\u6001\u4efb\u52a1\uff08\u5982\u89c6\u89c9\u6570\u5b66\u548c\u79d1\u5b66\u95ee\u7b54\uff09\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5728\u7406\u89e3\u6bd4\u55bb\u8bed\u8a00\uff08\u5982\u8bbd\u523a\u3001\u5e7d\u9ed8\u3001\u9690\u55bb\uff09\u65b9\u9762\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u6bd4\u55bb\u8bed\u8a00\u901a\u8fc7\u8868\u8fbe\u610f\u4e49\u4e0e\u610f\u56fe\u610f\u4e49\u4e4b\u95f4\u7684\u5fae\u5999\u4e0d\u4e00\u81f4\u6765\u4f20\u8fbe\u610f\u56fe\u548c\u60c5\u611f\uff0c\u5728\u591a\u6a21\u6001\u73af\u5883\u4e2d\uff0c\u4f34\u968f\u7684\u56fe\u50cf\u53ef\u4ee5\u653e\u5927\u6216\u53cd\u8f6c\u6587\u672c\u542b\u4e49\uff0c\u9700\u8981\u80fd\u591f\u8de8\u6a21\u6001\u63a8\u7406\u5e76\u8003\u8651\u4e3b\u89c2\u6027\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e09\u6b65\u9aa4\u6846\u67b6\u5f00\u53d1\u9ad8\u6548\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578b\uff1a1) \u89e3\u91ca\u591a\u6a21\u6001\u6bd4\u55bb\u8bed\u8a00\uff1b2) \u63d0\u4f9b\u900f\u660e\u7684\u63a8\u7406\u8f68\u8ff9\uff1b3) \u8de8\u591a\u79cd\u6bd4\u55bb\u98ce\u683c\u6cdb\u5316\u3002\u5728\u56db\u79cd\u98ce\u683c\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7814\u7a76\u63a8\u7406\u8f68\u8ff9\u7684\u878d\u5165\u6548\u679c\u3001\u98ce\u683c\u95f4\u7684\u77e5\u8bc6\u8fc1\u79fb\u4ee5\u53ca\u8de8\u98ce\u683c\u8054\u5408\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff1a1) \u878d\u5165\u63a8\u7406\u8f68\u8ff9\u663e\u8457\u63d0\u5347\u591a\u6a21\u6001\u6bd4\u55bb\u7406\u89e3\u80fd\u529b\uff1b2) \u5728\u4e00\u79cd\u98ce\u683c\u4e2d\u5b66\u5230\u7684\u63a8\u7406\u80fd\u529b\u53ef\u4ee5\u8fc1\u79fb\u5230\u5176\u4ed6\u98ce\u683c\uff0c\u7279\u522b\u662f\u5728\u76f8\u5173\u98ce\u683c\uff08\u5982\u8bbd\u523a\u548c\u5e7d\u9ed8\uff09\u4e4b\u95f4\uff1b3) \u8de8\u98ce\u683c\u8054\u5408\u8bad\u7ec3\u4ea7\u751f\u7684\u901a\u7528\u63a8\u7406\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4f18\u4e8e\u66f4\u5927\u7684\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\u3002", "conclusion": "\u8f7b\u91cf\u7ea7\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u53ef\u9a8c\u8bc1\u7684\u63a8\u7406\u80fd\u591f\u5b9e\u73b0\u9c81\u68d2\u7684\u8de8\u98ce\u683c\u6cdb\u5316\uff0c\u540c\u65f6\u4e3a\u591a\u6a21\u6001\u4efb\u52a1\u63d0\u4f9b\u53ef\u68c0\u67e5\u7684\u63a8\u7406\u8f68\u8ff9\u3002\u8fd9\u8868\u660e\u9ad8\u6548\u7684\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578b\u53ef\u4ee5\u5728\u4fdd\u6301\u8f7b\u91cf\u5316\u7684\u540c\u65f6\uff0c\u6709\u6548\u5904\u7406\u590d\u6742\u7684\u6bd4\u55bb\u8bed\u8a00\u7406\u89e3\u4efb\u52a1\u3002"}}
{"id": "2601.17426", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.17426", "abs": "https://arxiv.org/abs/2601.17426", "authors": ["Zhengqing Zang", "Yuqi Ding", "Yanmei Gu", "Changkai Song", "Zhengkai Yang", "Guoping Du", "Junbo Zhao", "Haobo Wang"], "title": "A Syllogistic Probe: Tracing the Evolution of Logic Reasoning in Large Language Models", "comment": null, "summary": "Human logic has gradually shifted from intuition-driven inference to rigorous formal systems. Motivated by recent advances in large language models (LLMs), we explore whether LLMs exhibit a similar evolution in the underlying logical framework. Using existential import as a probe, we for evaluate syllogism under traditional and modern logic. Through extensive experiments of testing SOTA LLMs on a new syllogism dataset, we have some interesting findings: (i) Model size scaling promotes the shift toward modern logic; (ii) Thinking serves as an efficient accelerator beyond parameter scaling; (iii) the Base model plays a crucial role in determining how easily and stably this shift can emerge. Beyond these core factors, we conduct additional experiments for in-depth analysis of properties of current LLMs on syllogistic reasoning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u903b\u8f91\u63a8\u7406\u4e2d\u662f\u5426\u8868\u73b0\u51fa\u4ece\u4f20\u7edf\u903b\u8f91\u5411\u73b0\u4ee3\u903b\u8f91\u7684\u6f14\u53d8\uff0c\u4f7f\u7528\u5b58\u5728\u5f15\u5165\u4f5c\u4e3a\u63a2\u9488\uff0c\u901a\u8fc7\u4e09\u6bb5\u8bba\u6d4b\u8bd5\u53d1\u73b0\u6a21\u578b\u89c4\u6a21\u3001\u601d\u7ef4\u94fe\u548c\u57fa\u7840\u6a21\u578b\u662f\u5f71\u54cd\u8fd9\u4e00\u6f14\u53d8\u7684\u5173\u952e\u56e0\u7d20\u3002", "motivation": "\u4eba\u7c7b\u903b\u8f91\u4ece\u76f4\u89c9\u9a71\u52a8\u63a8\u7406\u8f6c\u5411\u4e25\u8c28\u7684\u5f62\u5f0f\u7cfb\u7edf\uff0c\u53d7\u5927\u8bed\u8a00\u6a21\u578b\u6700\u65b0\u8fdb\u5c55\u542f\u53d1\uff0c\u7814\u7a76\u8005\u63a2\u7d22LLMs\u662f\u5426\u5728\u5e95\u5c42\u903b\u8f91\u6846\u67b6\u4e0a\u8868\u73b0\u51fa\u7c7b\u4f3c\u7684\u6f14\u53d8\uff0c\u7279\u522b\u662f\u4f7f\u7528\u5b58\u5728\u5f15\u5165\u4f5c\u4e3a\u63a2\u9488\u6765\u8bc4\u4f30\u4e09\u6bb5\u8bba\u63a8\u7406\u3002", "method": "\u4f7f\u7528\u5b58\u5728\u5f15\u5165\u4f5c\u4e3a\u63a2\u9488\uff0c\u5728\u4f20\u7edf\u903b\u8f91\u548c\u73b0\u4ee3\u903b\u8f91\u6846\u67b6\u4e0b\u8bc4\u4f30\u4e09\u6bb5\u8bba\u63a8\u7406\u3002\u901a\u8fc7\u5728\u65b0\u6784\u5efa\u7684\u4e09\u6bb5\u8bba\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u6700\u5148\u8fdb\u7684LLMs\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u5206\u6790\u6a21\u578b\u89c4\u6a21\u3001\u601d\u7ef4\u94fe\u548c\u57fa\u7840\u6a21\u578b\u7b49\u56e0\u7d20\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u4e09\u4e2a\u5173\u952e\u7ed3\u679c\uff1a(1) \u6a21\u578b\u89c4\u6a21\u6269\u5c55\u4fc3\u8fdb\u5411\u73b0\u4ee3\u903b\u8f91\u7684\u8f6c\u53d8\uff1b(2) \u601d\u7ef4\u94fe\u4f5c\u4e3a\u53c2\u6570\u6269\u5c55\u4e4b\u5916\u7684\u9ad8\u6548\u52a0\u901f\u5668\uff1b(3) \u57fa\u7840\u6a21\u578b\u5728\u51b3\u5b9a\u8fd9\u4e00\u8f6c\u53d8\u7684\u5bb9\u6613\u7a0b\u5ea6\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u8d77\u5173\u952e\u4f5c\u7528\u3002\u6b64\u5916\u8fd8\u8fdb\u884c\u4e86\u989d\u5916\u5b9e\u9a8c\u6df1\u5165\u5206\u6790\u5f53\u524dLLMs\u5728\u4e09\u6bb5\u8bba\u63a8\u7406\u4e0a\u7684\u7279\u6027\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u903b\u8f91\u63a8\u7406\u4e2d\u786e\u5b9e\u8868\u73b0\u51fa\u4ece\u4f20\u7edf\u903b\u8f91\u5411\u73b0\u4ee3\u903b\u8f91\u7684\u6f14\u53d8\u8d8b\u52bf\uff0c\u6a21\u578b\u89c4\u6a21\u3001\u601d\u7ef4\u94fe\u548c\u57fa\u7840\u6a21\u578b\u662f\u5f71\u54cd\u8fd9\u4e00\u6f14\u53d8\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4e3a\u7406\u89e3LLMs\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2601.17787", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.17787", "abs": "https://arxiv.org/abs/2601.17787", "authors": ["Wei-Ning Chiu", "Chuan-Ju Wang", "Pu-Jen Cheng"], "title": "Token-Weighted Multi-Target Learning for Generative Recommenders with Curriculum Learning", "comment": "11 pages, 5 figures", "summary": "Generative recommender systems have recently attracted attention by formulating next-item prediction as an autoregressive sequence generation task. However, most existing methods optimize standard next-token likelihood and implicitly treat all tokens as equally informative, which is misaligned with semantic-ID-based generation. Accordingly, we propose two complementary information-gain-based token-weighting strategies tailored to generative recommendation with semantic IDs. Front-Greater Weighting captures conditional semantic information gain by prioritizing early tokens that most effectively reduce candidate-item uncertainty given their prefixes and encode coarse semantics. Frequency Weighting models marginal information gain under long-tailed item and token distributions, upweighting rare tokens to counteract popularity bias. Beyond individual strategies, we introduce a multi-target learning framework with curriculum learning that jointly optimizes the two token-weighted objectives alongside standard likelihood, enabling stable optimization and adaptive emphasis across training stages. Extensive experiments on benchmark datasets show that our method consistently outperforms strong baselines and existing token-weighting approaches, with improved robustness, strong generalization across different semantic-ID constructions, and substantial gains on both head and tail items. Code is available at https://github.com/CHIUWEINING/Token-Weighted-Multi-Target-Learning-for-Generative-Recommenders-with-Curriculum-Learning.", "code_url": "https://github.com/CHIUWEINING/Token-Weighted-Multi-Target-Learning-for-Generative-Recommenders-with-Curriculum-Learnin", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9488\u5bf9\u8bed\u4e49ID\u751f\u6210\u63a8\u8350\u7cfb\u7edf\u7684\u4e24\u79cd\u4e92\u8865\u7684token\u52a0\u6743\u7b56\u7565\u548c\u8bfe\u7a0b\u5b66\u4e60\u591a\u76ee\u6807\u6846\u67b6\uff0c\u89e3\u51b3\u6807\u51c6\u4f3c\u7136\u4f18\u5316\u4e2d\u6240\u6709token\u540c\u7b49\u5bf9\u5f85\u7684\u95ee\u9898\uff0c\u63d0\u5347\u63a8\u8350\u6027\u80fd", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u5c06\u4e0b\u4e00\u9879\u9884\u6d4b\u89c6\u4e3a\u81ea\u56de\u5f52\u5e8f\u5217\u751f\u6210\u4efb\u52a1\uff0c\u4f46\u5927\u591a\u4f18\u5316\u6807\u51c6\u4e0b\u4e00token\u4f3c\u7136\uff0c\u9690\u542b\u5730\u5c06\u6240\u6709token\u89c6\u4e3a\u540c\u7b49\u4fe1\u606f\u91cf\uff0c\u8fd9\u4e0e\u57fa\u4e8e\u8bed\u4e49ID\u7684\u751f\u6210\u4e0d\u5339\u914d", "method": "\u63d0\u51fa\u4e24\u79cd\u4e92\u8865\u7684\u4fe1\u606f\u589e\u76catoken\u52a0\u6743\u7b56\u7565\uff1a1) Front-Greater Weighting\u901a\u8fc7\u4f18\u5148\u8003\u8651\u6700\u80fd\u51cf\u5c11\u5019\u9009\u9879\u4e0d\u786e\u5b9a\u6027\u7684\u65e9\u671ftoken\u6765\u6355\u83b7\u6761\u4ef6\u8bed\u4e49\u4fe1\u606f\u589e\u76ca\uff1b2) Frequency Weighting\u5728\u957f\u5c3e\u5206\u5e03\u4e0b\u5efa\u6a21\u8fb9\u9645\u4fe1\u606f\u589e\u76ca\uff0c\u5bf9\u7a00\u6709token\u52a0\u6743\u4ee5\u62b5\u6d88\u6d41\u884c\u5ea6\u504f\u5dee\u3002\u6b64\u5916\u5f15\u5165\u8bfe\u7a0b\u5b66\u4e60\u591a\u76ee\u6807\u6846\u67b6\uff0c\u8054\u5408\u4f18\u5316\u4e24\u4e2atoken\u52a0\u6743\u76ee\u6807\u548c\u6807\u51c6\u4f3c\u7136", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u548c\u73b0\u6709token\u52a0\u6743\u65b9\u6cd5\uff0c\u5177\u6709\u6539\u8fdb\u7684\u9c81\u68d2\u6027\u3001\u8de8\u4e0d\u540c\u8bed\u4e49ID\u6784\u5efa\u7684\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u4ee5\u53ca\u5728\u5934\u90e8\u548c\u5c3e\u90e8\u9879\u76ee\u4e0a\u7684\u663e\u8457\u589e\u76ca", "conclusion": "\u63d0\u51fa\u7684token\u52a0\u6743\u591a\u76ee\u6807\u5b66\u4e60\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u8bed\u4e49ID\u751f\u6210\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u4fe1\u606f\u589e\u76ca\u7b56\u7565\u548c\u8bfe\u7a0b\u5b66\u4e60\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u63a8\u8350\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u957f\u5c3e\u5206\u5e03\u548c\u8bed\u4e49\u4fe1\u606f\u6355\u83b7\u65b9\u9762"}}
{"id": "2601.17203", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17203", "abs": "https://arxiv.org/abs/2601.17203", "authors": ["Scott Friedman", "Sonja Schmer-Galunder", "Anthony Chen", "Jeffrey Rye"], "title": "Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis", "comment": "7 pages, 5 figures. Presented at the First Workshop on Gender Bias in Natural Language Processing (GeBNLP 2019)", "summary": "Modern models for common NLP tasks often employ machine learning techniques and train on journalistic, social media, or other culturally-derived text. These have recently been scrutinized for racial and gender biases, rooting from inherent bias in their training text. These biases are often sub-optimal and recent work poses methods to rectify them; however, these biases may shed light on actual racial or gender gaps in the culture(s) that produced the training text, thereby helping us understand cultural context through big data. This paper presents an approach for quantifying gender bias in word embeddings, and then using them to characterize statistical gender gaps in education, politics, economics, and health. We validate these metrics on 2018 Twitter data spanning 51 U.S. regions and 99 countries. We correlate state and country word embedding biases with 18 international and 5 U.S.-based statistical gender gaps, characterizing regularities and predictive strength.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5316\u8bcd\u5d4c\u5165\u4e2d\u6027\u522b\u504f\u89c1\u7684\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u504f\u89c1\u6765\u8868\u5f81\u6559\u80b2\u3001\u653f\u6cbb\u3001\u7ecf\u6d4e\u548c\u5065\u5eb7\u9886\u57df\u7684\u7edf\u8ba1\u6027\u522b\u5dee\u8ddd\uff0c\u901a\u8fc72018\u5e74\u63a8\u7279\u6570\u636e\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u572851\u4e2a\u7f8e\u56fd\u5730\u533a\u548c99\u4e2a\u56fd\u5bb6\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u4ee3NLP\u6a21\u578b\u901a\u5e38\u57fa\u4e8e\u65b0\u95fb\u3001\u793e\u4ea4\u5a92\u4f53\u7b49\u6587\u5316\u884d\u751f\u6587\u672c\u8fdb\u884c\u8bad\u7ec3\uff0c\u8fd9\u4e9b\u6587\u672c\u5b58\u5728\u56fa\u6709\u7684\u79cd\u65cf\u548c\u6027\u522b\u504f\u89c1\u3002\u867d\u7136\u8fd9\u4e9b\u504f\u89c1\u901a\u5e38\u88ab\u89c6\u4e3a\u9700\u8981\u4fee\u6b63\u7684\u95ee\u9898\uff0c\u4f46\u5b83\u4eec\u4e5f\u53ef\u80fd\u53cd\u6620\u4e86\u4ea7\u751f\u8bad\u7ec3\u6587\u672c\u7684\u6587\u5316\u4e2d\u5b9e\u9645\u5b58\u5728\u7684\u6027\u522b\u5dee\u8ddd\uff0c\u4ece\u800c\u6709\u52a9\u4e8e\u901a\u8fc7\u5927\u6570\u636e\u7406\u89e3\u6587\u5316\u80cc\u666f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5316\u8bcd\u5d4c\u5165\u4e2d\u6027\u522b\u504f\u89c1\u7684\u65b9\u6cd5\uff0c\u7136\u540e\u5229\u7528\u8fd9\u4e9b\u504f\u89c1\u6765\u8868\u5f81\u6559\u80b2\u3001\u653f\u6cbb\u3001\u7ecf\u6d4e\u548c\u5065\u5eb7\u9886\u57df\u7684\u7edf\u8ba1\u6027\u522b\u5dee\u8ddd\u3002\u4f7f\u75282018\u5e74\u63a8\u7279\u6570\u636e\u5bf951\u4e2a\u7f8e\u56fd\u5730\u533a\u548c99\u4e2a\u56fd\u5bb6\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5c06\u8bcd\u5d4c\u5165\u504f\u89c1\u4e0e\u56fd\u9645\u548c\u7f8e\u56fd\u7edf\u8ba1\u6027\u522b\u5dee\u8ddd\u8fdb\u884c\u76f8\u5173\u6027\u5206\u6790\u3002", "result": "\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u57282018\u5e74\u63a8\u7279\u6570\u636e\u4e0a\u7684\u6709\u6548\u6027\uff0c\u8986\u76d651\u4e2a\u7f8e\u56fd\u5730\u533a\u548c99\u4e2a\u56fd\u5bb6\u3002\u5c06\u5dde\u548c\u56fd\u5bb6\u5c42\u9762\u7684\u8bcd\u5d4c\u5165\u504f\u89c1\u4e0e18\u4e2a\u56fd\u9645\u7edf\u8ba1\u6027\u522b\u5dee\u8ddd\u548c5\u4e2a\u7f8e\u56fd\u7edf\u8ba1\u6027\u522b\u5dee\u8ddd\u8fdb\u884c\u76f8\u5173\u6027\u5206\u6790\uff0c\u8868\u5f81\u4e86\u89c4\u5f8b\u6027\u548c\u9884\u6d4b\u5f3a\u5ea6\u3002", "conclusion": "\u8bcd\u5d4c\u5165\u4e2d\u7684\u6027\u522b\u504f\u89c1\u4e0d\u4ec5\u53cd\u6620\u4e86\u6a21\u578b\u504f\u5dee\uff0c\u4e5f\u53ef\u80fd\u63ed\u793a\u4e86\u4ea7\u751f\u8bad\u7ec3\u6587\u672c\u7684\u6587\u5316\u4e2d\u5b9e\u9645\u5b58\u5728\u7684\u7edf\u8ba1\u6027\u522b\u5dee\u8ddd\u3002\u8be5\u65b9\u6cd5\u4e3a\u901a\u8fc7\u5927\u6570\u636e\u5206\u6790\u7406\u89e3\u6587\u5316\u80cc\u666f\u4e2d\u7684\u6027\u522b\u5dee\u5f02\u63d0\u4f9b\u4e86\u91cf\u5316\u5de5\u5177\u3002"}}
{"id": "2601.17481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17481", "abs": "https://arxiv.org/abs/2601.17481", "authors": ["Emily Broadhurst", "Tawab Safi", "Joseph Edell", "Vashisht Ganesh", "Karime Maamari"], "title": "Lattice: Generative Guardrails for Conversational Agents", "comment": null, "summary": "Conversational AI systems require guardrails to prevent harmful outputs, yet existing approaches use static rules that cannot adapt to new threats or deployment contexts. We introduce Lattice, a framework for self-constructing and continuously improving guardrails. Lattice operates in two stages: construction builds initial guardrails from labeled examples through iterative simulation and optimization; continuous improvement autonomously adapts deployed guardrails through risk assessment, adversarial testing, and consolidation. Evaluated on the ProsocialDialog dataset, Lattice achieves 91% F1 on held-out data, outperforming keyword baselines by 43pp, LlamaGuard by 25pp, and NeMo by 4pp. The continuous improvement stage achieves 7pp F1 improvement on cross-domain data through closed-loop optimization. Our framework shows that effective guardrails can be self-constructed through iterative optimization.", "AI": {"tldr": "Lattice\u662f\u4e00\u4e2a\u7528\u4e8e\u5bf9\u8bddAI\u7cfb\u7edf\u62a4\u680f\u7684\u81ea\u6784\u5efa\u548c\u6301\u7eed\u6539\u8fdb\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u65b9\u6cd5\u5b9e\u73b0\u81ea\u9002\u5e94\u5b89\u5168\u9632\u62a4\u3002", "motivation": "\u73b0\u6709\u5bf9\u8bddAI\u7cfb\u7edf\u7684\u62a4\u680f\u4f7f\u7528\u9759\u6001\u89c4\u5219\uff0c\u65e0\u6cd5\u9002\u5e94\u65b0\u5a01\u80c1\u6216\u90e8\u7f72\u73af\u5883\u53d8\u5316\uff0c\u9700\u8981\u80fd\u591f\u81ea\u6211\u6784\u5efa\u548c\u6301\u7eed\u6539\u8fdb\u7684\u62a4\u680f\u6846\u67b6\u3002", "method": "Lattice\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u6784\u5efa\u9636\u6bb5\u901a\u8fc7\u8fed\u4ee3\u6a21\u62df\u548c\u4f18\u5316\u4ece\u6807\u6ce8\u793a\u4f8b\u6784\u5efa\u521d\u59cb\u62a4\u680f\uff1b\u6301\u7eed\u6539\u8fdb\u9636\u6bb5\u901a\u8fc7\u98ce\u9669\u8bc4\u4f30\u3001\u5bf9\u6297\u6d4b\u8bd5\u548c\u6574\u5408\u81ea\u4e3b\u9002\u5e94\u5df2\u90e8\u7f72\u7684\u62a4\u680f\u3002", "result": "\u5728ProsocialDialog\u6570\u636e\u96c6\u4e0a\uff0cLattice\u5728\u4fdd\u7559\u6570\u636e\u4e0a\u8fbe\u523091% F1\u5206\u6570\uff0c\u6bd4\u5173\u952e\u8bcd\u57fa\u7ebf\u9ad843\u4e2a\u767e\u5206\u70b9\uff0c\u6bd4LlamaGuard\u9ad825\u4e2a\u767e\u5206\u70b9\uff0c\u6bd4NeMo\u9ad84\u4e2a\u767e\u5206\u70b9\u3002\u6301\u7eed\u6539\u8fdb\u9636\u6bb5\u901a\u8fc7\u95ed\u73af\u4f18\u5316\u5728\u8de8\u57df\u6570\u636e\u4e0a\u5b9e\u73b07\u4e2a\u767e\u5206\u70b9\u7684F1\u63d0\u5347\u3002", "conclusion": "Lattice\u6846\u67b6\u8868\u660e\uff0c\u6709\u6548\u7684\u62a4\u680f\u53ef\u4ee5\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u5b9e\u73b0\u81ea\u6211\u6784\u5efa\uff0c\u4e3a\u5bf9\u8bddAI\u7cfb\u7edf\u63d0\u4f9b\u81ea\u9002\u5e94\u5b89\u5168\u9632\u62a4\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17836", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.17836", "abs": "https://arxiv.org/abs/2601.17836", "authors": ["Weijiang Lai", "Beihong Jin", "Di Zhang", "Siru Chen", "Jiongyan Zhang", "Yuhang Gou", "Jian Dong", "Xingxing Wang"], "title": "Unleashing the Potential of Sparse Attention on Long-term Behaviors for CTR Prediction", "comment": null, "summary": "In recent years, the success of large language models (LLMs) has driven the exploration of scaling laws in recommender systems. However, models that demonstrate scaling laws are actually challenging to deploy in industrial settings for modeling long sequences of user behaviors, due to the high computational complexity of the standard self-attention mechanism. Despite various sparse self-attention mechanisms proposed in other fields, they are not fully suited for recommendation scenarios. This is because user behaviors exhibit personalization and temporal characteristics: different users have distinct behavior patterns, and these patterns change over time, with data from these users differing significantly from data in other fields in terms of distribution. To address these challenges, we propose SparseCTR, an efficient and effective model specifically designed for long-term behaviors of users. To be precise, we first segment behavior sequences into chunks in a personalized manner to avoid separating continuous behaviors and enable parallel processing of sequences. Based on these chunks, we propose a three-branch sparse self-attention mechanism to jointly identify users' global interests, interest transitions, and short-term interests. Furthermore, we design a composite relative temporal encoding via learnable, head-specific bias coefficients, better capturing sequential and periodic relationships among user behaviors. Extensive experimental results show that SparseCTR not only improves efficiency but also outperforms state-of-the-art methods. More importantly, it exhibits an obvious scaling law phenomenon, maintaining performance improvements across three orders of magnitude in FLOPs. In online A/B testing, SparseCTR increased CTR by 1.72\\% and CPM by 1.41\\%. Our source code is available at https://github.com/laiweijiang/SparseCTR.", "code_url": "https://github.com/laiweijiang/SparseCTR", "code_stars": 1, "code_last_update": "2026-01-23", "AI": {"tldr": "SparseCTR\uff1a\u9488\u5bf9\u63a8\u8350\u7cfb\u7edf\u4e2d\u7528\u6237\u957f\u884c\u4e3a\u5e8f\u5217\u7684\u9ad8\u6548\u7a00\u758f\u6ce8\u610f\u529b\u6a21\u578b\uff0c\u901a\u8fc7\u4e2a\u6027\u5316\u5206\u5757\u548c\u4e09\u5206\u652f\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u63d0\u5347\u6548\u7387\u7684\u540c\u65f6\u5c55\u73b0\u660e\u663e\u7684\u7f29\u653e\u5b9a\u5f8b\u73b0\u8c61\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7f29\u653e\u5b9a\u5f8b\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u96be\u4ee5\u5b9e\u9645\u90e8\u7f72\uff0c\u56e0\u4e3a\u6807\u51c6\u81ea\u6ce8\u610f\u529b\u673a\u5236\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3002\u73b0\u6709\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u4e0d\u5b8c\u5168\u9002\u5408\u63a8\u8350\u573a\u666f\uff0c\u56e0\u4e3a\u7528\u6237\u884c\u4e3a\u5177\u6709\u4e2a\u6027\u5316\u3001\u65f6\u5e8f\u6027\u548c\u5206\u5e03\u7279\u6b8a\u6027\u3002", "method": "1. \u4e2a\u6027\u5316\u5206\u5757\uff1a\u5c06\u884c\u4e3a\u5e8f\u5217\u6309\u4e2a\u6027\u5316\u65b9\u5f0f\u5206\u5757\uff0c\u907f\u514d\u5206\u5272\u8fde\u7eed\u884c\u4e3a\u5e76\u652f\u6301\u5e76\u884c\u5904\u7406\uff1b2. \u4e09\u5206\u652f\u7a00\u758f\u81ea\u6ce8\u610f\u529b\uff1a\u8054\u5408\u8bc6\u522b\u7528\u6237\u5168\u5c40\u5174\u8da3\u3001\u5174\u8da3\u8f6c\u79fb\u548c\u77ed\u671f\u5174\u8da3\uff1b3. \u590d\u5408\u76f8\u5bf9\u65f6\u5e8f\u7f16\u7801\uff1a\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5934\u7279\u5b9a\u504f\u7f6e\u7cfb\u6570\u6355\u6349\u884c\u4e3a\u95f4\u7684\u65f6\u5e8f\u548c\u5468\u671f\u6027\u5173\u7cfb\u3002", "result": "SparseCTR\u4e0d\u4ec5\u63d0\u5347\u6548\u7387\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5728\u4e09\u4e2a\u6570\u91cf\u7ea7\u7684FLOPs\u8303\u56f4\u5185\u4fdd\u6301\u6027\u80fd\u63d0\u5347\uff0c\u5c55\u73b0\u660e\u663e\u7f29\u653e\u5b9a\u5f8b\u73b0\u8c61\u3002\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2dCTR\u63d0\u53471.72%\uff0cCPM\u63d0\u53471.41%\u3002", "conclusion": "SparseCTR\u662f\u9488\u5bf9\u7528\u6237\u957f\u884c\u4e3a\u5e8f\u5217\u7684\u9ad8\u6548\u6709\u6548\u6a21\u578b\uff0c\u901a\u8fc7\u4e2a\u6027\u5316\u5206\u5757\u548c\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u89e3\u51b3\u4e86\u63a8\u8350\u573a\u666f\u7684\u7279\u6b8a\u9700\u6c42\uff0c\u5b9e\u73b0\u4e86\u6548\u7387\u4e0e\u6027\u80fd\u7684\u53cc\u91cd\u63d0\u5347\uff0c\u5e76\u9a8c\u8bc1\u4e86\u7f29\u653e\u5b9a\u5f8b\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2601.17212", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17212", "abs": "https://arxiv.org/abs/2601.17212", "authors": ["Saadat Hasan Khan", "Spencer Hong", "Jingyu Wu", "Kevin Lybarger", "Youbing Yin", "Erin Babinsky", "Daben Liu"], "title": "DF-RAG: Query-Aware Diversity for Retrieval-Augmented Generation", "comment": "Accepted to Findings of EACL 2026", "summary": "Retrieval-augmented generation (RAG) is a common technique for grounding language model outputs in domain-specific information. However, RAG is often challenged by reasoning-intensive question-answering (QA), since common retrieval methods like cosine similarity maximize relevance at the cost of introducing redundant content, which can reduce information recall. To address this, we introduce Diversity-Focused Retrieval-Augmented Generation (DF-RAG), which systematically incorporates diversity into the retrieval step to improve performance on complex, reasoning-intensive QA benchmarks. DF-RAG builds upon the Maximal Marginal Relevance framework to select information chunks that are both relevant to the query and maximally dissimilar from each other. A key innovation of DF-RAG is its ability to optimize the level of diversity for each query dynamically at test time without requiring any additional fine-tuning or prior information. We show that DF-RAG improves F1 performance on reasoning-intensive QA benchmarks by 4-10 percent over vanilla RAG using cosine similarity and also outperforms other established baselines. Furthermore, we estimate an Oracle ceiling of up to 18 percent absolute F1 gains over vanilla RAG, of which DF-RAG captures up to 91.3 percent.", "AI": {"tldr": "DF-RAG\u901a\u8fc7\u591a\u6837\u6027\u589e\u5f3a\u68c0\u7d22\u6765\u63d0\u5347\u63a8\u7406\u5bc6\u96c6\u578bQA\u6027\u80fd\uff0c\u52a8\u6001\u4f18\u5316\u591a\u6837\u6027\u6c34\u5e73\uff0c\u65e0\u9700\u989d\u5916\u5fae\u8c03", "motivation": "\u4f20\u7edfRAG\u5728\u63a8\u7406\u5bc6\u96c6\u578bQA\u4efb\u52a1\u4e2d\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u57fa\u4e8e\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u68c0\u7d22\u65b9\u6cd5\u867d\u7136\u6700\u5927\u5316\u76f8\u5173\u6027\uff0c\u4f46\u4f1a\u5f15\u5165\u5197\u4f59\u5185\u5bb9\uff0c\u964d\u4f4e\u4fe1\u606f\u53ec\u56de\u7387", "method": "\u57fa\u4e8e\u6700\u5927\u8fb9\u9645\u76f8\u5173\u6027\u6846\u67b6\uff0c\u9009\u62e9\u65e2\u4e0e\u67e5\u8be2\u76f8\u5173\u53c8\u5f7c\u6b64\u6700\u5927\u7a0b\u5ea6\u4e0d\u540c\u7684\u4fe1\u606f\u5757\uff1b\u5173\u952e\u521b\u65b0\u662f\u80fd\u591f\u5728\u6d4b\u8bd5\u65f6\u52a8\u6001\u4f18\u5316\u6bcf\u4e2a\u67e5\u8be2\u7684\u591a\u6837\u6027\u6c34\u5e73\uff0c\u65e0\u9700\u989d\u5916\u5fae\u8c03\u6216\u5148\u9a8c\u4fe1\u606f", "result": "\u5728\u63a8\u7406\u5bc6\u96c6\u578bQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDF-RAG\u6bd4\u4f7f\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u666e\u901aRAG\u63d0\u9ad8\u4e864-10%\u7684F1\u5206\u6570\uff0c\u5e76\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\uff1b\u4f30\u8ba1Oracle\u4e0a\u9650\u6bd4\u666e\u901aRAG\u9ad8\u51fa18%\u7edd\u5bf9F1\u589e\u76ca\uff0c\u5176\u4e2dDF-RAG\u6355\u83b7\u4e86\u9ad8\u8fbe91.3%", "conclusion": "DF-RAG\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u5c06\u591a\u6837\u6027\u7eb3\u5165\u68c0\u7d22\u6b65\u9aa4\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u63a8\u7406\u5bc6\u96c6\u578bQA\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u591a\u6837\u6027\u589e\u5f3a\u68c0\u7d22\u5728RAG\u7cfb\u7edf\u4e2d\u7684\u91cd\u8981\u6027"}}
{"id": "2601.17542", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.17542", "abs": "https://arxiv.org/abs/2601.17542", "authors": ["Vinoth Punniyamoorthy", "Nitin Saksena", "Srivenkateswara Reddy Sankiti", "Nachiappan Chockalingam", "Aswathnarayan Muthukrishnan Kirubakaran", "Shiva Kumar Reddy Carimireddy", "Durgaraman Maruthavanan"], "title": "Cognitive Platform Engineering for Autonomous Cloud Operations", "comment": null, "summary": "Modern DevOps practices have accelerated software delivery through automation, CI/CD pipelines, and observability tooling,but these approaches struggle to keep pace with the scale and dynamism of cloud-native systems. As telemetry volume grows and configuration drift increases, traditional, rule-driven automation often results in reactive operations, delayed remediation, and dependency on manual expertise. This paper introduces Cognitive Platform Engineering, a next-generation paradigm that integrates sensing, reasoning, and autonomous action directly into the platform lifecycle. This paper propose a four-plane reference architecture that unifies data collection, intelligent inference, policy-driven orchestration, and human experience layers within a continuous feedback loop. A prototype implementation built with Kubernetes, Terraform, Open Policy Agent, and ML-based anomaly detection demonstrates improvements in mean time to resolution, resource efficiency, and compliance. The results show that embedding intelligence into platform operations enables resilient, self-adjusting, and intent-aligned cloud environments. The paper concludes with research opportunities in reinforcement learning, explainable governance, and sustainable self-managing cloud ecosystems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u8ba4\u77e5\u5e73\u53f0\u5de5\u7a0b\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u56db\u5c42\u53c2\u8003\u67b6\u6784\u5c06\u611f\u77e5\u3001\u63a8\u7406\u548c\u81ea\u4e3b\u884c\u52a8\u96c6\u6210\u5230\u5e73\u53f0\u751f\u547d\u5468\u671f\u4e2d\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edfDevOps\u5728\u4e91\u539f\u751f\u7cfb\u7edf\u89c4\u6a21\u548c\u52a8\u6001\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edfDevOps\u5b9e\u8df5\uff08\u81ea\u52a8\u5316\u3001CI/CD\u7ba1\u9053\u3001\u53ef\u89c2\u6d4b\u6027\u5de5\u5177\uff09\u96be\u4ee5\u5e94\u5bf9\u4e91\u539f\u751f\u7cfb\u7edf\u7684\u89c4\u6a21\u548c\u52a8\u6001\u6027\u6311\u6218\u3002\u968f\u7740\u9065\u6d4b\u6570\u636e\u91cf\u589e\u957f\u548c\u914d\u7f6e\u6f02\u79fb\u52a0\u5267\uff0c\u57fa\u4e8e\u89c4\u5219\u7684\u81ea\u52a8\u5316\u5f80\u5f80\u5bfc\u81f4\u88ab\u52a8\u8fd0\u7ef4\u3001\u4fee\u590d\u5ef6\u8fdf\u548c\u5bf9\u4eba\u5de5\u4e13\u4e1a\u77e5\u8bc6\u7684\u4f9d\u8d56\u3002", "method": "\u63d0\u51fa\u8ba4\u77e5\u5e73\u53f0\u5de5\u7a0b\u8303\u5f0f\uff0c\u8bbe\u8ba1\u56db\u5c42\u53c2\u8003\u67b6\u6784\uff1a\u6570\u636e\u6536\u96c6\u5c42\u3001\u667a\u80fd\u63a8\u7406\u5c42\u3001\u7b56\u7565\u9a71\u52a8\u7f16\u6392\u5c42\u548c\u4eba\u7c7b\u4f53\u9a8c\u5c42\uff0c\u5f62\u6210\u6301\u7eed\u53cd\u9988\u5faa\u73af\u3002\u539f\u578b\u5b9e\u73b0\u57fa\u4e8eKubernetes\u3001Terraform\u3001Open Policy Agent\u548c\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "\u539f\u578b\u6f14\u793a\u663e\u793a\u5728\u5e73\u5747\u89e3\u51b3\u65f6\u95f4\u3001\u8d44\u6e90\u6548\u7387\u548c\u5408\u89c4\u6027\u65b9\u9762\u5747\u6709\u6539\u8fdb\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5c06\u667a\u80fd\u5d4c\u5165\u5e73\u53f0\u8fd0\u7ef4\u80fd\u591f\u5b9e\u73b0\u5f39\u6027\u3001\u81ea\u6211\u8c03\u6574\u548c\u610f\u56fe\u5bf9\u9f50\u7684\u4e91\u73af\u5883\u3002", "conclusion": "\u8ba4\u77e5\u5e73\u53f0\u5de5\u7a0b\u901a\u8fc7\u5c06\u667a\u80fd\u96c6\u6210\u5230\u5e73\u53f0\u64cd\u4f5c\u4e2d\uff0c\u4f7f\u4e91\u73af\u5883\u66f4\u5177\u5f39\u6027\u3001\u81ea\u6211\u8c03\u6574\u80fd\u529b\u548c\u610f\u56fe\u5bf9\u9f50\u6027\u3002\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u5f3a\u5316\u5b66\u4e60\u3001\u53ef\u89e3\u91ca\u6cbb\u7406\u548c\u53ef\u6301\u7eed\u81ea\u7ba1\u7406\u4e91\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2601.18009", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18009", "abs": "https://arxiv.org/abs/2601.18009", "authors": ["Ervin Dervishaj", "Maria Maistro", "Tuukka Ruotsalo", "Christina Lioma"], "title": "Post-Training Denoising of User Profiles with LLMs in Collaborative Filtering Recommendation", "comment": "Accepted at the 48th European Conference on Information Retrieval (ECIR 2026)", "summary": "Implicit feedback -- the main data source for training Recommender Systems (RSs) -- is inherently noisy and has been shown to negatively affect recommendation effectiveness. Denoising has been proposed as a method for removing noisy implicit feedback and improving recommendations. Prior work has focused on in-training denoising, however this requires additional data, changes to the model architecture and training procedure or fine-tuning, all of which can be costly and data hungry. In this work, we focus on post-training denoising. Different from in-training denoising, post-training denoising does not involve changing the architecture of the model nor its training procedure, and does not require additional data. Specifically, we present a method for post-training denoising user profiles using Large Language Models (LLMs) for Collaborative Filtering (CF) recommendations. Our approach prompts LLMs with (i) a user profile (user interactions), (ii) a candidate item, and (iii) its rank as given by the CF recommender, and asks the LLM to remove items from the user profile to improve the rank of the candidate item. Experiments with a state-of-the-art CF recommender and 4 open and closed source LLMs in 3 datasets show that our denoising yields improvements up to 13% in effectiveness over the original user profiles. Our code is available at https://github.com/edervishaj/denoising-user-profiles-LLM.", "code_url": "https://github.com/edervishaj/denoising-user-profiles-LLM", "code_stars": 0, "code_last_update": "2026-01-27", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u534f\u540c\u8fc7\u6ee4\u63a8\u8350\u540e\u8bad\u7ec3\u53bb\u566a\u65b9\u6cd5\uff0c\u901a\u8fc7LLM\u5206\u6790\u7528\u6237\u4ea4\u4e92\u5386\u53f2\u3001\u5019\u9009\u7269\u54c1\u53ca\u5176\u6392\u540d\uff0c\u4ece\u7528\u6237\u6863\u6848\u4e2d\u79fb\u9664\u566a\u58f0\u4ea4\u4e92\u4ee5\u63d0\u5347\u63a8\u8350\u6548\u679c", "motivation": "\u9690\u5f0f\u53cd\u9988\u6570\u636e\u5b58\u5728\u56fa\u6709\u566a\u58f0\uff0c\u5f71\u54cd\u63a8\u8350\u7cfb\u7edf\u6548\u679c\u3002\u73b0\u6709\u53bb\u566a\u65b9\u6cd5\u591a\u4e3a\u8bad\u7ec3\u4e2d\u5904\u7406\uff0c\u9700\u8981\u989d\u5916\u6570\u636e\u3001\u6539\u53d8\u6a21\u578b\u67b6\u6784\u6216\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u6210\u672c\u9ad8\u4e14\u6570\u636e\u9700\u6c42\u5927\u3002\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65e0\u9700\u6539\u53d8\u6a21\u578b\u67b6\u6784\u3001\u8bad\u7ec3\u8fc7\u7a0b\u6216\u989d\u5916\u6570\u636e\u7684\u540e\u8bad\u7ec3\u53bb\u566a\u65b9\u6cd5", "method": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u534f\u540c\u8fc7\u6ee4\u63a8\u8350\u540e\u8bad\u7ec3\u53bb\u566a\u65b9\u6cd5\uff1a\u5411LLM\u63d0\u4f9b(i)\u7528\u6237\u4ea4\u4e92\u5386\u53f2\uff08\u7528\u6237\u6863\u6848\uff09\u3001(ii)\u5019\u9009\u7269\u54c1\u3001(iii)\u534f\u540c\u8fc7\u6ee4\u63a8\u8350\u5668\u7ed9\u51fa\u7684\u6392\u540d\uff0c\u8981\u6c42LLM\u4ece\u7528\u6237\u6863\u6848\u4e2d\u79fb\u9664\u53ef\u80fd\u964d\u4f4e\u5019\u9009\u7269\u54c1\u6392\u540d\u7684\u566a\u58f0\u4ea4\u4e92\u9879", "result": "\u5b9e\u9a8c\u4f7f\u7528\u6700\u5148\u8fdb\u7684\u534f\u540c\u8fc7\u6ee4\u63a8\u8350\u5668\u548c4\u4e2a\u5f00\u6e90/\u95ed\u6e90LLM\uff0c\u57283\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u53bb\u566a\u540e\u7684\u7528\u6237\u6863\u6848\u76f8\u6bd4\u539f\u59cb\u6863\u6848\u63d0\u5347\u6548\u679c\u8fbe13%", "conclusion": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u540e\u8bad\u7ec3\u53bb\u566a\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u534f\u540c\u8fc7\u6ee4\u63a8\u8350\u6548\u679c\uff0c\u65e0\u9700\u6539\u53d8\u6a21\u578b\u67b6\u6784\u3001\u8bad\u7ec3\u8fc7\u7a0b\u6216\u989d\u5916\u6570\u636e\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u53bb\u566a\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2601.17223", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17223", "abs": "https://arxiv.org/abs/2601.17223", "authors": ["Massimiliano Pronesti", "Anya Belz", "Yufang Hou"], "title": "Beyond Outcome Verification: Verifiable Process Reward Models for Structured Reasoning", "comment": null, "summary": "Recent work on reinforcement learning with verifiable rewards (RLVR) has shown that large language models (LLMs) can be substantially improved using outcome-level verification signals, such as unit tests for code or exact-match checks for mathematics. In parallel, process supervision has long been explored as a way to shape the intermediate reasoning behaviour of LLMs, but existing approaches rely on neural judges to score chain-of-thought steps, leaving them vulnerable to opacity, bias, and reward hacking. To address this gap, we introduce Verifiable Process Reward Models (VPRMs), a reinforcement-learning framework in which intermediate reasoning steps are checked by deterministic, rule-based verifiers. We apply VPRMs to risk-of-bias assessment for medical evidence synthesis, a domain where guideline-defined criteria and rule-based decision paths enable programmatic verification of reasoning traces. Across multiple datasets, we find that VPRMs generate reasoning that adheres closely to domain rules and achieve substantially higher coherence between step-level decisions and final labels. Results show that VPRMs achieve up to 20% higher F1 than state-of-the-art models and 6.5% higher than verifiable outcome rewards, with substantial gains in evidence grounding and logical coherence.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u9a8c\u8bc1\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08VPRMs\uff09\uff0c\u901a\u8fc7\u786e\u5b9a\u6027\u89c4\u5219\u9a8c\u8bc1\u5668\u68c0\u67e5\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\uff0c\u5e94\u7528\u4e8e\u533b\u5b66\u8bc1\u636e\u5408\u6210\u4e2d\u7684\u504f\u501a\u98ce\u9669\u8bc4\u4f30\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6027\u80fd", "motivation": "\u73b0\u6709\u8fc7\u7a0b\u76d1\u7763\u65b9\u6cd5\u4f9d\u8d56\u795e\u7ecf\u8bc4\u5206\u5668\u8bc4\u4f30\u601d\u7ef4\u94fe\u6b65\u9aa4\uff0c\u5b58\u5728\u4e0d\u900f\u660e\u6027\u3001\u504f\u89c1\u548c\u5956\u52b1\u653b\u51fb\u6f0f\u6d1e\uff1b\u800c\u53ef\u9a8c\u8bc1\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\uff08RLVR\uff09\u4ec5\u4f7f\u7528\u7ed3\u679c\u7ea7\u9a8c\u8bc1\u4fe1\u53f7\u3002\u9700\u8981\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\uff0c\u5728\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u4e2d\u5f15\u5165\u786e\u5b9a\u6027\u89c4\u5219\u9a8c\u8bc1", "method": "\u63d0\u51fa\u53ef\u9a8c\u8bc1\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08VPRMs\uff09\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u786e\u5b9a\u6027\u3001\u57fa\u4e8e\u89c4\u5219\u7684\u9a8c\u8bc1\u5668\u68c0\u67e5\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u3002\u5e94\u7528\u4e8e\u533b\u5b66\u8bc1\u636e\u5408\u6210\u504f\u501a\u98ce\u9669\u8bc4\u4f30\uff0c\u5229\u7528\u6307\u5357\u5b9a\u4e49\u7684\u6807\u51c6\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u51b3\u7b56\u8def\u5f84\u5bf9\u63a8\u7406\u8f68\u8ff9\u8fdb\u884c\u7a0b\u5e8f\u5316\u9a8c\u8bc1", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cVPRMs\u751f\u6210\u7684\u63a8\u7406\u7d27\u5bc6\u9075\u5faa\u9886\u57df\u89c4\u5219\uff0c\u6b65\u9aa4\u7ea7\u51b3\u7b56\u4e0e\u6700\u7ec8\u6807\u7b7e\u7684\u4e00\u81f4\u6027\u663e\u8457\u63d0\u9ad8\u3002\u76f8\u6bd4\u6700\u5148\u8fdb\u6a21\u578b\u63d0\u5347\u9ad8\u8fbe20%\u7684F1\u5206\u6570\uff0c\u6bd4\u53ef\u9a8c\u8bc1\u7ed3\u679c\u5956\u52b1\u9ad86.5%\uff0c\u5728\u8bc1\u636e\u57fa\u7840\u548c\u903b\u8f91\u4e00\u81f4\u6027\u65b9\u9762\u6709\u5b9e\u8d28\u6027\u63d0\u5347", "conclusion": "VPRMs\u901a\u8fc7\u786e\u5b9a\u6027\u89c4\u5219\u9a8c\u8bc1\u5668\u5b9e\u73b0\u8fc7\u7a0b\u76d1\u7763\uff0c\u89e3\u51b3\u4e86\u795e\u7ecf\u8bc4\u5206\u5668\u7684\u4e0d\u900f\u660e\u6027\u548c\u504f\u89c1\u95ee\u9898\uff0c\u5728\u533b\u5b66\u8bc1\u636e\u5408\u6210\u504f\u501a\u98ce\u9669\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u4e3a\u9700\u8981\u53ef\u89e3\u91ca\u3001\u89c4\u5219\u9075\u5faa\u63a8\u7406\u7684\u9886\u57df\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.17564", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17564", "abs": "https://arxiv.org/abs/2601.17564", "authors": ["Aadam", "Monu Verma", "Mohamed Abdel-Mottaleb"], "title": "JaxARC: A High-Performance JAX-based Environment for Abstraction and Reasoning Research", "comment": null, "summary": "The Abstraction and Reasoning Corpus (ARC) tests AI systems' ability to perform human-like inductive reasoning from a few demonstration pairs. Existing Gymnasium-based RL environments severely limit experimental scale due to computational bottlenecks. We present JaxARC, an open-source, high-performance RL environment for ARC implemented in JAX. Its functional, stateless architecture enables massive parallelism, achieving 38-5,439x speedup over Gymnasium at matched batch sizes, with peak throughput of 790M steps/second. JaxARC supports multiple ARC datasets, flexible action spaces, composable wrappers, and configuration-driven reproducibility, enabling large-scale RL research previously computationally infeasible. JaxARC is available at https://github.com/aadimator/JaxARC.", "code_url": "https://github.com/aadimator/JaxARC", "code_stars": 11, "code_last_update": "2025-12-29", "AI": {"tldr": "JaxARC\u662f\u4e00\u4e2a\u57fa\u4e8eJAX\u5b9e\u73b0\u7684\u9ad8\u6027\u80fd\u5f3a\u5316\u5b66\u4e60\u73af\u5883\uff0c\u7528\u4e8eARC\u63a8\u7406\u4efb\u52a1\uff0c\u76f8\u6bd4Gymnasium\u5b9e\u73b038-5,439\u500d\u52a0\u901f\uff0c\u652f\u6301\u5927\u89c4\u6a21\u5e76\u884c\u5b9e\u9a8c\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eGymnasium\u7684RL\u73af\u5883\u5728ARC\u4efb\u52a1\u4e0a\u5b58\u5728\u8ba1\u7b97\u74f6\u9888\uff0c\u9650\u5236\u4e86\u5b9e\u9a8c\u89c4\u6a21\uff0c\u9700\u8981\u9ad8\u6027\u80fd\u73af\u5883\u6765\u652f\u6301\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\u3002", "method": "\u91c7\u7528JAX\u5b9e\u73b0\u529f\u80fd\u5316\u3001\u65e0\u72b6\u6001\u7684\u67b6\u6784\uff0c\u652f\u6301\u5927\u89c4\u6a21\u5e76\u884c\u8ba1\u7b97\uff0c\u63d0\u4f9b\u591a\u79cdARC\u6570\u636e\u96c6\u3001\u7075\u6d3b\u7684\u52a8\u4f5c\u7a7a\u95f4\u3001\u53ef\u7ec4\u5408\u7684\u5305\u88c5\u5668\u548c\u914d\u7f6e\u9a71\u52a8\u7684\u53ef\u590d\u73b0\u6027\u3002", "result": "\u5728\u5339\u914d\u7684\u6279\u91cf\u5927\u5c0f\u4e0b\uff0c\u76f8\u6bd4Gymnasium\u5b9e\u73b038-5,439\u500d\u52a0\u901f\uff0c\u5cf0\u503c\u541e\u5410\u91cf\u8fbe\u52307.9\u4ebf\u6b65/\u79d2\uff0c\u652f\u6301\u5148\u524d\u8ba1\u7b97\u4e0a\u4e0d\u53ef\u884c\u7684\u5927\u89c4\u6a21RL\u7814\u7a76\u3002", "conclusion": "JaxARC\u901a\u8fc7\u9ad8\u6027\u80fd\u5b9e\u73b0\u89e3\u51b3\u4e86ARC\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8ba1\u7b97\u74f6\u9888\u95ee\u9898\uff0c\u4e3a\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u5b9e\u9a8c\u5e73\u53f0\u3002"}}
{"id": "2601.18096", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18096", "abs": "https://arxiv.org/abs/2601.18096", "authors": ["Yuting Zhang", "Ziliang Pei", "Chao Wang", "Ying Sun", "Fuzhen Zhuang"], "title": "Enhancing LLM-based Recommendation with Preference Hint Discovery from Knowledge Graph", "comment": null, "summary": "LLMs have garnered substantial attention in recommendation systems. Yet they fall short of traditional recommenders when capturing complex preference patterns. Recent works have tried integrating traditional recommendation embeddings into LLMs to resolve this issue, yet a core gap persists between their continuous embedding and discrete semantic spaces. Intuitively, textual attributes derived from interactions can serve as critical preference rationales for LLMs' recommendation logic. However, directly inputting such attribute knowledge presents two core challenges: (1) Deficiency of sparse interactions in reflecting preference hints for unseen items; (2) Substantial noise introduction from treating all attributes as hints. To this end, we propose a preference hint discovery model based on the interaction-integrated knowledge graph, enhancing LLM-based recommendation. It utilizes traditional recommendation principles to selectively extract crucial attributes as hints. Specifically, we design a collaborative preference hint extraction schema, which utilizes semantic knowledge from similar users' explicit interactions as hints for unseen items. Furthermore, we develop an instance-wise dual-attention mechanism to quantify the preference credibility of candidate attributes, identifying hints specific to each unseen item. Using these item- and user-based hints, we adopt a flattened hint organization method to shorten input length and feed the textual hint information to the LLM for commonsense reasoning. Extensive experiments on both pair-wise and list-wise recommendation tasks verify the effectiveness of our proposed framework, indicating an average relative improvement of over 3.02% against baselines.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4ea4\u4e92\u96c6\u6210\u77e5\u8bc6\u56fe\u8c31\u7684\u504f\u597d\u63d0\u793a\u53d1\u73b0\u6a21\u578b\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u63d0\u53d6\u5173\u952e\u5c5e\u6027\u4f5c\u4e3a\u63d0\u793a\u6765\u589e\u5f3aLLM\u63a8\u8350\u6027\u80fd\uff0c\u89e3\u51b3\u4f20\u7edf\u63a8\u8350\u5d4c\u5165\u4e0eLLM\u8bed\u4e49\u7a7a\u95f4\u4e0d\u5339\u914d\u7684\u95ee\u9898\u3002", "motivation": "LLMs\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u867d\u53d7\u5173\u6ce8\uff0c\u4f46\u5728\u6355\u6349\u590d\u6742\u504f\u597d\u6a21\u5f0f\u65b9\u9762\u4e0d\u5982\u4f20\u7edf\u63a8\u8350\u5668\u3002\u73b0\u6709\u65b9\u6cd5\u5c06\u4f20\u7edf\u63a8\u8350\u5d4c\u5165\u96c6\u6210\u5230LLMs\u4e2d\uff0c\u4f46\u8fde\u7eed\u5d4c\u5165\u7a7a\u95f4\u4e0e\u79bb\u6563\u8bed\u4e49\u7a7a\u95f4\u5b58\u5728\u6838\u5fc3\u5dee\u8ddd\u3002\u6587\u672c\u5c5e\u6027\u53ef\u4f5c\u4e3aLLMs\u63a8\u8350\u903b\u8f91\u7684\u5173\u952e\u504f\u597d\u4f9d\u636e\uff0c\u4f46\u76f4\u63a5\u8f93\u5165\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a\u7a00\u758f\u4ea4\u4e92\u96be\u4ee5\u53cd\u6620\u672a\u89c1\u9879\u76ee\u7684\u504f\u597d\u7ebf\u7d22\uff1b\u5c06\u6240\u6709\u5c5e\u6027\u4f5c\u4e3a\u7ebf\u7d22\u4f1a\u5f15\u5165\u5927\u91cf\u566a\u58f0\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4ea4\u4e92\u96c6\u6210\u77e5\u8bc6\u56fe\u8c31\u7684\u504f\u597d\u63d0\u793a\u53d1\u73b0\u6a21\u578b\uff1a1) \u8bbe\u8ba1\u534f\u4f5c\u5f0f\u504f\u597d\u63d0\u793a\u63d0\u53d6\u65b9\u6848\uff0c\u5229\u7528\u76f8\u4f3c\u7528\u6237\u663e\u5f0f\u4ea4\u4e92\u7684\u8bed\u4e49\u77e5\u8bc6\u4f5c\u4e3a\u672a\u89c1\u9879\u76ee\u7684\u63d0\u793a\uff1b2) \u5f00\u53d1\u5b9e\u4f8b\u7ea7\u53cc\u91cd\u6ce8\u610f\u529b\u673a\u5236\uff0c\u91cf\u5316\u5019\u9009\u5c5e\u6027\u7684\u504f\u597d\u53ef\u4fe1\u5ea6\uff0c\u8bc6\u522b\u9488\u5bf9\u6bcf\u4e2a\u672a\u89c1\u9879\u76ee\u7684\u7279\u5b9a\u63d0\u793a\uff1b3) \u91c7\u7528\u6241\u5e73\u5316\u63d0\u793a\u7ec4\u7ec7\u65b9\u6cd5\u7f29\u77ed\u8f93\u5165\u957f\u5ea6\uff0c\u5c06\u6587\u672c\u63d0\u793a\u4fe1\u606f\u8f93\u5165LLM\u8fdb\u884c\u5e38\u8bc6\u63a8\u7406\u3002", "result": "\u5728\u6210\u5bf9\u548c\u5217\u8868\u63a8\u8350\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u76f8\u5bf9\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u5e73\u5747\u76f8\u5bf9\u6539\u8fdb\u8d85\u8fc73.02%\u3002", "conclusion": "\u63d0\u51fa\u7684\u504f\u597d\u63d0\u793a\u53d1\u73b0\u6a21\u578b\u80fd\u591f\u6709\u6548\u5229\u7528\u4f20\u7edf\u63a8\u8350\u539f\u5219\u9009\u62e9\u6027\u63d0\u53d6\u5173\u952e\u5c5e\u6027\u4f5c\u4e3a\u63d0\u793a\uff0c\u901a\u8fc7\u534f\u4f5c\u5f0f\u63d0\u793a\u63d0\u53d6\u548c\u5b9e\u4f8b\u7ea7\u6ce8\u610f\u529b\u673a\u5236\u89e3\u51b3\u7a00\u758f\u4ea4\u4e92\u548c\u566a\u58f0\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347LLM\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2601.17226", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17226", "abs": "https://arxiv.org/abs/2601.17226", "authors": ["David Y. Liu", "Xanthe Muston", "Aditya Joshi", "Sebastian Sequoiah-Grayson"], "title": "Retell, Reward, Repeat: Reinforcement Learning for Narrative Theory-Informed Story Generation", "comment": "8 Pages, 6 figures", "summary": "Despite the subjective nature of storytelling, past works on automatic story generation (ASG) have relied on limited ground truths for training and evaluation. In this work, we explore reinforcement learning (d-RLAIF) as a post-training alternative to supervised fine-tuning (SFT). We first apply Todorov's Theory of Narrative Equilibrium to establish principles that define desirable ASG qualities. We prompt 7B and 14B LLM-as-judge models with our principles to test alignment with human annotators and provide reward signals during d-RLAIF. We use Gemini-3-Flash to evaluate the output of our post-trained models and compare them to human-written stories from the TimeTravel dataset. We show that d-RLAIF offers a viable alternative to supervised fine-tuning (SFT)--producing stories that are more diverse and aligned with human narrative conventions. Our paper demonstrates the promise of reinforcement learning for linguistically grounded post-training for subjective tasks such as ASG.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\uff08d-RLAIF\uff09\u4f5c\u4e3a\u76d1\u7763\u5fae\u8c03\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u7528\u4e8e\u81ea\u52a8\u6545\u4e8b\u751f\u6210\u4efb\u52a1\uff0c\u901a\u8fc7\u53d9\u4e8b\u5e73\u8861\u7406\u8bba\u5efa\u7acb\u8bc4\u4f30\u539f\u5219\uff0c\u4f7f\u7528LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u63d0\u4f9b\u5956\u52b1\u4fe1\u53f7\uff0c\u6700\u7ec8\u751f\u6210\u66f4\u7b26\u5408\u4eba\u7c7b\u53d9\u4e8b\u60ef\u4f8b\u7684\u591a\u6837\u5316\u6545\u4e8b\u3002", "motivation": "\u81ea\u52a8\u6545\u4e8b\u751f\u6210\uff08ASG\uff09\u5177\u6709\u4e3b\u89c2\u6027\uff0c\u4f46\u4ee5\u5f80\u7814\u7a76\u4f9d\u8d56\u6709\u9650\u7684\u771f\u5b9e\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5f3a\u5316\u5b66\u4e60\u4f5c\u4e3a\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4ee5\u89e3\u51b3ASG\u4efb\u52a1\u4e2d\u4e3b\u89c2\u6027\u8bc4\u4f30\u7684\u6311\u6218\u3002", "method": "1. \u5e94\u7528Todorov\u7684\u53d9\u4e8b\u5e73\u8861\u7406\u8bba\u5efa\u7acb\u5b9a\u4e49\u7406\u60f3ASG\u8d28\u91cf\u7684\u539f\u5219\uff1b2. \u4f7f\u75287B\u548c14B\u53c2\u6570\u7684LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u6a21\u578b\uff0c\u6d4b\u8bd5\u8fd9\u4e9b\u539f\u5219\u4e0e\u4eba\u7c7b\u6807\u6ce8\u8005\u7684\u4e00\u81f4\u6027\uff0c\u5e76\u5728d-RLAIF\u8fc7\u7a0b\u4e2d\u63d0\u4f9b\u5956\u52b1\u4fe1\u53f7\uff1b3. \u4f7f\u7528Gemini-3-Flash\u8bc4\u4f30\u540e\u8bad\u7ec3\u6a21\u578b\u7684\u8f93\u51fa\uff0c\u5e76\u4e0eTimeTravel\u6570\u636e\u96c6\u4e2d\u7684\u4eba\u7c7b\u64b0\u5199\u6545\u4e8b\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "d-RLAIF\u63d0\u4f9b\u4e86\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u7684\u53ef\u884c\u66ff\u4ee3\u65b9\u6848\uff0c\u751f\u6210\u7684\u6545\u4e8b\u66f4\u52a0\u591a\u6837\u5316\u4e14\u66f4\u7b26\u5408\u4eba\u7c7b\u53d9\u4e8b\u60ef\u4f8b\u3002\u7814\u7a76\u8868\u660e\u5f3a\u5316\u5b66\u4e60\u5728\u4e3b\u89c2\u4efb\u52a1\u5982ASG\u7684\u8bed\u8a00\u57fa\u7840\u540e\u8bad\u7ec3\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002", "conclusion": "\u672c\u6587\u5c55\u793a\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u81ea\u52a8\u6545\u4e8b\u751f\u6210\u7b49\u4e3b\u89c2\u4efb\u52a1\u4e2d\u8fdb\u884c\u8bed\u8a00\u57fa\u7840\u540e\u8bad\u7ec3\u7684\u524d\u666f\uff0cd-RLAIF\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u66f4\u7b26\u5408\u4eba\u7c7b\u53d9\u4e8b\u6807\u51c6\u7684\u591a\u6837\u5316\u6545\u4e8b\uff0c\u4e3aASG\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2601.18146", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18146", "abs": "https://arxiv.org/abs/2601.18146", "authors": ["Huizhong Guo", "Tianjun Wei", "Dongxia Wang", "Yingpeng Du", "Ziyan Wang", "Jie Zhang", "Zhu Sun"], "title": "Think When Needed: Model-Aware Reasoning Routing for LLM-based Ranking", "comment": null, "summary": "Large language models (LLMs) are increasingly applied to ranking tasks in retrieval and recommendation. Although reasoning prompting can enhance ranking utility, our preliminary exploration reveals that its benefits are inconsistent and come at a substantial computational cost, suggesting that when to reason is as crucial as how to reason. To address this issue, we propose a reasoning routing framework that employs a lightweight, plug-and-play router head to decide whether to use direct inference (Non-Think) or reasoning (Think) for each instance before generation. The router head relies solely on pre-generation signals: i) compact ranking-aware features (e.g., candidate dispersion) and ii) model-aware difficulty signals derived from a diagnostic checklist reflecting the model's estimated need for reasoning. By leveraging these features before generation, the router outputs a controllable token that determines whether to apply the Think mode. Furthermore, the router can adaptively select its operating policy along the validation Pareto frontier during deployment, enabling dynamic allocation of computational resources toward instances most likely to benefit from Think under varying system constraints. Experiments on three public ranking datasets with different scales of open-source LLMs show consistent improvements in ranking utility with reduced token consumption (e.g., +6.3\\% NDCG@10 with -49.5\\% tokens on MovieLens with Qwen3-4B), demonstrating reasoning routing as a practical solution to the accuracy-efficiency trade-off.", "AI": {"tldr": "\u63d0\u51fa\u63a8\u7406\u8def\u7531\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8def\u7531\u5668\u5934\u5728\u751f\u6210\u524d\u51b3\u5b9a\u662f\u5426\u5bf9\u6bcf\u4e2a\u5b9e\u4f8b\u4f7f\u7528\u63a8\u7406\u6a21\u5f0f\uff0c\u4ee5\u5e73\u8861\u6392\u540d\u6548\u679c\u4e0e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u867d\u7136\u63a8\u7406\u63d0\u793a\u53ef\u4ee5\u63d0\u5347LLM\u5728\u6392\u540d\u4efb\u52a1\u4e2d\u7684\u6548\u679c\uff0c\u4f46\u5176\u6536\u76ca\u4e0d\u7a33\u5b9a\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u56e0\u6b64\u4f55\u65f6\u63a8\u7406\u4e0e\u5982\u4f55\u63a8\u7406\u540c\u7b49\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u63a8\u7406\u8def\u7531\u6846\u67b6\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u3001\u5373\u63d2\u5373\u7528\u7684\u8def\u7531\u5668\u5934\uff0c\u5728\u751f\u6210\u524d\u57fa\u4e8e\u9884\u751f\u6210\u4fe1\u53f7\uff08\u7d27\u51d1\u7684\u6392\u540d\u611f\u77e5\u7279\u5f81\u548c\u6a21\u578b\u611f\u77e5\u7684\u96be\u5ea6\u4fe1\u53f7\uff09\u51b3\u5b9a\u4f7f\u7528\u76f4\u63a5\u63a8\u7406\u8fd8\u662f\u63a8\u7406\u6a21\u5f0f\u3002\u8def\u7531\u5668\u53ef\u6cbf\u9a8c\u8bc1\u5e15\u7d2f\u6258\u524d\u6cbf\u81ea\u9002\u5e94\u9009\u62e9\u64cd\u4f5c\u7b56\u7565\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u6392\u540d\u6570\u636e\u96c6\u548c\u4e0d\u540c\u89c4\u6a21\u7684\u5f00\u6e90LLM\u4e0a\u5b9e\u9a8c\uff0c\u663e\u793a\u6392\u540d\u6548\u679c\u6301\u7eed\u63d0\u5347\u540c\u65f6\u663e\u8457\u51cf\u5c11token\u6d88\u8017\uff08\u4f8b\u5982\u5728MovieLens\u4e0a\u4f7f\u7528Qwen3-4B\u65f6\uff0cNDCG@10\u63d0\u53476.3%\uff0ctoken\u6d88\u8017\u51cf\u5c1149.5%\uff09\u3002", "conclusion": "\u63a8\u7406\u8def\u7531\u6846\u67b6\u662f\u89e3\u51b3\u51c6\u786e\u6027\u4e0e\u6548\u7387\u6743\u8861\u7684\u5b9e\u7528\u65b9\u6848\uff0c\u901a\u8fc7\u667a\u80fd\u8def\u7531\u51b3\u7b56\u5728\u4fdd\u6301\u6392\u540d\u6548\u679c\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2601.17232", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17232", "abs": "https://arxiv.org/abs/2601.17232", "authors": ["Jacob Devasier", "Akshith Putta", "Qing Wang", "Alankrit Moses", "Chengkai Li"], "title": "Frame-Guided Synthetic Claim Generation for Automatic Fact-Checking Using High-Volume Tabular Data", "comment": null, "summary": "Automated fact-checking benchmarks have largely ignored the challenge of verifying claims against real-world, high-volume structured data, instead focusing on small, curated tables. We introduce a new large-scale, multilingual dataset to address this critical gap. It contains 78,503 synthetic claims grounded in 434 complex OECD tables, which average over 500K rows each. We propose a novel, frame-guided methodology where algorithms programmatically select significant data points based on six semantic frames to generate realistic claims in English, Chinese, Spanish, and Hindi. Crucially, we demonstrate through knowledge-probing experiments that LLMs have not memorized these facts, forcing systems to perform genuine retrieval and reasoning rather than relying on parameterized knowledge. We provide a baseline SQL-generation system and show that our benchmark is highly challenging. Our analysis identifies evidence retrieval as the primary bottleneck, with models struggling to find the correct data in massive tables. This dataset provides a critical new resource for advancing research on this unsolved, real-world problem.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u9488\u5bf9\u5927\u89c4\u6a21\u7ed3\u6784\u5316\u6570\u636e\u7684\u4e8b\u5b9e\u6838\u67e5\u65b0\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b78,503\u4e2a\u57fa\u4e8e\u590d\u6742OECD\u8868\u683c\u7684\u5408\u6210\u58f0\u660e\uff0c\u6311\u6218\u73b0\u6709\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u9ad8\u5bb9\u91cf\u6570\u636e\u4e0a\u7684\u68c0\u7d22\u4e0e\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u4e8b\u5b9e\u6838\u67e5\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u5c0f\u578b\u3001\u7cbe\u9009\u8868\u683c\uff0c\u5ffd\u7565\u4e86\u9a8c\u8bc1\u58f0\u660e\u5bf9\u6297\u771f\u5b9e\u4e16\u754c\u9ad8\u5bb9\u91cf\u7ed3\u6784\u5316\u6570\u636e\u7684\u6311\u6218\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u5173\u952e\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u6846\u67b6\u5f15\u5bfc\u65b9\u6cd5\uff0c\u57fa\u4e8e\u516d\u79cd\u8bed\u4e49\u6846\u67b6\u7a0b\u5e8f\u5316\u9009\u62e9\u663e\u8457\u6570\u636e\u70b9\u751f\u6210\u73b0\u5b9e\u58f0\u660e\uff1b\u521b\u5efa\u591a\u8bed\u8a00\u6570\u636e\u96c6\uff08\u82f1\u3001\u4e2d\u3001\u897f\u3001\u5370\u5730\u8bed\uff09\uff1b\u901a\u8fc7\u77e5\u8bc6\u63a2\u6d4b\u5b9e\u9a8c\u786e\u4fddLLMs\u672a\u8bb0\u5fc6\u8fd9\u4e9b\u4e8b\u5b9e\uff1b\u63d0\u4f9bSQL\u751f\u6210\u57fa\u7ebf\u7cfb\u7edf\u3002", "result": "\u6570\u636e\u96c6\u5305\u542b78,503\u4e2a\u5408\u6210\u58f0\u660e\uff0c\u57fa\u4e8e434\u4e2a\u590d\u6742OECD\u8868\u683c\uff08\u5e73\u5747\u8d8550\u4e07\u884c\uff09\uff1b\u8bc1\u660eLLMs\u672a\u8bb0\u5fc6\u8fd9\u4e9b\u4e8b\u5b9e\uff1b\u57fa\u51c6\u6781\u5177\u6311\u6218\u6027\uff0c\u8bc1\u636e\u68c0\u7d22\u662f\u4e3b\u8981\u74f6\u9888\uff0c\u6a21\u578b\u96be\u4ee5\u5728\u5e9e\u5927\u8868\u683c\u4e2d\u627e\u5230\u6b63\u786e\u6570\u636e\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u4e3a\u89e3\u51b3\u672a\u89e3\u51b3\u7684\u73b0\u5b9e\u4e16\u754c\u95ee\u9898\u63d0\u4f9b\u4e86\u5173\u952e\u65b0\u8d44\u6e90\uff0c\u63a8\u52a8\u5927\u89c4\u6a21\u7ed3\u6784\u5316\u6570\u636e\u4e8b\u5b9e\u6838\u67e5\u7814\u7a76\uff0c\u5f3a\u8c03\u8bc1\u636e\u68c0\u7d22\u662f\u5f53\u524d\u4e3b\u8981\u6311\u6218\u3002"}}
{"id": "2601.17642", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17642", "abs": "https://arxiv.org/abs/2601.17642", "authors": ["Zhihao Zhang", "Liting Huang", "Guanghao Wu", "Preslav Nakov", "Heng Ji", "Usman Naseem"], "title": "Health-ORSC-Bench: A Benchmark for Measuring Over-Refusal and Safety Completion in Health Context", "comment": "Preprint", "summary": "Safety alignment in Large Language Models is critical for healthcare; however, reliance on binary refusal boundaries often results in \\emph{over-refusal} of benign queries or \\emph{unsafe compliance} with harmful ones. While existing benchmarks measure these extremes, they fail to evaluate Safe Completion: the model's ability to maximise helpfulness on dual-use or borderline queries by providing safe, high-level guidance without crossing into actionable harm. We introduce \\textbf{Health-ORSC-Bench}, the first large-scale benchmark designed to systematically measure \\textbf{Over-Refusal} and \\textbf{Safe Completion} quality in healthcare. Comprising 31,920 benign boundary prompts across seven health categories (e.g., self-harm, medical misinformation), our framework uses an automated pipeline with human validation to test models at varying levels of intent ambiguity. We evaluate 30 state-of-the-art LLMs, including GPT-5 and Claude-4, revealing a significant tension: safety-optimised models frequently refuse up to 80\\% of \"Hard\" benign prompts, while domain-specific models often sacrifice safety for utility. Our findings demonstrate that model family and size significantly influence calibration: larger frontier models (e.g., GPT-5, Llama-4) exhibit \"safety-pessimism\" and higher over-refusal than smaller or MoE-based counterparts (e.g., Qwen-3-Next), highlighting that current LLMs struggle to balance refusal and compliance. Health-ORSC-Bench provides a rigorous standard for calibrating the next generation of medical AI assistants toward nuanced, safe, and helpful completions. The code and data will be released upon acceptance. \\textcolor{red}{Warning: Some contents may include toxic or undesired contents.}", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86Health-ORSC-Bench\uff0c\u9996\u4e2a\u5927\u89c4\u6a21\u533b\u7597\u9886\u57df\u57fa\u51c6\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30LLM\u7684\u8fc7\u5ea6\u62d2\u7edd\u548c\u5b89\u5168\u5b8c\u6210\u8d28\u91cf\uff0c\u63ed\u793a\u5f53\u524d\u6a21\u578b\u5728\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u4e4b\u95f4\u7684\u5e73\u8861\u56f0\u5883\u3002", "motivation": "\u5f53\u524d\u533b\u7597\u9886\u57dfLLM\u7684\u5b89\u5168\u5bf9\u9f50\u4e3b\u8981\u4f9d\u8d56\u4e8c\u5143\u62d2\u7edd\u8fb9\u754c\uff0c\u5bfc\u81f4\u5bf9\u826f\u6027\u67e5\u8be2\u7684\u8fc7\u5ea6\u62d2\u7edd\u6216\u5bf9\u6709\u5bb3\u67e5\u8be2\u7684\u4e0d\u5b89\u5168\u9075\u4ece\u3002\u73b0\u6709\u57fa\u51c6\u4ec5\u6d4b\u91cf\u6781\u7aef\u60c5\u51b5\uff0c\u65e0\u6cd5\u8bc4\u4f30\u6a21\u578b\u5728\u53cc\u7528\u9014\u6216\u8fb9\u754c\u67e5\u8be2\u4e0a\u63d0\u4f9b\u5b89\u5168\u3001\u9ad8\u7ea7\u6307\u5bfc\u800c\u4e0d\u8de8\u8d8a\u53ef\u64cd\u4f5c\u4f24\u5bb3\u7684\u80fd\u529b\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b31,920\u4e2a\u826f\u6027\u8fb9\u754c\u63d0\u793a\u7684Health-ORSC-Bench\u57fa\u51c6\uff0c\u6db5\u76d6\u4e03\u4e2a\u5065\u5eb7\u7c7b\u522b\uff08\u5982\u81ea\u6b8b\u3001\u533b\u7597\u9519\u8bef\u4fe1\u606f\uff09\u3002\u91c7\u7528\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\u7ed3\u5408\u4eba\u5de5\u9a8c\u8bc1\uff0c\u5728\u4e0d\u540c\u610f\u56fe\u6a21\u7cca\u5ea6\u7ea7\u522b\u6d4b\u8bd5\u6a21\u578b\u3002\u8bc4\u4f30\u4e8630\u4e2a\u6700\u5148\u8fdb\u7684LLM\uff0c\u5305\u62ecGPT-5\u548cClaude-4\u3002", "result": "\u5b89\u5168\u4f18\u5316\u6a21\u578b\u5bf9\"\u56f0\u96be\"\u826f\u6027\u63d0\u793a\u7684\u62d2\u7edd\u7387\u9ad8\u8fbe80%\uff0c\u800c\u9886\u57df\u7279\u5b9a\u6a21\u578b\u5e38\u4e3a\u5b9e\u7528\u6027\u727a\u7272\u5b89\u5168\u6027\u3002\u6a21\u578b\u5bb6\u65cf\u548c\u89c4\u6a21\u663e\u8457\u5f71\u54cd\u6821\u51c6\uff1a\u5927\u578b\u524d\u6cbf\u6a21\u578b\uff08\u5982GPT-5\u3001Llama-4\uff09\u8868\u73b0\u51fa\"\u5b89\u5168\u60b2\u89c2\u4e3b\u4e49\"\u548c\u66f4\u9ad8\u7684\u8fc7\u5ea6\u62d2\u7edd\uff0c\u8f83\u5c0f\u6216MoE\u6a21\u578b\uff08\u5982Qwen-3-Next\uff09\u8868\u73b0\u4e0d\u540c\u3002\u5f53\u524dLLM\u96be\u4ee5\u5e73\u8861\u62d2\u7edd\u548c\u9075\u4ece\u3002", "conclusion": "Health-ORSC-Bench\u4e3a\u6821\u51c6\u4e0b\u4e00\u4ee3\u533b\u7597AI\u52a9\u624b\u63d0\u4f9b\u4e86\u4e25\u683c\u6807\u51c6\uff0c\u63a8\u52a8\u5176\u5b9e\u73b0\u7ec6\u81f4\u3001\u5b89\u5168\u548c\u6709\u7528\u7684\u5b8c\u6210\u3002\u6a21\u578b\u5bb6\u65cf\u548c\u89c4\u6a21\u662f\u5f71\u54cd\u5b89\u5168-\u6548\u7528\u6743\u8861\u7684\u5173\u952e\u56e0\u7d20\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u6821\u51c6\u65b9\u6cd5\u3002"}}
{"id": "2601.18213", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18213", "abs": "https://arxiv.org/abs/2601.18213", "authors": ["Chengkai Huang", "Xiaodi Chen", "Hongtao Huang", "Quan Z. Sheng", "Lina Yao"], "title": "Generative Chain of Behavior for User Trajectory Prediction", "comment": null, "summary": "Modeling long-term user behavior trajectories is essential for understanding evolving preferences and enabling proactive recommendations. However, most sequential recommenders focus on next-item prediction, overlooking dependencies across multiple future actions. We propose Generative Chain of Behavior (GCB), a generative framework that models user interactions as an autoregressive chain of semantic behaviors over multiple future steps. GCB first encodes items into semantic IDs via RQ-VAE with k-means refinement, forming a discrete latent space that preserves semantic proximity. On top of this space, a transformer-based autoregressive generator predicts multi-step future behaviors conditioned on user history, capturing long-horizon intent transitions and generating coherent trajectories. Experiments on benchmark datasets show that GCB consistently outperforms state-of-the-art sequential recommenders in multi-step accuracy and trajectory consistency. Beyond these gains, GCB offers a unified generative formulation for capturing user preference evolution.", "AI": {"tldr": "GCB\u662f\u4e00\u4e2a\u751f\u6210\u5f0f\u884c\u4e3a\u94fe\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u7269\u54c1\u7f16\u7801\u4e3a\u8bed\u4e49ID\uff0c\u4f7f\u7528\u81ea\u56de\u5f52\u53d8\u6362\u5668\u751f\u6210\u591a\u6b65\u672a\u6765\u884c\u4e3a\u8f68\u8ff9\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u5e8f\u5217\u63a8\u8350\u5668\u7684\u5355\u6b65\u9884\u6d4b\u9650\u5236\u3002", "motivation": "\u73b0\u6709\u5e8f\u5217\u63a8\u8350\u5668\u4e3b\u8981\u5173\u6ce8\u4e0b\u4e00\u9879\u9884\u6d4b\uff0c\u5ffd\u7565\u4e86\u591a\u4e2a\u672a\u6765\u52a8\u4f5c\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u65e0\u6cd5\u6355\u6349\u7528\u6237\u504f\u597d\u7684\u957f\u671f\u6f14\u53d8\u3002\u9700\u8981\u5efa\u6a21\u957f\u671f\u7528\u6237\u884c\u4e3a\u8f68\u8ff9\u6765\u7406\u89e3\u6f14\u5316\u504f\u597d\u5e76\u5b9e\u73b0\u4e3b\u52a8\u63a8\u8350\u3002", "method": "1. \u4f7f\u7528RQ-VAE\u548ck-means\u7ec6\u5316\u5c06\u7269\u54c1\u7f16\u7801\u4e3a\u8bed\u4e49ID\uff0c\u5f62\u6210\u4fdd\u6301\u8bed\u4e49\u90bb\u8fd1\u6027\u7684\u79bb\u6563\u6f5c\u5728\u7a7a\u95f4\uff1b2. \u57fa\u4e8e\u8be5\u7a7a\u95f4\uff0c\u91c7\u7528\u53d8\u6362\u5668\u81ea\u56de\u5f52\u751f\u6210\u5668\uff0c\u4ee5\u7528\u6237\u5386\u53f2\u4e3a\u6761\u4ef6\u9884\u6d4b\u591a\u6b65\u672a\u6765\u884c\u4e3a\uff0c\u6355\u6349\u957f\u65f6\u610f\u56fe\u8f6c\u6362\u5e76\u751f\u6210\u8fde\u8d2f\u8f68\u8ff9\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGCB\u5728\u591a\u6b65\u51c6\u786e\u6027\u548c\u8f68\u8ff9\u4e00\u81f4\u6027\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u5e8f\u5217\u63a8\u8350\u5668\u3002", "conclusion": "GCB\u4e0d\u4ec5\u53d6\u5f97\u4e86\u6027\u80fd\u63d0\u5347\uff0c\u8fd8\u4e3a\u6355\u6349\u7528\u6237\u504f\u597d\u6f14\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u751f\u6210\u5f0f\u6846\u67b6\uff0c\u80fd\u591f\u5efa\u6a21\u957f\u671f\u884c\u4e3a\u8f68\u8ff9\u548c\u610f\u56fe\u8f6c\u6362\u3002"}}
{"id": "2601.17277", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17277", "abs": "https://arxiv.org/abs/2601.17277", "authors": ["Mohammad Rifqi Farhansyah", "Hanif Muhammad Zhafran", "Farid Adilazuarda", "Shamsuddeen Hassan Muhammad", "Maryam Ibrahim Mukhtar", "Nedjma Ousidhoum", "Genta Indra Winata", "Ayu Purwarianti", "Alham Fikri Aji"], "title": "PingPong: A Natural Benchmark for Multi-Turn Code-Switching Dialogues", "comment": "preprint", "summary": "Code-switching is a widespread practice among the world's multilingual majority, yet few benchmarks accurately reflect its complexity in everyday communication. We present PingPong, a benchmark for natural multi-party code-switching dialogues covering five language-combination variations, some of which are trilingual. Our dataset consists of human-authored conversations among 2 to 4 participants covering authentic, multi-threaded structures where replies frequently reference much earlier points in the dialogue. We demonstrate that our data is significantly more natural and structurally diverse than machine-generated alternatives, offering greater variation in message length, speaker dominance, and reply distance. Based on these dialogues, we define three downstream tasks: Question Answering, Dialogue Summarization, and Topic Classification. Evaluations of several state-of-the-art language models on PingPong reveal that performance remains limited on code-switched inputs, underscoring the urgent need for more robust NLP systems capable of addressing the intricacies of real-world multilingual discourse.", "AI": {"tldr": "PingPong\u662f\u4e00\u4e2a\u7528\u4e8e\u81ea\u7136\u591a\u8bed\u8a00\u4ee3\u7801\u5207\u6362\u5bf9\u8bdd\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u4e94\u79cd\u8bed\u8a00\u7ec4\u5408\u53d8\u4f53\uff0c\u6db5\u76d6\u771f\u5b9e\u7684\u591a\u65b9\u5bf9\u8bdd\u7ed3\u6784\uff0c\u5e76\u5b9a\u4e49\u4e86\u4e09\u4e2a\u4e0b\u6e38\u4efb\u52a1\u6765\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u7684\u8868\u73b0\u3002", "motivation": "\u4ee3\u7801\u5207\u6362\u662f\u5168\u7403\u591a\u8bed\u8a00\u4eba\u7fa4\u7684\u666e\u904d\u5b9e\u8df5\uff0c\u4f46\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u51c6\u786e\u53cd\u6620\u65e5\u5e38\u4ea4\u6d41\u4e2d\u7684\u590d\u6742\u6027\u3002\u9700\u8981\u6784\u5efa\u66f4\u81ea\u7136\u7684\u4ee3\u7801\u5207\u6362\u5bf9\u8bdd\u6570\u636e\u96c6\u6765\u63a8\u52a8\u591a\u8bed\u8a00NLP\u7cfb\u7edf\u7684\u53d1\u5c55\u3002", "method": "\u521b\u5efaPingPong\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u4eba\u7c7b\u64b0\u5199\u76842-4\u4eba\u5bf9\u8bdd\uff0c\u8986\u76d6\u4e94\u79cd\u8bed\u8a00\u7ec4\u5408\u53d8\u4f53\uff08\u5305\u62ec\u4e09\u8bed\u5bf9\u8bdd\uff09\u3002\u5bf9\u8bdd\u5177\u6709\u771f\u5b9e\u7684\u591a\u7ebf\u7a0b\u7ed3\u6784\uff0c\u56de\u590d\u7ecf\u5e38\u5f15\u7528\u5bf9\u8bdd\u65e9\u671f\u5185\u5bb9\u3002\u6570\u636e\u96c6\u5728\u6d88\u606f\u957f\u5ea6\u3001\u8bf4\u8bdd\u8005\u4e3b\u5bfc\u6027\u548c\u56de\u590d\u8ddd\u79bb\u65b9\u9762\u63d0\u4f9b\u66f4\u5927\u53d8\u5316\u3002", "result": "PingPong\u6570\u636e\u6bd4\u673a\u5668\u751f\u6210\u7684\u6570\u636e\u66f4\u81ea\u7136\u4e14\u7ed3\u6784\u66f4\u591a\u6837\u3002\u57fa\u4e8e\u8fd9\u4e9b\u5bf9\u8bdd\u5b9a\u4e49\u4e86\u4e09\u4e2a\u4e0b\u6e38\u4efb\u52a1\uff1a\u95ee\u7b54\u3001\u5bf9\u8bdd\u6458\u8981\u548c\u4e3b\u9898\u5206\u7c7b\u3002\u8bc4\u4f30\u663e\u793a\u5f53\u524d\u6700\u5148\u8fdb\u7684\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u5207\u6362\u8f93\u5165\u4e0a\u7684\u8868\u73b0\u4ecd\u7136\u6709\u9650\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u66f4\u5f3a\u5927\u7684NLP\u7cfb\u7edf\u6765\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u591a\u8bed\u8a00\u4ea4\u6d41\u7684\u590d\u6742\u6027\u3002PingPong\u57fa\u51c6\u6d4b\u8bd5\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdb\u591a\u8bed\u8a00\u4ee3\u7801\u5207\u6362\u80fd\u529b\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\u3002"}}
{"id": "2601.17284", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17284", "abs": "https://arxiv.org/abs/2601.17284", "authors": ["Yaokun Liu", "Yifan Liu", "Phoebe Mbuvi", "Zelin Li", "Ruichen Yao", "Gawon Lim", "Dong Wang"], "title": "Mind the Ambiguity: Aleatoric Uncertainty Quantification in LLMs for Safe Medical Question Answering", "comment": "Accepted at The Web Conference 2026 (WWW 2026)", "summary": "The deployment of Large Language Models in Medical Question Answering is severely hampered by ambiguous user queries, a significant safety risk that demonstrably reduces answer accuracy in high-stakes healthcare settings. In this paper, we formalize this challenge by linking input ambiguity to aleatoric uncertainty (AU), which is the irreducible uncertainty arising from underspecified input. To facilitate research in this direction, we construct CV-MedBench, the first benchmark designed for studying input ambiguity in Medical QA. Using this benchmark, we analyze AU from a representation engineering perspective, revealing that AU is linearly encoded in LLM's internal activation patterns. Leveraging this insight, we introduce a novel AU-guided \"Clarify-Before-Answer\" framework, which incorporates AU-Probe - a lightweight module that detects input ambiguity directly from hidden states. Unlike existing uncertainty estimation methods, AU-Probe requires neither LLM fine-tuning nor multiple forward passes, enabling an efficient mechanism to proactively request user clarification and significantly enhance safety. Extensive experiments across four open LLMs demonstrate the effectiveness of our QA framework, with an average accuracy improvement of 9.48% over baselines. Our framework provides an efficient and robust solution for safe Medical QA, strengthening the reliability of health-related applications. The code is available at https://github.com/yaokunliu/AU-Med.git, and the CV-MedBench dataset is released on Hugging Face at https://huggingface.co/datasets/yaokunl/CV-MedBench.", "code_url": "https://github.com/yaokunliu/AU-Med", "code_stars": 1, "code_last_update": "2026-01-24", "AI": {"tldr": "\u63d0\u51faCV-MedBench\u57fa\u51c6\uff0c\u7528\u4e8e\u7814\u7a76\u533b\u5b66\u95ee\u7b54\u4e2d\u7684\u8f93\u5165\u6a21\u7cca\u6027\u95ee\u9898\uff0c\u5e76\u57fa\u4e8e\u8868\u793a\u5de5\u7a0b\u89c6\u89d2\u53d1\u73b0\u6a21\u7cca\u6027\u4e0eLLM\u5185\u90e8\u6fc0\u6d3b\u6a21\u5f0f\u7684\u7ebf\u6027\u7f16\u7801\u5173\u7cfb\uff0c\u5f00\u53d1\u4e86\u65e0\u9700\u5fae\u8c03\u6216\u591a\u6b21\u524d\u5411\u4f20\u64ad\u7684AU-Probe\u6a21\u5757\uff0c\u6784\u5efa\u4e86\"\u5148\u6f84\u6e05\u540e\u56de\u7b54\"\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u533b\u5b66\u95ee\u7b54\u5b89\u5168\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u95ee\u7b54\u4e2d\u7684\u90e8\u7f72\u53d7\u5230\u6a21\u7cca\u7528\u6237\u67e5\u8be2\u7684\u4e25\u91cd\u963b\u788d\uff0c\u8fd9\u79cd\u5b89\u5168\u98ce\u9669\u663e\u8457\u964d\u4f4e\u4e86\u9ad8\u98ce\u9669\u533b\u7597\u73af\u5883\u4e2d\u7684\u56de\u7b54\u51c6\u786e\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u5904\u7406\u8f93\u5165\u6a21\u7cca\u6027\u5e26\u6765\u7684\u4e0d\u53ef\u7ea6\u4e0d\u786e\u5b9a\u6027\u3002", "method": "1) \u6784\u5efaCV-MedBench\u57fa\u51c6\uff0c\u4e13\u95e8\u7814\u7a76\u533b\u5b66QA\u4e2d\u7684\u8f93\u5165\u6a21\u7cca\u6027\uff1b2) \u4ece\u8868\u793a\u5de5\u7a0b\u89d2\u5ea6\u5206\u6790\u6a21\u7cca\u6027\uff0c\u53d1\u73b0\u5176\u7ebf\u6027\u7f16\u7801\u4e8eLLM\u5185\u90e8\u6fc0\u6d3b\u6a21\u5f0f\uff1b3) \u63d0\u51faAU-Probe\u8f7b\u91cf\u6a21\u5757\uff0c\u76f4\u63a5\u4ece\u9690\u85cf\u72b6\u6001\u68c0\u6d4b\u8f93\u5165\u6a21\u7cca\u6027\uff1b4) \u8bbe\u8ba1AU\u5f15\u5bfc\u7684\"\u5148\u6f84\u6e05\u540e\u56de\u7b54\"\u6846\u67b6\uff0c\u4e3b\u52a8\u8bf7\u6c42\u7528\u6237\u6f84\u6e05\u3002", "result": "\u5728\u56db\u4e2a\u5f00\u6e90LLM\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5QA\u6846\u67b6\u5e73\u5747\u51c6\u786e\u7387\u6bd4\u57fa\u7ebf\u63d0\u9ad89.48%\u3002AU-Probe\u65e0\u9700LLM\u5fae\u8c03\u6216\u591a\u6b21\u524d\u5411\u4f20\u64ad\uff0c\u63d0\u4f9b\u9ad8\u6548\u7684\u6a21\u7cca\u6027\u68c0\u6d4b\u673a\u5236\uff0c\u663e\u8457\u589e\u5f3a\u533b\u5b66\u95ee\u7b54\u5b89\u5168\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5b89\u5168\u533b\u5b66\u95ee\u7b54\u63d0\u4f9b\u4e86\u9ad8\u6548\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u8f93\u5165\u6a21\u7cca\u6027\u4e0e\u4e0d\u53ef\u7ea6\u4e0d\u786e\u5b9a\u6027\u7684\u5173\u7cfb\uff0c\u5e76\u5f00\u53d1\u57fa\u4e8e\u8868\u793a\u5de5\u7a0b\u7684\u68c0\u6d4b\u6846\u67b6\uff0c\u589e\u5f3a\u4e86\u5065\u5eb7\u76f8\u5173\u5e94\u7528\u7684\u53ef\u9760\u6027\u3002\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.17699", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17699", "abs": "https://arxiv.org/abs/2601.17699", "authors": ["Harper Hua", "Zhen Han", "Zhengyuan Shen", "Jeremy Lee", "Patrick Guan", "Qi Zhu", "Sullam Jeoung", "Yueyan Chen", "Yunfei Bai", "Shuai Wang", "Vassilis Ioannidis", "Huzefa Rangwala"], "title": "SQL-Trail: Multi-Turn Reinforcement Learning with Interleaved Feedback for Text-to-SQL", "comment": null, "summary": "While large language models (LLMs) have substantially improved Text-to-SQL generation, a pronounced gap remains between AI systems and human experts on challenging benchmarks such as BIRD-SQL. We argue this gap stems largely from the prevailing single-pass paradigm, which lacks the iterative reasoning, schema exploration, and error-correction behaviors that humans naturally employ. To address this limitation, we introduce SQL-Trail, a multi-turn reinforcement learning (RL) agentic framework for Text-to-SQL. Rather than producing a query in one shot, SQL-Trail interacts with the database environment and uses execution feedback to iteratively refine its predictions. Our approach centers on two key ideas: (i) an adaptive turn-budget allocation mechanism that scales the agent's interaction depth to match question difficulty, and (ii) a composite reward panel that jointly incentivizes SQL correctness and efficient exploration. Across benchmarks, SQL-Trail sets a new state of the art and delivers strong data efficiency--up to 18x higher than prior single-pass RL state-of-the-art methods. Notably, our 7B and 14B models outperform substantially larger proprietary systems by 5% on average, underscoring the effectiveness of interactive, agentic workflows for robust Text-to-SQL generation.", "AI": {"tldr": "SQL-Trail\uff1a\u4e00\u4e2a\u7528\u4e8eText-to-SQL\u7684\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u6570\u636e\u5e93\u73af\u5883\u6267\u884c\u53cd\u9988\u8fed\u4ee3\u4f18\u5316\u67e5\u8be2\uff0c\u5728BIRD-SQL\u7b49\u57fa\u51c6\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd", "motivation": "\u5f53\u524dText-to-SQL\u751f\u6210\u4e3b\u8981\u91c7\u7528\u5355\u6b21\u63a8\u7406\u8303\u5f0f\uff0c\u7f3a\u4e4f\u4eba\u7c7b\u4e13\u5bb6\u4f7f\u7528\u7684\u8fed\u4ee3\u63a8\u7406\u3001\u6a21\u5f0f\u63a2\u7d22\u548c\u9519\u8bef\u7ea0\u6b63\u884c\u4e3a\uff0c\u5bfc\u81f4\u5728BIRD-SQL\u7b49\u6311\u6218\u6027\u57fa\u51c6\u4e0a\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5b58\u5728\u660e\u663e\u5dee\u8ddd", "method": "\u63d0\u51faSQL-Trail\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u6846\u67b6\uff1a1\uff09\u81ea\u9002\u5e94\u8f6e\u6b21\u9884\u7b97\u5206\u914d\u673a\u5236\uff0c\u6839\u636e\u95ee\u9898\u96be\u5ea6\u8c03\u6574\u667a\u80fd\u4f53\u4ea4\u4e92\u6df1\u5ea6\uff1b2\uff09\u590d\u5408\u5956\u52b1\u9762\u677f\uff0c\u8054\u5408\u6fc0\u52b1SQL\u6b63\u786e\u6027\u548c\u9ad8\u6548\u63a2\u7d22\uff1b\u901a\u8fc7\u4e0e\u6570\u636e\u5e93\u73af\u5883\u4ea4\u4e92\u5e76\u4f7f\u7528\u6267\u884c\u53cd\u9988\u8fed\u4ee3\u4f18\u5316\u9884\u6d4b", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u6570\u636e\u6548\u7387\u6bd4\u5148\u524d\u5355\u6b21\u63a8\u7406RL\u65b9\u6cd5\u9ad818\u500d\uff1b7B\u548c14B\u6a21\u578b\u5e73\u5747\u6bd4\u5927\u5f97\u591a\u7684\u4e13\u6709\u7cfb\u7edf\u6027\u80fd\u9ad85%\uff0c\u8bc1\u660e\u4e86\u4ea4\u4e92\u5f0f\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u6709\u6548\u6027", "conclusion": "\u4ea4\u4e92\u5f0f\u3001\u667a\u80fd\u4f53\u5316\u7684\u5de5\u4f5c\u6d41\u7a0b\u5bf9\u4e8e\u7a33\u5065\u7684Text-to-SQL\u751f\u6210\u975e\u5e38\u6709\u6548\uff0c\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u7f29\u5c0fAI\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5728\u590d\u6742SQL\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u5dee\u8ddd"}}
{"id": "2601.17312", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17312", "abs": "https://arxiv.org/abs/2601.17312", "authors": ["Hugo Silva", "Mateus Mendes", "Hugo Gon\u00e7alo Oliveira"], "title": "Meta-Judging with Large Language Models: Concepts, Methods, and Challenges", "comment": null, "summary": "Large language models (LLMs) are evolving fast and are now frequently used as evaluators, in a process typically referred to as LLM-as-a-Judge, which provides quality assessments of model outputs. However, recent research points out significant vulnerabilities in such evaluation, including sensitivity to prompts, systematic biases, verbosity effects, and unreliable or hallucinated rationales. These limitations motivated the development of a more robust paradigm, dubbed LLM-as-a-Meta-Judge. This survey reviews recent advances in meta-judging and organizes the literature, by introducing a framework along six key perspectives: (i) Conceptual Foundations, (ii) Mechanisms of Meta-Judging, (iii) Alignment Training Methods, (iv) Evaluation, (v) Limitations and Failure Modes, and (vi) Future Directions. By analyzing the limitations of LLM-as-a-Judge and summarizing recent advances in meta-judging by LLMs, we argue that LLM-as-a-Meta-Judge offers a promising direction for more stable and trustworthy automated evaluation, while highlighting remaining challenges related to cost, prompt sensitivity, and shared model biases, which must be addressed to advance the next generation of LLM evaluation methodologies.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86LLM\u4f5c\u4e3a\u8bc4\u4f30\u8005\uff08LLM-as-a-Judge\uff09\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86LLM\u4f5c\u4e3a\u5143\u8bc4\u4f30\u8005\uff08LLM-as-a-Meta-Judge\uff09\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u516d\u4e2a\u5173\u952e\u89c6\u89d2\u7ec4\u7ec7\u76f8\u5173\u6587\u732e\uff0c\u65e8\u5728\u5b9e\u73b0\u66f4\u7a33\u5b9a\u53ef\u9760\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524dLLM\u4f5c\u4e3a\u8bc4\u4f30\u8005\u5b58\u5728\u663e\u8457\u8106\u5f31\u6027\uff0c\u5305\u62ec\u5bf9\u63d0\u793a\u8bcd\u7684\u654f\u611f\u6027\u3001\u7cfb\u7edf\u6027\u504f\u89c1\u3001\u5197\u957f\u6548\u5e94\u4ee5\u53ca\u4e0d\u53ef\u9760\u6216\u5e7b\u89c9\u5316\u7684\u63a8\u7406\u8fc7\u7a0b\u3002\u8fd9\u4e9b\u5c40\u9650\u6027\u4fc3\u4f7f\u9700\u8981\u5f00\u53d1\u66f4\u7a33\u5065\u7684\u8bc4\u4f30\u8303\u5f0f\u3002", "method": "\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5305\u542b\u516d\u4e2a\u5173\u952e\u89c6\u89d2\u7684\u6846\u67b6\u6765\u7ec4\u7ec7\u5143\u8bc4\u4f30\u7814\u7a76\uff1a\u6982\u5ff5\u57fa\u7840\u3001\u5143\u8bc4\u4f30\u673a\u5236\u3001\u5bf9\u9f50\u8bad\u7ec3\u65b9\u6cd5\u3001\u8bc4\u4f30\u3001\u5c40\u9650\u6027\u4e0e\u5931\u8d25\u6a21\u5f0f\u3001\u672a\u6765\u65b9\u5411\u3002", "result": "\u5206\u6790\u8868\u660eLLM-as-a-Meta-Judge\u4e3a\u66f4\u7a33\u5b9a\u548c\u53ef\u4fe1\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u6210\u672c\u3001\u63d0\u793a\u654f\u611f\u6027\u548c\u5171\u4eab\u6a21\u578b\u504f\u89c1\u7b49\u6311\u6218\u3002", "conclusion": "LLM-as-a-Meta-Judge\u662f\u63a8\u8fdb\u4e0b\u4e00\u4ee3LLM\u8bc4\u4f30\u65b9\u6cd5\u5b66\u7684\u6709\u5e0c\u671b\u8def\u5f84\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u89e3\u51b3\u73b0\u6709\u6311\u6218\u4ee5\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u7cfb\u7edf\u3002"}}
{"id": "2601.17717", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17717", "abs": "https://arxiv.org/abs/2601.17717", "authors": ["Kaituo Zhang", "Mingzhi Hu", "Hoang Anh Duy Le", "Fariha Kabir Torsha", "Zhimeng Jiang", "Minh Khai Bui", "Chia-Yuan Chang", "Yu-Neng Chuang", "Zhen Xiong", "Ying Lin", "Guanchu Wang", "Na Zou"], "title": "The LLM Data Auditor: A Metric-oriented Survey on Quality and Trustworthiness in Evaluating Synthetic Data", "comment": null, "summary": "Large Language Models (LLMs) have emerged as powerful tools for generating data across various modalities. By transforming data from a scarce resource into a controllable asset, LLMs mitigate the bottlenecks imposed by the acquisition costs of real-world data for model training, evaluation, and system iteration. However, ensuring the high quality of LLM-generated synthetic data remains a critical challenge. Existing research primarily focuses on generation methodologies, with limited direct attention to the quality of the resulting data. Furthermore, most studies are restricted to single modalities, lacking a unified perspective across different data types. To bridge this gap, we propose the \\textbf{LLM Data Auditor framework}. In this framework, we first describe how LLMs are utilized to generate data across six distinct modalities. More importantly, we systematically categorize intrinsic metrics for evaluating synthetic data from two dimensions: quality and trustworthiness. This approach shifts the focus from extrinsic evaluation, which relies on downstream task performance, to the inherent properties of the data itself. Using this evaluation system, we analyze the experimental evaluations of representative generation methods for each modality and identify substantial deficiencies in current evaluation practices. Based on these findings, we offer concrete recommendations for the community to improve the evaluation of data generation. Finally, the framework outlines methodologies for the practical application of synthetic data across different modalities.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86LLM\u6570\u636e\u5ba1\u8ba1\u6846\u67b6\uff0c\u7cfb\u7edf\u8bc4\u4f30LLM\u751f\u6210\u7684\u591a\u6a21\u6001\u5408\u6210\u6570\u636e\u8d28\u91cf\u4e0e\u53ef\u4fe1\u5ea6\uff0c\u6307\u51fa\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u7684\u4e0d\u8db3\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "LLM\u5df2\u6210\u4e3a\u751f\u6210\u591a\u6a21\u6001\u6570\u636e\u7684\u6709\u529b\u5de5\u5177\uff0c\u5c06\u6570\u636e\u4ece\u7a00\u7f3a\u8d44\u6e90\u8f6c\u53d8\u4e3a\u53ef\u63a7\u8d44\u4ea7\uff0c\u964d\u4f4e\u4e86\u771f\u5b9e\u6570\u636e\u83b7\u53d6\u6210\u672c\u3002\u7136\u800c\uff0c\u786e\u4fddLLM\u751f\u6210\u5408\u6210\u6570\u636e\u7684\u9ad8\u8d28\u91cf\u4ecd\u662f\u5173\u952e\u6311\u6218\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u751f\u6210\u65b9\u6cd5\uff0c\u5bf9\u6570\u636e\u8d28\u91cf\u5173\u6ce8\u6709\u9650\uff0c\u4e14\u591a\u5c40\u9650\u4e8e\u5355\u4e00\u6a21\u6001\uff0c\u7f3a\u4e4f\u8de8\u6a21\u6001\u7684\u7edf\u4e00\u89c6\u89d2\u3002", "method": "\u63d0\u51faLLM\u6570\u636e\u5ba1\u8ba1\u6846\u67b6\uff1a1) \u63cf\u8ff0LLM\u5982\u4f55\u751f\u6210\u516d\u79cd\u4e0d\u540c\u6a21\u6001\u7684\u6570\u636e\uff1b2) \u4ece\u8d28\u91cf\u548c\u53ef\u4fe1\u5ea6\u4e24\u4e2a\u7ef4\u5ea6\u7cfb\u7edf\u5206\u7c7b\u5408\u6210\u6570\u636e\u7684\u5185\u5728\u8bc4\u4f30\u6307\u6807\uff0c\u5c06\u8bc4\u4f30\u91cd\u70b9\u4ece\u4f9d\u8d56\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u7684\u5916\u5728\u8bc4\u4f30\u8f6c\u5411\u6570\u636e\u672c\u8eab\u56fa\u6709\u5c5e\u6027\uff1b3) \u4f7f\u7528\u8be5\u8bc4\u4f30\u7cfb\u7edf\u5206\u6790\u5404\u6a21\u6001\u4ee3\u8868\u6027\u751f\u6210\u65b9\u6cd5\u7684\u5b9e\u9a8c\u8bc4\u4f30\uff1b4) \u57fa\u4e8e\u53d1\u73b0\u63d0\u51fa\u6539\u8fdb\u6570\u636e\u751f\u6210\u8bc4\u4f30\u7684\u5177\u4f53\u5efa\u8bae\uff1b5) \u6982\u8ff0\u5408\u6210\u6570\u636e\u5728\u4e0d\u540c\u6a21\u6001\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u5206\u6790\u5404\u6a21\u6001\u4ee3\u8868\u6027\u751f\u6210\u65b9\u6cd5\u7684\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u53d1\u73b0\u4e86\u5f53\u524d\u8bc4\u4f30\u5b9e\u8df5\u4e2d\u7684\u91cd\u5927\u7f3a\u9677\u3002\u57fa\u4e8e\u8fd9\u4e9b\u53d1\u73b0\uff0c\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u6539\u8fdb\u6570\u636e\u751f\u6210\u8bc4\u4f30\u7684\u5177\u4f53\u5efa\u8bae\u3002", "conclusion": "LLM\u6570\u636e\u5ba1\u8ba1\u6846\u67b6\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u8de8\u6a21\u6001\u7684\u7edf\u4e00\u8bc4\u4f30\u89c6\u89d2\u3002\u8be5\u6846\u67b6\u4e0d\u4ec5\u8bc6\u522b\u4e86\u5f53\u524d\u8bc4\u4f30\u5b9e\u8df5\u7684\u4e0d\u8db3\uff0c\u8fd8\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\uff0c\u5e76\u4e3a\u5408\u6210\u6570\u636e\u5728\u4e0d\u540c\u6a21\u6001\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8LLM\u751f\u6210\u5408\u6210\u6570\u636e\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.17344", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17344", "abs": "https://arxiv.org/abs/2601.17344", "authors": ["Chen Chen", "Kim Young Il", "Yuan Yang", "Wenhao Su", "Yilin Zhang", "Xueluan Gong", "Qian Wang", "Yongsen Zheng", "Ziyao Liu", "Kwok-Yan Lam"], "title": "The Shadow Self: Intrinsic Value Misalignment in Large Language Model Agents", "comment": "21 pages, 11 figures", "summary": "Large language model (LLM) agents with extended autonomy unlock new capabilities, but also introduce heightened challenges for LLM safety. In particular, an LLM agent may pursue objectives that deviate from human values and ethical norms, a risk known as value misalignment. Existing evaluations primarily focus on responses to explicit harmful input or robustness against system failure, while value misalignment in realistic, fully benign, and agentic settings remains largely underexplored. To fill this gap, we first formalize the Loss-of-Control risk and identify the previously underexamined Intrinsic Value Misalignment (Intrinsic VM). We then introduce IMPRESS (Intrinsic Value Misalignment Probes in REalistic Scenario Set), a scenario-driven framework for systematically assessing this risk. Following our framework, we construct benchmarks composed of realistic, fully benign, and contextualized scenarios, using a multi-stage LLM generation pipeline with rigorous quality control. We evaluate Intrinsic VM on 21 state-of-the-art LLM agents and find that it is a common and broadly observed safety risk across models. Moreover, the misalignment rates vary by motives, risk types, model scales, and architectures. While decoding strategies and hyperparameters exhibit only marginal influence, contextualization and framing mechanisms significantly shape misalignment behaviors. Finally, we conduct human verification to validate our automated judgments and assess existing mitigation strategies, such as safety prompting and guardrails, which show instability or limited effectiveness. We further demonstrate key use cases of IMPRESS across the AI Ecosystem. Our code and benchmark will be publicly released upon acceptance.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86IMPRESS\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u5728\u5b8c\u5168\u826f\u6027\u3001\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u5185\u5728\u4ef7\u503c\u9519\u4f4d\u98ce\u9669\uff0c\u53d1\u73b0\u8fd9\u662f\u666e\u904d\u5b58\u5728\u7684\u5b89\u5168\u95ee\u9898\uff0c\u73b0\u6709\u7f13\u89e3\u7b56\u7565\u6548\u679c\u6709\u9650\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u5bf9\u663e\u6027\u6709\u5bb3\u8f93\u5165\u7684\u54cd\u5e94\u6216\u7cfb\u7edf\u6545\u969c\u7684\u9c81\u68d2\u6027\uff0c\u800c\u5728\u5b8c\u5168\u826f\u6027\u3001\u73b0\u5b9e\u7684\u667a\u80fd\u4f53\u8bbe\u7f6e\u4e2d\u7684\u4ef7\u503c\u9519\u4f4d\u98ce\u9669\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002LLM\u667a\u80fd\u4f53\u53ef\u80fd\u8ffd\u6c42\u504f\u79bb\u4eba\u7c7b\u4ef7\u503c\u89c2\u548c\u9053\u5fb7\u89c4\u8303\u7684\u76ee\u6807\uff0c\u8fd9\u79cd\u98ce\u9669\u88ab\u79f0\u4e3a\u4ef7\u503c\u9519\u4f4d\u3002", "method": "\u9996\u5148\u5f62\u5f0f\u5316\u5931\u63a7\u98ce\u9669\uff0c\u8bc6\u522b\u5185\u5728\u4ef7\u503c\u9519\u4f4d\u3002\u7136\u540e\u5f15\u5165IMPRESS\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u9636\u6bb5LLM\u751f\u6210\u7ba1\u9053\u6784\u5efa\u73b0\u5b9e\u3001\u5b8c\u5168\u826f\u6027\u548c\u60c5\u5883\u5316\u7684\u573a\u666f\u57fa\u51c6\uff0c\u5bf921\u4e2a\u6700\u5148\u8fdb\u7684LLM\u667a\u80fd\u4f53\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u8fdb\u884c\u4eba\u5de5\u9a8c\u8bc1\u3002", "result": "\u5185\u5728\u4ef7\u503c\u9519\u4f4d\u662f\u8de8\u6a21\u578b\u7684\u666e\u904d\u5b89\u5168\u98ce\u9669\uff0c\u9519\u4f4d\u7387\u56e0\u52a8\u673a\u3001\u98ce\u9669\u7c7b\u578b\u3001\u6a21\u578b\u89c4\u6a21\u548c\u67b6\u6784\u800c\u5f02\u3002\u89e3\u7801\u7b56\u7565\u548c\u8d85\u53c2\u6570\u5f71\u54cd\u6709\u9650\uff0c\u4f46\u60c5\u5883\u5316\u548c\u6846\u67b6\u673a\u5236\u663e\u8457\u5f71\u54cd\u9519\u4f4d\u884c\u4e3a\u3002\u73b0\u6709\u7f13\u89e3\u7b56\u7565\uff08\u5982\u5b89\u5168\u63d0\u793a\u548c\u62a4\u680f\uff09\u8868\u73b0\u51fa\u4e0d\u7a33\u5b9a\u6027\u6216\u6709\u9650\u6548\u679c\u3002", "conclusion": "IMPRESS\u6846\u67b6\u586b\u8865\u4e86\u73b0\u5b9e\u3001\u826f\u6027\u573a\u666f\u4e2dLLM\u667a\u80fd\u4f53\u4ef7\u503c\u9519\u4f4d\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u63ed\u793a\u4e86\u8fd9\u4e00\u666e\u904d\u5b89\u5168\u98ce\u9669\uff0c\u5e76\u5c55\u793a\u4e86\u5728AI\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u7528\u4f8b\u3002\u73b0\u6709\u5b89\u5168\u63aa\u65bd\u9700\u8981\u6539\u8fdb\u4ee5\u6709\u6548\u5e94\u5bf9\u5185\u5728\u4ef7\u503c\u9519\u4f4d\u3002"}}
{"id": "2601.17722", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17722", "abs": "https://arxiv.org/abs/2601.17722", "authors": ["Ying Mo", "Yu Bai", "Dapeng Sun", "Yuqian Shi", "Yukai Miao", "Li Chen", "Dan Li"], "title": "EntWorld: A Holistic Environment and Benchmark for Verifiable Enterprise GUI Agents", "comment": null, "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have enabled agents to operate in open-ended web and operating system environments. However, existing benchmarks predominantly target consumer-oriented scenarios (e.g., e-commerce and travel booking), failing to capture the complexity and rigor of professional enterprise workflows. Enterprise systems pose distinct challenges, including high-density user interfaces, strict business logic constraints, and a strong reliance on precise, state-consistent information retrieval-settings in which current generalist agents often struggle. To address this gap, we introduce EntWorld, a large-scale benchmark consisting of 1,756 tasks across six representative enterprise domains, including customer relationship management (CRM), information technology infrastructure library (ITIL), and enterprise resource planning (ERP) systems. Unlike previous datasets that depend on fragile execution traces or extensive manual annotation, EntWorld adopts a schema-grounded task generation framework that directly reverse-engineers business logic from underlying database schemas, enabling the synthesis of realistic, long-horizon workflows. Moreover, we propose a SQL-based deterministic verification mechanism in building datasets that replaces ambiguous visual matching with rigorous state-transition validation. Experimental results demonstrate that state-of-the-art models (e.g., GPT-4.1) achieve 47.61% success rate on EntWorld, substantially lower than the human performance, highlighting a pronounced enterprise gap in current agentic capabilities and the necessity of developing domain-specific agents. We release EntWorld as a rigorous testbed to facilitate the development and evaluation of the next generation of enterprise-ready digital agents.", "AI": {"tldr": "EntWorld\u662f\u4e00\u4e2a\u9488\u5bf9\u4f01\u4e1a\u7ea7\u5de5\u4f5c\u6d41\u7a0b\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b1,756\u4e2a\u4efb\u52a1\uff0c\u8986\u76d6CRM\u3001ITIL\u3001ERP\u7b49\u516d\u4e2a\u4f01\u4e1a\u9886\u57df\uff0c\u91c7\u7528\u57fa\u4e8e\u6570\u636e\u5e93\u6a21\u5f0f\u7684\u786e\u5b9a\u6027\u9a8c\u8bc1\u673a\u5236\uff0c\u63ed\u793a\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u663e\u8457\u6027\u80fd\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u9488\u5bf9\u6d88\u8d39\u7ea7\u573a\u666f\uff08\u5982\u7535\u5546\u3001\u65c5\u884c\u9884\u8ba2\uff09\uff0c\u65e0\u6cd5\u6355\u6349\u4f01\u4e1a\u5de5\u4f5c\u6d41\u7a0b\u7684\u590d\u6742\u6027\u548c\u4e25\u8c28\u6027\u3002\u4f01\u4e1a\u7cfb\u7edf\u5177\u6709\u9ad8\u5bc6\u5ea6\u7528\u6237\u754c\u9762\u3001\u4e25\u683c\u4e1a\u52a1\u903b\u8f91\u7ea6\u675f\u548c\u7cbe\u786e\u72b6\u6001\u4e00\u81f4\u6027\u8981\u6c42\u7b49\u7279\u70b9\uff0c\u5f53\u524d\u901a\u7528\u667a\u80fd\u4f53\u5728\u8fd9\u4e9b\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u4e13\u95e8\u7684\u4f01\u4e1a\u7ea7\u57fa\u51c6\u6d4b\u8bd5\u6765\u63a8\u52a8\u9886\u57df\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u5f0f\u7684\u4efb\u52a1\u751f\u6210\u6846\u67b6\uff0c\u76f4\u63a5\u4ece\u5e95\u5c42\u6570\u636e\u5e93\u6a21\u5f0f\u9006\u5411\u5de5\u7a0b\u4e1a\u52a1\u903b\u8f91\uff0c\u5408\u6210\u771f\u5b9e\u7684\u957f\u6d41\u7a0b\u5de5\u4f5c\u6d41\u3002\u91c7\u7528\u57fa\u4e8eSQL\u7684\u786e\u5b9a\u6027\u9a8c\u8bc1\u673a\u5236\uff0c\u7528\u4e25\u683c\u7684\u72b6\u6001\u8f6c\u6362\u9a8c\u8bc1\u66ff\u4ee3\u6a21\u7cca\u7684\u89c6\u89c9\u5339\u914d\uff0c\u786e\u4fdd\u4efb\u52a1\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6700\u5148\u8fdb\u6a21\u578b\uff08\u5982GPT-4.1\uff09\u5728EntWorld\u4e0a\u7684\u6210\u529f\u7387\u4ec5\u4e3a47.61%\uff0c\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\u8868\u73b0\u3002\u8fd9\u8868\u660e\u5f53\u524d\u667a\u80fd\u4f53\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u80fd\u529b\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u9700\u8981\u5f00\u53d1\u9886\u57df\u7279\u5b9a\u7684\u4f01\u4e1a\u7ea7\u667a\u80fd\u4f53\u3002", "conclusion": "EntWorld\u4f5c\u4e3a\u4e00\u4e2a\u4e25\u8c28\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f01\u4e1a\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5f00\u53d1\u4e0b\u4e00\u4ee3\u4f01\u4e1a\u7ea7\u6570\u5b57\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u5f3a\u8c03\u4e86\u5f00\u53d1\u9886\u57df\u7279\u5b9a\u667a\u80fd\u4f53\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2601.18457", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18457", "abs": "https://arxiv.org/abs/2601.18457", "authors": ["Fake Lin", "Binbin Hu", "Zhi Zheng", "Xi Zhu", "Ziqi Liu", "Zhiqiang Zhang", "Jun Zhou", "Tong Xu"], "title": "Token-level Collaborative Alignment for LLM-based Generative Recommendation", "comment": "11 pages, 2 figures, 7 tables, WWW 2026", "summary": "Large Language Models (LLMs) have demonstrated strong potential for generative recommendation by leveraging rich semantic knowledge. However, existing LLM-based recommender systems struggle to effectively incorporate collaborative filtering (CF) signals, due to a fundamental mismatch between item-level preference modeling in CF and token-level next-token prediction (NTP) optimization in LLMs. Prior approaches typically treat CF as contextual hints or representation bias, and resort to multi-stage training to reduce behavioral semantic space discrepancies, leaving CF unable to explicitly regulate LLM generation. In this work, we propose Token-level Collaborative Alignment for Recommendation (TCA4Rec), a model-agnostic and plug-and-play framework that establishes an explicit optimization-level interface between CF supervision and LLM generation. TCA4Rec consists of (i) Collaborative Tokenizer, which projects raw item-level CF logits into token-level distributions aligned with the LLM token space, and (ii) Soft Label Alignment, which integrates these CF-informed distributions with one-hot supervision to optimize a soft NTP objective. This design preserves the generative nature of LLM training while enabling collaborative alignment with essential user preference of CF models. We highlight TCA4Rec is compatible with arbitrary traditional CF models and generalizes across a wide range of decoder-based LLM recommender architectures. Moreover, it provides an explicit mechanism to balance behavioral alignment and semantic fluency, yielding generative recommendations that are both accurate and controllable. Extensive experiments demonstrate that TCA4Rec consistently improves recommendation performance across a broad spectrum of CF models and LLM-based recommender systems.", "AI": {"tldr": "TCA4Rec\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u5373\u63d2\u5373\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u4ee4\u724c\u7ea7\u534f\u540c\u5bf9\u9f50\u89e3\u51b3LLM\u63a8\u8350\u7cfb\u7edf\u4e2d\u96be\u4ee5\u6709\u6548\u6574\u5408\u534f\u540c\u8fc7\u6ee4\u4fe1\u53f7\u7684\u95ee\u9898", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u63a8\u8350\u7cfb\u7edf\u96be\u4ee5\u6709\u6548\u6574\u5408\u534f\u540c\u8fc7\u6ee4\u4fe1\u53f7\uff0c\u56e0\u4e3aCF\u57fa\u4e8e\u7269\u54c1\u7ea7\u504f\u597d\u5efa\u6a21\uff0c\u800cLLM\u57fa\u4e8e\u4ee4\u724c\u7ea7\u4e0b\u4e00\u4ee4\u724c\u9884\u6d4b\u4f18\u5316\uff0c\u4e24\u8005\u5b58\u5728\u6839\u672c\u6027\u4e0d\u5339\u914d\u3002\u5148\u524d\u65b9\u6cd5\u901a\u5e38\u5c06CF\u89c6\u4e3a\u4e0a\u4e0b\u6587\u63d0\u793a\u6216\u8868\u793a\u504f\u5dee\uff0c\u9700\u8981\u591a\u9636\u6bb5\u8bad\u7ec3\u6765\u51cf\u5c11\u884c\u4e3a\u8bed\u4e49\u7a7a\u95f4\u5dee\u5f02\uff0c\u5bfc\u81f4CF\u65e0\u6cd5\u663e\u5f0f\u8c03\u63a7LLM\u751f\u6210\u3002", "method": "\u63d0\u51faTCA4Rec\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a(1)\u534f\u540c\u4ee4\u724c\u5316\u5668\uff1a\u5c06\u539f\u59cb\u7269\u54c1\u7ea7CF\u5bf9\u6570\u6982\u7387\u6295\u5f71\u5230\u4e0eLLM\u4ee4\u724c\u7a7a\u95f4\u5bf9\u9f50\u7684\u4ee4\u724c\u7ea7\u5206\u5e03\uff1b(2)\u8f6f\u6807\u7b7e\u5bf9\u9f50\uff1a\u5c06\u8fd9\u4e9bCF\u4fe1\u606f\u5316\u7684\u5206\u5e03\u4e0e\u72ec\u70ed\u76d1\u7763\u7ed3\u5408\uff0c\u4f18\u5316\u8f6fNTP\u76ee\u6807\u3002\u8be5\u8bbe\u8ba1\u4fdd\u7559\u4e86LLM\u8bad\u7ec3\u7684\u751f\u6210\u6027\u8d28\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u4e0eCF\u6a21\u578b\u6838\u5fc3\u7528\u6237\u504f\u597d\u7684\u534f\u540c\u5bf9\u9f50\u3002", "result": "TCA4Rec\u4e0e\u4efb\u610f\u4f20\u7edfCF\u6a21\u578b\u517c\u5bb9\uff0c\u53ef\u6cdb\u5316\u5230\u5e7f\u6cdb\u7684\u57fa\u4e8e\u89e3\u7801\u5668\u7684LLM\u63a8\u8350\u67b6\u6784\u3002\u5b83\u63d0\u4f9b\u4e86\u663e\u5f0f\u673a\u5236\u6765\u5e73\u8861\u884c\u4e3a\u5bf9\u9f50\u548c\u8bed\u4e49\u6d41\u7545\u6027\uff0c\u751f\u6210\u65e2\u51c6\u786e\u53c8\u53ef\u63a7\u5236\u7684\u63a8\u8350\u3002\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cTCA4Rec\u5728\u5404\u79cdCF\u6a21\u578b\u548c\u57fa\u4e8eLLM\u7684\u63a8\u8350\u7cfb\u7edf\u4e2d\u6301\u7eed\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002", "conclusion": "TCA4Rec\u901a\u8fc7\u5efa\u7acbCF\u76d1\u7763\u4e0eLLM\u751f\u6210\u4e4b\u95f4\u7684\u663e\u5f0f\u4f18\u5316\u7ea7\u63a5\u53e3\uff0c\u89e3\u51b3\u4e86LLM\u63a8\u8350\u7cfb\u7edf\u4e2d\u534f\u540c\u8fc7\u6ee4\u6574\u5408\u7684\u96be\u9898\uff0c\u5b9e\u73b0\u4e86\u751f\u6210\u6027\u63a8\u8350\u4e2d\u884c\u4e3a\u5bf9\u9f50\u4e0e\u8bed\u4e49\u6d41\u7545\u6027\u7684\u5e73\u8861\uff0c\u4e3aLLM\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u534f\u540c\u5bf9\u9f50\u6846\u67b6\u3002"}}
{"id": "2601.17363", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17363", "abs": "https://arxiv.org/abs/2601.17363", "authors": ["Michael Farrell"], "title": "Do readers prefer AI-generated Italian short stories?", "comment": "7 pages", "summary": "This study investigates whether readers prefer AI-generated short stories in Italian over one written by a renowned Italian author. In a blind setup, 20 participants read and evaluated three stories, two created with ChatGPT-4o and one by Alberto Moravia, without being informed of their origin. To explore potential influencing factors, reading habits and demographic data, comprising age, gender, education and first language, were also collected. The results showed that the AI-written texts received slightly higher average ratings and were more frequently preferred, although differences were modest. No statistically significant associations were found between text preference and demographic or reading-habit variables. These findings challenge assumptions about reader preference for human-authored fiction and raise questions about the necessity of synthetic-text editing in literary contexts.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u76f2\u6d4b\u6bd4\u8f83AI\u751f\u6210\u4e0e\u4eba\u7c7b\u4f5c\u5bb6\u77ed\u7bc7\u5c0f\u8bf4\uff0c\u53d1\u73b0AI\u4f5c\u54c1\u83b7\u5f97\u7565\u9ad8\u8bc4\u5206\u548c\u504f\u597d\uff0c\u6311\u6218\u4e86\u4eba\u7c7b\u6587\u5b66\u521b\u4f5c\u4f18\u52bf\u7684\u5047\u8bbe\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u8bfb\u8005\u662f\u5426\u66f4\u504f\u597dAI\u751f\u6210\u7684\u610f\u5927\u5229\u8bed\u77ed\u7bc7\u5c0f\u8bf4\u800c\u975e\u77e5\u540d\u610f\u5927\u5229\u4f5c\u5bb6\u7684\u4f5c\u54c1\uff0c\u6311\u6218\u5173\u4e8e\u4eba\u7c7b\u521b\u4f5c\u6587\u5b66\u4f18\u8d8a\u6027\u7684\u666e\u904d\u5047\u8bbe\uff0c\u5e76\u68c0\u9a8c\u5408\u6210\u6587\u672c\u5728\u6587\u5b66\u8bed\u5883\u4e2d\u7684\u63a5\u53d7\u5ea6\u3002", "method": "\u91c7\u7528\u76f2\u6d4b\u5b9e\u9a8c\u8bbe\u8ba1\uff0c20\u540d\u53c2\u4e0e\u8005\u5728\u4e0d\u77e5\u60c5\u60c5\u51b5\u4e0b\u9605\u8bfb\u5e76\u8bc4\u4f30\u4e09\u7bc7\u77ed\u7bc7\u5c0f\u8bf4\uff1a\u4e24\u7bc7\u7531ChatGPT-4o\u751f\u6210\uff0c\u4e00\u7bc7\u7531\u610f\u5927\u5229\u8457\u540d\u4f5c\u5bb6Alberto Moravia\u521b\u4f5c\u3002\u540c\u65f6\u6536\u96c6\u53c2\u4e0e\u8005\u7684\u9605\u8bfb\u4e60\u60ef\u548c\u4eba\u53e3\u7edf\u8ba1\u5b66\u6570\u636e\uff08\u5e74\u9f84\u3001\u6027\u522b\u3001\u6559\u80b2\u7a0b\u5ea6\u3001\u6bcd\u8bed\uff09\u3002", "result": "AI\u751f\u6210\u7684\u6587\u672c\u83b7\u5f97\u4e86\u7565\u9ad8\u7684\u5e73\u5747\u8bc4\u5206\uff0c\u4e14\u66f4\u9891\u7e41\u88ab\u504f\u597d\uff0c\u4f46\u5dee\u5f02\u4e0d\u5927\u3002\u6587\u672c\u504f\u597d\u4e0e\u4eba\u53e3\u7edf\u8ba1\u5b66\u53d8\u91cf\u6216\u9605\u8bfb\u4e60\u60ef\u4e4b\u95f4\u672a\u53d1\u73b0\u7edf\u8ba1\u5b66\u663e\u8457\u5173\u8054\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6311\u6218\u4e86\u8bfb\u8005\u66f4\u504f\u597d\u4eba\u7c7b\u521b\u4f5c\u5c0f\u8bf4\u7684\u5047\u8bbe\uff0c\u5e76\u5f15\u53d1\u4e86\u5bf9\u6587\u5b66\u8bed\u5883\u4e2d\u5408\u6210\u6587\u672c\u7f16\u8f91\u5fc5\u8981\u6027\u7684\u8d28\u7591\u3002"}}
{"id": "2601.18570", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18570", "abs": "https://arxiv.org/abs/2601.18570", "authors": ["Mingzhe Han", "Jiahao Liu", "Dongsheng Li", "Hansu Gu", "Peng Zhang", "Ning Gu", "Tun Lu"], "title": "Feature-Indexed Federated Recommendation with Residual-Quantized Codebooks", "comment": null, "summary": "Federated recommendation provides a privacy-preserving solution for training recommender systems without centralizing user interactions. However, existing methods follow an ID-indexed communication paradigm that transmit whole item embeddings between clients and the server, which has three major limitations: 1) consumes uncontrollable communication resources, 2) the uploaded item information cannot generalize to related non-interacted items, and 3) is sensitive to client noisy feedback. To solve these problems, it is necessary to fundamentally change the existing ID-indexed communication paradigm. Therefore, we propose a feature-indexed communication paradigm that transmits feature code embeddings as codebooks rather than raw item embeddings. Building on this paradigm, we present RQFedRec, which assigns each item a list of discrete code IDs via Residual Quantization (RQ)-Kmeans. Each client generates and trains code embeddings as codebooks based on discrete code IDs provided by the server, and the server collects and aggregates these codebooks rather than item embeddings. This design makes communication controllable since the codebooks could cover all items, enabling updates to propagate across related items in same code ID. In addition, since code embedding represents many items, which is more robust to a single noisy item. To jointly capture semantic and collaborative information, RQFedRec further adopts a collaborative-semantic dual-channel aggregation with a curriculum strategy that emphasizes semantic codes early and gradually increases the contribution of collaborative codes over training. Extensive experiments on real-world datasets demonstrate that RQFedRec consistently outperforms state-of-the-art federated recommendation baselines while significantly reducing communication overhead.", "AI": {"tldr": "RQFedRec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7279\u5f81\u7d22\u5f15\u901a\u4fe1\u8303\u5f0f\u7684\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u6b8b\u5dee\u91cf\u5316K-means\u751f\u6210\u79bb\u6563\u4ee3\u7801ID\uff0c\u4f20\u8f93\u4ee3\u7801\u672c\u800c\u975e\u539f\u59cb\u9879\u76ee\u5d4c\u5165\uff0c\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u5e76\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u63a8\u8350\u65b9\u6cd5\u91c7\u7528ID\u7d22\u5f15\u901a\u4fe1\u8303\u5f0f\uff0c\u4f20\u8f93\u6574\u4e2a\u9879\u76ee\u5d4c\u5165\uff0c\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u901a\u4fe1\u8d44\u6e90\u6d88\u8017\u4e0d\u53ef\u63a7\uff1b2) \u4e0a\u4f20\u7684\u9879\u76ee\u4fe1\u606f\u65e0\u6cd5\u6cdb\u5316\u5230\u76f8\u5173\u7684\u672a\u4ea4\u4e92\u9879\u76ee\uff1b3) \u5bf9\u5ba2\u6237\u7aef\u566a\u58f0\u53cd\u9988\u654f\u611f\u3002\u9700\u8981\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u73b0\u6709\u7684\u901a\u4fe1\u8303\u5f0f\u3002", "method": "\u63d0\u51fa\u7279\u5f81\u7d22\u5f15\u901a\u4fe1\u8303\u5f0f\uff0c\u901a\u8fc7\u6b8b\u5dee\u91cf\u5316K-means\u4e3a\u6bcf\u4e2a\u9879\u76ee\u5206\u914d\u79bb\u6563\u4ee3\u7801ID\u5217\u8868\u3002\u5ba2\u6237\u7aef\u57fa\u4e8e\u670d\u52a1\u5668\u63d0\u4f9b\u7684\u4ee3\u7801ID\u751f\u6210\u5e76\u8bad\u7ec3\u4ee3\u7801\u5d4c\u5165\u4f5c\u4e3a\u4ee3\u7801\u672c\uff0c\u670d\u52a1\u5668\u805a\u5408\u8fd9\u4e9b\u4ee3\u7801\u672c\u800c\u975e\u9879\u76ee\u5d4c\u5165\u3002\u91c7\u7528\u534f\u4f5c-\u8bed\u4e49\u53cc\u901a\u9053\u805a\u5408\u7b56\u7565\uff0c\u914d\u5408\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u65e9\u671f\u5f3a\u8c03\u8bed\u4e49\u4ee3\u7801\uff0c\u9010\u6b65\u589e\u52a0\u534f\u4f5c\u4ee3\u7801\u7684\u8d21\u732e\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cRQFedRec\u5728\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u7684\u540c\u65f6\uff0c\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u8054\u90a6\u63a8\u8350\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "RQFedRec\u901a\u8fc7\u7279\u5f81\u7d22\u5f15\u901a\u4fe1\u8303\u5f0f\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfID\u7d22\u5f15\u8303\u5f0f\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u901a\u4fe1\u53ef\u63a7\u6027\u3001\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u7684\u63d0\u5347\uff0c\u4e3a\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17364", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17364", "abs": "https://arxiv.org/abs/2601.17364", "authors": ["Mohammed Fasha", "Bassam Hammo", "Bilal Sowan", "Husam Barham", "Esam Nsour"], "title": "Parameter Efficient Fine Tuning Llama 3.1 for Answering Arabic Legal Questions: A Case Study on Jordanian Laws", "comment": "5 pages, resources at: https://github.com/msfasha/Research-Resources/tree/main/ArabicLegalLLM", "summary": "This study uses Jordanian law as a case study to explore the fine-tuning of the Llama-3.1 large language model for Arabic question-answering. Two versions of the model - Llama-3.1-8B-bnb-4bit and Llama-3.1-8B-Instruct-bnb-4bit - were fine-tuned using parameter-efficient fine-tuning (PEFT) with LoRA adapters and 4-bit quantized models, leveraging the Unsloth framework for accelerated and resource-efficient training. A custom dataset of 6000 legal question-answer pairs was curated from Jordanian laws and formatted into structured prompts. Performance was evaluated using the BLEU and the ROUGE metrics to compare the fine-tuned models to their respective base versions. Results demonstrated improved legal reasoning and accuracy while achieving resource efficiency through quantization and optimized fine-tuning strategies. This work underscores the potential of adapting large language models for Arabic legal domains and highlights effective techniques for fine-tuning domain-specific tasks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4ee5\u7ea6\u65e6\u6cd5\u5f8b\u4e3a\u6848\u4f8b\uff0c\u63a2\u7d22\u4e86Llama-3.1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u963f\u62c9\u4f2f\u8bed\u6cd5\u5f8b\u95ee\u7b54\u4efb\u52a1\u4e0a\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cf\u5316\u548c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f\u5b9e\u73b0\u4e86\u8d44\u6e90\u9ad8\u6548\u7684\u9886\u57df\u9002\u5e94\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u6709\u6548\u9002\u5e94\u5230\u963f\u62c9\u4f2f\u8bed\u6cd5\u5f8b\u9886\u57df\uff0c\u89e3\u51b3\u7279\u5b9a\u9886\u57df\u4efb\u52a1\u4e2d\u7684\u8d44\u6e90\u6548\u7387\u548c\u51c6\u786e\u6027\u6311\u6218\uff0c\u4e3a\u963f\u62c9\u4f2f\u8bed\u6cd5\u5f8bAI\u5e94\u7528\u63d0\u4f9b\u6280\u672f\u65b9\u6848\u3002", "method": "\u4f7f\u7528Llama-3.1-8B-bnb-4bit\u548cLlama-3.1-8B-Instruct-bnb-4bit\u4e24\u4e2a\u7248\u672c\u6a21\u578b\uff0c\u91c7\u7528\u53c2\u6570\u9ad8\u6548\u5fae\u8c03(PEFT)\u7ed3\u5408LoRA\u9002\u914d\u5668\u548c4\u4f4d\u91cf\u5316\u6280\u672f\uff0c\u5229\u7528Unsloth\u6846\u67b6\u8fdb\u884c\u52a0\u901f\u8bad\u7ec3\u3002\u6784\u5efa\u4e86\u5305\u542b6000\u4e2a\u6cd5\u5f8b\u95ee\u7b54\u5bf9\u7684\u5b9a\u5236\u6570\u636e\u96c6\uff0c\u5e76\u683c\u5f0f\u5316\u4e3a\u7ed3\u6784\u5316\u63d0\u793a\u3002", "result": "\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5728\u6cd5\u5f8b\u63a8\u7406\u548c\u51c6\u786e\u6027\u65b9\u9762\u5747\u6709\u63d0\u5347\uff0c\u540c\u65f6\u901a\u8fc7\u91cf\u5316\u548c\u4f18\u5316\u5fae\u8c03\u7b56\u7565\u5b9e\u73b0\u4e86\u8d44\u6e90\u6548\u7387\u3002\u4f7f\u7528BLEU\u548cROUGE\u6307\u6807\u8bc4\u4f30\u663e\u793a\uff0c\u5fae\u8c03\u6a21\u578b\u76f8\u6bd4\u57fa\u7840\u7248\u672c\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u9002\u5e94\u5230\u963f\u62c9\u4f2f\u8bed\u6cd5\u5f8b\u9886\u57df\u7684\u53ef\u884c\u6027\uff0c\u5c55\u793a\u4e86\u91cf\u5316\u6280\u672f\u548c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u5728\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u963f\u62c9\u4f2f\u8bed\u6cd5\u5f8bAI\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2601.18579", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18579", "abs": "https://arxiv.org/abs/2601.18579", "authors": ["Seonho An", "Chaejeong Hyun", "Min-Soo Kim"], "title": "FastInsight: Fast and Insightful Retrieval via Fusion Operators for Graph RAG", "comment": "under review", "summary": "Existing Graph RAG methods aiming for insightful retrieval on corpus graphs typically rely on time-intensive processes that interleave Large Language Model (LLM) reasoning. To enable time-efficient insightful retrieval, we propose FastInsight. We first introduce a graph retrieval taxonomy that categorizes existing methods into three fundamental operations: vector search, graph search, and model-based search. Through this taxonomy, we identify two critical limitations in current approaches: the topology-blindness of model-based search and the semantics-blindness of graph search. FastInsight overcomes these limitations by interleaving two novel fusion operators: the Graph-based Reranker (GRanker), which functions as a graph model-based search, and Semantic-Topological eXpansion (STeX), which operates as a vector-graph search. Extensive experiments on broad retrieval and generation datasets demonstrate that FastInsight significantly improves both retrieval accuracy and generation quality compared to state-of-the-art baselines, achieving a substantial Pareto improvement in the trade-off between effectiveness and efficiency.", "AI": {"tldr": "FastInsight\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u56feRAG\u65b9\u6cd5\uff0c\u901a\u8fc7\u878d\u5408\u56fe\u6a21\u578b\u641c\u7d22\u548c\u5411\u91cf-\u56fe\u641c\u7d22\u6765\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u7684\u62d3\u6251\u76f2\u70b9\u548c\u8bed\u4e49\u76f2\u70b9\uff0c\u5728\u4fdd\u6301\u9ad8\u6548\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u68c0\u7d22\u548c\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u56feRAG\u65b9\u6cd5\u4f9d\u8d56\u8017\u65f6\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\uff0c\u65e0\u6cd5\u5b9e\u73b0\u65f6\u95f4\u9ad8\u6548\u7684\u6df1\u5165\u68c0\u7d22\u3002\u901a\u8fc7\u56fe\u68c0\u7d22\u5206\u7c7b\u5b66\u5206\u6790\uff0c\u53d1\u73b0\u5f53\u524d\u65b9\u6cd5\u5b58\u5728\u6a21\u578b\u641c\u7d22\u7684\u62d3\u6251\u76f2\u70b9\u548c\u56fe\u641c\u7d22\u7684\u8bed\u4e49\u76f2\u70b9\u4e24\u5927\u5173\u952e\u9650\u5236\u3002", "method": "\u63d0\u51faFastInsight\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u65b0\u578b\u878d\u5408\u7b97\u5b50\uff1a1) Graph-based Reranker (GRanker)\u4f5c\u4e3a\u56fe\u6a21\u578b\u641c\u7d22\uff0c2) Semantic-Topological eXpansion (STeX)\u4f5c\u4e3a\u5411\u91cf-\u56fe\u641c\u7d22\u3002\u901a\u8fc7\u8fd9\u4e24\u4e2a\u7b97\u5b50\u7684\u4ea4\u66ff\u4f7f\u7528\u6765\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "result": "\u5728\u5e7f\u6cdb\u7684\u68c0\u7d22\u548c\u751f\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFastInsight\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u68c0\u7d22\u51c6\u786e\u7387\u548c\u751f\u6210\u8d28\u91cf\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u5728\u6548\u679c\u4e0e\u6548\u7387\u7684\u6743\u8861\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u5e15\u7d2f\u6258\u6539\u8fdb\u3002", "conclusion": "FastInsight\u901a\u8fc7\u521b\u65b0\u7684\u878d\u5408\u7b97\u5b50\u89e3\u51b3\u4e86\u56feRAG\u4e2d\u7684\u62d3\u6251\u76f2\u70b9\u548c\u8bed\u4e49\u76f2\u70b9\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u65f6\u95f4\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u6df1\u5165\u7684\u68c0\u7d22\u80fd\u529b\uff0c\u4e3a\u9ad8\u6548\u56fe\u68c0\u7d22\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17367", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17367", "abs": "https://arxiv.org/abs/2601.17367", "authors": ["Zecheng Tang", "Quantong Qiu", "Yi Yang", "Zhiyi Hong", "Haiya Xiang", "Kebin Liu", "Qingqing Dang", "Juntao Li", "Min Zhang"], "title": "Elastic Attention: Test-time Adaptive Sparsity Ratios for Efficient Transformers", "comment": null, "summary": "The quadratic complexity of standard attention mechanisms poses a significant scalability bottleneck for large language models (LLMs) in long-context scenarios. While hybrid attention strategies that combine sparse and full attention within a single model offer a viable solution, they typically employ static computation ratios (i.e., fixed proportions of sparse versus full attention) and fail to adapt to the varying sparsity sensitivities of downstream tasks during inference. To address this issue, we propose Elastic Attention, which allows the model to dynamically adjust its overall sparsity based on the input. This is achieved by integrating a lightweight Attention Router into the existing pretrained model, which dynamically assigns each attention head to different computation modes. Within only 12 hours of training on 8xA800 GPUs, our method enables models to achieve both strong performance and efficient inference. Experiments across three long-context benchmarks on widely-used LLMs demonstrate the superiority of our method.", "AI": {"tldr": "\u63d0\u51faElastic Attention\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7Attention Router\u52a8\u6001\u8c03\u6574\u6ce8\u610f\u529b\u7a00\u758f\u5ea6\uff0c\u89e3\u51b3\u6df7\u5408\u6ce8\u610f\u529b\u4e2d\u9759\u6001\u8ba1\u7b97\u6bd4\u4f8b\u65e0\u6cd5\u9002\u5e94\u4e0b\u6e38\u4efb\u52a1\u53d8\u5316\u7684\u95ee\u9898\u3002", "motivation": "\u6807\u51c6\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e8c\u6b21\u590d\u6742\u5ea6\u9650\u5236\u4e86LLM\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u7684\u53ef\u6269\u5c55\u6027\u3002\u73b0\u6709\u6df7\u5408\u6ce8\u610f\u529b\u7b56\u7565\u91c7\u7528\u9759\u6001\u7a00\u758f-\u5168\u6ce8\u610f\u529b\u6bd4\u4f8b\uff0c\u65e0\u6cd5\u9002\u5e94\u4e0b\u6e38\u4efb\u52a1\u5728\u63a8\u7406\u65f6\u7684\u7a00\u758f\u654f\u611f\u6027\u53d8\u5316\u3002", "method": "\u63d0\u51faElastic Attention\uff0c\u96c6\u6210\u8f7b\u91cf\u7ea7Attention Router\u5230\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\uff0c\u52a8\u6001\u5206\u914d\u6bcf\u4e2a\u6ce8\u610f\u529b\u5934\u5230\u4e0d\u540c\u8ba1\u7b97\u6a21\u5f0f\uff0c\u4f7f\u6a21\u578b\u80fd\u6839\u636e\u8f93\u5165\u8c03\u6574\u6574\u4f53\u7a00\u758f\u5ea6\u3002", "result": "\u57288xA800 GPU\u4e0a\u4ec5\u8bad\u7ec312\u5c0f\u65f6\uff0c\u6a21\u578b\u5728\u4e09\u4e2a\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u5f3a\u6027\u80fd\u548c\u9ad8\u6548\u63a8\u7406\u7684\u5e73\u8861\u3002", "conclusion": "Elastic Attention\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u6ce8\u610f\u529b\u7a00\u758f\u5ea6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6df7\u5408\u6ce8\u610f\u529b\u4e2d\u9759\u6001\u8ba1\u7b97\u6bd4\u4f8b\u7684\u5c40\u9650\u6027\uff0c\u4e3aLLM\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18664", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18664", "abs": "https://arxiv.org/abs/2601.18664", "authors": ["Zihao Guo", "Jian Wang", "Ruxin Zhou", "Youhua Liu", "Jiawei Guo", "Jun Zhao", "Xiaoxiao Xu", "Yongqi Liu", "Kaiqiao Zhan"], "title": "S$^2$GR: Stepwise Semantic-Guided Reasoning in Latent Space for Generative Recommendation", "comment": null, "summary": "Generative Recommendation (GR) has emerged as a transformative paradigm with its end-to-end generation advantages. However, existing GR methods primarily focus on direct Semantic ID (SID) generation from interaction sequences, failing to activate deeper reasoning capabilities analogous to those in large language models and thus limiting performance potential. We identify two critical limitations in current reasoning-enhanced GR approaches: (1) Strict sequential separation between reasoning and generation steps creates imbalanced computational focus across hierarchical SID codes, degrading quality for SID codes; (2) Generated reasoning vectors lack interpretable semantics, while reasoning paths suffer from unverifiable supervision. In this paper, we propose stepwise semantic-guided reasoning in latent space (S$^2$GR), a novel reasoning enhanced GR framework. First, we establish a robust semantic foundation via codebook optimization, integrating item co-occurrence relationship to capture behavioral patterns, and load balancing and uniformity objectives that maximize codebook utilization while reinforcing coarse-to-fine semantic hierarchies. Our core innovation introduces the stepwise reasoning mechanism inserting thinking tokens before each SID generation step, where each token explicitly represents coarse-grained semantics supervised via contrastive learning against ground-truth codebook cluster distributions ensuring physically grounded reasoning paths and balanced computational focus across all SID codes. Extensive experiments demonstrate the superiority of S$^2$GR, and online A/B test confirms efficacy on large-scale industrial short video platform.", "AI": {"tldr": "S\u00b2GR\uff1a\u4e00\u79cd\u901a\u8fc7\u6f5c\u5728\u7a7a\u95f4\u9010\u6b65\u8bed\u4e49\u5f15\u5bfc\u63a8\u7406\u589e\u5f3a\u751f\u6210\u5f0f\u63a8\u8350\u7684\u65b0\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u63a8\u7406\u4e0e\u751f\u6210\u5206\u79bb\u3001\u8ba1\u7b97\u4e0d\u5e73\u8861\u548c\u8bed\u4e49\u4e0d\u53ef\u89e3\u91ca\u7b49\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u63a8\u8350\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4ece\u4ea4\u4e92\u5e8f\u5217\u76f4\u63a5\u751f\u6210\u8bed\u4e49ID\uff0c\u672a\u80fd\u6fc0\u6d3b\u7c7b\u4f3c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6df1\u5c42\u63a8\u7406\u80fd\u529b\uff0c\u9650\u5236\u4e86\u6027\u80fd\u6f5c\u529b\u3002\u5f53\u524d\u63a8\u7406\u589e\u5f3a\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5c40\u9650\uff1a1) \u63a8\u7406\u4e0e\u751f\u6210\u6b65\u9aa4\u7684\u4e25\u683c\u987a\u5e8f\u5206\u79bb\u5bfc\u81f4\u5c42\u6b21\u5316\u8bed\u4e49ID\u4ee3\u7801\u95f4\u8ba1\u7b97\u7126\u70b9\u4e0d\u5e73\u8861\uff1b2) \u751f\u6210\u7684\u63a8\u7406\u5411\u91cf\u7f3a\u4e4f\u53ef\u89e3\u91ca\u8bed\u4e49\uff0c\u63a8\u7406\u8def\u5f84\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u76d1\u7763\u3002", "method": "\u63d0\u51faS\u00b2GR\u6846\u67b6\uff1a\u9996\u5148\u901a\u8fc7\u4ee3\u7801\u672c\u4f18\u5316\u5efa\u7acb\u7a33\u5065\u8bed\u4e49\u57fa\u7840\uff0c\u6574\u5408\u7269\u54c1\u5171\u73b0\u5173\u7cfb\u6355\u6349\u884c\u4e3a\u6a21\u5f0f\uff0c\u5e76\u91c7\u7528\u8d1f\u8f7d\u5747\u8861\u548c\u4e00\u81f4\u6027\u76ee\u6807\u6700\u5927\u5316\u4ee3\u7801\u672c\u5229\u7528\u7387\u540c\u65f6\u5f3a\u5316\u4ece\u7c97\u5230\u7ec6\u7684\u8bed\u4e49\u5c42\u6b21\u3002\u6838\u5fc3\u521b\u65b0\u662f\u9010\u6b65\u63a8\u7406\u673a\u5236\uff0c\u5728\u6bcf\u4e2a\u8bed\u4e49ID\u751f\u6210\u6b65\u9aa4\u524d\u63d2\u5165\u601d\u8003\u4ee4\u724c\uff0c\u6bcf\u4e2a\u4ee4\u724c\u660e\u786e\u8868\u793a\u7c97\u7c92\u5ea6\u8bed\u4e49\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u76d1\u7763\u786e\u4fdd\u7269\u7406\u57fa\u7840\u7684\u63a8\u7406\u8def\u5f84\u548c\u6240\u6709\u8bed\u4e49ID\u4ee3\u7801\u95f4\u7684\u5e73\u8861\u8ba1\u7b97\u7126\u70b9\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u4e86S\u00b2GR\u7684\u4f18\u8d8a\u6027\uff0c\u5728\u7ebfA/B\u6d4b\u8bd5\u786e\u8ba4\u4e86\u5176\u5728\u5927\u89c4\u6a21\u5de5\u4e1a\u77ed\u89c6\u9891\u5e73\u53f0\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "S\u00b2GR\u901a\u8fc7\u6f5c\u5728\u7a7a\u95f4\u9010\u6b65\u8bed\u4e49\u5f15\u5bfc\u63a8\u7406\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u751f\u6210\u5f0f\u63a8\u8350\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u5e73\u8861\u7684\u8ba1\u7b97\u5206\u914d\u548c\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8def\u5f84\uff0c\u5728\u5de5\u4e1a\u89c4\u6a21\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2601.17377", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17377", "abs": "https://arxiv.org/abs/2601.17377", "authors": ["Kiyotada Mori", "Shohei Tanaka", "Tosho Hirasawa", "Tadashi Kozuno", "Koichiro Yoshino", "Yoshitaka Ushiku"], "title": "WarrantScore: Modeling Warrants between Claims and Evidence for Substantiation Evaluation in Peer Reviews", "comment": null, "summary": "The scientific peer-review process is facing a shortage of human resources due to the rapid growth in the number of submitted papers. The use of language models to reduce the human cost of peer review has been actively explored as a potential solution to this challenge. A method has been proposed to evaluate the level of substantiation in scientific reviews in a manner that is interpretable by humans. This method extracts the core components of an argument, claims and evidence, and assesses the level of substantiation based on the proportion of claims supported by evidence. The level of substantiation refers to the extent to which claims are based on objective facts. However, when assessing the level of substantiation, simply detecting the presence or absence of supporting evidence for a claim is insufficient; it is also necessary to accurately assess the logical inference between a claim and its evidence. We propose a new evaluation metric for scientific review comments that assesses the logical inference between claims and evidence. Experimental results show that the proposed method achieves a higher correlation with human scores than conventional methods, indicating its potential to better support the efficiency of the peer-review process.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8bc4\u4f30\u79d1\u5b66\u8bc4\u5ba1\u610f\u89c1\u4e2d\u4e3b\u5f20\u4e0e\u8bc1\u636e\u95f4\u903b\u8f91\u63a8\u7406\u7684\u65b0\u65b9\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u80fd\u66f4\u597d\u5730\u4e0e\u4eba\u5de5\u8bc4\u5206\u76f8\u5173\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u540c\u884c\u8bc4\u5ba1\u6548\u7387", "motivation": "\u79d1\u5b66\u540c\u884c\u8bc4\u5ba1\u9762\u4e34\u4eba\u529b\u77ed\u7f3a\u95ee\u9898\uff0c\u8bed\u8a00\u6a21\u578b\u88ab\u63a2\u7d22\u7528\u4e8e\u964d\u4f4e\u8bc4\u5ba1\u6210\u672c\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u68c0\u6d4b\u4e3b\u5f20\u662f\u5426\u88ab\u8bc1\u636e\u652f\u6301\u6765\u8bc4\u4f30\u8bba\u8bc1\u7684\u624e\u5b9e\u7a0b\u5ea6\uff0c\u4f46\u4ec5\u68c0\u6d4b\u8bc1\u636e\u5b58\u5728\u4e0e\u5426\u4e0d\u8db3\u4ee5\u8bc4\u4f30\u4e3b\u5f20\u4e0e\u8bc1\u636e\u95f4\u7684\u903b\u8f91\u63a8\u7406\u5173\u7cfb", "method": "\u63d0\u51fa\u65b0\u7684\u79d1\u5b66\u8bc4\u5ba1\u610f\u89c1\u8bc4\u4f30\u6307\u6807\uff0c\u4e13\u6ce8\u4e8e\u8bc4\u4f30\u4e3b\u5f20\u4e0e\u8bc1\u636e\u4e4b\u95f4\u7684\u903b\u8f91\u63a8\u7406\u5173\u7cfb\u3002\u8be5\u65b9\u6cd5\u63d0\u53d6\u8bba\u8bc1\u7684\u6838\u5fc3\u7ec4\u4ef6\uff08\u4e3b\u5f20\u548c\u8bc1\u636e\uff09\uff0c\u5e76\u8bc4\u4f30\u903b\u8f91\u63a8\u7406\u7684\u8d28\u91cf\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u68c0\u6d4b\u8bc1\u636e\u7684\u5b58\u5728", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u6bd4\u4f20\u7edf\u65b9\u6cd5\u83b7\u5f97\u66f4\u9ad8\u7684\u4eba\u5de5\u8bc4\u5206\u76f8\u5173\u6027\uff0c\u8868\u660e\u5176\u80fd\u66f4\u597d\u5730\u8bc4\u4f30\u8bc4\u5ba1\u610f\u89c1\u7684\u8bba\u8bc1\u8d28\u91cf", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u4e3b\u5f20\u4e0e\u8bc1\u636e\u95f4\u7684\u903b\u8f91\u63a8\u7406\u5173\u7cfb\uff0c\u6709\u6f5c\u529b\u63d0\u9ad8\u540c\u884c\u8bc4\u5ba1\u8fc7\u7a0b\u7684\u6548\u7387\uff0c\u4e3a\u89e3\u51b3\u8bc4\u5ba1\u4eba\u529b\u77ed\u7f3a\u95ee\u9898\u63d0\u4f9b\u66f4\u597d\u7684\u652f\u6301"}}
{"id": "2601.17789", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17789", "abs": "https://arxiv.org/abs/2601.17789", "authors": ["Yiming Su", "Kunzhao Xu", "Yanjie Gao", "Fan Yang", "Cheng Li", "Mao Yang", "Tianyin Xu"], "title": "Neuro-Symbolic Verification on Instruction Following of LLMs", "comment": null, "summary": "A fundamental problem of applying Large Language Models (LLMs) to important applications is that LLMs do not always follow instructions, and violations are often hard to observe or check. In LLM-based agentic workflows, such violations can propagate and amplify along reasoning chains, causing task failures and system incidents. This paper presents NSVIF, a neuro-symbolic framework for verifying whether an LLM's output follows the instructions used to prompt the LLM. NSVIF is a universal, general-purpose verifier; it makes no assumption about the instruction or the LLM. NSVIF formulates instruction-following verification as a constraint-satisfaction problem by modeling user instructions as constraints. NSVIF models both logical and semantic constraints; constraint solving is done by a unified solver that orchestrates logical reasoning and semantic analysis. To evaluate NSVIF, we develop VIFBENCH, a new benchmark for instruction-following verifiers with fine-grained data labels. Experiments show that NSVIF significantly outperforms LLM-based approaches and provides interpretable feedback. We also show that feedback from NSVIF helps improve LLMs' instruction-following capability without post-training.", "AI": {"tldr": "NSVIF\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u7528\u4e8e\u9a8c\u8bc1LLM\u8f93\u51fa\u662f\u5426\u9075\u5faa\u6307\u4ee4\uff0c\u5c06\u6307\u4ee4\u9075\u5faa\u9a8c\u8bc1\u5efa\u6a21\u4e3a\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u53cd\u9988", "motivation": "LLM\u4e0d\u603b\u662f\u9075\u5faa\u6307\u4ee4\uff0c\u4e14\u8fdd\u89c4\u884c\u4e3a\u96be\u4ee5\u89c2\u5bdf\u6216\u68c0\u67e5\uff0c\u5728\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u4e2d\uff0c\u8fd9\u4e9b\u8fdd\u89c4\u4f1a\u6cbf\u63a8\u7406\u94fe\u4f20\u64ad\u653e\u5927\uff0c\u5bfc\u81f4\u4efb\u52a1\u5931\u8d25\u548c\u7cfb\u7edf\u4e8b\u6545", "method": "NSVIF\u5c06\u6307\u4ee4\u9075\u5faa\u9a8c\u8bc1\u5efa\u6a21\u4e3a\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\uff0c\u5c06\u7528\u6237\u6307\u4ee4\u5efa\u6a21\u4e3a\u7ea6\u675f\uff0c\u540c\u65f6\u5efa\u6a21\u903b\u8f91\u548c\u8bed\u4e49\u7ea6\u675f\uff0c\u901a\u8fc7\u7edf\u4e00\u6c42\u89e3\u5668\u534f\u8c03\u903b\u8f91\u63a8\u7406\u548c\u8bed\u4e49\u5206\u6790", "result": "NSVIF\u663e\u8457\u4f18\u4e8e\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u53cd\u9988\uff0c\u4e14NSVIF\u7684\u53cd\u9988\u6709\u52a9\u4e8e\u5728\u4e0d\u8fdb\u884c\u540e\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8LLM\u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b", "conclusion": "NSVIF\u662f\u4e00\u4e2a\u901a\u7528\u3001\u901a\u7528\u7684\u9a8c\u8bc1\u5668\uff0c\u5bf9\u6307\u4ee4\u6216LLM\u4e0d\u505a\u5047\u8bbe\uff0c\u4e3a\u89e3\u51b3LLM\u6307\u4ee4\u9075\u5faa\u9a8c\u8bc1\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u795e\u7ecf\u7b26\u53f7\u6846\u67b6"}}
{"id": "2601.18747", "categories": ["cs.IR", "cs.AI", "cs.CC", "cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2601.18747", "abs": "https://arxiv.org/abs/2601.18747", "authors": ["Amir Aavani"], "title": "Capturing P: On the Expressive Power and Efficient Evaluation of Boolean Retrieval", "comment": null, "summary": "Modern information retrieval is transitioning from simple document filtering to complex, neuro-symbolic reasoning workflows. However, current retrieval architectures face a fundamental efficiency dilemma when handling the rigorous logical and arithmetic constraints required by this new paradigm. Standard iterator-based engines (Document-at-a-Time) do not natively support complex, nested logic graphs; forcing them to execute such queries typically results in intractable runtime performance. Conversely, naive recursive approaches (Term-at-a-Time), while capable of supporting these structures, suffer from prohibitive memory consumption when enforcing broad logical exclusions.\n  In this paper, we propose that a retrieval engine must be capable of ``Capturing $\\mathbf{P}$'' -- evaluating any polynomial-time property directly over its index in a computationally efficient manner. We define a formal Retrieval Language ($\\mathcal{L}_R$) based on Directed Acyclic Graphs (DAGs) and prove it precisely captures the complexity class $\\mathbf{P}$. We introduce \\texttt{ComputePN}, a novel evaluation algorithm that makes $\\mathcal{L}_R$ tractable. By combining native DAG traversal with a memory-efficient ``Positive-Negative'' response mechanism, \\texttt{ComputePN} ensures the efficient evaluation of any query in $\\mathcal{L}_R$. This work establishes the theoretical foundation for turning the search index into a general-purpose computational engine.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u7684\u68c0\u7d22\u8bed\u8a00$\\mathcal{L}_R$\uff0c\u8bc1\u660e\u5176\u7cbe\u786e\u6355\u83b7\u590d\u6742\u5ea6\u7c7b$\\mathbf{P}$\uff0c\u5e76\u8bbe\u8ba1ComputePN\u7b97\u6cd5\u5b9e\u73b0\u9ad8\u6548\u67e5\u8be2\u8bc4\u4f30\uff0c\u5c06\u641c\u7d22\u7d22\u5f15\u8f6c\u53d8\u4e3a\u901a\u7528\u8ba1\u7b97\u5f15\u64ce\u3002", "motivation": "\u73b0\u4ee3\u4fe1\u606f\u68c0\u7d22\u6b63\u4ece\u7b80\u5355\u6587\u6863\u8fc7\u6ee4\u8f6c\u5411\u590d\u6742\u7684\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u5de5\u4f5c\u6d41\uff0c\u4f46\u73b0\u6709\u68c0\u7d22\u67b6\u6784\u5728\u5904\u7406\u903b\u8f91\u548c\u7b97\u672f\u7ea6\u675f\u65f6\u9762\u4e34\u6548\u7387\u56f0\u5883\uff1a\u57fa\u4e8e\u8fed\u4ee3\u5668\u7684\u5f15\u64ce\u65e0\u6cd5\u9ad8\u6548\u5904\u7406\u590d\u6742\u5d4c\u5957\u903b\u8f91\u56fe\uff0c\u800c\u9012\u5f52\u65b9\u6cd5\u5728\u5f3a\u5236\u6267\u884c\u5e7f\u6cdb\u903b\u8f91\u6392\u9664\u65f6\u5185\u5b58\u6d88\u8017\u8fc7\u9ad8\u3002", "method": "1. \u5b9a\u4e49\u57fa\u4e8e\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u7684\u5f62\u5f0f\u5316\u68c0\u7d22\u8bed\u8a00$\\mathcal{L}_R$\uff1b2. \u8bc1\u660e$\\mathcal{L}_R$\u7cbe\u786e\u6355\u83b7\u590d\u6742\u5ea6\u7c7b$\\mathbf{P}$\uff1b3. \u63d0\u51faComputePN\u8bc4\u4f30\u7b97\u6cd5\uff0c\u7ed3\u5408\u539f\u751fDAG\u904d\u5386\u548c\u5185\u5b58\u9ad8\u6548\u7684\"\u6b63-\u8d1f\"\u54cd\u5e94\u673a\u5236\uff0c\u786e\u4fdd$\\mathcal{L}_R$\u4e2d\u4efb\u4f55\u67e5\u8be2\u7684\u9ad8\u6548\u8bc4\u4f30\u3002", "result": "\u5efa\u7acb\u4e86\u5c06\u641c\u7d22\u7d22\u5f15\u8f6c\u53d8\u4e3a\u901a\u7528\u8ba1\u7b97\u5f15\u64ce\u7684\u7406\u8bba\u57fa\u7840\uff0c\u901a\u8fc7$\\mathcal{L}_R$\u8bed\u8a00\u548cComputePN\u7b97\u6cd5\u89e3\u51b3\u4e86\u590d\u6742\u903b\u8f91\u7ea6\u675f\u67e5\u8be2\u7684\u6548\u7387\u56f0\u5883\uff0c\u5b9e\u73b0\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u7684\u9ad8\u6548\u67e5\u8be2\u8bc4\u4f30\u3002", "conclusion": "\u68c0\u7d22\u5f15\u64ce\u5fc5\u987b\u80fd\u591f\"\u6355\u83b7$\\mathbf{P}$\"\u2014\u2014\u5728\u7d22\u5f15\u4e0a\u4ee5\u8ba1\u7b97\u9ad8\u6548\u7684\u65b9\u5f0f\u76f4\u63a5\u8bc4\u4f30\u4efb\u4f55\u591a\u9879\u5f0f\u65f6\u95f4\u5c5e\u6027\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5c06\u641c\u7d22\u7d22\u5f15\u8f6c\u53d8\u4e3a\u901a\u7528\u8ba1\u7b97\u5f15\u64ce\u5960\u5b9a\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u89e3\u51b3\u4e86\u73b0\u4ee3\u4fe1\u606f\u68c0\u7d22\u4e2d\u590d\u6742\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u5de5\u4f5c\u6d41\u7684\u6548\u7387\u74f6\u9888\u3002"}}
{"id": "2601.17387", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17387", "abs": "https://arxiv.org/abs/2601.17387", "authors": ["Toshiki Nakai", "Varsha Suresh", "Vera Demberg"], "title": "Revisiting Modality Invariance in a Multilingual Speech-Text Model via Neuron-Level Analysis", "comment": "8 pages for the main text, 51 figures, 1 table", "summary": "Multilingual speech-text foundation models aim to process language uniformly across both modality and language, yet it remains unclear whether they internally represent the same language consistently when it is spoken versus written. We investigate this question in SeamlessM4T v2 through three complementary analyses that probe where language and modality information is encoded, how selective neurons causally influence decoding, and how concentrated this influence is across the network. We identify language- and modality-selective neurons using average-precision ranking, investigate their functional role via median-replacement interventions at inference time, and analyze activation-magnitude inequality across languages and modalities. Across experiments, we find evidence of incomplete modality invariance. Although encoder representations become increasingly language-agnostic, this compression makes it more difficult for the shared decoder to recover the language of origin when constructing modality-agnostic representations, particularly when adapting from speech to text. We further observe sharply localized modality-selective structure in cross-attention key and value projections. Finally, speech-conditioned decoding and non-dominant scripts exhibit higher activation concentration, indicating heavier reliance on a small subset of neurons, which may underlie increased brittleness across modalities and languages.", "AI": {"tldr": "SeamlessM4T v2\u591a\u8bed\u8a00\u8bed\u97f3-\u6587\u672c\u57fa\u7840\u6a21\u578b\u5728\u8bed\u97f3\u548c\u6587\u672c\u6a21\u6001\u4e0b\u5bf9\u540c\u4e00\u8bed\u8a00\u7684\u5185\u90e8\u8868\u793a\u4e0d\u4e00\u81f4\uff0c\u5b58\u5728\u4e0d\u5b8c\u5168\u7684\u6a21\u6001\u4e0d\u53d8\u6027\uff0c\u89e3\u7801\u5668\u96be\u4ee5\u4ece\u538b\u7f29\u7684\u7f16\u7801\u5668\u8868\u793a\u4e2d\u6062\u590d\u6e90\u8bed\u8a00\u4fe1\u606f\u3002", "motivation": "\u7814\u7a76\u591a\u8bed\u8a00\u8bed\u97f3-\u6587\u672c\u57fa\u7840\u6a21\u578b\u662f\u5426\u5728\u5185\u90e8\u4e00\u81f4\u5730\u8868\u793a\u540c\u4e00\u8bed\u8a00\u7684\u8bed\u97f3\u548c\u6587\u672c\u5f62\u5f0f\uff0c\u63a2\u7a76\u6a21\u6001\u4e0d\u53d8\u6027\u7684\u7a0b\u5ea6\u53ca\u5176\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u4e09\u79cd\u4e92\u8865\u5206\u6790\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u5e73\u5747\u7cbe\u5ea6\u6392\u540d\u8bc6\u522b\u8bed\u8a00\u548c\u6a21\u6001\u9009\u62e9\u6027\u795e\u7ecf\u5143\uff1b2) \u901a\u8fc7\u63a8\u7406\u65f6\u7684\u4e2d\u4f4d\u6570\u66ff\u6362\u5e72\u9884\u7814\u7a76\u5176\u529f\u80fd\u4f5c\u7528\uff1b3) \u5206\u6790\u8de8\u8bed\u8a00\u548c\u6a21\u6001\u7684\u6fc0\u6d3b\u5e45\u5ea6\u4e0d\u5e73\u7b49\u6027\u3002", "result": "\u53d1\u73b0\u4e0d\u5b8c\u5168\u7684\u6a21\u6001\u4e0d\u53d8\u6027\uff1a\u7f16\u7801\u5668\u8868\u793a\u53d8\u5f97\u8bed\u8a00\u65e0\u5173\uff0c\u4f46\u5171\u4eab\u89e3\u7801\u5668\u96be\u4ee5\u4ece\u6a21\u6001\u65e0\u5173\u8868\u793a\u4e2d\u6062\u590d\u6e90\u8bed\u8a00\uff0c\u7279\u522b\u662f\u4ece\u8bed\u97f3\u9002\u5e94\u5230\u6587\u672c\u65f6\u3002\u8de8\u6ce8\u610f\u529b\u952e\u503c\u6295\u5f71\u4e2d\u5b58\u5728\u5c40\u90e8\u5316\u7684\u6a21\u6001\u9009\u62e9\u6027\u7ed3\u6784\u3002\u8bed\u97f3\u6761\u4ef6\u89e3\u7801\u548c\u975e\u4e3b\u5bfc\u811a\u672c\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u6fc0\u6d3b\u96c6\u4e2d\u5ea6\u3002", "conclusion": "\u591a\u8bed\u8a00\u8bed\u97f3-\u6587\u672c\u6a21\u578b\u5728\u8bed\u97f3\u548c\u6587\u672c\u6a21\u6001\u4e0b\u5bf9\u540c\u4e00\u8bed\u8a00\u7684\u8868\u793a\u4e0d\u4e00\u81f4\uff0c\u8fd9\u79cd\u4e0d\u5b8c\u5168\u7684\u6a21\u6001\u4e0d\u53d8\u6027\u53ef\u80fd\u5bfc\u81f4\u8de8\u6a21\u6001\u548c\u8bed\u8a00\u7684\u8106\u5f31\u6027\uff0c\u7279\u522b\u662f\u8bed\u97f3\u5230\u6587\u672c\u8f6c\u6362\u548c\u975e\u4e3b\u5bfc\u811a\u672c\u5904\u7406\u65f6\u3002"}}
{"id": "2601.17814", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17814", "abs": "https://arxiv.org/abs/2601.17814", "authors": ["Haoxuan Ma", "Guannan Lai", "Han-Jia Ye"], "title": "MMR-Bench: A Comprehensive Benchmark for Multimodal LLM Routing", "comment": null, "summary": "Multimodal large language models (MLLMs) have advanced rapidly, yet heterogeneity in architecture, alignment strategies, and efficiency means that no single model is uniformly superior across tasks. In practical deployments, workloads span lightweight OCR to complex multimodal reasoning; using one MLLM for all queries either over-provisions compute on easy instances or sacrifices accuracy on hard ones. Query-level model selection (routing) addresses this tension, but extending routing from text-only LLMs to MLLMs is nontrivial due to modality fusion, wide variation in computational cost across models, and the absence of a standardized, budget-aware evaluation. We present MMR-Bench, a unified benchmark that isolates the multimodal routing problem and enables comparison under fixed candidate sets and cost models. MMR-Bench provides (i) a controlled environment with modality-aware inputs and variable compute budgets, (ii) a broad suite of vision-language tasks covering OCR, general VQA, and multimodal math reasoning, and (iii) strong single-model reference, oracle upper bounds, and representative routing policies. Using MMR-Bench, we show that incorporating multimodal signals improves routing quality. Empirically, these cues improve the cost-accuracy frontier and enable the routed system to exceed the strongest single model's accuracy at roughly 33% of its cost. Furthermore, policies trained on a subset of models and tasks generalize zero-shot to new datasets and text-only benchmarks without retuning, establishing MMR-Bench as a foundation for studying adaptive multimodal model selection and efficient MLLM deployment. The code will be available at: https://github.com/Hunter-Wrynn/MMR-Bench.", "code_url": "https://github.com/Hunter-Wrynn/MMR-Bench", "code_stars": 2, "code_last_update": "2026-01-25", "AI": {"tldr": "MMR-Bench\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8def\u7531\u7b56\u7565\u7684\u7edf\u4e00\u57fa\u51c6\uff0c\u901a\u8fc7\u63a7\u5236\u5019\u9009\u6a21\u578b\u96c6\u548c\u8ba1\u7b97\u6210\u672c\u6a21\u578b\uff0c\u5e2e\u52a9\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u9009\u62e9\u6700\u4f18\u6a21\u578b\uff0c\u63d0\u5347\u591a\u6a21\u6001\u4efb\u52a1\u90e8\u7f72\u6548\u7387\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u67b6\u6784\u3001\u5bf9\u9f50\u7b56\u7565\u548c\u6548\u7387\u65b9\u9762\u5b58\u5728\u5f02\u8d28\u6027\uff0c\u5355\u4e00\u6a21\u578b\u65e0\u6cd5\u5728\u6240\u6709\u4efb\u52a1\u4e0a\u8868\u73b0\u6700\u4f18\u3002\u5b9e\u9645\u90e8\u7f72\u4e2d\uff0c\u5de5\u4f5c\u8d1f\u8f7d\u4ece\u8f7b\u91cf\u7ea7OCR\u5230\u590d\u6742\u591a\u6a21\u6001\u63a8\u7406\u4e0d\u7b49\uff0c\u4f7f\u7528\u5355\u4e00\u6a21\u578b\u8981\u4e48\u5728\u7b80\u5355\u5b9e\u4f8b\u4e0a\u8fc7\u5ea6\u914d\u7f6e\u8ba1\u7b97\u8d44\u6e90\uff0c\u8981\u4e48\u5728\u56f0\u96be\u5b9e\u4f8b\u4e0a\u727a\u7272\u51c6\u786e\u6027\u3002\u9700\u8981\u4e00\u79cd\u67e5\u8be2\u7ea7\u522b\u7684\u6a21\u578b\u9009\u62e9\uff08\u8def\u7531\uff09\u673a\u5236\u6765\u89e3\u51b3\u8fd9\u4e00\u77db\u76fe\u3002", "method": "\u63d0\u51fa\u4e86MMR-Bench\u57fa\u51c6\uff0c\u5305\u542b\uff1a(1) \u5177\u6709\u6a21\u6001\u611f\u77e5\u8f93\u5165\u548c\u53ef\u53d8\u8ba1\u7b97\u9884\u7b97\u7684\u63a7\u5236\u73af\u5883\uff1b(2) \u6db5\u76d6OCR\u3001\u901a\u7528\u89c6\u89c9\u95ee\u7b54\u548c\u591a\u6a21\u6001\u6570\u5b66\u63a8\u7406\u7684\u5e7f\u6cdb\u89c6\u89c9\u8bed\u8a00\u4efb\u52a1\u5957\u4ef6\uff1b(3) \u5f3a\u5927\u7684\u5355\u6a21\u578b\u53c2\u8003\u3001\u7406\u8bba\u4e0a\u9650\u548c\u4ee3\u8868\u6027\u8def\u7531\u7b56\u7565\u3002\u901a\u8fc7\u8be5\u57fa\u51c6\u8bc4\u4f30\u591a\u6a21\u6001\u4fe1\u53f7\u5bf9\u8def\u7531\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u878d\u5165\u591a\u6a21\u6001\u4fe1\u53f7\u80fd\u663e\u8457\u63d0\u5347\u8def\u7531\u8d28\u91cf\uff0c\u6539\u5584\u6210\u672c-\u51c6\u786e\u6027\u8fb9\u754c\u3002\u8def\u7531\u7cfb\u7edf\u80fd\u4ee5\u6700\u5f3a\u5355\u6a21\u578b\u7ea633%\u7684\u6210\u672c\u8d85\u8d8a\u5176\u51c6\u786e\u6027\u3002\u6b64\u5916\uff0c\u5728\u90e8\u5206\u6a21\u578b\u548c\u4efb\u52a1\u4e0a\u8bad\u7ec3\u7684\u7b56\u7565\u80fd\u591f\u96f6\u6837\u672c\u6cdb\u5316\u5230\u65b0\u6570\u636e\u96c6\u548c\u7eaf\u6587\u672c\u57fa\u51c6\uff0c\u65e0\u9700\u91cd\u65b0\u8c03\u6574\u3002", "conclusion": "MMR-Bench\u4e3a\u7814\u7a76\u81ea\u9002\u5e94\u591a\u6a21\u6001\u6a21\u578b\u9009\u62e9\u548c\u9ad8\u6548MLLM\u90e8\u7f72\u63d0\u4f9b\u4e86\u57fa\u7840\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u591a\u6a21\u6001\u8def\u7531\u5728\u5e73\u8861\u8ba1\u7b97\u6210\u672c\u4e0e\u4efb\u52a1\u6027\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u8d44\u6e90\u4f18\u5316\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17569", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.17569", "abs": "https://arxiv.org/abs/2601.17569", "authors": ["Alireza Salemi", "Hamed Zamani"], "title": "Improving User Privacy in Personalized Generation: Client-Side Retrieval-Augmented Modification of Server-Side Generated Speculations", "comment": null, "summary": "Personalization is crucial for aligning Large Language Model (LLM) outputs with individual user preferences and background knowledge. State-of-the-art solutions are based on retrieval augmentation, where relevant context from a user profile is retrieved for LLM consumption. These methods deal with a trade-off between exposing retrieved private data to cloud providers and relying on less capable local models. We introduce $P^3$, an interactive framework for high-quality personalization without revealing private profiles to server-side LLMs. In $P^3$, a large server-side model generates a sequence of $k$ draft tokens based solely on the user query, while a small client-side model, with retrieval access to the user's private profile, evaluates and modifies these drafts to better reflect user preferences. This process repeats until an end token is generated. Experiments on LaMP-QA, a recent benchmark consisting of three personalized question answering datasets, show that $P^3$ consistently outperforms both non-personalized server-side and personalized client-side baselines, achieving statistically significant improvements of $7.4%$ to $9%$ on average. Importantly, $P^3$ recovers $90.3%$ to $95.7%$ of the utility of a ``leaky'' upper-bound scenario in which the full profile is exposed to the large server-side model. Privacy analyses, including linkability and attribute inference attacks, indicate that $P^3$ preserves the privacy of a non-personalized server-side model, introducing only marginal additional leakage ($1.5%$--$3.5%$) compared to submitting a query without any personal context. Additionally, the framework is efficient for edge deployment, with the client-side model generating only $9.2%$ of the total tokens. These results demonstrate that $P^3$ provides a practical, effective solution for personalized generation with improved privacy.", "AI": {"tldr": "P\u00b3\u6846\u67b6\uff1a\u901a\u8fc7\u5ba2\u6237\u7aef\u6a21\u578b\u8bc4\u4f30\u548c\u4fee\u6539\u670d\u52a1\u5668\u751f\u6210\u7684\u8349\u7a3f\u4ee4\u724c\uff0c\u5b9e\u73b0\u4e2a\u6027\u5316LLM\u8f93\u51fa\uff0c\u4fdd\u62a4\u7528\u6237\u9690\u79c1\uff0c\u6027\u80fd\u63a5\u8fd1\u5b8c\u5168\u66b4\u9732\u7528\u6237\u914d\u7f6e\u7684\u57fa\u51c6", "motivation": "\u73b0\u6709\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u7684\u4e2a\u6027\u5316\u65b9\u6cd5\u9762\u4e34\u9690\u79c1\u4e0e\u6027\u80fd\u7684\u6743\u8861\uff1a\u8981\u4e48\u5c06\u7528\u6237\u79c1\u6709\u6570\u636e\u66b4\u9732\u7ed9\u4e91\u7aefLLM\uff0c\u8981\u4e48\u4f9d\u8d56\u80fd\u529b\u8f83\u5f31\u7684\u672c\u5730\u6a21\u578b\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u62a4\u9690\u79c1\u53c8\u80fd\u63d0\u4f9b\u9ad8\u8d28\u91cf\u4e2a\u6027\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faP\u00b3\u4ea4\u4e92\u6846\u67b6\uff1a1) \u670d\u52a1\u5668\u7aef\u5927\u6a21\u578b\u4ec5\u57fa\u4e8e\u7528\u6237\u67e5\u8be2\u751f\u6210k\u4e2a\u8349\u7a3f\u4ee4\u724c\uff1b2) \u5ba2\u6237\u7aef\u5c0f\u6a21\u578b\u8bbf\u95ee\u7528\u6237\u79c1\u6709\u914d\u7f6e\uff0c\u8bc4\u4f30\u5e76\u4fee\u6539\u8fd9\u4e9b\u8349\u7a3f\u4ee5\u66f4\u597d\u5730\u53cd\u6620\u7528\u6237\u504f\u597d\uff1b3) \u91cd\u590d\u6b64\u8fc7\u7a0b\u76f4\u5230\u751f\u6210\u7ed3\u675f\u4ee4\u724c\u3002", "result": "\u5728LaMP-QA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cP\u00b3\u663e\u8457\u4f18\u4e8e\u975e\u4e2a\u6027\u5316\u670d\u52a1\u5668\u7aef\u548c\u4e2a\u6027\u5316\u5ba2\u6237\u7aef\u57fa\u7ebf\uff0c\u5e73\u5747\u63d0\u53477.4%\u81f39%\u3002\u6062\u590d\u7387\u9ad8\u8fbe90.3%\u81f395.7%\uff08\u76f8\u6bd4\u5b8c\u5168\u66b4\u9732\u7528\u6237\u914d\u7f6e\u7684\u57fa\u51c6\uff09\u3002\u9690\u79c1\u5206\u6790\u663e\u793a\u4ec5\u589e\u52a01.5%-3.5%\u7684\u6cc4\u6f0f\u98ce\u9669\u3002\u5ba2\u6237\u7aef\u6a21\u578b\u4ec5\u751f\u6210\u603b\u4ee4\u724c\u76849.2%\u3002", "conclusion": "P\u00b3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u6709\u6548\u7684\u4e2a\u6027\u5316\u751f\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u63a5\u8fd1\u5b8c\u5168\u66b4\u9732\u914d\u7f6e\u7684\u6027\u80fd\uff0c\u9002\u5408\u8fb9\u7f18\u90e8\u7f72\u3002"}}
{"id": "2601.17397", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17397", "abs": "https://arxiv.org/abs/2601.17397", "authors": ["Yucheng Hu", "Wei Zhou", "Juesi Xiao"], "title": "CLM-Bench: Benchmarking and Analyzing Cross-lingual Misalignment of LLMs in Knowledge Editing", "comment": "EACL MME workshop paper", "summary": "Knowledge Editing (KE) has emerged as a promising paradigm for updating facts in Large Language Models (LLMs) without retraining. However, progress in Multilingual Knowledge Editing (MKE) is currently hindered by biased evaluation frameworks. We observe that existing MKE benchmarks are typically constructed by mechanically translating English-centric datasets into target languages (e.g., English-to-Chinese). This approach introduces translation artifacts and neglects culturally specific entities native to the target language, failing to reflect the true knowledge distribution of LLMs. To address this, we propose CLM-Bench, a culture-aware benchmark constructed using a native Chinese-first methodology. We curate 1,010 high-quality CounterFact pairs rooted in Chinese cultural contexts and align them with English counterparts. Using CLM-Bench, we conduct extensive experiments on representative LLMs (e.g., Llama-3, Qwen2) and reveal a significant Cross-lingual Misalignment: edits in one language function independently and fail to propagate to the other. We further provide a geometric explanation via layer-wise representation analysis, demonstrating that edit vectors for Chinese and English are nearly orthogonal -- residing in disjoint subspaces -- while mixed-lingual editing exhibits linear additivity of these vectors. Our findings challenge the effectiveness of current methods in cross-lingual transfer and underscore the importance of culturally native benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CLM-Bench\uff0c\u4e00\u4e2a\u6587\u5316\u611f\u77e5\u7684\u4e2d\u6587\u4f18\u5148\u591a\u8bed\u8a00\u77e5\u8bc6\u7f16\u8f91\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u65b9\u6cd5\u5728\u8de8\u8bed\u8a00\u77e5\u8bc6\u4f20\u64ad\u4e0a\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709MKE\u57fa\u51c6\u901a\u5e38\u901a\u8fc7\u673a\u68b0\u7ffb\u8bd1\u82f1\u6587\u6570\u636e\u96c6\u6784\u5efa\uff0c\u5b58\u5728\u7ffb\u8bd1\u4f2a\u5f71\u4e14\u5ffd\u7565\u76ee\u6807\u8bed\u8a00\u7684\u6587\u5316\u7279\u5b9a\u5b9e\u4f53\uff0c\u65e0\u6cd5\u53cd\u6620LLMs\u7684\u771f\u5b9e\u77e5\u8bc6\u5206\u5e03\uff0c\u963b\u788d\u4e86\u591a\u8bed\u8a00\u77e5\u8bc6\u7f16\u8f91\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51faCLM-Bench\u57fa\u51c6\uff0c\u91c7\u7528\u4e2d\u6587\u4f18\u5148\u65b9\u6cd5\u6784\u5efa\uff0c\u5305\u542b1,010\u4e2a\u57fa\u4e8e\u4e2d\u6587\u6587\u5316\u80cc\u666f\u7684\u9ad8\u8d28\u91cfCounterFact\u5bf9\uff0c\u5e76\u4e0e\u82f1\u6587\u5bf9\u5e94\u9879\u5bf9\u9f50\u3002\u901a\u8fc7\u8be5\u57fa\u51c6\u5bf9\u4ee3\u8868\u6027LLMs\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u901a\u8fc7\u5206\u5c42\u8868\u793a\u5206\u6790\u63d0\u4f9b\u51e0\u4f55\u89e3\u91ca\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u663e\u8457\u7684\u8de8\u8bed\u8a00\u9519\u4f4d\u73b0\u8c61\uff1a\u4e00\u79cd\u8bed\u8a00\u7684\u7f16\u8f91\u72ec\u7acb\u8fd0\u4f5c\u4e14\u65e0\u6cd5\u4f20\u64ad\u5230\u53e6\u4e00\u79cd\u8bed\u8a00\u3002\u51e0\u4f55\u5206\u6790\u663e\u793a\u4e2d\u6587\u548c\u82f1\u6587\u7684\u7f16\u8f91\u5411\u91cf\u51e0\u4e4e\u6b63\u4ea4\uff0c\u4f4d\u4e8e\u4e0d\u76f8\u4ea4\u7684\u5b50\u7a7a\u95f4\u4e2d\uff0c\u800c\u6df7\u5408\u8bed\u8a00\u7f16\u8f91\u5219\u8868\u73b0\u51fa\u8fd9\u4e9b\u5411\u91cf\u7684\u7ebf\u6027\u53ef\u52a0\u6027\u3002", "conclusion": "\u5f53\u524d\u65b9\u6cd5\u5728\u8de8\u8bed\u8a00\u8fc1\u79fb\u65b9\u9762\u6548\u679c\u6709\u9650\uff0c\u5f3a\u8c03\u6587\u5316\u539f\u751f\u57fa\u51c6\u7684\u91cd\u8981\u6027\u3002\u7814\u7a76\u7ed3\u679c\u6311\u6218\u4e86\u73b0\u6709\u591a\u8bed\u8a00\u77e5\u8bc6\u7f16\u8f91\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u65b9\u5411\u3002"}}
{"id": "2601.17826", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17826", "abs": "https://arxiv.org/abs/2601.17826", "authors": ["Siyuan Yang", "Xihan Bian", "Jiayin Tang"], "title": "RegGuard: AI-Powered Retrieval-Enhanced Assistant for Pharmaceutical Regulatory Compliance", "comment": null, "summary": "The increasing frequency and complexity of regulatory updates present a significant burden for multinational pharmaceutical companies. Compliance teams must interpret evolving rules across jurisdictions, formats, and agencies, often manually, at high cost and risk of error. We introduce RegGuard, an industrial-scale AI assistant designed to automate the interpretation of heterogeneous regulatory texts and align them with internal corporate policies. The system ingests heterogeneous document sources through a secure pipeline and enhances retrieval and generation quality with two novel components: HiSACC (Hierarchical Semantic Aggregation for Contextual Chunking) semantically segments long documents into coherent units while maintaining consistency across non-contiguous sections. ReLACE (Regulatory Listwise Adaptive Cross-Encoder for Reranking), a domain-adapted cross-encoder built on an open-source model, jointly models user queries and retrieved candidates to improve ranking relevance. Evaluations in enterprise settings demonstrate that RegGuard improves answer quality specifically in terms of relevance, groundedness, and contextual focus, while significantly mitigating hallucination risk. The system architecture is built for auditability and traceability, featuring provenance tracking, access control, and incremental indexing, making it highly responsive to evolving document sources and relevant for any domain with stringent compliance demands.", "AI": {"tldr": "RegGuard\uff1a\u9762\u5411\u8de8\u56fd\u836f\u4f01\u7684\u5de5\u4e1a\u7ea7AI\u52a9\u624b\uff0c\u901a\u8fc7HiSACC\u548cReLACE\u6280\u672f\u81ea\u52a8\u89e3\u6790\u5f02\u6784\u76d1\u7ba1\u6587\u672c\uff0c\u63d0\u5347\u5408\u89c4\u6548\u7387\u5e76\u964d\u4f4e\u98ce\u9669", "motivation": "\u76d1\u7ba1\u66f4\u65b0\u65e5\u76ca\u9891\u7e41\u590d\u6742\uff0c\u8de8\u56fd\u836f\u4f01\u5408\u89c4\u56e2\u961f\u9700\u624b\u52a8\u89e3\u8bfb\u591a\u53f8\u6cd5\u7ba1\u8f96\u533a\u3001\u591a\u683c\u5f0f\u3001\u591a\u673a\u6784\u7684\u76d1\u7ba1\u89c4\u5219\uff0c\u6210\u672c\u9ad8\u4e14\u6613\u51fa\u9519\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848", "method": "1. \u901a\u8fc7\u5b89\u5168\u7ba1\u9053\u6444\u5165\u5f02\u6784\u6587\u6863\u6e90\uff1b2. HiSACC\uff08\u5206\u5c42\u8bed\u4e49\u805a\u5408\u4e0a\u4e0b\u6587\u5206\u5757\uff09\u5c06\u957f\u6587\u6863\u8bed\u4e49\u5206\u5272\u4e3a\u8fde\u8d2f\u5355\u5143\uff1b3. ReLACE\uff08\u76d1\u7ba1\u5217\u8868\u81ea\u9002\u5e94\u4ea4\u53c9\u7f16\u7801\u5668\u91cd\u6392\u5e8f\uff09\u57fa\u4e8e\u5f00\u6e90\u6a21\u578b\u6784\u5efa\u9886\u57df\u9002\u5e94\u4ea4\u53c9\u7f16\u7801\u5668\uff0c\u8054\u5408\u5efa\u6a21\u7528\u6237\u67e5\u8be2\u4e0e\u68c0\u7d22\u5019\u9009\u9879\u4ee5\u63d0\u5347\u6392\u5e8f\u76f8\u5173\u6027", "result": "\u4f01\u4e1a\u73af\u5883\u8bc4\u4f30\u663e\u793a\uff0cRegGuard\u5728\u76f8\u5173\u6027\u3001\u4e8b\u5b9e\u4f9d\u636e\u6027\u548c\u4e0a\u4e0b\u6587\u805a\u7126\u65b9\u9762\u663e\u8457\u63d0\u5347\u7b54\u6848\u8d28\u91cf\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u5e7b\u89c9\u98ce\u9669\uff1b\u7cfb\u7edf\u67b6\u6784\u5177\u5907\u53ef\u5ba1\u8ba1\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\uff0c\u652f\u6301\u6eaf\u6e90\u8ddf\u8e2a\u3001\u8bbf\u95ee\u63a7\u5236\u548c\u589e\u91cf\u7d22\u5f15", "conclusion": "RegGuard\u4e3a\u5177\u6709\u4e25\u683c\u5408\u89c4\u9700\u6c42\u7684\u9886\u57df\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u9760\u7684\u76d1\u7ba1\u6587\u672c\u81ea\u52a8\u5316\u89e3\u8bfb\u89e3\u51b3\u65b9\u6848\uff0c\u5176\u67b6\u6784\u8bbe\u8ba1\u4f7f\u5176\u80fd\u591f\u5feb\u901f\u9002\u5e94\u4e0d\u65ad\u6f14\u53d8\u7684\u6587\u6863\u6e90"}}
{"id": "2601.17421", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17421", "abs": "https://arxiv.org/abs/2601.17421", "authors": ["Jaehui Hwang", "Dongyoon Han", "Sangdoo Yun", "Byeongho Heo"], "title": "Oops, Wait: Token-Level Signals as a Lens into LLM Reasoning", "comment": null, "summary": "The emergence of discourse-like tokens such as \"wait\" and \"therefore\" in large language models (LLMs) has offered a unique window into their reasoning processes. However, systematic analyses of how such signals vary across training strategies and model scales remain lacking. In this paper, we analyze token-level signals through token probabilities across various models. We find that specific tokens strongly correlate with reasoning correctness, varying with training strategies while remaining stable across model scales. A closer look at the \"wait\" token in relation to answer probability demonstrates that models fine-tuned on small-scale datasets acquire reasoning ability through such signals but exploit them only partially. This work provides a systematic lens to observe and understand the dynamics of LLM reasoning.", "AI": {"tldr": "\u5206\u6790\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\"wait\"\u3001\"therefore\"\u7b49\u8bdd\u8bed\u6807\u8bb0\u8bcd\u7684\u6982\u7387\u4fe1\u53f7\uff0c\u53d1\u73b0\u8fd9\u4e9b\u4fe1\u53f7\u4e0e\u63a8\u7406\u6b63\u786e\u6027\u76f8\u5173\uff0c\u53d7\u8bad\u7ec3\u7b56\u7565\u5f71\u54cd\u4f46\u8de8\u6a21\u578b\u89c4\u6a21\u7a33\u5b9a", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u51fa\u73b0\u4e86\"wait\"\u3001\"therefore\"\u7b49\u7c7b\u4f3c\u8bdd\u8bed\u7684\u6807\u8bb0\u8bcd\uff0c\u4e3a\u7406\u89e3\u5176\u63a8\u7406\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u72ec\u7279\u7a97\u53e3\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u8fd9\u7c7b\u4fe1\u53f7\u5982\u4f55\u968f\u8bad\u7ec3\u7b56\u7565\u548c\u6a21\u578b\u89c4\u6a21\u53d8\u5316\u7684\u7cfb\u7edf\u6027\u5206\u6790", "method": "\u901a\u8fc7\u5206\u6790\u5404\u79cd\u6a21\u578b\u7684\u6807\u8bb0\u8bcd\u6982\u7387\u6765\u7814\u7a76\u6807\u8bb0\u7ea7\u522b\u7684\u4fe1\u53f7\uff0c\u7279\u522b\u5173\u6ce8\"wait\"\u6807\u8bb0\u8bcd\u4e0e\u7b54\u6848\u6982\u7387\u7684\u5173\u7cfb", "result": "\u53d1\u73b0\u7279\u5b9a\u6807\u8bb0\u8bcd\u4e0e\u63a8\u7406\u6b63\u786e\u6027\u5f3a\u70c8\u76f8\u5173\uff0c\u8fd9\u4e9b\u76f8\u5173\u6027\u968f\u8bad\u7ec3\u7b56\u7565\u53d8\u5316\u4f46\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0b\u4fdd\u6301\u7a33\u5b9a\uff1b\u5728\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u7684\u6a21\u578b\u901a\u8fc7\u8fd9\u7c7b\u4fe1\u53f7\u83b7\u5f97\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u4ec5\u90e8\u5206\u5229\u7528\u8fd9\u4e9b\u4fe1\u53f7", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u89c2\u5bdf\u548c\u7406\u89e3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u52a8\u6001\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u89c6\u89d2"}}
{"id": "2601.17828", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17828", "abs": "https://arxiv.org/abs/2601.17828", "authors": ["Tanvi Verma", "Yang Zhou", "Rick Siow Mong Goh", "Yong Liu"], "title": "Aligning Medical Conversational AI through Online Reinforcement Learning with Information-Theoretic Rewards", "comment": null, "summary": "We present Information Gain Fine-Tuning (IGFT), a novel approach for training medical conversational AI to conduct effective patient interviews and generate comprehensive History of Present Illness (HPI) without requiring pre-collected human conversations. IGFT combines online Group Relative Policy Optimization (GRPO) with information-theoretic rewards, enabling models to learn from self-generated conversations with simulated patients. Unlike existing approaches that rely on expensive expert-annotated conversations or static datasets, our online RL framework allows models to discover effective questioning strategies through exploration. Our key innovation is an information gain reward function that tracks which clinical entities such as symptoms, temporal patterns, and medical history, are revealed during conversation. Each question's reward is computed based on its expected information gain combined with GPT-4o-mini quality assessments across dimensions including clinical relevance, patient engagement, and specificity. This hybrid approach ensures models learn to ask targeted, clinically appropriate questions that efficiently gather diagnostic information. We fine-tune two models using LoRA: Llama-3.1-8B-Instruct and DeepSeek-R1-Distill-Qwen-7B (a reasoning-optimized model). Training exclusively on Avey data containing concise HPIs, we evaluate generalization to MIMIC data with longer, more elaborate HPIs. DeepSeek-R1-Distill-Qwen-7B (IGFT) achieves F1 scores of 0.408 on Avey (10.9% improvement over base) and 0.289 on MIMIC (12.9% improvement), while Llama-3.1-8B-Instruct (IGFT) reaches 0.384 and 0.336 respectively. Both models outperform OpenAI's model on MIMIC and surpass medical domain-specific baselines like HuatuoGPT and UltraMedical, which were optimized for single-turn medical QA rather than multi-turn conversations.", "AI": {"tldr": "IGFT\u662f\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u5bf9\u8bdd\u6570\u636e\u3001\u57fa\u4e8e\u4fe1\u606f\u589e\u76ca\u5956\u52b1\u548c\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u533b\u7597\u5bf9\u8bddAI\u8fdb\u884c\u60a3\u8005\u8bbf\u8c08\u7684\u65b0\u65b9\u6cd5\uff0c\u5728HPI\u751f\u6210\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u533b\u7597\u5bf9\u8bddAI\u8bad\u7ec3\u4f9d\u8d56\u6602\u8d35\u7684\u4eba\u5de5\u6807\u6ce8\u5bf9\u8bdd\u6570\u636e\u6216\u9759\u6001\u6570\u636e\u96c6\uff0c\u65e0\u6cd5\u6709\u6548\u5b66\u4e60\u591a\u8f6e\u8bbf\u8c08\u7b56\u7565\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u81ea\u4e3b\u63a2\u7d22\u6709\u6548\u63d0\u95ee\u7b56\u7565\u3001\u65e0\u9700\u9884\u6536\u96c6\u4eba\u7c7b\u5bf9\u8bdd\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4fe1\u606f\u589e\u76ca\u5fae\u8c03(IGFT)\uff0c\u7ed3\u5408\u5728\u7ebf\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(GRPO)\u548c\u4fe1\u606f\u8bba\u5956\u52b1\u3002\u4f7f\u7528\u4fe1\u606f\u589e\u76ca\u5956\u52b1\u51fd\u6570\u8ffd\u8e2a\u4e34\u5e8a\u5b9e\u4f53\uff08\u75c7\u72b6\u3001\u65f6\u95f4\u6a21\u5f0f\u3001\u75c5\u53f2\uff09\u5728\u5bf9\u8bdd\u4e2d\u7684\u63ed\u793a\u60c5\u51b5\uff0c\u7ed3\u5408GPT-4o-mini\u7684\u8d28\u91cf\u8bc4\u4f30\uff08\u4e34\u5e8a\u76f8\u5173\u6027\u3001\u60a3\u8005\u53c2\u4e0e\u5ea6\u3001\u7279\u5f02\u6027\uff09\u8ba1\u7b97\u95ee\u9898\u5956\u52b1\u3002\u4f7f\u7528LoRA\u5fae\u8c03Llama-3.1-8B-Instruct\u548cDeepSeek-R1-Distill-Qwen-7B\u6a21\u578b\u3002", "result": "\u5728Avey\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u5728MIMIC\u6570\u636e\u4e0a\u8bc4\u4f30\u6cdb\u5316\u80fd\u529b\u3002DeepSeek-R1-Distill-Qwen-7B(IGFT)\u5728Avey\u4e0aF1\u5f97\u5206\u4e3a0.408\uff08\u6bd4\u57fa\u7840\u6a21\u578b\u63d0\u534710.9%\uff09\uff0c\u5728MIMIC\u4e0a\u4e3a0.289\uff08\u63d0\u534712.9%\uff09\u3002Llama-3.1-8B-Instruct(IGFT)\u5206\u522b\u8fbe\u52300.384\u548c0.336\u3002\u4e24\u4e2a\u6a21\u578b\u5728MIMIC\u4e0a\u90fd\u4f18\u4e8eOpenAI\u6a21\u578b\uff0c\u5e76\u8d85\u8d8aHuatuoGPT\u548cUltraMedical\u7b49\u533b\u7597\u9886\u57df\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "IGFT\u901a\u8fc7\u4fe1\u606f\u589e\u76ca\u5956\u52b1\u548c\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\uff0c\u4f7f\u533b\u7597\u5bf9\u8bddAI\u80fd\u591f\u81ea\u4e3b\u53d1\u73b0\u6709\u6548\u7684\u63d0\u95ee\u7b56\u7565\uff0c\u65e0\u9700\u4f9d\u8d56\u9884\u6536\u96c6\u7684\u4eba\u7c7b\u5bf9\u8bdd\u6570\u636e\uff0c\u5728\u591a\u8f6e\u60a3\u8005\u8bbf\u8c08\u548cHPI\u751f\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2601.18380", "categories": ["cs.CL", "cs.CY", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18380", "abs": "https://arxiv.org/abs/2601.18380", "authors": ["Ignatius Ezeani"], "title": "Corpus-Based Approaches to Igbo Diacritic Restoration", "comment": "270 page. Ph.D. Thesis. The University of Sheffield", "summary": "With natural language processing (NLP), researchers aim to enable computers to identify and understand patterns in human languages. This is often difficult because a language embeds many dynamic and varied properties in its syntax, pragmatics and phonology, which need to be captured and processed. The capacity of computers to process natural languages is increasing because NLP researchers are pushing its boundaries. But these research works focus more on well-resourced languages such as English, Japanese, German, French, Russian, Mandarin Chinese, etc. Over 95% of the world's 7000 languages are low-resourced for NLP, i.e. they have little or no data, tools, and techniques for NLP work.\n  In this thesis, we present an overview of diacritic ambiguity and a review of previous diacritic disambiguation approaches on other languages. Focusing on the Igbo language, we report the steps taken to develop a flexible framework for generating datasets for diacritic restoration. Three main approaches, the standard n-gram model, the classification models and the embedding models were proposed. The standard n-gram models use a sequence of previous words to the target stripped word as key predictors of the correct variants. For the classification models, a window of words on both sides of the target stripped word was used. The embedding models compare the similarity scores of the combined context word embeddings and the embeddings of each of the candidate variant vectors.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u7279\u522b\u662f\u4f0a\u535a\u8bed\uff09\u5f00\u53d1\u4e86\u53d8\u97f3\u7b26\u53f7\u6062\u590d\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u4e3b\u8981\u65b9\u6cd5\uff1a\u6807\u51c6n-gram\u6a21\u578b\u3001\u5206\u7c7b\u6a21\u578b\u548c\u5d4c\u5165\u6a21\u578b\u6765\u89e3\u51b3\u53d8\u97f3\u7b26\u53f7\u6b67\u4e49\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u82f1\u8bed\u3001\u6c49\u8bed\u7b49\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u800c\u5168\u740395%\u4ee5\u4e0a\u7684\u8bed\u8a00\uff08\u8d85\u8fc77000\u79cd\uff09\u5c5e\u4e8e\u4f4e\u8d44\u6e90\u8bed\u8a00\uff0c\u7f3a\u4e4fNLP\u6240\u9700\u7684\u6570\u636e\u3001\u5de5\u5177\u548c\u6280\u672f\u3002\u4f0a\u535a\u8bed\u4f5c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\uff0c\u5b58\u5728\u53d8\u97f3\u7b26\u53f7\u6b67\u4e49\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u53d8\u97f3\u7b26\u53f7\u6d88\u6b67\u65b9\u6cd5\uff1a1) \u6807\u51c6n-gram\u6a21\u578b\uff1a\u4f7f\u7528\u76ee\u6807\u8bcd\u4e4b\u524d\u7684\u8bcd\u5e8f\u5217\u4f5c\u4e3a\u6b63\u786e\u53d8\u4f53\u9884\u6d4b\u7684\u5173\u952e\u7279\u5f81\uff1b2) \u5206\u7c7b\u6a21\u578b\uff1a\u4f7f\u7528\u76ee\u6807\u8bcd\u4e24\u4fa7\u7684\u7a97\u53e3\u8bcd\u4f5c\u4e3a\u7279\u5f81\uff1b3) \u5d4c\u5165\u6a21\u578b\uff1a\u6bd4\u8f83\u4e0a\u4e0b\u6587\u8bcd\u5d4c\u5165\u7ec4\u5408\u4e0e\u5019\u9009\u53d8\u4f53\u5411\u91cf\u5d4c\u5165\u7684\u76f8\u4f3c\u5ea6\u5f97\u5206\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7075\u6d3b\u7684\u6846\u67b6\u7528\u4e8e\u751f\u6210\u53d8\u97f3\u7b26\u53f7\u6062\u590d\u6570\u636e\u96c6\uff0c\u5e76\u9488\u5bf9\u4f0a\u535a\u8bed\u5b9e\u73b0\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u53d8\u97f3\u7b26\u53f7\u6d88\u6b67\u65b9\u6cd5\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684NLP\u5904\u7406\u63d0\u4f9b\u4e86\u6280\u672f\u65b9\u6848\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u53d8\u97f3\u7b26\u53f7\u6062\u590d\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u89e3\u51b3\u65b9\u6848\u6846\u67b6\uff0c\u586b\u8865\u4e86NLP\u7814\u7a76\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u5904\u7406\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u7279\u522b\u662f\u9488\u5bf9\u4f0a\u535a\u8bed\u7b49\u975e\u6d32\u8bed\u8a00\u7684\u53d8\u97f3\u7b26\u53f7\u6b67\u4e49\u95ee\u9898\u3002"}}
{"id": "2601.17443", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17443", "abs": "https://arxiv.org/abs/2601.17443", "authors": ["Ondrej Bohdal", "Pramit Saha", "Umberto Michieli", "Mete Ozay", "Taha Ceritli"], "title": "Clustering-driven Memory Compression for On-device Large Language Models", "comment": "Accepted at ICASSP 2026", "summary": "Large language models (LLMs) often rely on user-specific memories distilled from past interactions to enable personalized generation. A common practice is to concatenate these memories with the input prompt, but this approach quickly exhausts the limited context available in on-device LLMs. Compressing memories by averaging can mitigate context growth, yet it frequently harms performance due to semantic conflicts across heterogeneous memories. In this work, we introduce a clustering-based memory compression strategy that balances context efficiency and personalization quality. Our method groups memories by similarity and merges them within clusters prior to concatenation, thereby preserving coherence while reducing redundancy. Experiments demonstrate that our approach substantially lowers the number of memory tokens while outperforming baseline strategies such as naive averaging or direct concatenation. Furthermore, for a fixed context budget, clustering-driven merging yields more compact memory representations and consistently enhances generation quality.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u805a\u7c7b\u7684\u8bb0\u5fc6\u538b\u7f29\u7b56\u7565\uff0c\u5728\u6709\u9650\u4e0a\u4e0b\u6587\u9884\u7b97\u4e0b\u5e73\u8861\u538b\u7f29\u6548\u7387\u4e0e\u4e2a\u6027\u5316\u8d28\u91cf", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u76f4\u63a5\u62fc\u63a5\u8bb0\u5fc6\u4f1a\u8017\u5c3d\u8bbe\u5907\u7aefLLM\u7684\u6709\u9650\u4e0a\u4e0b\u6587\uff1b\u5e73\u5747\u538b\u7f29\u4f1a\u56e0\u8bed\u4e49\u51b2\u7a81\u635f\u5bb3\u6027\u80fd", "method": "\u57fa\u4e8e\u805a\u7c7b\u7684\u8bb0\u5fc6\u538b\u7f29\u7b56\u7565\uff1a\u6309\u76f8\u4f3c\u6027\u5bf9\u8bb0\u5fc6\u5206\u7ec4\uff0c\u5728\u805a\u7c7b\u5185\u5408\u5e76\u8bb0\u5fc6\u540e\u518d\u62fc\u63a5\uff0c\u51cf\u5c11\u5197\u4f59\u540c\u65f6\u4fdd\u6301\u8bed\u4e49\u8fde\u8d2f\u6027", "result": "\u663e\u8457\u51cf\u5c11\u8bb0\u5fc6token\u6570\u91cf\uff0c\u6027\u80fd\u4f18\u4e8e\u6734\u7d20\u5e73\u5747\u6216\u76f4\u63a5\u62fc\u63a5\u57fa\u7ebf\uff1b\u5728\u56fa\u5b9a\u4e0a\u4e0b\u6587\u9884\u7b97\u4e0b\uff0c\u805a\u7c7b\u9a71\u52a8\u5408\u5e76\u4ea7\u751f\u66f4\u7d27\u51d1\u7684\u8bb0\u5fc6\u8868\u793a\u5e76\u6301\u7eed\u63d0\u5347\u751f\u6210\u8d28\u91cf", "conclusion": "\u805a\u7c7b\u538b\u7f29\u7b56\u7565\u6709\u6548\u5e73\u8861\u4e0a\u4e0b\u6587\u6548\u7387\u4e0e\u4e2a\u6027\u5316\u8d28\u91cf\uff0c\u4e3a\u8bbe\u5907\u7aefLLM\u7684\u8bb0\u5fc6\u7ba1\u7406\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.18771", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18771", "abs": "https://arxiv.org/abs/2601.18771", "authors": ["Yanming Liu", "Xinyue Peng", "Zixuan Yan", "Yanxin Shen", "Wenjie Xu", "Yuefeng Huang", "Xinyi Wang", "Jiannan Cao", "Jianwei Yin", "Xuhong Zhang"], "title": "Dep-Search: Learning Dependency-Aware Reasoning Traces with Persistent Memory", "comment": "Dep-Search 1st version", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, particularly when augmented with search mechanisms that enable systematic exploration of external knowledge bases. The field has evolved from traditional retrieval-augmented generation (RAG) frameworks to more sophisticated search-based frameworks that orchestrate multi-step reasoning through explicit search strategies. However, existing search frameworks still rely heavily on implicit natural language reasoning to determine search strategies and how to leverage retrieved information across reasoning steps. This reliance on implicit reasoning creates fundamental challenges for managing dependencies between sub-questions, efficiently reusing previously retrieved knowledge, and learning optimal search strategies through reinforcement learning. To address these limitations, we propose Dep-Search, a dependency-aware search framework that advances beyond existing search frameworks by integrating structured reasoning, retrieval, and persistent memory through GRPO. Dep-Search introduces explicit control mechanisms that enable the model to decompose questions with dependency relationships, retrieve information when needed, access previously stored knowledge from memory, and summarize long reasoning contexts into reusable memory entries. Through extensive experiments on seven diverse question answering datasets, we demonstrate that Dep-Search significantly enhances LLMs' ability to tackle complex multi-hop reasoning tasks, achieving substantial improvements over strong baselines across different model scales.", "AI": {"tldr": "Dep-Search\u662f\u4e00\u4e2a\u4f9d\u8d56\u611f\u77e5\u7684\u641c\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63a8\u7406\u3001\u68c0\u7d22\u548c\u6301\u4e45\u5185\u5b58\u96c6\u6210\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u641c\u7d22\u6846\u67b6\u5728\u7ba1\u7406\u5b50\u95ee\u9898\u4f9d\u8d56\u3001\u91cd\u7528\u68c0\u7d22\u77e5\u8bc6\u548c\u5b66\u4e60\u6700\u4f18\u641c\u7d22\u7b56\u7565\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u641c\u7d22\u6846\u67b6\u867d\u7136\u589e\u5f3a\u4e86LLMs\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u4ecd\u4e25\u91cd\u4f9d\u8d56\u9690\u5f0f\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u6765\u786e\u5b9a\u641c\u7d22\u7b56\u7565\u548c\u8de8\u63a8\u7406\u6b65\u9aa4\u5229\u7528\u68c0\u7d22\u4fe1\u606f\u3002\u8fd9\u79cd\u9690\u5f0f\u63a8\u7406\u5728\u7ba1\u7406\u5b50\u95ee\u9898\u4f9d\u8d56\u3001\u9ad8\u6548\u91cd\u7528\u5148\u524d\u68c0\u7d22\u77e5\u8bc6\u4ee5\u53ca\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b66\u4e60\u6700\u4f18\u641c\u7d22\u7b56\u7565\u65b9\u9762\u5b58\u5728\u6839\u672c\u6027\u6311\u6218\u3002", "method": "\u63d0\u51faDep-Search\u6846\u67b6\uff0c\u901a\u8fc7GRPO\u96c6\u6210\u7ed3\u6784\u5316\u63a8\u7406\u3001\u68c0\u7d22\u548c\u6301\u4e45\u5185\u5b58\u3002\u5f15\u5165\u663e\u5f0f\u63a7\u5236\u673a\u5236\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\uff1a1\uff09\u5206\u89e3\u5177\u6709\u4f9d\u8d56\u5173\u7cfb\u7684\u5b50\u95ee\u9898\uff1b2\uff09\u5728\u9700\u8981\u65f6\u68c0\u7d22\u4fe1\u606f\uff1b3\uff09\u4ece\u5185\u5b58\u8bbf\u95ee\u5148\u524d\u5b58\u50a8\u7684\u77e5\u8bc6\uff1b4\uff09\u5c06\u957f\u63a8\u7406\u4e0a\u4e0b\u6587\u603b\u7ed3\u4e3a\u53ef\u91cd\u7528\u7684\u5185\u5b58\u6761\u76ee\u3002", "result": "\u5728\u4e03\u4e2a\u4e0d\u540c\u7684\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660eDep-Search\u663e\u8457\u589e\u5f3a\u4e86LLMs\u5904\u7406\u590d\u6742\u591a\u8df3\u63a8\u7406\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0a\u90fd\u5b9e\u73b0\u4e86\u5bf9\u5f3a\u57fa\u7ebf\u7684\u5b9e\u8d28\u6027\u6539\u8fdb\u3002", "conclusion": "Dep-Search\u901a\u8fc7\u4f9d\u8d56\u611f\u77e5\u7684\u641c\u7d22\u6846\u67b6\u89e3\u51b3\u4e86\u73b0\u6709\u641c\u7d22\u6846\u67b6\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63a8\u7406\u3001\u68c0\u7d22\u548c\u6301\u4e45\u5185\u5b58\u7684\u96c6\u6210\uff0c\u4e3aLLMs\u5728\u590d\u6742\u591a\u8df3\u63a8\u7406\u4efb\u52a1\u4e2d\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17530", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17530", "abs": "https://arxiv.org/abs/2601.17530", "authors": ["Gautam Siddharth Kashyap", "Harsh Joshi", "Niharika Jain", "Ebad Shabbir", "Jiechao Gao", "Nipun Joshi", "Usman Naseem"], "title": "Revealing the Truth with ConLLM for Detecting Multi-Modal Deepfakes", "comment": "Accepted at EACL Findings 2026", "summary": "The rapid rise of deepfake technology poses a severe threat to social and political stability by enabling hyper-realistic synthetic media capable of manipulating public perception. However, existing detection methods struggle with two core limitations: (1) modality fragmentation, which leads to poor generalization across diverse and adversarial deepfake modalities; and (2) shallow inter-modal reasoning, resulting in limited detection of fine-grained semantic inconsistencies. To address these, we propose ConLLM (Contrastive Learning with Large Language Models), a hybrid framework for robust multimodal deepfake detection. ConLLM employs a two-stage architecture: stage 1 uses Pre-Trained Models (PTMs) to extract modality-specific embeddings; stage 2 aligns these embeddings via contrastive learning to mitigate modality fragmentation, and refines them using LLM-based reasoning to address shallow inter-modal reasoning by capturing semantic inconsistencies. ConLLM demonstrates strong performance across audio, video, and audio-visual modalities. It reduces audio deepfake EER by up to 50%, improves video accuracy by up to 8%, and achieves approximately 9% accuracy gains in audio-visual tasks. Ablation studies confirm that PTM-based embeddings contribute 9%-10% consistent improvements across modalities.", "AI": {"tldr": "\u63d0\u51faConLLM\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u548cLLM\u63a8\u7406\u89e3\u51b3\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u4e2d\u7684\u6a21\u6001\u788e\u7247\u5316\u548c\u6d45\u5c42\u8de8\u6a21\u6001\u63a8\u7406\u95ee\u9898\uff0c\u5728\u97f3\u9891\u3001\u89c6\u9891\u548c\u89c6\u542c\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\u5bf9\u793e\u4f1a\u653f\u6cbb\u7a33\u5b9a\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u6838\u5fc3\u5c40\u9650\uff1a1) \u6a21\u6001\u788e\u7247\u5316\u5bfc\u81f4\u8de8\u591a\u6837\u5316\u548c\u5bf9\u6297\u6027\u6df1\u5ea6\u4f2a\u9020\u6a21\u6001\u7684\u6cdb\u5316\u80fd\u529b\u5dee\uff1b2) \u6d45\u5c42\u8de8\u6a21\u6001\u63a8\u7406\u5bfc\u81f4\u7ec6\u7c92\u5ea6\u8bed\u4e49\u4e0d\u4e00\u81f4\u6027\u68c0\u6d4b\u6709\u9650\u3002", "method": "\u63d0\u51faConLLM\uff08\u5bf9\u6bd4\u5b66\u4e60\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff09\u6df7\u5408\u6846\u67b6\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u67b6\u6784\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u63d0\u53d6\u6a21\u6001\u7279\u5b9a\u5d4c\u5165\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u9f50\u5d4c\u5165\u4ee5\u7f13\u89e3\u6a21\u6001\u788e\u7247\u5316\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8eLLM\u7684\u63a8\u7406\u7ec6\u5316\u5d4c\u5165\u4ee5\u89e3\u51b3\u6d45\u5c42\u8de8\u6a21\u6001\u63a8\u7406\u95ee\u9898\uff0c\u6355\u83b7\u8bed\u4e49\u4e0d\u4e00\u81f4\u6027\u3002", "result": "ConLLM\u5728\u97f3\u9891\u3001\u89c6\u9891\u548c\u89c6\u542c\u591a\u6a21\u6001\u4e0a\u8868\u73b0\u4f18\u5f02\uff1a\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020EER\u964d\u4f4e\u8fbe50%\uff0c\u89c6\u9891\u51c6\u786e\u7387\u63d0\u5347\u8fbe8%\uff0c\u89c6\u542c\u4efb\u52a1\u51c6\u786e\u7387\u63d0\u5347\u7ea69%\u3002\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u57fa\u4e8ePTM\u7684\u5d4c\u5165\u4e3a\u5404\u6a21\u6001\u5e26\u67659%-10%\u7684\u7a33\u5b9a\u6539\u8fdb\u3002", "conclusion": "ConLLM\u901a\u8fc7\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u548cLLM\u63a8\u7406\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u4e2d\u7684\u6a21\u6001\u788e\u7247\u5316\u548c\u6d45\u5c42\u8de8\u6a21\u6001\u63a8\u7406\u95ee\u9898\uff0c\u5728\u591a\u6a21\u6001\u68c0\u6d4b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u4e3a\u9c81\u68d2\u7684\u591a\u6a21\u6001\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17897", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17897", "abs": "https://arxiv.org/abs/2601.17897", "authors": ["Jiayu Liu", "Yinhe Long", "Zhenya Huang", "Enhong Chen"], "title": "UniCog: Uncovering Cognitive Abilities of LLMs through Latent Mind Space Analysis", "comment": null, "summary": "A growing body of research suggests that the cognitive processes of large language models (LLMs) differ fundamentally from those of humans. However, existing interpretability methods remain limited in explaining how cognitive abilities are engaged during LLM reasoning. In this paper, we propose UniCog, a unified framework that analyzes LLM cognition via a latent mind space. Formulated as a latent variable model, UniCog encodes diverse abilities from dense model activations into sparse, disentangled latent dimensions. Through extensive analysis on six advanced LLMs, including DeepSeek-V3.2 and GPT-4o, we reveal a Pareto principle of LLM cognition, where a shared reasoning core is complemented by ability-specific signatures. Furthermore, we discover that reasoning failures often manifest as anomalous intensity in latent activations. These findings opens a new paradigm in LLM analysis, providing a cognition grounded view of reasoning dynamics. Finally, leveraging these insights, we introduce a latent-informed candidate prioritization strategy, which improves reasoning performance by up to 7.5% across challenging benchmarks. Our code is available at https://github.com/milksalute/unicog.", "code_url": "https://github.com/milksalute/unico", "AI": {"tldr": "UniCog\u662f\u4e00\u4e2a\u901a\u8fc7\u6f5c\u5728\u601d\u7ef4\u7a7a\u95f4\u5206\u6790LLM\u8ba4\u77e5\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u5c06\u5bc6\u96c6\u6a21\u578b\u6fc0\u6d3b\u7f16\u7801\u4e3a\u7a00\u758f\u89e3\u8026\u7684\u6f5c\u5728\u7ef4\u5ea6\uff0c\u63ed\u793a\u4e86LLM\u8ba4\u77e5\u7684\u5e15\u7d2f\u6258\u539f\u5219\uff0c\u5e76\u5229\u7528\u6f5c\u5728\u6fc0\u6d3b\u5f02\u5e38\u68c0\u6d4b\u63a8\u7406\u5931\u8d25\uff0c\u6700\u7ec8\u901a\u8fc7\u6f5c\u5728\u4fe1\u606f\u5019\u9009\u4f18\u5148\u7ea7\u7b56\u7565\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5728\u89e3\u91caLLM\u63a8\u7406\u8fc7\u7a0b\u4e2d\u8ba4\u77e5\u80fd\u529b\u5982\u4f55\u88ab\u8c03\u7528\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u800c\u7814\u7a76\u8868\u660eLLM\u7684\u8ba4\u77e5\u8fc7\u7a0b\u4e0e\u4eba\u7c7b\u5b58\u5728\u6839\u672c\u5dee\u5f02\uff0c\u9700\u8981\u65b0\u7684\u5206\u6790\u6846\u67b6\u6765\u6df1\u5165\u7406\u89e3LLM\u7684\u8ba4\u77e5\u673a\u5236\u3002", "method": "\u63d0\u51faUniCog\u7edf\u4e00\u6846\u67b6\uff0c\u91c7\u7528\u6f5c\u5728\u53d8\u91cf\u6a21\u578b\u5c06\u5bc6\u96c6\u6a21\u578b\u6fc0\u6d3b\u7f16\u7801\u4e3a\u7a00\u758f\u89e3\u8026\u7684\u6f5c\u5728\u7ef4\u5ea6\uff0c\u5bf9\u516d\u4e2a\u5148\u8fdbLLM\uff08\u5305\u62ecDeepSeek-V3.2\u548cGPT-4o\uff09\u8fdb\u884c\u5e7f\u6cdb\u5206\u6790\uff0c\u53d1\u73b0\u8ba4\u77e5\u7684\u5e15\u7d2f\u6258\u539f\u5219\u548c\u63a8\u7406\u5931\u8d25\u7684\u6f5c\u5728\u6fc0\u6d3b\u5f02\u5e38\u6a21\u5f0f\u3002", "result": "\u63ed\u793a\u4e86LLM\u8ba4\u77e5\u7684\u5e15\u7d2f\u6258\u539f\u5219\uff1a\u5b58\u5728\u5171\u4eab\u63a8\u7406\u6838\u5fc3\u548c\u7279\u5b9a\u80fd\u529b\u7279\u5f81\uff1b\u53d1\u73b0\u63a8\u7406\u5931\u8d25\u5e38\u8868\u73b0\u4e3a\u6f5c\u5728\u6fc0\u6d3b\u5f02\u5e38\uff1b\u63d0\u51fa\u7684\u6f5c\u5728\u4fe1\u606f\u5019\u9009\u4f18\u5148\u7ea7\u7b56\u7565\u5728\u591a\u4e2a\u6311\u6218\u6027\u57fa\u51c6\u4e0a\u63d0\u5347\u63a8\u7406\u6027\u80fd\u8fbe7.5%\u3002", "conclusion": "UniCog\u4e3aLLM\u5206\u6790\u5f00\u8f9f\u4e86\u65b0\u8303\u5f0f\uff0c\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8ba4\u77e5\u7684\u63a8\u7406\u52a8\u6001\u89c6\u56fe\uff0c\u901a\u8fc7\u6f5c\u5728\u601d\u7ef4\u7a7a\u95f4\u5206\u6790\u80fd\u591f\u6df1\u5165\u7406\u89e3LLM\u8ba4\u77e5\u673a\u5236\u5e76\u5b9e\u9645\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2601.17532", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17532", "abs": "https://arxiv.org/abs/2601.17532", "authors": ["Zhipeng Song", "Yizhi Zhou", "Xiangyu Kong", "Jiulong Jiao", "Xinrui Bao", "Xu You", "Xueqing Shi", "Yuhang Zhou", "Heng Qi"], "title": "Less is More for RAG: Information Gain Pruning for Generator-Aligned Reranking and Evidence Selection", "comment": "26 pages, 10 figures", "summary": "Retrieval-augmented generation (RAG) grounds large language models with external evidence, but under a limited context budget, the key challenge is deciding which retrieved passages should be injected. We show that retrieval relevance metrics (e.g., NDCG) correlate weakly with end-to-end QA quality and can even become negatively correlated under multi-passage injection, where redundancy and mild conflicts destabilize generation. We propose \\textbf{Information Gain Pruning (IGP)}, a deployment-friendly reranking-and-pruning module that selects evidence using a generator-aligned utility signal and filters weak or harmful passages before truncation, without changing existing budget interfaces. Across five open-domain QA benchmarks and multiple retrievers and generators, IGP consistently improves the quality--cost trade-off. In a representative multi-evidence setting, IGP delivers about +12--20% relative improvement in average F1 while reducing final-stage input tokens by roughly 76--79% compared to retriever-only baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4fe1\u606f\u589e\u76ca\u526a\u679d\uff08IGP\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u5668\u5bf9\u9f50\u7684\u6548\u7528\u4fe1\u53f7\u9009\u62e9\u548c\u8fc7\u6ee4\u68c0\u7d22\u5230\u7684\u8bc1\u636e\uff0c\u5728\u6709\u9650\u4e0a\u4e0b\u6587\u9884\u7b97\u4e0b\u4f18\u5316\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u8d28\u91cf-\u6210\u672c\u6743\u8861\u3002", "motivation": "\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u867d\u7136\u80fd\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u5916\u90e8\u8bc1\u636e\uff0c\u4f46\u5728\u6709\u9650\u4e0a\u4e0b\u6587\u9884\u7b97\u4e0b\uff0c\u5173\u952e\u6311\u6218\u5728\u4e8e\u51b3\u5b9a\u6ce8\u5165\u54ea\u4e9b\u68c0\u7d22\u5230\u7684\u6bb5\u843d\u3002\u7814\u7a76\u53d1\u73b0\u68c0\u7d22\u76f8\u5173\u6027\u6307\u6807\uff08\u5982NDCG\uff09\u4e0e\u7aef\u5230\u7aefQA\u8d28\u91cf\u76f8\u5173\u6027\u8f83\u5f31\uff0c\u5728\u591a\u6bb5\u843d\u6ce8\u5165\u65f6\u751a\u81f3\u53ef\u80fd\u8d1f\u76f8\u5173\uff0c\u56e0\u4e3a\u5197\u4f59\u548c\u8f7b\u5fae\u51b2\u7a81\u4f1a\u7834\u574f\u751f\u6210\u7684\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u4fe1\u606f\u589e\u76ca\u526a\u679d\uff08IGP\uff09\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u4e2a\u90e8\u7f72\u53cb\u597d\u7684\u91cd\u6392\u5e8f\u548c\u526a\u679d\u6a21\u5757\u3002\u5b83\u4f7f\u7528\u751f\u6210\u5668\u5bf9\u9f50\u7684\u6548\u7528\u4fe1\u53f7\u6765\u9009\u62e9\u8bc1\u636e\uff0c\u5728\u622a\u65ad\u524d\u8fc7\u6ee4\u5f31\u6216\u6709\u5bb3\u7684\u6bb5\u843d\uff0c\u800c\u4e0d\u6539\u53d8\u73b0\u6709\u7684\u9884\u7b97\u63a5\u53e3\u3002IGP\u901a\u8fc7\u8bc4\u4f30\u6bcf\u4e2a\u6bb5\u843d\u5bf9\u751f\u6210\u7b54\u6848\u7684\u4fe1\u606f\u589e\u76ca\u6765\u8fdb\u884c\u9009\u62e9\u548c\u8fc7\u6ee4\u3002", "result": "\u5728\u4e94\u4e2a\u5f00\u653e\u57dfQA\u57fa\u51c6\u6d4b\u8bd5\u548c\u591a\u79cd\u68c0\u7d22\u5668\u548c\u751f\u6210\u5668\u4e0a\uff0cIGP\u59cb\u7ec8\u6539\u5584\u4e86\u8d28\u91cf-\u6210\u672c\u6743\u8861\u3002\u5728\u4ee3\u8868\u6027\u7684\u591a\u8bc1\u636e\u8bbe\u7f6e\u4e2d\uff0c\u4e0e\u4ec5\u4f7f\u7528\u68c0\u7d22\u5668\u7684\u57fa\u7ebf\u76f8\u6bd4\uff0cIGP\u5728\u5e73\u5747F1\u4e0a\u5e26\u6765\u7ea612-20%\u7684\u76f8\u5bf9\u6539\u8fdb\uff0c\u540c\u65f6\u5c06\u6700\u7ec8\u9636\u6bb5\u8f93\u5165token\u51cf\u5c11\u7ea676-79%\u3002", "conclusion": "IGP\u901a\u8fc7\u751f\u6210\u5668\u5bf9\u9f50\u7684\u8bc1\u636e\u9009\u62e9\u6709\u6548\u89e3\u51b3\u4e86RAG\u5728\u6709\u9650\u4e0a\u4e0b\u6587\u9884\u7b97\u4e0b\u7684\u8bc1\u636e\u6ce8\u5165\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u7684\u6548\u7387\u548c\u6548\u679c\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17920", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17920", "abs": "https://arxiv.org/abs/2601.17920", "authors": ["Xuanzhou Chen", "Audrey Wang", "Stanley Yin", "Hanyang Jiang", "Dong Zhang"], "title": "Agentic AI for Self-Driving Laboratories in Soft Matter: Taxonomy, Benchmarks,and Open Challenges", "comment": null, "summary": "Self-driving laboratories (SDLs) close the loop between experiment design, automated execution, and data-driven decision making, and they provide a demanding testbed for agentic AI under expensive actions, noisy and delayed feedback, strict feasibility and safety constraints, and non-stationarity. This survey uses soft matter as a representative setting but focuses on the AI questions that arise in real laboratories. We frame SDL autonomy as an agent environment interaction problem with explicit observations, actions, costs, and constraints, and we use this formulation to connect common SDL pipelines to established AI principles. We review the main method families that enable closed loop experimentation, including Bayesian optimization and active learning for sample efficient experiment selection, planning and reinforcement learning for long horizon protocol optimization, and tool using agents that orchestrate heterogeneous instruments and software. We emphasize verifiable and provenance aware policies that support debugging, reproducibility, and safe operation. We then propose a capability driven taxonomy that organizes systems by decision horizon, uncertainty modeling, action parameterization, constraint handling, failure recovery, and human involvement. To enable meaningful comparison, we synthesize benchmark task templates and evaluation metrics that prioritize cost aware performance, robustness to drift, constraint violation behavior, and reproducibility. Finally, we distill lessons from deployed SDLs and outline open challenges in multi-modal representation, calibrated uncertainty, safe exploration, and shared benchmark infrastructure.", "AI": {"tldr": "\u5173\u4e8e\u81ea\u4e3b\u5b9e\u9a8c\u5ba4\u4e2d\u667a\u80fd\u4f53AI\u7684\u7efc\u8ff0\uff0c\u805a\u7126\u8f6f\u7269\u8d28\u9886\u57df\uff0c\u7cfb\u7edf\u5206\u6790SDL\u4f5c\u4e3a\u667a\u80fd\u4f53-\u73af\u5883\u4ea4\u4e92\u95ee\u9898\u7684AI\u65b9\u6cd5\u3001\u5206\u7c7b\u4f53\u7cfb\u3001\u8bc4\u4f30\u6307\u6807\u53ca\u6311\u6218", "motivation": "\u81ea\u4e3b\u5b9e\u9a8c\u5ba4\u4e3aAI\u63d0\u4f9b\u4e86\u5177\u6709\u6602\u8d35\u64cd\u4f5c\u3001\u566a\u58f0\u5ef6\u8fdf\u53cd\u9988\u3001\u4e25\u683c\u7ea6\u675f\u548c\u975e\u5e73\u7a33\u6027\u7684\u6d4b\u8bd5\u73af\u5883\uff0c\u9700\u8981\u7cfb\u7edf\u68b3\u7406\u5176\u4e2d\u4ea7\u751f\u7684AI\u95ee\u9898\u548c\u65b9\u6cd5\u6846\u67b6", "method": "\u5c06SDL\u81ea\u4e3b\u6027\u6784\u5efa\u4e3a\u667a\u80fd\u4f53-\u73af\u5883\u4ea4\u4e92\u95ee\u9898\uff0c\u7efc\u8ff0\u8d1d\u53f6\u65af\u4f18\u5316\u3001\u4e3b\u52a8\u5b66\u4e60\u3001\u89c4\u5212\u3001\u5f3a\u5316\u5b66\u4e60\u3001\u5de5\u5177\u4f7f\u7528\u667a\u80fd\u4f53\u7b49\u65b9\u6cd5\uff0c\u63d0\u51fa\u80fd\u529b\u9a71\u52a8\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u5408\u6210\u57fa\u51c6\u4efb\u52a1\u6a21\u677f\u548c\u8bc4\u4f30\u6307\u6807", "result": "\u5efa\u7acb\u4e86SDL\u7684AI\u65b9\u6cd5\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u51b3\u7b56\u89c6\u91ce\u3001\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u3001\u52a8\u4f5c\u53c2\u6570\u5316\u3001\u7ea6\u675f\u5904\u7406\u3001\u6545\u969c\u6062\u590d\u548c\u4eba\u7c7b\u53c2\u4e0e\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u8bbe\u8ba1\u4e86\u6210\u672c\u611f\u77e5\u6027\u80fd\u3001\u6f02\u79fb\u9c81\u68d2\u6027\u3001\u7ea6\u675f\u8fdd\u53cd\u884c\u4e3a\u548c\u53ef\u91cd\u590d\u6027\u7b49\u8bc4\u4f30\u6307\u6807", "conclusion": "\u81ea\u4e3b\u5b9e\u9a8c\u5ba4\u662fAI\u7684\u91cd\u8981\u6d4b\u8bd5\u5e73\u53f0\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u53d1\u5c55\u591a\u6a21\u6001\u8868\u793a\u3001\u6821\u51c6\u4e0d\u786e\u5b9a\u6027\u3001\u5b89\u5168\u63a2\u7d22\u548c\u5171\u4eab\u57fa\u51c6\u57fa\u7840\u8bbe\u65bd\uff0c\u53ef\u9a8c\u8bc1\u548c\u6eaf\u6e90\u611f\u77e5\u7684\u7b56\u7565\u5bf9\u8c03\u8bd5\u3001\u53ef\u91cd\u590d\u6027\u548c\u5b89\u5168\u64cd\u4f5c\u81f3\u5173\u91cd\u8981"}}
{"id": "2601.17585", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17585", "abs": "https://arxiv.org/abs/2601.17585", "authors": ["Matija Luka Kuki\u0107", "Marko \u010culjak", "David Duki\u0107", "Martin Tutek", "Jan \u0160najder"], "title": "Sequence Repetition Enhances Token Embeddings and Improves Sequence Labeling with Decoder-only Language Models", "comment": "Accepted at EACL 2026 Findings", "summary": "Modern language models (LMs) are trained in an autoregressive manner, conditioned only on the prefix. In contrast, sequence labeling (SL) tasks assign labels to each individual input token, naturally benefiting from bidirectional context. This discrepancy has historically led SL to rely on inherently bidirectional encoder-only models. However, the rapid development of decoder-only models has raised the question of whether they can be adapted to SL. While causal mask removal has emerged as a viable technique for adapting decoder-only models to leverage the full context for SL, it requires considerable changes to the base model functionality. In this work, we explore sequence repetition (SR) as a less invasive alternative for enabling bidirectionality in decoder-only models. Through fine-tuning experiments, we show that SR inherently makes decoders bidirectional, improving the quality of token-level embeddings and surpassing encoders and unmasked decoders. Contrary to earlier claims, we find that increasing the number of repetitions does not degrade SL performance. Finally, we demonstrate that embeddings from intermediate layers are highly effective for SR, comparable to those from final layers, while being significantly more efficient to compute. Our findings underscore that SR alleviates the structural limitations of decoders, enabling more efficient and adaptable LMs and broadening their applicability to other token-level tasks.", "AI": {"tldr": "\u5e8f\u5217\u91cd\u590d\uff08SR\uff09\u662f\u4e00\u79cd\u975e\u4fb5\u5165\u6027\u65b9\u6cd5\uff0c\u4f7f\u4ec5\u89e3\u7801\u5668\u6a21\u578b\u5177\u5907\u53cc\u5411\u6027\uff0c\u63d0\u5347\u5e8f\u5217\u6807\u6ce8\u4efb\u52a1\u6027\u80fd\uff0c\u8d85\u8d8a\u7f16\u7801\u5668\u548c\u65e0\u63a9\u7801\u89e3\u7801\u5668", "motivation": "\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u662f\u81ea\u56de\u5f52\u8bad\u7ec3\u7684\uff0c\u4ec5\u57fa\u4e8e\u524d\u7f00\u6761\u4ef6\uff0c\u800c\u5e8f\u5217\u6807\u6ce8\u4efb\u52a1\u9700\u8981\u53cc\u5411\u4e0a\u4e0b\u6587\u3002\u867d\u7136\u79fb\u9664\u56e0\u679c\u63a9\u7801\u53ef\u4f7f\u89e3\u7801\u5668\u6a21\u578b\u9002\u5e94\u5e8f\u5217\u6807\u6ce8\uff0c\u4f46\u9700\u8981\u5927\u91cf\u4fee\u6539\u57fa\u7840\u6a21\u578b\u529f\u80fd\u3002\u672c\u7814\u7a76\u63a2\u7d22\u5e8f\u5217\u91cd\u590d\u4f5c\u4e3a\u66f4\u5c11\u4fb5\u5165\u6027\u7684\u66ff\u4ee3\u65b9\u6848", "method": "\u63d0\u51fa\u5e8f\u5217\u91cd\u590d\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u590d\u8f93\u5165\u5e8f\u5217\u4f7f\u4ec5\u89e3\u7801\u5668\u6a21\u578b\u5177\u5907\u53cc\u5411\u6027\u3002\u901a\u8fc7\u5fae\u8c03\u5b9e\u9a8c\u9a8c\u8bc1\u8be5\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e0d\u540c\u91cd\u590d\u6b21\u6570\u7684\u5f71\u54cd\uff0c\u5e76\u5206\u6790\u4e2d\u95f4\u5c42\u4e0e\u6700\u7ec8\u5c42\u5d4c\u5165\u7684\u6709\u6548\u6027", "result": "\u5e8f\u5217\u91cd\u590d\u4f7f\u89e3\u7801\u5668\u5177\u5907\u5185\u5728\u53cc\u5411\u6027\uff0c\u63d0\u5347\u8bcd\u7ea7\u5d4c\u5165\u8d28\u91cf\uff0c\u8d85\u8d8a\u7f16\u7801\u5668\u548c\u65e0\u63a9\u7801\u89e3\u7801\u5668\u3002\u589e\u52a0\u91cd\u590d\u6b21\u6570\u4e0d\u4f1a\u964d\u4f4e\u5e8f\u5217\u6807\u6ce8\u6027\u80fd\u3002\u4e2d\u95f4\u5c42\u5d4c\u5165\u4e0e\u6700\u7ec8\u5c42\u5d4c\u5165\u6548\u679c\u76f8\u5f53\uff0c\u4f46\u8ba1\u7b97\u6548\u7387\u663e\u8457\u66f4\u9ad8", "conclusion": "\u5e8f\u5217\u91cd\u590d\u7f13\u89e3\u4e86\u89e3\u7801\u5668\u7684\u7ed3\u6784\u9650\u5236\uff0c\u4f7f\u8bed\u8a00\u6a21\u578b\u66f4\u9ad8\u6548\u3001\u9002\u5e94\u6027\u66f4\u5f3a\uff0c\u62d3\u5bbd\u4e86\u5176\u5728\u8bcd\u7ea7\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u8303\u56f4"}}
{"id": "2601.17923", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17923", "abs": "https://arxiv.org/abs/2601.17923", "authors": ["Ali Najar"], "title": "Learning Transferable Skills in Action RPGs via Directed Skill Graphs and Selective Adaptation", "comment": "5 pages", "summary": "Lifelong agents should expand their competence over time without retraining from scratch or overwriting previously learned behaviors. We investigate this in a challenging real-time control setting (Dark Souls III) by representing combat as a directed skill graph and training its components in a hierarchical curriculum. The resulting agent decomposes control into five reusable skills: camera control, target lock-on, movement, dodging, and a heal-attack decision policy, each optimized for a narrow responsibility. This factorization improves sample efficiency by reducing the burden on any single policy and supports selective post-training: when the environment shifts from Phase 1 to Phase 2, only a subset of skills must be adapted, while upstream skills remain transferable. Empirically, we find that targeted fine-tuning of just two skills rapidly recovers performance under a limited interaction budget, suggesting that skill-graph curricula together with selective fine-tuning offer a practical pathway toward evolving, continually learning agents in complex real-time environments.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6280\u80fd\u56fe\u7684\u5206\u5c42\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u590d\u6742\u5b9e\u65f6\u73af\u5883\uff08\u9ed1\u6697\u4e4b\u9b42III\uff09\u4e2d\u8bad\u7ec3\u7ec8\u8eab\u5b66\u4e60\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u6280\u80fd\u5206\u89e3\u548c\u9009\u62e9\u6027\u5fae\u8c03\u5b9e\u73b0\u9ad8\u6548\u9002\u5e94\u73af\u5883\u53d8\u5316\u3002", "motivation": "\u7ec8\u8eab\u5b66\u4e60\u667a\u80fd\u4f53\u9700\u8981\u5728\u4e0d\u4ece\u5934\u8bad\u7ec3\u6216\u8986\u76d6\u5df2\u5b66\u884c\u4e3a\u7684\u60c5\u51b5\u4e0b\u6269\u5c55\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u5b9e\u65f6\u63a7\u5236\u73af\u5883\u4e2d\u3002\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u5982\u4f55\u5728\u73af\u5883\u53d8\u5316\u65f6\u9ad8\u6548\u9002\u5e94\uff0c\u540c\u65f6\u4fdd\u6301\u5148\u524d\u5b66\u5230\u7684\u6280\u80fd\u3002", "method": "\u5c06\u6218\u6597\u8868\u793a\u4e3a\u6709\u5411\u6280\u80fd\u56fe\uff0c\u91c7\u7528\u5206\u5c42\u8bfe\u7a0b\u8bad\u7ec3\u65b9\u6cd5\u3002\u5c06\u63a7\u5236\u5206\u89e3\u4e3a\u4e94\u4e2a\u53ef\u91cd\u7528\u6280\u80fd\uff1a\u76f8\u673a\u63a7\u5236\u3001\u76ee\u6807\u9501\u5b9a\u3001\u79fb\u52a8\u3001\u95ea\u907f\u548c\u6cbb\u7597-\u653b\u51fb\u51b3\u7b56\u7b56\u7565\uff0c\u6bcf\u4e2a\u6280\u80fd\u9488\u5bf9\u7279\u5b9a\u804c\u8d23\u4f18\u5316\u3002\u5f53\u73af\u5883\u4ece\u7b2c\u4e00\u9636\u6bb5\u53d8\u4e3a\u7b2c\u4e8c\u9636\u6bb5\u65f6\uff0c\u4ec5\u5bf9\u90e8\u5206\u6280\u80fd\u8fdb\u884c\u9009\u62e9\u6027\u5fae\u8c03\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4ec5\u5bf9\u4e24\u4e2a\u6280\u80fd\u8fdb\u884c\u9488\u5bf9\u6027\u5fae\u8c03\u5c31\u80fd\u5728\u6709\u9650\u4ea4\u4e92\u9884\u7b97\u4e0b\u5feb\u901f\u6062\u590d\u6027\u80fd\u3002\u6280\u80fd\u5206\u89e3\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\uff0c\u51cf\u5c11\u4e86\u5355\u4e2a\u7b56\u7565\u7684\u8d1f\u62c5\uff0c\u4e0a\u6e38\u6280\u80fd\u4fdd\u6301\u53ef\u8fc1\u79fb\u6027\u3002", "conclusion": "\u6280\u80fd\u56fe\u8bfe\u7a0b\u4e0e\u9009\u62e9\u6027\u5fae\u8c03\u76f8\u7ed3\u5408\uff0c\u4e3a\u590d\u6742\u5b9e\u65f6\u73af\u5883\u4e2d\u6f14\u5316\u3001\u6301\u7eed\u5b66\u4e60\u7684\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002\u8fd9\u79cd\u5206\u89e3\u65b9\u6cd5\u652f\u6301\u9ad8\u6548\u9002\u5e94\u73af\u5883\u53d8\u5316\uff0c\u540c\u65f6\u4fdd\u6301\u5df2\u5b66\u6280\u80fd\u7684\u53ef\u7528\u6027\u3002"}}
{"id": "2601.17593", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17593", "abs": "https://arxiv.org/abs/2601.17593", "authors": ["Tianjun Zhong", "Linyang He", "Nima Mesgarani"], "title": "From Chains to DAGs: Probing the Graph Structure of Reasoning in LLMs", "comment": null, "summary": "Recent progress in large language models has renewed interest in mechanistically characterizing how multi-step reasoning is represented and computed. While much prior work treats reasoning as a linear chain of steps, many reasoning problems are more naturally structured as directed acyclic graphs (DAGs), where intermediate conclusions may depend on multiple premises, branch into parallel sub-derivations, and later merge or be reused. Understanding whether such graph-structured reasoning is reflected in model internals remains an open question.\n  In this work, we introduce Reasoning DAG Probing, a framework that directly asks whether LLM hidden states encode the geometry of a reasoning DAG in a linearly accessible form, and where this structure emerges across layers. Within this framework, we associate each reasoning node with a textual realization and train lightweight probes to predict two graph-theoretic properties from hidden states: node depth and pairwise node distance. We use these probes to analyze the layerwise emergence of DAG structure and evaluate controls that disrupt reasoning-relevant structure while preserving superficial textual properties. Our results provide evidence that reasoning DAG geometry is meaningfully encoded in intermediate layers, with recoverability varying systematically by node depth and model scale, suggesting that LLM reasoning is not only sequential but exhibits measurable internal graph structure.", "AI": {"tldr": "LLM\u9690\u85cf\u72b6\u6001\u7f16\u7801\u63a8\u7406\u6709\u5411\u65e0\u73af\u56fe\u7ed3\u6784\uff0c\u53ef\u901a\u8fc7\u8f7b\u91cf\u7ea7\u63a2\u9488\u9884\u6d4b\u8282\u70b9\u6df1\u5ea6\u548c\u8ddd\u79bb\uff0c\u63ed\u793a\u63a8\u7406\u5185\u90e8\u56fe\u7ed3\u6784", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5c06\u63a8\u7406\u89c6\u4e3a\u7ebf\u6027\u94fe\uff0c\u4f46\u8bb8\u591a\u63a8\u7406\u95ee\u9898\u66f4\u9002\u5408\u7528\u6709\u5411\u65e0\u73af\u56fe\u8868\u793a\uff0c\u5176\u4e2d\u4e2d\u95f4\u7ed3\u8bba\u4f9d\u8d56\u591a\u4e2a\u524d\u63d0\u3001\u5206\u652f\u5e76\u884c\u63a8\u5bfc\u3001\u540e\u671f\u5408\u5e76\u6216\u91cd\u7528\u3002\u7406\u89e3\u6a21\u578b\u5185\u90e8\u662f\u5426\u53cd\u6620\u8fd9\u79cd\u56fe\u7ed3\u6784\u63a8\u7406\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u63a8\u7406DAG\u63a2\u6d4b\u6846\u67b6\uff0c\u5c06\u6bcf\u4e2a\u63a8\u7406\u8282\u70b9\u4e0e\u6587\u672c\u5b9e\u73b0\u5173\u8054\uff0c\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u63a2\u9488\u4ece\u9690\u85cf\u72b6\u6001\u9884\u6d4b\u4e24\u4e2a\u56fe\u8bba\u5c5e\u6027\uff1a\u8282\u70b9\u6df1\u5ea6\u548c\u6210\u5bf9\u8282\u70b9\u8ddd\u79bb\u3002\u5206\u6790DAG\u7ed3\u6784\u7684\u5c42\u7ea7\u6d8c\u73b0\uff0c\u5e76\u8bc4\u4f30\u7834\u574f\u63a8\u7406\u76f8\u5173\u7ed3\u6784\u4f46\u4fdd\u7559\u8868\u9762\u6587\u672c\u5c5e\u6027\u7684\u63a7\u5236\u6761\u4ef6\u3002", "result": "\u7ed3\u679c\u8868\u660e\u63a8\u7406DAG\u51e0\u4f55\u5728\u4e2d\u95f4\u5c42\u6709\u610f\u4e49\u5730\u7f16\u7801\uff0c\u53ef\u6062\u590d\u6027\u968f\u8282\u70b9\u6df1\u5ea6\u548c\u6a21\u578b\u89c4\u6a21\u7cfb\u7edf\u6027\u53d8\u5316\uff0c\u8868\u660eLLM\u63a8\u7406\u4e0d\u4ec5\u662f\u987a\u5e8f\u7684\uff0c\u800c\u4e14\u8868\u73b0\u51fa\u53ef\u6d4b\u91cf\u7684\u5185\u90e8\u56fe\u7ed3\u6784\u3002", "conclusion": "LLM\u63a8\u7406\u5185\u90e8\u5b58\u5728\u53ef\u63a2\u6d4b\u7684\u56fe\u7ed3\u6784\uff0c\u63a8\u7406DAG\u51e0\u4f55\u5728\u9690\u85cf\u72b6\u6001\u4e2d\u4ee5\u7ebf\u6027\u53ef\u8bbf\u95ee\u5f62\u5f0f\u7f16\u7801\uff0c\u8fd9\u4e3a\u7406\u89e3\u590d\u6742\u63a8\u7406\u7684\u673a\u5236\u8868\u5f81\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2601.17942", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2601.17942", "abs": "https://arxiv.org/abs/2601.17942", "authors": ["Yu-Jie Yang", "Hung-Fu Chang", "Po-An Chen"], "title": "LLM-Based SQL Generation: Prompting, Self-Refinement, and Adaptive Weighted Majority Voting", "comment": "29 pages, 22 figures", "summary": "Text-to-SQL has emerged as a prominent research area, particularly with the rapid advancement of large language models (LLMs). By enabling users to query databases through natural language rather than SQL, this technology significantly lowers the barrier to data analysis. However, generating accurate SQL from natural language remains challenging due to ambiguity in user queries, the complexity of schema linking, limited generalization across SQL dialects, and the need for domain-specific understanding. In this study, we propose a Single-Agent Self-Refinement with Ensemble Voting (SSEV) pipeline built on PET-SQL that operates without ground-truth data, integrating self-refinement with Weighted Majority Voting (WMV) and its randomized variant (RWMA). Experimental results show that the SSEV achieves competitive performance across multiple benchmarks, attaining execution accuracies of 85.5% on Spider 1.0-Dev, 86.4% on Spider 1.0-Test, and 66.3% on BIRD-Dev. Building on insights from the SSEV pipeline, we further propose ReCAPAgent-SQL (Refinement-Critique-Act-Plan agent-based SQL framework) to address the growing complexity of enterprise databases and real-world Text-to-SQL tasks. The framework integrates multiple specialized agents for planning, external knowledge retrieval, critique, action generation, self-refinement, schema linking, and result validation, enabling iterative refinement of SQL predictions through agent collaboration. ReCAPAgent-SQL's WMA results achieve 31% execution accuracy on the first 100 queries of Spider 2.0-Lite, demonstrating significant improvements in handling real-world enterprise scenarios. Overall, our work facilitates the deployment of scalable Text-to-SQL systems in practical settings, supporting better data-driven decision-making at lower cost and with greater efficiency.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e24\u79cdText-to-SQL\u65b9\u6cd5\uff1aSSEV\uff08\u5355\u667a\u80fd\u4f53\u81ea\u7cbe\u70bc\u96c6\u6210\u6295\u7968\uff09\u7ba1\u9053\u548cReCAPAgent-SQL\uff08\u57fa\u4e8e\u667a\u80fd\u4f53\u7684SQL\u6846\u67b6\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u5230SQL\u8f6c\u6362\u4e2d\u7684\u6311\u6218\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u7ade\u4e89\u6027\u6027\u80fd\u3002", "motivation": "Text-to-SQL\u6280\u672f\u867d\u7136\u964d\u4f4e\u4e86\u6570\u636e\u5206\u6790\u95e8\u69db\uff0c\u4f46\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u7684\u6b67\u4e49\u6027\u3001\u6a21\u5f0f\u94fe\u63a5\u7684\u590d\u6742\u6027\u3001SQL\u65b9\u8a00\u7684\u6cdb\u5316\u9650\u5236\u4ee5\u53ca\u9886\u57df\u7279\u5b9a\u7406\u89e3\u7684\u9700\u6c42\u4f7f\u5f97\u751f\u6210\u51c6\u786eSQL\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u9700\u8981\u5f00\u53d1\u66f4\u5f3a\u5927\u7684\u65b9\u6cd5\u6765\u5904\u7406\u4f01\u4e1a\u6570\u636e\u5e93\u548c\u771f\u5b9e\u4e16\u754cText-to-SQL\u4efb\u52a1\u7684\u590d\u6742\u6027\u3002", "method": "1. SSEV\u7ba1\u9053\uff1a\u57fa\u4e8ePET-SQL\u6784\u5efa\uff0c\u65e0\u9700\u771f\u5b9e\u6570\u636e\uff0c\u96c6\u6210\u81ea\u7cbe\u70bc\u4e0e\u52a0\u6743\u591a\u6570\u6295\u7968\uff08WMV\uff09\u53ca\u5176\u968f\u673a\u53d8\u4f53\uff08RWMA\uff09\u30022. ReCAPAgent-SQL\u6846\u67b6\uff1a\u57fa\u4e8e\u667a\u80fd\u4f53\u7684SQL\u6846\u67b6\uff0c\u96c6\u6210\u591a\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53\uff08\u89c4\u5212\u3001\u5916\u90e8\u77e5\u8bc6\u68c0\u7d22\u3001\u6279\u5224\u3001\u52a8\u4f5c\u751f\u6210\u3001\u81ea\u7cbe\u70bc\u3001\u6a21\u5f0f\u94fe\u63a5\u3001\u7ed3\u679c\u9a8c\u8bc1\uff09\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u534f\u4f5c\u5b9e\u73b0SQL\u9884\u6d4b\u7684\u8fed\u4ee3\u7cbe\u70bc\u3002", "result": "SSEV\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u7ade\u4e89\u6027\u6027\u80fd\uff1aSpider 1.0-Dev\u6267\u884c\u51c6\u786e\u738785.5%\uff0cSpider 1.0-Test 86.4%\uff0cBIRD-Dev 66.3%\u3002ReCAPAgent-SQL\u5728Spider 2.0-Lite\u524d100\u4e2a\u67e5\u8be2\u4e2d\u8fbe\u523031%\u7684\u6267\u884c\u51c6\u786e\u7387\uff0c\u5728\u5904\u7406\u771f\u5b9e\u4e16\u754c\u4f01\u4e1a\u573a\u666f\u65b9\u9762\u663e\u793a\u51fa\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u65b9\u6cd5\u4fc3\u8fdb\u4e86\u53ef\u6269\u5c55Text-to-SQL\u7cfb\u7edf\u5728\u5b9e\u9645\u73af\u5883\u4e2d\u7684\u90e8\u7f72\uff0c\u652f\u6301\u4ee5\u66f4\u4f4e\u6210\u672c\u548c\u66f4\u9ad8\u6548\u7387\u8fdb\u884c\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u3002\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\u7279\u522b\u9002\u5408\u5904\u7406\u590d\u6742\u7684\u4f01\u4e1a\u6570\u636e\u5e93\u573a\u666f\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17596", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17596", "abs": "https://arxiv.org/abs/2601.17596", "authors": ["Yunxiang Zhang", "Kang Zhou", "Zhichao Xu", "Kiran Ramnath", "Yun Zhou", "Sangmin Woo", "Haibo Ding", "Lin Lee Cheong"], "title": "Learning to Ideate for Machine Learning Engineering Agents", "comment": "EACL 2026 main conference", "summary": "Existing machine learning engineering (MLE) agents struggle to iteratively optimize their implemented algorithms for effectiveness. To address this, we introduce MLE-Ideator, a dual-agent framework that separates ideation from implementation. In our system, an implementation agent can request strategic help from a dedicated Ideator. We show this approach is effective in two ways. First, in a training-free setup, our framework significantly outperforms implementation-only agent baselines on MLE-Bench. Second, we demonstrate that the Ideator can be trained with reinforcement learning (RL) to generate more effective ideas. With only 1K training samples from 10 MLE tasks, our RL-trained Qwen3-8B Ideator achieves an 11.5% relative improvement compared to its untrained counterpart and surpasses Claude Sonnet 3.5. These results highlights a promising path toward training strategic AI systems for scientific discovery.", "AI": {"tldr": "MLE-Ideator\uff1a\u53cc\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u6784\u601d\u4e0e\u5b9e\u73b0\u5206\u79bb\uff0c\u901a\u8fc7\u4e13\u95e8\u7684\u6784\u601d\u5668\u5e2e\u52a9\u5b9e\u73b0\u667a\u80fd\u4f53\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\uff0c\u5728MLE-Bench\u4e0a\u663e\u8457\u4f18\u4e8e\u4ec5\u5b9e\u73b0\u667a\u80fd\u4f53\u57fa\u7ebf\uff0c\u4e14\u6784\u601d\u5668\u53ef\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\uff08MLE\uff09\u667a\u80fd\u4f53\u5728\u8fed\u4ee3\u4f18\u5316\u7b97\u6cd5\u6548\u679c\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u9700\u8981\u5206\u79bb\u6784\u601d\u4e0e\u5b9e\u73b0\u8fc7\u7a0b\u4ee5\u63d0\u9ad8\u4f18\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faMLE-Ideator\u53cc\u667a\u80fd\u4f53\u6846\u67b6\uff1a\u5b9e\u73b0\u667a\u80fd\u4f53\u8d1f\u8d23\u7b97\u6cd5\u5b9e\u65bd\uff0c\u6784\u601d\u667a\u80fd\u4f53\u4e13\u95e8\u63d0\u4f9b\u6218\u7565\u5e2e\u52a9\uff1b\u6784\u601d\u5668\u53ef\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u4ec5\u97001K\u8bad\u7ec3\u6837\u672c\u5373\u53ef\u63d0\u5347\u6027\u80fd\u3002", "result": "1. \u5728\u65e0\u9700\u8bad\u7ec3\u7684\u8bbe\u7f6e\u4e0b\uff0c\u6846\u67b6\u5728MLE-Bench\u4e0a\u663e\u8457\u4f18\u4e8e\u4ec5\u5b9e\u73b0\u667a\u80fd\u4f53\u57fa\u7ebf\uff1b2. \u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684Qwen3-8B\u6784\u601d\u5668\u76f8\u6bd4\u672a\u8bad\u7ec3\u7248\u672c\u5b9e\u73b011.5%\u76f8\u5bf9\u63d0\u5347\uff0c\u5e76\u8d85\u8d8aClaude Sonnet 3.5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8bad\u7ec3\u6218\u7565AI\u7cfb\u7edf\u8fdb\u884c\u79d1\u5b66\u53d1\u73b0\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u8def\u5f84\uff0c\u901a\u8fc7\u5206\u79bb\u6784\u601d\u4e0e\u5b9e\u73b0\u5e76\u8bad\u7ec3\u6784\u601d\u5668\uff0c\u80fd\u6709\u6548\u63d0\u5347\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u4efb\u52a1\u7684\u8fed\u4ee3\u4f18\u5316\u80fd\u529b\u3002"}}
{"id": "2601.17609", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17609", "abs": "https://arxiv.org/abs/2601.17609", "authors": ["Sara Rezaeimanesh", "Mohammad M. Ghassemi"], "title": "What Language Models Know But Don't Say: Non-Generative Prior Extraction for Generalization", "comment": null, "summary": "In domains like medicine and finance, large-scale labeled data is costly and often unavailable, leading to models trained on small datasets that struggle to generalize to real-world populations. Large language models contain extensive knowledge from years of research across these domains. We propose LoID (Logit-Informed Distributions), a deterministic method for extracting informative prior distributions for Bayesian logistic regression by directly accessing their token-level predictions. Rather than relying on generated text, we probe the model's confidence in opposing semantic directions (positive vs. negative impact) through carefully constructed sentences. By measuring how consistently the LLM favors one direction across diverse phrasings, we extract the strength and reliability of the model's belief about each feature's influence. We evaluate LoID on ten real-world tabular datasets under synthetic out-of-distribution (OOD) settings characterized by covariate shift, where the training data represents only a subset of the population. We compare our approach against (1) standard uninformative priors, (2) AutoElicit, a recent method that prompts LLMs to generate priors via text completions, (3) LLMProcesses, a method that uses LLMs to generate numerical predictions through in-context learning and (4) an oracle-style upper bound derived from fitting logistic regression on the full dataset. We assess performance using Area Under the Curve (AUC). Across datasets, LoID significantly improves performance over logistic regression trained on OOD data, recovering up to \\textbf{59\\%} of the performance gap relative to the oracle model. LoID outperforms AutoElicit and LLMProcessesc on 8 out of 10 datasets, while providing a reproducible and computationally efficient mechanism for integrating LLM knowledge into Bayesian inference.", "AI": {"tldr": "LoID\uff1a\u4e00\u79cd\u786e\u5b9a\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u76f4\u63a5\u8bbf\u95eeLLM\u7684token\u7ea7\u9884\u6d4b\u6765\u63d0\u53d6\u8d1d\u53f6\u65af\u903b\u8f91\u56de\u5f52\u7684\u4fe1\u606f\u5148\u9a8c\u5206\u5e03\uff0c\u5728\u534f\u53d8\u91cf\u504f\u79fb\u7684OOD\u8bbe\u7f6e\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd", "motivation": "\u5728\u533b\u5b66\u548c\u91d1\u878d\u7b49\u9886\u57df\uff0c\u5927\u89c4\u6a21\u6807\u6ce8\u6570\u636e\u6210\u672c\u9ad8\u6602\u4e14\u901a\u5e38\u4e0d\u53ef\u5f97\uff0c\u5bfc\u81f4\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u96be\u4ee5\u6cdb\u5316\u5230\u771f\u5b9e\u4e16\u754c\u4eba\u7fa4\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5305\u542b\u8fd9\u4e9b\u9886\u57df\u591a\u5e74\u7814\u7a76\u7684\u5e7f\u6cdb\u77e5\u8bc6\uff0c\u4f46\u5982\u4f55\u6709\u6548\u63d0\u53d6\u8fd9\u4e9b\u77e5\u8bc6\u7528\u4e8e\u7edf\u8ba1\u6a21\u578b\u4ecd\u5177\u6311\u6218\u3002", "method": "LoID\u901a\u8fc7\u7cbe\u5fc3\u6784\u9020\u7684\u53e5\u5b50\u63a2\u6d4bLLM\u5728\u76f8\u53cd\u8bed\u4e49\u65b9\u5411\uff08\u6b63\u9762vs\u8d1f\u9762\u5f71\u54cd\uff09\u4e0a\u7684\u7f6e\u4fe1\u5ea6\uff0c\u6d4b\u91cfLLM\u5728\u4e0d\u540c\u8868\u8ff0\u4e2d\u4e00\u81f4\u504f\u597d\u67d0\u4e00\u65b9\u5411\u7684\u7a0b\u5ea6\uff0c\u4ece\u800c\u63d0\u53d6\u6a21\u578b\u5bf9\u6bcf\u4e2a\u7279\u5f81\u5f71\u54cd\u7684\u5f3a\u5ea6\u548c\u53ef\u9760\u6027\u7684\u4fe1\u5ff5\u3002\u8be5\u65b9\u6cd5\u76f4\u63a5\u8bbf\u95eetoken\u7ea7\u9884\u6d4b\u800c\u975e\u4f9d\u8d56\u751f\u6210\u6587\u672c\u3002", "result": "\u572810\u4e2a\u771f\u5b9e\u4e16\u754c\u8868\u683c\u6570\u636e\u96c6\u4e0a\uff0c\u5728\u534f\u53d8\u91cf\u504f\u79fb\u7684\u5408\u6210OOD\u8bbe\u7f6e\u4e0b\uff0cLoID\u663e\u8457\u63d0\u5347\u4e86\u5728OOD\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u903b\u8f91\u56de\u5f52\u6027\u80fd\uff0c\u6062\u590d\u4e86\u9ad8\u8fbe59%\u76f8\u5bf9\u4e8e\u5168\u6570\u636e\u96c6\u62df\u5408\u7684oracle\u6a21\u578b\u7684\u6027\u80fd\u5dee\u8ddd\u3002\u57288/10\u6570\u636e\u96c6\u4e0a\u4f18\u4e8eAutoElicit\u548cLLMProcesses\u65b9\u6cd5\u3002", "conclusion": "LoID\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u91cd\u590d\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u673a\u5236\uff0c\u5c06LLM\u77e5\u8bc6\u6574\u5408\u5230\u8d1d\u53f6\u65af\u63a8\u65ad\u4e2d\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u4e14\u5b58\u5728\u534f\u53d8\u91cf\u504f\u79fb\u7684\u573a\u666f\u4e0b\uff0c\u80fd\u591f\u6709\u6548\u5229\u7528LLM\u7684\u9886\u57df\u77e5\u8bc6\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2601.18061", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.18061", "abs": "https://arxiv.org/abs/2601.18061", "authors": ["Kiana Jafari", "Paul Ulrich Nikolaus Rust", "Duncan Eddy", "Robbie Fraser", "Nina Vasan", "Darja Djordjevic", "Akanksha Dadlani", "Max Lamparth", "Eugenia Kim", "Mykel Kochenderfer"], "title": "Expert Evaluation and the Limits of Human Feedback in Mental Health AI Safety Testing", "comment": "17 pages, 7 pages of appendix, 21 tables", "summary": "Learning from human feedback~(LHF) assumes that expert judgments, appropriately aggregated, yield valid ground truth for training and evaluating AI systems. We tested this assumption in mental health, where high safety stakes make expert consensus essential. Three certified psychiatrists independently evaluated LLM-generated responses using a calibrated rubric. Despite similar training and shared instructions, inter-rater reliability was consistently poor ($ICC$ $0.087$--$0.295$), falling below thresholds considered acceptable for consequential assessment. Disagreement was highest on the most safety-critical items. Suicide and self-harm responses produced greater divergence than any other category, and was systematic rather than random. One factor yielded negative reliability (Krippendorff's $\u03b1= -0.203$), indicating structured disagreement worse than chance. Qualitative interviews revealed that disagreement reflects coherent but incompatible individual clinical frameworks, safety-first, engagement-centered, and culturally-informed orientations, rather than measurement error. By demonstrating that experts rely on holistic risk heuristics rather than granular factor discrimination, these findings suggest that aggregated labels function as arithmetic compromises that effectively erase grounded professional philosophies. Our results characterize expert disagreement in safety-critical AI as a sociotechnical phenomenon where professional experience introduces sophisticated layers of principled divergence. We discuss implications for reward modeling, safety classification, and evaluation benchmarks, recommending that practitioners shift from consensus-based aggregation to alignment methods that preserve and learn from expert disagreement.", "AI": {"tldr": "\u4e13\u5bb6\u5728\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u5bf9AI\u751f\u6210\u54cd\u5e94\u7684\u8bc4\u4f30\u5b58\u5728\u7cfb\u7edf\u6027\u5206\u6b67\uff0c\u5c24\u5176\u662f\u5728\u5b89\u5168\u5173\u952e\u9879\u76ee\u4e0a\uff0c\u4e00\u81f4\u6027\u4f4e\u4e8e\u53ef\u63a5\u53d7\u9608\u503c\uff0c\u8868\u660e\u57fa\u4e8e\u5171\u8bc6\u7684\u805a\u5408\u65b9\u6cd5\u5b58\u5728\u95ee\u9898", "motivation": "\u9a8c\u8bc1\u5b66\u4e60\u4eba\u7c7b\u53cd\u9988(LHF)\u7684\u57fa\u672c\u5047\u8bbe\u2014\u2014\u4e13\u5bb6\u5224\u65ad\u7ecf\u8fc7\u9002\u5f53\u805a\u5408\u540e\u80fd\u63d0\u4f9b\u6709\u6548\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30\u57fa\u7840\u3002\u5728\u5fc3\u7406\u5065\u5eb7\u8fd9\u4e00\u5b89\u5168\u8981\u6c42\u6781\u9ad8\u7684\u9886\u57df\uff0c\u4e13\u5bb6\u5171\u8bc6\u5c24\u4e3a\u91cd\u8981", "method": "\u4e09\u4f4d\u8ba4\u8bc1\u7cbe\u795e\u79d1\u533b\u751f\u4f7f\u7528\u6821\u51c6\u7684\u8bc4\u5206\u6807\u51c6\u72ec\u7acb\u8bc4\u4f30LLM\u751f\u6210\u7684\u54cd\u5e94\uff1b\u901a\u8fc7\u5b9a\u91cf\u5206\u6790\u8bc4\u4f30\u8005\u95f4\u4fe1\u5ea6\uff08ICC\u3001Krippendorff's \u03b1\uff09\uff0c\u5e76\u8fdb\u884c\u5b9a\u6027\u8bbf\u8c08\u4e86\u89e3\u5206\u6b67\u539f\u56e0", "result": "\u8bc4\u4f30\u8005\u95f4\u4fe1\u5ea6\u6301\u7eed\u8f83\u5dee\uff08ICC 0.087-0.295\uff09\uff0c\u4f4e\u4e8e\u53ef\u63a5\u53d7\u9608\u503c\uff1b\u81ea\u6740\u548c\u81ea\u6b8b\u7c7b\u522b\u7684\u5206\u6b67\u6700\u5927\uff1b\u4e00\u4e2a\u56e0\u7d20\u7684\u4fe1\u5ea6\u7cfb\u6570\u4e3a\u8d1f\uff08\u03b1=-0.203\uff09\uff0c\u8868\u660e\u5b58\u5728\u7ed3\u6784\u5316\u5206\u6b67\uff1b\u5206\u6b67\u6e90\u4e8e\u4e0d\u540c\u7684\u4e34\u5e8a\u6846\u67b6\u800c\u975e\u6d4b\u91cf\u8bef\u5dee", "conclusion": "\u4e13\u5bb6\u5206\u6b67\u662f\u539f\u5219\u6027\u7684\u793e\u4f1a\u6280\u672f\u73b0\u8c61\uff0c\u53cd\u6620\u4e86\u4e0d\u540c\u7684\u4e13\u4e1a\u54f2\u5b66\uff1b\u57fa\u4e8e\u5171\u8bc6\u7684\u805a\u5408\u65b9\u6cd5\u4f1a\u62b9\u6740\u4e13\u4e1a\u5224\u65ad\u7684\u591a\u6837\u6027\uff1b\u5efa\u8bae\u4ece\u5171\u8bc6\u805a\u5408\u8f6c\u5411\u80fd\u591f\u4fdd\u7559\u548c\u5b66\u4e60\u4e13\u5bb6\u5206\u6b67\u7684\u5bf9\u9f50\u65b9\u6cd5"}}
{"id": "2601.17658", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17658", "abs": "https://arxiv.org/abs/2601.17658", "authors": ["Bich Ngoc", "Doan", "Giuseppe Russo", "Gianmarco De Francisci Morales", "Robert West"], "title": "Beyond the Rabbit Hole: Mapping the Relational Harms of QAnon Radicalization", "comment": null, "summary": "The rise of conspiracy theories has created far-reaching societal harm in the public discourse by eroding trust and fueling polarization. Beyond this public impact lies a deeply personal toll on the friends and families of conspiracy believers, a dimension often overlooked in large-scale computational research. This study fills this gap by systematically mapping radicalization journeys and quantifying the associated emotional toll inflicted on loved ones. We use the prominent case of QAnon as a case study, analyzing 12747 narratives from the r/QAnonCasualties support community through a novel mixed-methods approach. First, we use topic modeling (BERTopic) to map the radicalization trajectories, identifying key pre-existing conditions, triggers, and post-radicalization characteristics. From this, we apply an LDA-based graphical model to uncover six recurring archetypes of QAnon adherents, which we term \"radicalization personas.\" Finally, using LLM-assisted emotion detection and regression modeling, we link these personas to the specific emotional toll reported by narrators. Our findings reveal that these personas are not just descriptive; they are powerful predictors of the specific emotional harms experienced by narrators. Radicalization perceived as a deliberate ideological choice is associated with narrator anger and disgust, while those marked by personal and cognitive collapse are linked to fear and sadness. This work provides the first empirical framework for understanding radicalization as a relational phenomenon, offering a vital roadmap for researchers and practitioners to navigate its interpersonal fallout.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790QAnon\u652f\u6301\u793e\u533a\u4e2d\u768412747\u4e2a\u53d9\u4e8b\uff0c\u7cfb\u7edf\u6027\u5730\u7ed8\u5236\u4e86\u9634\u8c0b\u8bba\u4fe1\u5f92\u7684\u6fc0\u8fdb\u5316\u8f68\u8ff9\uff0c\u8bc6\u522b\u4e86\u516d\u79cd\u6fc0\u8fdb\u5316\u4eba\u683c\u7c7b\u578b\uff0c\u5e76\u91cf\u5316\u4e86\u8fd9\u4e9b\u7c7b\u578b\u5bf9\u4eb2\u53cb\u9020\u6210\u7684\u7279\u5b9a\u60c5\u611f\u4f24\u5bb3\u3002", "motivation": "\u73b0\u6709\u5927\u89c4\u6a21\u8ba1\u7b97\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u9634\u8c0b\u8bba\u5bf9\u516c\u5171\u8bdd\u8bed\u7684\u5b8f\u89c2\u5f71\u54cd\uff08\u5982\u4fe1\u4efb\u4fb5\u8680\u548c\u4e24\u6781\u5206\u5316\uff09\uff0c\u4f46\u5f80\u5f80\u5ffd\u89c6\u4e86\u5176\u5bf9\u4fe1\u5f92\u4eb2\u53cb\u9020\u6210\u7684\u4e2a\u4eba\u60c5\u611f\u4f24\u5bb3\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7cfb\u7edf\u6027\u5730\u7406\u89e3\u6fc0\u8fdb\u5316\u4f5c\u4e3a\u5173\u7cfb\u73b0\u8c61\u7684\u4eba\u9645\u540e\u679c\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff1a1) \u4f7f\u7528BERTopic\u4e3b\u9898\u5efa\u6a21\u5206\u679012747\u4e2ar/QAnonCasualties\u793e\u533a\u53d9\u4e8b\uff0c\u7ed8\u5236\u6fc0\u8fdb\u5316\u8f68\u8ff9\uff08\u8bc6\u522b\u524d\u5146\u6761\u4ef6\u3001\u89e6\u53d1\u56e0\u7d20\u548c\u6fc0\u8fdb\u5316\u540e\u7279\u5f81\uff09\uff1b2) \u5e94\u7528LDA\u56fe\u6a21\u578b\u8bc6\u522b\u516d\u79cd\u53cd\u590d\u51fa\u73b0\u7684QAnon\u4fe1\u5f92\u539f\u578b\uff08\"\u6fc0\u8fdb\u5316\u4eba\u683c\"\uff09\uff1b3) \u4f7f\u7528LLM\u8f85\u52a9\u7684\u60c5\u611f\u68c0\u6d4b\u548c\u56de\u5f52\u6a21\u578b\uff0c\u5c06\u8fd9\u4e9b\u4eba\u683c\u7c7b\u578b\u4e0e\u53d9\u8ff0\u8005\u62a5\u544a\u7684\u5177\u4f53\u60c5\u611f\u4f24\u5bb3\u8054\u7cfb\u8d77\u6765\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1) \u8bc6\u522b\u51fa\u516d\u79cdQAnon\u4fe1\u5f92\u7684\u6fc0\u8fdb\u5316\u4eba\u683c\u7c7b\u578b\uff1b2) \u8fd9\u4e9b\u4eba\u683c\u7c7b\u578b\u4e0d\u4ec5\u4ec5\u662f\u63cf\u8ff0\u6027\u7684\uff0c\u800c\u662f\u53d9\u8ff0\u8005\u6240\u7ecf\u5386\u7279\u5b9a\u60c5\u611f\u4f24\u5bb3\u7684\u6709\u529b\u9884\u6d4b\u56e0\u5b50\uff1b3) \u88ab\u611f\u77e5\u4e3a\u6709\u610f\u610f\u8bc6\u5f62\u6001\u9009\u62e9\u7684\u6fc0\u8fdb\u5316\u4e0e\u53d9\u8ff0\u8005\u7684\u6124\u6012\u548c\u538c\u6076\u76f8\u5173\uff0c\u800c\u4ee5\u4e2a\u4eba\u548c\u8ba4\u77e5\u5d29\u6e83\u4e3a\u7279\u5f81\u7684\u6fc0\u8fdb\u5316\u5219\u4e0e\u6050\u60e7\u548c\u60b2\u4f24\u76f8\u5173\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u63d0\u4f9b\u4e86\u7406\u89e3\u6fc0\u8fdb\u5316\u4f5c\u4e3a\u5173\u7cfb\u73b0\u8c61\u7684\u5b9e\u8bc1\u6846\u67b6\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u5e94\u5bf9\u5176\u4eba\u9645\u540e\u679c\u63d0\u4f9b\u4e86\u91cd\u8981\u8def\u7ebf\u56fe\u3002\u7814\u7a76\u63ed\u793a\u4e86\u6fc0\u8fdb\u5316\u4eba\u683c\u7c7b\u578b\u4e0e\u7279\u5b9a\u60c5\u611f\u4f24\u5bb3\u4e4b\u95f4\u7684\u7cfb\u7edf\u6027\u5173\u8054\uff0c\u5f3a\u8c03\u4e86\u4ece\u5173\u7cfb\u89d2\u5ea6\u7406\u89e3\u6fc0\u8fdb\u5316\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.18067", "categories": ["cs.AI", "cs.NE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.18067", "abs": "https://arxiv.org/abs/2601.18067", "authors": ["Wei-Po Hsin", "Ren-Hao Deng", "Yao-Ting Hsieh", "En-Ming Huang", "Shih-Hao Hung"], "title": "EvolVE: Evolutionary Search for LLM-based Verilog Generation and Optimization", "comment": "17 pages, 6 figures, 8 tables", "summary": "Verilog's design cycle is inherently labor-intensive and necessitates extensive domain expertise. Although Large Language Models (LLMs) offer a promising pathway toward automation, their limited training data and intrinsic sequential reasoning fail to capture the strict formal logic and concurrency inherent in hardware systems. To overcome these barriers, we present EvolVE, the first framework to analyze multiple evolution strategies on chip design tasks, revealing that Monte Carlo Tree Search (MCTS) excels at maximizing functional correctness, while Idea-Guided Refinement (IGR) proves superior for optimization. We further leverage Structured Testbench Generation (STG) to accelerate the evolutionary process. To address the lack of complex optimization benchmarks, we introduce IC-RTL, targeting industry-scale problems derived from the National Integrated Circuit Contest. Evaluations establish EvolVE as the new state-of-the-art, achieving 98.1% on VerilogEval v2 and 92% on RTLLM v2. Furthermore, on the industry-scale IC-RTL suite, our framework surpasses reference implementations authored by contest participants, reducing the Power, Performance, Area (PPA) product by up to 66% in Huffman Coding and 17% in the geometric mean across all problems. The source code of the IC-RTL benchmark is available at https://github.com/weiber2002/ICRTL.", "code_url": "https://github.com/weiber2002/ICRTL", "code_stars": 1, "code_last_update": "2026-01-23", "AI": {"tldr": "EvolVE\u6846\u67b6\u901a\u8fc7\u591a\u79cd\u8fdb\u5316\u7b56\u7565\u5206\u6790\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u6d4b\u8bd5\u5e73\u53f0\u751f\u6210\uff0c\u5728Verilog\u786c\u4ef6\u8bbe\u8ba1\u4efb\u52a1\u4e2d\u5b9e\u73b0\u81ea\u52a8\u5316\uff0c\u663e\u8457\u63d0\u5347\u529f\u80fd\u6b63\u786e\u6027\u548c\u4f18\u5316\u6548\u679c\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "Verilog\u8bbe\u8ba1\u6d41\u7a0b\u52b3\u52a8\u5bc6\u96c6\u4e14\u9700\u8981\u5927\u91cf\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff0c\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u56e0\u8bad\u7ec3\u6570\u636e\u6709\u9650\u548c\u987a\u5e8f\u63a8\u7406\u7279\u6027\u96be\u4ee5\u6355\u6349\u786c\u4ef6\u7cfb\u7edf\u7684\u4e25\u683c\u5f62\u5f0f\u903b\u8f91\u548c\u5e76\u53d1\u7279\u6027\uff0c\u9700\u8981\u65b0\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faEvolVE\u6846\u67b6\uff0c\u5206\u6790\u591a\u79cd\u8fdb\u5316\u7b56\u7565\uff1a\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\u7528\u4e8e\u6700\u5927\u5316\u529f\u80fd\u6b63\u786e\u6027\uff0c\u601d\u8def\u5f15\u5bfc\u7cbe\u70bc\uff08IGR\uff09\u7528\u4e8e\u4f18\u5316\uff1b\u7ed3\u5408\u7ed3\u6784\u5316\u6d4b\u8bd5\u5e73\u53f0\u751f\u6210\uff08STG\uff09\u52a0\u901f\u8fdb\u5316\u8fc7\u7a0b\uff1b\u5f15\u5165IC-RTL\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u9488\u5bf9\u5de5\u4e1a\u89c4\u6a21\u95ee\u9898\u3002", "result": "\u5728VerilogEval v2\u4e0a\u8fbe\u523098.1%\uff0cRTLLM v2\u4e0a\u8fbe\u523092%\uff1b\u5728\u5de5\u4e1a\u89c4\u6a21IC-RTL\u5957\u4ef6\u4e0a\u8d85\u8d8a\u7ade\u8d5b\u53c2\u4e0e\u8005\u53c2\u8003\u5b9e\u73b0\uff0cHuffman\u7f16\u7801\u4e2dPPA\u4e58\u79ef\u964d\u4f4e66%\uff0c\u6240\u6709\u95ee\u9898\u51e0\u4f55\u5e73\u5747\u964d\u4f4e17%\u3002", "conclusion": "EvolVE\u6846\u67b6\u901a\u8fc7\u8fdb\u5316\u7b56\u7565\u5206\u6790\u548c\u7ed3\u6784\u5316\u6d4b\u8bd5\u5e73\u53f0\u751f\u6210\uff0c\u6210\u529f\u89e3\u51b3\u4e86Verilog\u786c\u4ef6\u8bbe\u8ba1\u7684\u81ea\u52a8\u5316\u6311\u6218\uff0c\u5728\u529f\u80fd\u6b63\u786e\u6027\u548c\u4f18\u5316\u65b9\u9762\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u4e3a\u5de5\u4e1a\u89c4\u6a21\u786c\u4ef6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17664", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17664", "abs": "https://arxiv.org/abs/2601.17664", "authors": ["Syed Muhammad Ali", "Hammad Sajid", "Zainab Haider", "Ali Muhammad Asad", "Haya Fatima", "Abdul Samad"], "title": "UrduLM: A Resource-Efficient Monolingual Urdu Language Model", "comment": "12 pages", "summary": "Urdu, spoken by 230 million people worldwide, lacks dedicated transformer-based language models and curated corpora. While multilingual models provide limited Urdu support, they suffer from poor performance, high computational costs, and cultural inaccuracies due to insufficient training data. To address these challenges, we present UrduLM, a pretrained Urdu monolingual language model trained in low-resource settings. We curate a 33GB Urdu corpus from diverse sources, develop a custom BPE tokenizer that reduces tokenization overhead by atleast 20-30% compared to multilingual alternatives, and pretrain a 100M-parameter decoder-only model. In few-shot evaluations, UrduLM achieves competitive performance with multilingual models up to 30x its size, reaching 66.6% accuracy on sentiment classification and BLEU scores exceeding 30 on grammar correction tasks. The complete methodology -- including corpus, tokenizer, model weights, and evaluation benchmarks -- is released openly to establish a baseline for Urdu NLP research and provide a scalable framework for other underrepresented languages.", "AI": {"tldr": "UrduLM\uff1a\u9996\u4e2a\u4e13\u4e3a\u4e4c\u5c14\u90fd\u8bed\u8bbe\u8ba1\u7684\u5355\u8bed\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u8bad\u7ec3\uff0c\u6027\u80fd\u4e0e\u89c4\u6a21\u592730\u500d\u7684\u591a\u8bed\u8a00\u6a21\u578b\u76f8\u5f53", "motivation": "\u4e4c\u5c14\u90fd\u8bed\uff08\u5168\u74032.3\u4ebf\u4f7f\u7528\u8005\uff09\u7f3a\u4e4f\u4e13\u95e8\u7684\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u6a21\u578b\u548c\u9ad8\u8d28\u91cf\u8bed\u6599\u5e93\u3002\u73b0\u6709\u7684\u591a\u8bed\u8a00\u6a21\u578b\u5bf9\u4e4c\u5c14\u90fd\u8bed\u652f\u6301\u6709\u9650\uff0c\u5b58\u5728\u6027\u80fd\u5dee\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u6587\u5316\u4e0d\u51c6\u786e\u7b49\u95ee\u9898\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3\u3002", "method": "1. \u4ece\u591a\u6837\u5316\u6765\u6e90\u6574\u740633GB\u4e4c\u5c14\u90fd\u8bed\u8bed\u6599\u5e93\uff1b2. \u5f00\u53d1\u5b9a\u5236BPE\u5206\u8bcd\u5668\uff0c\u76f8\u6bd4\u591a\u8bed\u8a00\u66ff\u4ee3\u65b9\u6848\u51cf\u5c11\u81f3\u5c1120-30%\u7684\u5206\u8bcd\u5f00\u9500\uff1b3. \u9884\u8bad\u7ec3100M\u53c2\u6570\u7684\u4ec5\u89e3\u7801\u5668\u6a21\u578b\u3002", "result": "\u5728\u5c11\u6837\u672c\u8bc4\u4f30\u4e2d\uff0cUrduLM\u4e0e\u89c4\u6a21\u592730\u500d\u7684\u591a\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u76f8\u5f53\uff1a\u60c5\u611f\u5206\u7c7b\u51c6\u786e\u7387\u8fbe\u523066.6%\uff0c\u8bed\u6cd5\u7ea0\u6b63\u4efb\u52a1\u7684BLEU\u5206\u6570\u8d85\u8fc730\u3002", "conclusion": "\u5b8c\u6574\u7684\u65b9\u6cd5\u8bba\uff08\u5305\u62ec\u8bed\u6599\u5e93\u3001\u5206\u8bcd\u5668\u3001\u6a21\u578b\u6743\u91cd\u548c\u8bc4\u4f30\u57fa\u51c6\uff09\u5df2\u5f00\u6e90\u53d1\u5e03\uff0c\u4e3a\u4e4c\u5c14\u90fd\u8bedNLP\u7814\u7a76\u5efa\u7acb\u57fa\u7ebf\uff0c\u5e76\u4e3a\u5176\u4ed6\u8d44\u6e90\u4e0d\u8db3\u8bed\u8a00\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u6846\u67b6\u3002"}}
{"id": "2601.18119", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18119", "abs": "https://arxiv.org/abs/2601.18119", "authors": ["Jing Ye", "Yiwen Duan", "Yonghong Yu", "Victor Ma", "Yang Gao", "Xing Chen"], "title": "Beyond Text-to-SQL: Can LLMs Really Debug Enterprise ETL SQL?", "comment": null, "summary": "SQL is central to enterprise data engineering, yet generating fully correct SQL code in a single attempt remains difficult, even for experienced developers and advanced text-to-SQL LLMs, often requiring multiple debugging iterations. We introduce OurBench, the first benchmark for enterprise-level SQL reasoning and debugging. Our benchmark is built on two key innovations: (1) an automated construction workflow that uses reverse engineering to systematically inject realistic bugs into large-scale SQL code, enabling scalable and diverse benchmark generation; and (2) an execution-free evaluation framework tailored to enterprise settings, providing fast, accurate, and resource-efficient assessment.\n  OurBench comprises 469 OurBenchSyn queries featuring syntax errors with explicit error messages, and 516 OurBenchSem queries targeting semantic errors in which the code fails to meet user intent. The queries are highly complex, averaging over 140 lines and featuring deep and wide abstract syntax trees.\n  Evaluation of nearly 30 LLMs reveals a substantial performance gap: the best-performing model, Claude-4-Sonnet, achieves only 36.46 percent accuracy on OurBenchSyn and 32.17 percent on OurBenchSem, while most models score below 20 percent. We further explore four solution strategies, identify key challenges, and outline promising directions for enterprise SQL debugging with LLMs.", "AI": {"tldr": "OurBench\u662f\u9996\u4e2a\u4f01\u4e1a\u7ea7SQL\u63a8\u7406\u4e0e\u8c03\u8bd5\u57fa\u51c6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6ce8\u5165\u771f\u5b9e\u9519\u8bef\u6784\u5efa\uff0c\u5305\u542b469\u4e2a\u8bed\u6cd5\u9519\u8bef\u67e5\u8be2\u548c516\u4e2a\u8bed\u4e49\u9519\u8bef\u67e5\u8be2\uff0c\u8bc4\u4f30\u663e\u793a\u5f53\u524dLLMs\u5728\u590d\u6742SQL\u8c03\u8bd5\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff08\u6700\u4f73\u6a21\u578b\u51c6\u786e\u7387\u4ec536.46%\uff09\u3002", "motivation": "\u4f01\u4e1a\u6570\u636e\u5de5\u7a0b\u4e2dSQL\u751f\u6210\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5373\u4f7f\u662f\u7ecf\u9a8c\u4e30\u5bcc\u7684\u5f00\u53d1\u8005\u548c\u5148\u8fdbLLMs\u4e5f\u96be\u4ee5\u4e00\u6b21\u6027\u751f\u6210\u5b8c\u5168\u6b63\u786e\u7684SQL\u4ee3\u7801\uff0c\u901a\u5e38\u9700\u8981\u591a\u6b21\u8c03\u8bd5\u8fed\u4ee3\u3002\u73b0\u6709\u57fa\u51c6\u7f3a\u4e4f\u5bf9\u4f01\u4e1a\u7ea7SQL\u8c03\u8bd5\u80fd\u529b\u7684\u8bc4\u4f30\uff0c\u9700\u8981\u4e13\u95e8\u9488\u5bf9SQL\u63a8\u7406\u548c\u8c03\u8bd5\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u63d0\u51fa\u4e24\u4e2a\u5173\u952e\u521b\u65b0\uff1a(1) \u81ea\u52a8\u5316\u6784\u5efa\u5de5\u4f5c\u6d41\uff0c\u4f7f\u7528\u9006\u5411\u5de5\u7a0b\u6280\u672f\u5728\u5927\u89c4\u6a21SQL\u4ee3\u7801\u4e2d\u7cfb\u7edf\u6ce8\u5165\u771f\u5b9e\u9519\u8bef\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u548c\u591a\u6837\u5316\u7684\u57fa\u51c6\u751f\u6210\uff1b(2) \u9762\u5411\u4f01\u4e1a\u73af\u5883\u7684\u514d\u6267\u884c\u8bc4\u4f30\u6846\u67b6\uff0c\u63d0\u4f9b\u5feb\u901f\u3001\u51c6\u786e\u4e14\u8d44\u6e90\u9ad8\u6548\u7684\u8bc4\u4f30\u3002\u6784\u5efa\u4e86469\u4e2a\u8bed\u6cd5\u9519\u8bef\u67e5\u8be2\uff08OurBenchSyn\uff09\u548c516\u4e2a\u8bed\u4e49\u9519\u8bef\u67e5\u8be2\uff08OurBenchSem\uff09\uff0c\u67e5\u8be2\u590d\u6742\u5ea6\u9ad8\uff08\u5e73\u5747\u8d85\u8fc7140\u884c\uff0c\u5177\u6709\u6df1\u5e7f\u7684\u62bd\u8c61\u8bed\u6cd5\u6811\uff09\u3002", "result": "\u8bc4\u4f30\u8fd130\u4e2aLLMs\u663e\u793a\u663e\u8457\u6027\u80fd\u5dee\u8ddd\uff1a\u6700\u4f73\u6a21\u578bClaude-4-Sonnet\u5728OurBenchSyn\u4e0a\u4ec5\u8fbe\u523036.46%\u51c6\u786e\u7387\uff0c\u5728OurBenchSem\u4e0a\u4e3a32.17%\uff0c\u5927\u591a\u6570\u6a21\u578b\u5f97\u5206\u4f4e\u4e8e20%\u3002\u7814\u7a76\u8fdb\u4e00\u6b65\u63a2\u7d22\u4e86\u56db\u79cd\u89e3\u51b3\u65b9\u6848\u7b56\u7565\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u6311\u6218\uff0c\u5e76\u6982\u8ff0\u4e86\u4f01\u4e1aSQL\u8c03\u8bd5\u7684\u6709\u524d\u666f\u65b9\u5411\u3002", "conclusion": "OurBench\u586b\u8865\u4e86\u4f01\u4e1a\u7ea7SQL\u8c03\u8bd5\u57fa\u51c6\u7684\u7a7a\u767d\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLMs\u5728\u590d\u6742SQL\u8c03\u8bd5\u4efb\u52a1\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u8bc4\u4f30\u5de5\u5177\u548c\u65b9\u5411\u6307\u5bfc\u3002\u7ed3\u679c\u8868\u660e\u4f01\u4e1aSQL\u8c03\u8bd5\u4ecd\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u5f00\u653e\u95ee\u9898\uff0c\u9700\u8981\u66f4\u5148\u8fdb\u7684\u63a8\u7406\u548c\u8c03\u8bd5\u80fd\u529b\u3002"}}
{"id": "2601.18123", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18123", "abs": "https://arxiv.org/abs/2601.18123", "authors": ["Muhammad Ibrahim Khan", "Bivin Pradeep", "James Brusey"], "title": "Deadline-Aware, Energy-Efficient Control of Domestic Immersion Hot Water Heaters", "comment": "Accepted at AAAI 2026", "summary": "Typical domestic immersion water heater systems are often operated continuously during winter, heating quickly rather than efficiently and ignoring predictable demand windows and ambient losses. We study deadline-aware control, where the aim is to reach a target temperature at a specified time while minimising energy consumption. We introduce an efficient Gymnasium environment that models an immersion hot water heater with first-order thermal losses and discrete on and off actions of 0 W and 6000 W applied every 120 seconds. Methods include a time-optimal bang-bang baseline, a zero-shot Monte Carlo Tree Search planner, and a Proximal Policy Optimisation policy. We report total energy consumption in watt-hours under identical physical dynamics. Across sweeps of initial temperature from 10 to 30 degrees Celsius, deadline from 30 to 90 steps, and target temperature from 40 to 80 degrees Celsius, PPO achieves the most energy-efficient performance at a 60-step horizon of 2 hours, using 3.23 kilowatt-hours, compared to 4.37 to 10.45 kilowatt-hours for bang-bang control and 4.18 to 6.46 kilowatt-hours for MCTS. This corresponds to energy savings of 26 percent at 30 steps and 69 percent at 90 steps. In a representative trajectory with a 50 kg water mass, 20 degrees Celsius ambient temperature, and a 60 degrees Celsius target, PPO consumes 54 percent less energy than bang-bang control and 33 percent less than MCTS. These results show that learned deadline-aware control reduces energy consumption under identical physical assumptions, while planners provide partial savings without training and learned policies offer near-zero inference cost once trained.", "AI": {"tldr": "\u7814\u7a76\u5bb6\u5ead\u6d78\u5165\u5f0f\u70ed\u6c34\u5668\u7684\u622a\u6b62\u65f6\u95f4\u611f\u77e5\u63a7\u5236\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08PPO\uff09\u76f8\u6bd4\u4f20\u7edfbang-bang\u63a7\u5236\u548cMCTS\u89c4\u5212\u5668\uff0c\u5728\u76f8\u540c\u7269\u7406\u6761\u4ef6\u4e0b\u663e\u8457\u964d\u4f4e\u80fd\u8017\u3002", "motivation": "\u4f20\u7edf\u5bb6\u5ead\u6d78\u5165\u5f0f\u70ed\u6c34\u5668\u5728\u51ac\u5b63\u901a\u5e38\u8fde\u7eed\u8fd0\u884c\uff0c\u8ffd\u6c42\u5feb\u901f\u52a0\u70ed\u800c\u975e\u6548\u7387\uff0c\u5ffd\u7565\u4e86\u53ef\u9884\u6d4b\u7684\u9700\u6c42\u7a97\u53e3\u548c\u73af\u5883\u70ed\u635f\u5931\u3002\u9700\u8981\u5f00\u53d1\u80fd\u5728\u6307\u5b9a\u65f6\u95f4\u8fbe\u5230\u76ee\u6807\u6e29\u5ea6\u540c\u65f6\u6700\u5c0f\u5316\u80fd\u8017\u7684\u667a\u80fd\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u5efa\u7acbGymnasium\u73af\u5883\u6a21\u62df\u6d78\u5165\u5f0f\u70ed\u6c34\u5668\uff08\u4e00\u9636\u70ed\u635f\u5931\u6a21\u578b\uff0c120\u79d2\u95f4\u9694\u76840W/6000W\u5f00\u5173\u63a7\u5236\uff09\u3002\u6bd4\u8f83\u4e09\u79cd\u65b9\u6cd5\uff1a\u65f6\u95f4\u6700\u4f18bang-bang\u57fa\u7ebf\u3001\u96f6\u6837\u672c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u89c4\u5212\u5668\u3001\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u5728\u521d\u59cb\u6e29\u5ea610-30\u00b0C\u3001\u622a\u6b62\u65f6\u95f430-90\u6b65\uff081-3\u5c0f\u65f6\uff09\u3001\u76ee\u6807\u6e29\u5ea640-80\u00b0C\u7684\u53c2\u6570\u626b\u63cf\u4e2d\uff0cPPO\u572860\u6b65\uff082\u5c0f\u65f6\uff09\u65f6\u8017\u80fd\u6700\u4f4e\uff083.23kWh\uff09\uff0c\u76f8\u6bd4bang-bang\u63a7\u5236\uff084.37-10.45kWh\uff09\u548cMCTS\uff084.18-6.46kWh\uff09\u663e\u8457\u8282\u80fd\u3002\u5178\u578b\u8f68\u8ff9\uff0850kg\u6c34\u8d28\u91cf\uff0c20\u00b0C\u73af\u5883\u6e29\u5ea6\uff0c60\u00b0C\u76ee\u6807\uff09\u4e2d\uff0cPPO\u6bd4bang-bang\u8282\u80fd54%\uff0c\u6bd4MCTS\u8282\u80fd33%\u3002", "conclusion": "\u5b66\u4e60\u578b\u622a\u6b62\u65f6\u95f4\u611f\u77e5\u63a7\u5236\u80fd\u5728\u76f8\u540c\u7269\u7406\u5047\u8bbe\u4e0b\u663e\u8457\u964d\u4f4e\u80fd\u8017\u3002\u89c4\u5212\u5668\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u63d0\u4f9b\u90e8\u5206\u8282\u80fd\uff0c\u800c\u5b66\u4e60\u7b56\u7565\u4e00\u65e6\u8bad\u7ec3\u5b8c\u6210\uff0c\u63a8\u7406\u6210\u672c\u51e0\u4e4e\u4e3a\u96f6\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.17702", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17702", "abs": "https://arxiv.org/abs/2601.17702", "authors": ["Qingsen Ma", "Dianyun Wang", "Yaoye Wang", "Lechen Ning", "Sujie Zhu", "Xiaohang Zhang", "Jiaming Lyu", "Linhao Ren", "Zhenbo Xu", "Zhaofeng He"], "title": "S$^3$-Attention:Attention-Aligned Endogenous Retrieval for Memory-Bounded Long-Context Inference", "comment": null, "summary": "Large language models are increasingly applied to multi-document and long-form inputs, yet long-context inference remains memory- and noise-inefficient. Key-value (KV) caching scales linearly with context length, while external retrieval methods often return lexically similar but causally irrelevant passages.\n  We present S3-Attention, a memory-first inference-time framework that treats long-context processing as attention-aligned endogenous retrieval. S3-Attention decodes transient key and query projections into top-k sparse feature identifiers using lightweight sparse autoencoders, and constructs a CPU-based inverted index mapping features to token positions or spans during a single streaming scan. This design allows the KV cache to be discarded entirely and bounds GPU memory usage by the scan chunk size.\n  At generation time, feature co-activation is used to retrieve compact evidence spans, optionally fused with BM25 for exact lexical matching. Under a unified LongBench evaluation protocol with fixed prompting, decoding, and matched token budgets, S3-Hybrid closely matches full-context inference across multiple model families and improves robustness in several information-dense settings. We also report an engineering limitation of the current prototype, which incurs higher wall-clock latency than optimized full-KV baselines, motivating future kernel-level optimization.", "AI": {"tldr": "S3-Attention\u662f\u4e00\u79cd\u5185\u5b58\u4f18\u5148\u7684\u63a8\u7406\u65f6\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u89c6\u4e3a\u6ce8\u610f\u529b\u5bf9\u9f50\u7684\u5185\u751f\u68c0\u7d22\uff0c\u5b8c\u5168\u4e22\u5f03KV\u7f13\u5b58\uff0c\u4f7f\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5c06\u952e\u503c\u6295\u5f71\u89e3\u7801\u4e3a\u7a00\u758f\u7279\u5f81\u6807\u8bc6\u7b26\uff0c\u5e76\u6784\u5efaCPU\u5012\u6392\u7d22\u5f15\u6765\u68c0\u7d22\u8bc1\u636e\u7247\u6bb5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u591a\u6587\u6863\u548c\u957f\u683c\u5f0f\u8f93\u5165\u65f6\u9762\u4e34\u5185\u5b58\u6548\u7387\u4f4e\u548c\u566a\u58f0\u95ee\u9898\u3002\u4f20\u7edf\u7684KV\u7f13\u5b58\u968f\u4e0a\u4e0b\u6587\u957f\u5ea6\u7ebf\u6027\u6269\u5c55\uff0c\u800c\u5916\u90e8\u68c0\u7d22\u65b9\u6cd5\u901a\u5e38\u8fd4\u56de\u8bcd\u6c47\u76f8\u4f3c\u4f46\u56e0\u679c\u65e0\u5173\u7684\u6bb5\u843d\u3002", "method": "S3-Attention\u5c06\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u89c6\u4e3a\u6ce8\u610f\u529b\u5bf9\u9f50\u7684\u5185\u751f\u68c0\u7d22\uff1a1) \u4f7f\u7528\u8f7b\u91cf\u7ea7\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5c06\u77ac\u6001\u952e\u548c\u67e5\u8be2\u6295\u5f71\u89e3\u7801\u4e3atop-k\u7a00\u758f\u7279\u5f81\u6807\u8bc6\u7b26\uff1b2) \u5728\u5355\u6b21\u6d41\u5f0f\u626b\u63cf\u4e2d\u6784\u5efaCPU\u5012\u6392\u7d22\u5f15\uff0c\u5c06\u7279\u5f81\u6620\u5c04\u5230token\u4f4d\u7f6e\u6216\u7247\u6bb5\uff1b3) \u751f\u6210\u65f6\u4f7f\u7528\u7279\u5f81\u5171\u6fc0\u6d3b\u68c0\u7d22\u7d27\u51d1\u8bc1\u636e\u7247\u6bb5\uff0c\u53ef\u9009\u4e0eBM25\u878d\u5408\u8fdb\u884c\u7cbe\u786e\u8bcd\u6c47\u5339\u914d\u3002", "result": "\u5728\u7edf\u4e00\u7684LongBench\u8bc4\u4f30\u534f\u8bae\u4e0b\uff0cS3-Hybrid\u5728\u591a\u4e2a\u6a21\u578b\u7cfb\u5217\u4e2d\u4e0e\u5b8c\u6574\u4e0a\u4e0b\u6587\u63a8\u7406\u7ed3\u679c\u63a5\u8fd1\uff0c\u5e76\u5728\u591a\u4e2a\u4fe1\u606f\u5bc6\u96c6\u573a\u666f\u4e2d\u63d0\u9ad8\u4e86\u9c81\u68d2\u6027\u3002\u4f46\u5f53\u524d\u539f\u578b\u5b58\u5728\u5de5\u7a0b\u9650\u5236\uff0c\u6bd4\u4f18\u5316\u7684\u5b8c\u6574KV\u57fa\u7ebf\u5177\u6709\u66f4\u9ad8\u7684\u5b9e\u9645\u5ef6\u8fdf\u3002", "conclusion": "S3-Attention\u901a\u8fc7\u5185\u5b58\u4f18\u5148\u7684\u63a8\u7406\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u7684\u5185\u5b58\u548c\u566a\u58f0\u6548\u7387\u95ee\u9898\uff0c\u5b8c\u5168\u4e22\u5f03KV\u7f13\u5b58\u5e76\u9650\u5236GPU\u5185\u5b58\u4f7f\u7528\u3002\u867d\u7136\u5f53\u524d\u539f\u578b\u5b58\u5728\u5ef6\u8fdf\u95ee\u9898\uff0c\u4f46\u8be5\u65b9\u6cd5\u4e3a\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u9700\u8981\u672a\u6765\u5185\u6838\u7ea7\u4f18\u5316\u3002"}}
{"id": "2601.17705", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17705", "abs": "https://arxiv.org/abs/2601.17705", "authors": ["Abdullah Qureshi", "Kenneth Rice", "Alexander Wolpert"], "title": "Distance-to-Distance Ratio: A Similarity Measure for Sentences Based on Rate of Change in LLM Embeddings", "comment": "8 pages, 4 figures", "summary": "A measure of similarity between text embeddings can be considered adequate only if it adheres to the human perception of similarity between texts. In this paper, we introduce the distance-to-distance ratio (DDR), a novel measure of similarity between LLM sentence embeddings. Inspired by Lipschitz continuity, DDR measures the rate of change in similarity between the pre-context word embeddings and the similarity between post-context LLM embeddings, thus measuring the semantic influence of context. We evaluate the performance of DDR in experiments designed as a series of perturbations applied to sentences drawn from a sentence dataset. For each sentence, we generate variants by replacing one, two, or three words with either synonyms, which constitute semantically similar text, or randomly chosen words, which constitute semantically dissimilar text. We compare the performance of DDR with other prevailing similarity metrics and demonstrate that DDR consistently provides finer discrimination between semantically similar and dissimilar texts, even under minimal, controlled edits.", "AI": {"tldr": "\u63d0\u51faDDR\uff08\u8ddd\u79bb-\u8ddd\u79bb\u6bd4\uff09\u4f5c\u4e3aLLM\u53e5\u5b50\u5d4c\u5165\u76f8\u4f3c\u6027\u5ea6\u91cf\uff0c\u901a\u8fc7\u6d4b\u91cf\u4e0a\u4e0b\u6587\u524d\u540e\u5d4c\u5165\u76f8\u4f3c\u5ea6\u7684\u53d8\u5316\u7387\u6765\u8bc4\u4f30\u8bed\u4e49\u5f71\u54cd\uff0c\u5728\u53d7\u63a7\u6270\u52a8\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u6587\u672c\u5d4c\u5165\u76f8\u4f3c\u6027\u5ea6\u91cf\u5fc5\u987b\u7b26\u5408\u4eba\u7c7b\u5bf9\u6587\u672c\u76f8\u4f3c\u6027\u7684\u611f\u77e5\uff0c\u73b0\u6709\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u4e0a\u4e0b\u6587\u5bf9\u8bed\u4e49\u7684\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u6765\u533a\u5206\u8bed\u4e49\u76f8\u4f3c\u548c\u76f8\u5f02\u7684\u6587\u672c\u3002", "method": "\u63d0\u51faDDR\uff08\u8ddd\u79bb-\u8ddd\u79bb\u6bd4\uff09\u5ea6\u91cf\uff0c\u53d7Lipschitz\u8fde\u7eed\u6027\u542f\u53d1\uff0c\u6d4b\u91cf\u9884\u4e0a\u4e0b\u6587\u8bcd\u5d4c\u5165\u76f8\u4f3c\u5ea6\u4e0e\u540e\u4e0a\u4e0b\u6587LLM\u5d4c\u5165\u76f8\u4f3c\u5ea6\u4e4b\u95f4\u7684\u53d8\u5316\u7387\uff0c\u4ece\u800c\u91cf\u5316\u4e0a\u4e0b\u6587\u7684\u8bed\u4e49\u5f71\u54cd\u3002\u901a\u8fc7\u8bbe\u8ba1\u6270\u52a8\u5b9e\u9a8c\uff1a\u4ece\u53e5\u5b50\u6570\u636e\u96c6\u4e2d\u9009\u53d6\u53e5\u5b50\uff0c\u751f\u6210\u53d8\u4f53\uff08\u66ff\u63621-3\u4e2a\u8bcd\u4e3a\u540c\u4e49\u8bcd\u6216\u968f\u673a\u8bcd\uff09\uff0c\u6bd4\u8f83DDR\u4e0e\u73b0\u6709\u76f8\u4f3c\u6027\u5ea6\u91cf\u7684\u6027\u80fd\u3002", "result": "DDR\u5728\u5b9e\u9a8c\u4e2d\u4e00\u81f4\u63d0\u4f9b\u66f4\u7cbe\u7ec6\u7684\u533a\u5206\u80fd\u529b\uff0c\u80fd\u66f4\u597d\u5730\u533a\u5206\u8bed\u4e49\u76f8\u4f3c\u548c\u76f8\u5f02\u7684\u6587\u672c\uff0c\u5373\u4f7f\u5728\u6700\u5c0f\u5316\u3001\u53d7\u63a7\u7684\u7f16\u8f91\u6761\u4ef6\u4e0b\u4e5f\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u5176\u4ed6\u4e3b\u6d41\u76f8\u4f3c\u6027\u5ea6\u91cf\u3002", "conclusion": "DDR\u662f\u4e00\u79cd\u6709\u6548\u7684LLM\u53e5\u5b50\u5d4c\u5165\u76f8\u4f3c\u6027\u5ea6\u91cf\uff0c\u80fd\u591f\u51c6\u786e\u6355\u6349\u4e0a\u4e0b\u6587\u5bf9\u8bed\u4e49\u7684\u5f71\u54cd\uff0c\u7b26\u5408\u4eba\u7c7b\u5bf9\u6587\u672c\u76f8\u4f3c\u6027\u7684\u611f\u77e5\uff0c\u4e3a\u6587\u672c\u76f8\u4f3c\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u7cbe\u7ec6\u7684\u5de5\u5177\u3002"}}
{"id": "2601.18132", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18132", "abs": "https://arxiv.org/abs/2601.18132", "authors": ["Xi Chen", "Hongru Zhou", "Huahui Yi", "Shiyu Feng", "Hanyu Zhou", "Tiancheng He", "Mingke You", "Li Wang", "Qiankun Li", "Kun Wang", "Weili Fu", "Kang Li", "Jian Li"], "title": "RareAlert: Aligning heterogeneous large language model reasoning for early rare disease risk screening", "comment": "28 page, 3 figures", "summary": "Missed and delayed diagnosis remains a major challenge in rare disease care. At the initial clinical encounters, physicians assess rare disease risk using only limited information under high uncertainty. When high-risk patients are not recognised at this stage, targeted diagnostic testing is often not initiated, resulting in missed diagnosis. Existing primary care triage processes are structurally insufficient to reliably identify patients with rare diseases at initial clinical presentation and universal screening is needed to reduce diagnostic delay. Here we present RareAlert, an early screening system which predict patient-level rare disease risk from routinely available primary-visit information. RareAlert integrates reasoning generated by ten LLMs, calibrates and weights these signals using machine learning, and distils the aligned reasoning into a single locally deployable model. To develop and evaluate RareAlert, we curated RareBench, a real-world dataset of 158,666 cases covering 33 Orphanet disease categories and more than 7,000 rare conditions, including both rare and non-rare presentations. The results showed that rare disease identification can be reconceptualised as a universal uncertainty resolution process applied to the general patient population. On an independent test set, RareAlert, a Qwen3-4B based model trained with calibrated reasoning signals, achieved an AUC of 0.917, outperforming the best machine learning ensemble and all evaluated LLMs, including GPT-5, DeepSeek-R1, Claude-3.7-Sonnet, o3-mini, Gemini-2.5-Pro, and Qwen3-235B. These findings demonstrate the diversity in LLM medical reasoning and the effectiveness of aligning such reasoning in highly uncertain clinical tasks. By incorporating calibrated reasoning into a single model, RareAlert enables accurate, privacy-preserving, and scalable rare disease risk screening suitable for large-scale local deployment.", "AI": {"tldr": "RareAlert\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u63a8\u7406\u6821\u51c6\u7684\u7f55\u89c1\u75c5\u65e9\u671f\u7b5b\u67e5\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u540810\u4e2aLLM\u7684\u63a8\u7406\u4fe1\u53f7\uff0c\u8bad\u7ec3\u51fa\u53ef\u5728\u672c\u5730\u90e8\u7f72\u7684\u5355\u4e00\u6a21\u578b\uff0c\u5728158,666\u4f8b\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u5b9e\u73b0\u4e860.917\u7684AUC\uff0c\u4f18\u4e8e\u6240\u6709\u8bc4\u4f30\u7684LLM\u548c\u673a\u5668\u5b66\u4e60\u96c6\u6210\u65b9\u6cd5\u3002", "motivation": "\u7f55\u89c1\u75c5\u7684\u6f0f\u8bca\u548c\u5ef6\u8fdf\u8bca\u65ad\u662f\u4e34\u5e8a\u4e3b\u8981\u6311\u6218\uff0c\u521d\u7ea7\u533b\u7597\u5206\u8bca\u6d41\u7a0b\u5728\u521d\u6b21\u5c31\u8bca\u65f6\u96be\u4ee5\u53ef\u9760\u8bc6\u522b\u7f55\u89c1\u75c5\u60a3\u8005\uff0c\u9700\u8981\u901a\u7528\u7b5b\u67e5\u6765\u51cf\u5c11\u8bca\u65ad\u5ef6\u8fdf\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u4fe1\u606f\u6709\u9650\u3001\u9ad8\u5ea6\u4e0d\u786e\u5b9a\u7684\u521d\u6b21\u4e34\u5e8a\u63a5\u89e6\u4e2d\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30\u7f55\u89c1\u75c5\u98ce\u9669\u3002", "method": "\u5f00\u53d1RareAlert\u7cfb\u7edf\uff1a1) \u6574\u540810\u4e2aLLM\u751f\u6210\u7684\u63a8\u7406\u4fe1\u53f7\uff1b2) \u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6821\u51c6\u548c\u52a0\u6743\u8fd9\u4e9b\u4fe1\u53f7\uff1b3) \u5c06\u5bf9\u9f50\u7684\u63a8\u7406\u84b8\u998f\u5230\u5355\u4e00\u53ef\u672c\u5730\u90e8\u7f72\u7684\u6a21\u578b\u3002\u4f7f\u7528RareBench\u6570\u636e\u96c6\uff08158,666\u4f8b\uff0c33\u4e2aOrphanet\u75be\u75c5\u7c7b\u522b\uff0c7000+\u7f55\u89c1\u75c5\uff09\u8fdb\u884c\u5f00\u53d1\u548c\u8bc4\u4f30\u3002", "result": "\u5728\u72ec\u7acb\u6d4b\u8bd5\u96c6\u4e0a\uff0c\u57fa\u4e8eQwen3-4B\u5e76\u4f7f\u7528\u6821\u51c6\u63a8\u7406\u4fe1\u53f7\u8bad\u7ec3\u7684RareAlert\u6a21\u578b\u8fbe\u52300.917\u7684AUC\uff0c\u4f18\u4e8e\u6700\u4f73\u673a\u5668\u5b66\u4e60\u96c6\u6210\u548c\u6240\u6709\u8bc4\u4f30\u7684LLM\uff08\u5305\u62ecGPT-5\u3001DeepSeek-R1\u3001Claude-3.7-Sonnet\u3001o3-mini\u3001Gemini-2.5-Pro\u3001Qwen3-235B\uff09\u3002", "conclusion": "\u7f55\u89c1\u75c5\u8bc6\u522b\u53ef\u91cd\u65b0\u6982\u5ff5\u5316\u4e3a\u5e94\u7528\u4e8e\u666e\u901a\u60a3\u8005\u7fa4\u4f53\u7684\u901a\u7528\u4e0d\u786e\u5b9a\u6027\u89e3\u51b3\u8fc7\u7a0b\u3002LLM\u5728\u533b\u5b66\u63a8\u7406\u4e2d\u5b58\u5728\u591a\u6837\u6027\uff0c\u5728\u9ad8\u5ea6\u4e0d\u786e\u5b9a\u7684\u4e34\u5e8a\u4efb\u52a1\u4e2d\u5bf9\u9f50\u8fd9\u79cd\u63a8\u7406\u662f\u6709\u6548\u7684\u3002RareAlert\u901a\u8fc7\u5c06\u6821\u51c6\u63a8\u7406\u6574\u5408\u5230\u5355\u4e00\u6a21\u578b\u4e2d\uff0c\u5b9e\u73b0\u4e86\u51c6\u786e\u3001\u9690\u79c1\u4fdd\u62a4\u3001\u53ef\u6269\u5c55\u7684\u7f55\u89c1\u75c5\u98ce\u9669\u7b5b\u67e5\uff0c\u9002\u5408\u5927\u89c4\u6a21\u672c\u5730\u90e8\u7f72\u3002"}}
{"id": "2601.17706", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.17706", "abs": "https://arxiv.org/abs/2601.17706", "authors": ["Saptarshi Ghosh", "Linfeng Liu", "Tianyu Jiang"], "title": "A Computational Approach to Visual Metonymy", "comment": "EACL 2026", "summary": "Images often communicate more than they literally depict: a set of tools can suggest an occupation and a cultural artifact can suggest a tradition. This kind of indirect visual reference, known as visual metonymy, invites viewers to recover a target concept via associated cues rather than explicit depiction. In this work, we present the first computational investigation of visual metonymy. We introduce a novel pipeline grounded in semiotic theory that leverages large language models and text-to-image models to generate metonymic visual representations. Using this framework, we construct ViMET, the first visual metonymy dataset comprising 2,000 multiple-choice questions to evaluate the cognitive reasoning abilities in multimodal language models. Experimental results on our dataset reveal a significant gap between human performance (86.9%) and state-of-the-art vision-language models (65.9%), highlighting limitations in machines' ability to interpret indirect visual references. Our dataset is publicly available at: https://github.com/cincynlp/ViMET.", "code_url": "https://github.com/cincynlp/ViMET", "code_stars": 0, "code_last_update": "2026-01-20", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u5bf9\u89c6\u89c9\u8f6c\u55bb\u8fdb\u884c\u7cfb\u7edf\u6027\u8ba1\u7b97\u7814\u7a76\uff0c\u63d0\u51fa\u57fa\u4e8e\u7b26\u53f7\u5b66\u7406\u8bba\u7684\u751f\u6210\u6846\u67b6\uff0c\u6784\u5efa\u4e86\u5305\u542b2000\u4e2a\u591a\u9009\u9898\u7684ViMET\u6570\u636e\u96c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u7406\u89e3\u95f4\u63a5\u89c6\u89c9\u5f15\u7528\u65b9\u9762\u4e0e\u4eba\u7c7b\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u56fe\u50cf\u901a\u5e38\u4f20\u8fbe\u6bd4\u5176\u5b57\u9762\u63cf\u7ed8\u66f4\u591a\u7684\u4fe1\u606f\uff08\u5982\u5de5\u5177\u6697\u793a\u804c\u4e1a\u3001\u6587\u7269\u6697\u793a\u4f20\u7edf\uff09\uff0c\u8fd9\u79cd\u95f4\u63a5\u89c6\u89c9\u5f15\u7528\uff08\u89c6\u89c9\u8f6c\u55bb\uff09\u8981\u6c42\u89c2\u8005\u901a\u8fc7\u5173\u8054\u7ebf\u7d22\u6062\u590d\u76ee\u6807\u6982\u5ff5\u3002\u5f53\u524d\u7f3a\u4e4f\u5bf9\u89c6\u89c9\u8f6c\u55bb\u7684\u8ba1\u7b97\u7814\u7a76\uff0c\u9700\u8981\u5efa\u7acb\u8bc4\u4f30\u591a\u6a21\u6001\u6a21\u578b\u8ba4\u77e5\u63a8\u7406\u80fd\u529b\u7684\u6570\u636e\u96c6\u548c\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7b26\u53f7\u5b66\u7406\u8bba\u7684\u65b0\u9896\u6d41\u7a0b\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u751f\u6210\u8f6c\u55bb\u89c6\u89c9\u8868\u793a\u3002\u901a\u8fc7\u8be5\u6846\u67b6\u6784\u5efaViMET\u6570\u636e\u96c6\uff082000\u4e2a\u591a\u9009\u9898\uff09\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u7684\u8ba4\u77e5\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u4eba\u7c7b\u8868\u73b0\uff0886.9%\uff09\u4e0e\u6700\u5148\u8fdb\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0865.9%\uff09\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u8868\u660e\u673a\u5668\u5728\u89e3\u91ca\u95f4\u63a5\u89c6\u89c9\u5f15\u7528\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002\u6570\u636e\u96c6\u5df2\u516c\u5f00\u53ef\u7528\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5bf9\u89c6\u89c9\u8f6c\u55bb\u7684\u8ba1\u7b97\u7814\u7a76\uff0c\u63d0\u51fa\u7684\u6846\u67b6\u548c\u6570\u636e\u96c6\u4e3a\u8bc4\u4f30\u591a\u6a21\u6001\u6a21\u578b\u7684\u8ba4\u77e5\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u7406\u89e3\u95f4\u63a5\u89c6\u89c9\u5f15\u7528\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u3002"}}
{"id": "2601.18137", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18137", "abs": "https://arxiv.org/abs/2601.18137", "authors": ["Yinger Zhang", "Shutong Jiang", "Renhao Li", "Jianhong Tu", "Yang Su", "Lianghao Deng", "Xudong Guo", "Chenxu Lv", "Junyang Lin"], "title": "DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints", "comment": null, "summary": "While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability. Meanwhile, existing LLM planning benchmarks underrepresent the active information gathering and fine-grained local constraints typical of real-world settings. To address this, we introduce DeepPlanning, a challenging benchmark for practical long-horizon agent planning. It features multi-day travel planning and multi-product shopping tasks that require proactive information acquisition, local constrained reasoning, and global constrained optimization. Evaluations on DeepPlanning show that even frontier agentic LLMs struggle with these problems, highlighting the importance of reliable explicit reasoning patterns and parallel tool use for achieving better effectiveness-efficiency trade-offs. Error analysis further points to promising directions for improving agentic LLMs over long planning horizons. We open-source the code and data to support future research.", "AI": {"tldr": "DeepPlanning\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u957f\u65f6\u7a0b\u667a\u80fd\u4f53\u89c4\u5212\u57fa\u51c6\uff0c\u4e13\u6ce8\u4e8e\u591a\u65e5\u65c5\u884c\u89c4\u5212\u548c\u591a\u4ea7\u54c1\u8d2d\u7269\u4efb\u52a1\uff0c\u9700\u8981\u4e3b\u52a8\u4fe1\u606f\u83b7\u53d6\u3001\u5c40\u90e8\u7ea6\u675f\u63a8\u7406\u548c\u5168\u5c40\u7ea6\u675f\u4f18\u5316\u3002", "motivation": "\u5f53\u524d\u667a\u80fd\u4f53\u8bc4\u4f30\u867d\u7136\u8f6c\u5411\u957f\u65f6\u7a0b\u4efb\u52a1\uff0c\u4f46\u5927\u591a\u6570\u57fa\u51c6\u4ecd\u5f3a\u8c03\u5c40\u90e8\u3001\u6b65\u9aa4\u7ea7\u63a8\u7406\uff0c\u800c\u975e\u9700\u8981\u771f\u6b63\u89c4\u5212\u80fd\u529b\u7684\u5168\u5c40\u7ea6\u675f\u4f18\u5316\uff08\u5982\u65f6\u95f4\u548c\u8d22\u52a1\u9884\u7b97\uff09\u3002\u73b0\u6709LLM\u89c4\u5212\u57fa\u51c6\u672a\u80fd\u5145\u5206\u4f53\u73b0\u73b0\u5b9e\u4e16\u754c\u4e2d\u5178\u578b\u7684\u4e3b\u52a8\u4fe1\u606f\u6536\u96c6\u548c\u7ec6\u7c92\u5ea6\u5c40\u90e8\u7ea6\u675f\u3002", "method": "\u5f15\u5165DeepPlanning\u57fa\u51c6\uff0c\u5305\u542b\u591a\u65e5\u65c5\u884c\u89c4\u5212\u548c\u591a\u4ea7\u54c1\u8d2d\u7269\u4efb\u52a1\uff0c\u8fd9\u4e9b\u4efb\u52a1\u8981\u6c42\u667a\u80fd\u4f53\u8fdb\u884c\u4e3b\u52a8\u4fe1\u606f\u83b7\u53d6\u3001\u5c40\u90e8\u7ea6\u675f\u63a8\u7406\u548c\u5168\u5c40\u7ea6\u675f\u4f18\u5316\u3002\u57fa\u51c6\u8bc4\u4f30\u524d\u6cbf\u667a\u80fd\u4f53LLM\u5728\u8fd9\u4e9b\u590d\u6742\u89c4\u5212\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u5373\u4f7f\u662f\u524d\u6cbf\u7684\u667a\u80fd\u4f53LLM\u5728\u8fd9\u4e9b\u95ee\u9898\u4e0a\u4e5f\u8868\u73b0\u4e0d\u4f73\uff0c\u7a81\u663e\u4e86\u53ef\u9760\u663e\u5f0f\u63a8\u7406\u6a21\u5f0f\u548c\u5e76\u884c\u5de5\u5177\u4f7f\u7528\u5bf9\u4e8e\u5b9e\u73b0\u66f4\u597d\u7684\u6548\u679c-\u6548\u7387\u6743\u8861\u7684\u91cd\u8981\u6027\u3002\u9519\u8bef\u5206\u6790\u4e3a\u8fdb\u4e00\u6b65\u6539\u8fdb\u957f\u89c4\u5212\u65f6\u7a0b\u7684\u667a\u80fd\u4f53LLM\u6307\u51fa\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002", "conclusion": "DeepPlanning\u57fa\u51c6\u586b\u8865\u4e86\u73b0\u6709LLM\u89c4\u5212\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u771f\u5b9e\u7684\u89c4\u5212\u80fd\u529b\u8bc4\u4f30\uff0c\u5305\u62ec\u4e3b\u52a8\u4fe1\u606f\u6536\u96c6\u548c\u7ea6\u675f\u4f18\u5316\u3002\u5f00\u6e90\u4ee3\u7801\u548c\u6570\u636e\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2601.17728", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17728", "abs": "https://arxiv.org/abs/2601.17728", "authors": ["Meysam Alizadeh", "Fabrizio Gilardi", "Zeynab Samei"], "title": "Unsupervised Elicitation of Moral Values from Language Models", "comment": null, "summary": "As AI systems become pervasive, grounding their behavior in human values is critical. Prior work suggests that language models (LMs) exhibit limited inherent moral reasoning, leading to calls for explicit moral teaching. However, constructing ground truth data for moral evaluation is difficult given plural frameworks and pervasive biases. We investigate unsupervised elicitation as an alternative, asking whether pretrained (base) LMs possess intrinsic moral reasoning capability that can be surfaced without human supervision. Using the Internal Coherence Maximization (ICM) algorithm across three benchmark datasets and four LMs, we test whether ICM can reliably label moral judgments, generalize across moral frameworks, and mitigate social bias. Results show that ICM outperforms all pre-trained and chatbot baselines on the Norm Bank and ETHICS benchmarks, while fine-tuning on ICM labels performs on par with or surpasses those of human labels. Across theoretically motivated moral frameworks, ICM yields its largest relative gains on Justice and Commonsense morality. Furthermore, although chatbot LMs exhibit social bias failure rates comparable to their pretrained ones, ICM reduces such errors by more than half, with the largest improvements in race, socioeconomic status, and politics. These findings suggest that pretrained LMs possess latent moral reasoning capacities that can be elicited through unsupervised methods like ICM, providing a scalable path for AI alignment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u5185\u90e8\u4e00\u81f4\u6027\u6700\u5927\u5316\uff08ICM\uff09\u7b97\u6cd5\u65e0\u76d1\u7763\u5730\u6fc0\u53d1\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u5728\u9053\u5fb7\u63a8\u7406\u80fd\u529b\uff0c\u65e0\u9700\u4eba\u5de5\u76d1\u7763\u5373\u53ef\u83b7\u5f97\u9ad8\u8d28\u91cf\u9053\u5fb7\u5224\u65ad\u6807\u7b7e\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u666e\u53ca\uff0c\u5c06\u5176\u884c\u4e3a\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u81f3\u5173\u91cd\u8981\u3002\u5148\u524d\u7814\u7a76\u8868\u660e\u8bed\u8a00\u6a21\u578b\u56fa\u6709\u7684\u9053\u5fb7\u63a8\u7406\u80fd\u529b\u6709\u9650\uff0c\u9700\u8981\u660e\u786e\u7684\u9053\u5fb7\u6559\u5bfc\u3002\u7136\u800c\uff0c\u6784\u5efa\u9053\u5fb7\u8bc4\u4f30\u7684\u57fa\u51c6\u6570\u636e\u9762\u4e34\u591a\u5143\u9053\u5fb7\u6846\u67b6\u548c\u666e\u904d\u504f\u89c1\u7684\u6311\u6218\u3002\u672c\u6587\u63a2\u7d22\u65e0\u76d1\u7763\u6fc0\u53d1\u4f5c\u4e3a\u66ff\u4ee3\u65b9\u6848\uff0c\u7814\u7a76\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u662f\u5426\u5177\u5907\u53ef\u901a\u8fc7\u65e0\u76d1\u7763\u65b9\u6cd5\u6fc0\u53d1\u7684\u5185\u5728\u9053\u5fb7\u63a8\u7406\u80fd\u529b\u3002", "method": "\u91c7\u7528\u5185\u90e8\u4e00\u81f4\u6027\u6700\u5927\u5316\uff08ICM\uff09\u7b97\u6cd5\uff0c\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff08Norm Bank\u3001ETHICS\u7b49\uff09\u548c\u56db\u4e2a\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002ICM\u901a\u8fc7\u6700\u5927\u5316\u6a21\u578b\u5185\u90e8\u4e00\u81f4\u6027\u6765\u65e0\u76d1\u7763\u5730\u751f\u6210\u9053\u5fb7\u5224\u65ad\u6807\u7b7e\uff0c\u65e0\u9700\u4eba\u7c7b\u76d1\u7763\u3002\u7814\u7a76\u6d4b\u8bd5\u4e86ICM\u5728\u53ef\u9760\u6807\u6ce8\u9053\u5fb7\u5224\u65ad\u3001\u8de8\u9053\u5fb7\u6846\u67b6\u6cdb\u5316\u4ee5\u53ca\u51cf\u8f7b\u793e\u4f1a\u504f\u89c1\u65b9\u9762\u7684\u80fd\u529b\u3002", "result": "ICM\u5728Norm Bank\u548cETHICS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u6240\u6709\u9884\u8bad\u7ec3\u548c\u804a\u5929\u673a\u5668\u4eba\u57fa\u7ebf\u3002\u4f7f\u7528ICM\u6807\u7b7e\u8fdb\u884c\u5fae\u8c03\u7684\u6a21\u578b\u8868\u73b0\u4e0e\u4f7f\u7528\u4eba\u7c7b\u6807\u7b7e\u7684\u6a21\u578b\u76f8\u5f53\u6216\u66f4\u4f18\u3002\u5728\u7406\u8bba\u9a71\u52a8\u7684\u9053\u5fb7\u6846\u67b6\u4e2d\uff0cICM\u5728\u6b63\u4e49\u548c\u5e38\u8bc6\u9053\u5fb7\u65b9\u9762\u83b7\u5f97\u6700\u5927\u76f8\u5bf9\u589e\u76ca\u3002\u867d\u7136\u804a\u5929\u673a\u5668\u4eba\u8bed\u8a00\u6a21\u578b\u7684\u793e\u4f1a\u504f\u89c1\u5931\u8d25\u7387\u4e0e\u9884\u8bad\u7ec3\u6a21\u578b\u76f8\u5f53\uff0c\u4f46ICM\u5c06\u6b64\u7c7b\u9519\u8bef\u51cf\u5c11\u4e86\u4e00\u534a\u4ee5\u4e0a\uff0c\u5728\u79cd\u65cf\u3001\u793e\u4f1a\u7ecf\u6d4e\u5730\u4f4d\u548c\u653f\u6cbb\u65b9\u9762\u7684\u6539\u8fdb\u6700\u5927\u3002", "conclusion": "\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5177\u5907\u53ef\u901a\u8fc7\u65e0\u76d1\u7763\u65b9\u6cd5\uff08\u5982ICM\uff09\u6fc0\u53d1\u7684\u6f5c\u5728\u9053\u5fb7\u63a8\u7406\u80fd\u529b\uff0c\u8fd9\u4e3aAI\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002ICM\u4e0d\u4ec5\u80fd\u53ef\u9760\u5730\u6807\u6ce8\u9053\u5fb7\u5224\u65ad\uff0c\u8fd8\u80fd\u8de8\u9053\u5fb7\u6846\u67b6\u6cdb\u5316\u5e76\u663e\u8457\u51cf\u8f7b\u793e\u4f1a\u504f\u89c1\u3002"}}
{"id": "2601.18175", "categories": ["cs.AI", "cs.LG", "eess.SY", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.18175", "abs": "https://arxiv.org/abs/2601.18175", "authors": ["Daniel Russo"], "title": "Success Conditioning as Policy Improvement: The Optimization Problem Solved by Imitating Success", "comment": null, "summary": "A widely used technique for improving policies is success conditioning, in which one collects trajectories, identifies those that achieve a desired outcome, and updates the policy to imitate the actions taken along successful trajectories. This principle appears under many names -- rejection sampling with SFT, goal-conditioned RL, Decision Transformers -- yet what optimization problem it solves, if any, has remained unclear. We prove that success conditioning exactly solves a trust-region optimization problem, maximizing policy improvement subject to a $\u03c7^2$ divergence constraint whose radius is determined automatically by the data. This yields an identity: relative policy improvement, the magnitude of policy change, and a quantity we call action-influence -- measuring how random variation in action choices affects success rates -- are exactly equal at every state. Success conditioning thus emerges as a conservative improvement operator. Exact success conditioning cannot degrade performance or induce dangerous distribution shift, but when it fails, it does so observably, by hardly changing the policy at all. We apply our theory to the common practice of return thresholding, showing this can amplify improvement, but at the cost of potential misalignment with the true objective.", "AI": {"tldr": "\u6210\u529f\u6761\u4ef6\u5316\uff08success conditioning\uff09\u662f\u4e00\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u7b56\u7565\u6539\u8fdb\u6280\u672f\uff0c\u901a\u8fc7\u6536\u96c6\u8f68\u8ff9\u3001\u8bc6\u522b\u6210\u529f\u8f68\u8ff9\u5e76\u6a21\u4eff\u5176\u52a8\u4f5c\u6765\u66f4\u65b0\u7b56\u7565\u3002\u672c\u6587\u8bc1\u660e\u8be5\u65b9\u6cd5\u7cbe\u786e\u89e3\u51b3\u4e86\u4e00\u4e2a\u4fe1\u4efb\u57df\u4f18\u5316\u95ee\u9898\uff0c\u5efa\u7acb\u4e86\u7b56\u7565\u6539\u8fdb\u3001\u7b56\u7565\u53d8\u5316\u5e45\u5ea6\u548c\u52a8\u4f5c\u5f71\u54cd\u4e4b\u95f4\u7684\u6052\u7b49\u5f0f\uff0c\u63ed\u793a\u4e86\u8be5\u65b9\u6cd5\u4f5c\u4e3a\u4fdd\u5b88\u6539\u8fdb\u7b97\u5b50\u7684\u672c\u8d28\u3002", "motivation": "\u6210\u529f\u6761\u4ef6\u5316\u6280\u672f\uff08\u5982\u62d2\u7edd\u91c7\u6837+SFT\u3001\u76ee\u6807\u6761\u4ef6RL\u3001\u51b3\u7b56\u53d8\u6362\u5668\u7b49\uff09\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u89e3\u51b3\u7684\u4f18\u5316\u95ee\u9898\u672c\u8d28\u4e00\u76f4\u4e0d\u660e\u786e\u3002\u672c\u6587\u65e8\u5728\u4ece\u7406\u8bba\u5c42\u9762\u9610\u660e\u6210\u529f\u6761\u4ef6\u5316\u7a76\u7adf\u89e3\u51b3\u4e86\u4ec0\u4e48\u4f18\u5316\u95ee\u9898\uff0c\u4ee5\u53ca\u5176\u6570\u5b66\u57fa\u7840\u662f\u4ec0\u4e48\u3002", "method": "\u901a\u8fc7\u6570\u5b66\u8bc1\u660e\uff0c\u5c55\u793a\u6210\u529f\u6761\u4ef6\u5316\u7cbe\u786e\u89e3\u51b3\u4e86\u4e00\u4e2a\u4fe1\u4efb\u57df\u4f18\u5316\u95ee\u9898\uff1a\u5728\u03c7\u00b2\u6563\u5ea6\u7ea6\u675f\u4e0b\u6700\u5927\u5316\u7b56\u7565\u6539\u8fdb\uff0c\u5176\u4e2d\u7ea6\u675f\u534a\u5f84\u7531\u6570\u636e\u81ea\u52a8\u786e\u5b9a\u3002\u5efa\u7acb\u4e86\u76f8\u5bf9\u7b56\u7565\u6539\u8fdb\u3001\u7b56\u7565\u53d8\u5316\u5e45\u5ea6\u548c\u52a8\u4f5c\u5f71\u54cd\u4e4b\u95f4\u7684\u6052\u7b49\u5173\u7cfb\u3002\u8fd8\u5c06\u7406\u8bba\u5e94\u7528\u4e8e\u5e38\u89c1\u7684\u56de\u62a5\u9608\u503c\u5316\u5b9e\u8df5\u3002", "result": "\u6210\u529f\u6761\u4ef6\u5316\u88ab\u8bc1\u660e\u662f\u4fdd\u5b88\u7684\u6539\u8fdb\u7b97\u5b50\uff1a\u5b83\u4e0d\u4f1a\u964d\u4f4e\u6027\u80fd\u6216\u5f15\u53d1\u5371\u9669\u7684\u5206\u5e03\u504f\u79fb\u3002\u5f53\u5931\u8d25\u65f6\uff0c\u5b83\u4f1a\u901a\u8fc7\u51e0\u4e4e\u4e0d\u6539\u53d8\u7b56\u7565\u6765\u53ef\u89c2\u5bdf\u5730\u5931\u8d25\u3002\u56de\u62a5\u9608\u503c\u5316\u53ef\u4ee5\u653e\u5927\u6539\u8fdb\uff0c\u4f46\u53ef\u80fd\u4ee5\u4e0e\u771f\u5b9e\u76ee\u6807\u4e0d\u5bf9\u9f50\u4e3a\u4ee3\u4ef7\u3002", "conclusion": "\u6210\u529f\u6761\u4ef6\u5316\u6280\u672f\u5177\u6709\u575a\u5b9e\u7684\u6570\u5b66\u57fa\u7840\uff0c\u5b83\u7cbe\u786e\u89e3\u51b3\u4e86\u4e00\u4e2a\u4fe1\u4efb\u57df\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u4f5c\u4e3a\u4fdd\u5b88\u7684\u6539\u8fdb\u7b97\u5b50\u8fd0\u884c\u3002\u8be5\u65b9\u6cd5\u5728\u7406\u8bba\u4e0a\u4fdd\u8bc1\u4e86\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4e3a\u5b9e\u8df5\u4e2d\u5e38\u89c1\u7684\u56de\u62a5\u9608\u503c\u5316\u63d0\u4f9b\u4e86\u7406\u8bba\u89e3\u91ca\u548c\u8b66\u793a\u3002"}}
{"id": "2601.17753", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17753", "abs": "https://arxiv.org/abs/2601.17753", "authors": ["Roberto Crotti", "Giovanni Denaro", "Zhiqiang Du", "Ricardo Mu\u00f1oz Mart\u00edn"], "title": "Hylog: A Hybrid Approach to Logging Text Production in Non-alphabetic Scripts", "comment": null, "summary": "Research keyloggers are essential for cognitive studies of text production, yet most fail to capture the on-screen transformations performed by Input Method Editors (IMEs) for non-alphabetic scripts. To address this methodological gap, we present Hylog, a novel hybrid logging system that combines analytical keylogging with ecological text logging for a more complete and finer-grained analysis. Our modular, open-source system uses plug-ins for standard applications (Microsoft Word, Google Chrome) to capture both keyboard output and rendered text, which a hybridizer module then synchronizes into a dual trace. To validate the system's technical feasibility and demonstrate its analytical capabilities, we conducted a proof-of-concept study where two volunteers translated a text into simplified Chinese. Hylog successfully captured keypresses and temporal intervals between Latin letters, Chinese characters, and IME confirmations -- some measurements invisible to traditional keyloggers. The resulting data enable the formulation of new, testable hypotheses about the cognitive restrictions and affordances at different linguistic layers in IME-mediated typing. Our plug-in architecture enables extension to other IME systems and fosters more inclusive multilingual text-production research.", "AI": {"tldr": "Hylog\u662f\u4e00\u4e2a\u6df7\u5408\u65e5\u5fd7\u7cfb\u7edf\uff0c\u7ed3\u5408\u5206\u6790\u6027\u952e\u76d8\u8bb0\u5f55\u548c\u751f\u6001\u6587\u672c\u8bb0\u5f55\uff0c\u7528\u4e8e\u7814\u7a76\u975e\u5b57\u6bcd\u6587\u5b57\u8f93\u5165\u6cd5\u7f16\u8f91\u5668\u7684\u5c4f\u5e55\u8f6c\u6362\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u952e\u76d8\u8bb0\u5f55\u5de5\u5177\u5927\u591a\u65e0\u6cd5\u6355\u6349\u975e\u5b57\u6bcd\u6587\u5b57\u8f93\u5165\u6cd5\u7f16\u8f91\u5668\uff08IME\uff09\u5728\u5c4f\u5e55\u4e0a\u8fdb\u884c\u7684\u8f6c\u6362\u8fc7\u7a0b\uff0c\u8fd9\u9650\u5236\u4e86\u8ba4\u77e5\u7814\u7a76\u4e2d\u6587\u672c\u751f\u4ea7\u7684\u5b8c\u6574\u5206\u6790\u3002", "method": "\u5f00\u53d1\u4e86\u6a21\u5757\u5316\u5f00\u6e90\u7cfb\u7edfHylog\uff0c\u901a\u8fc7\u63d2\u4ef6\u6355\u83b7\u6807\u51c6\u5e94\u7528\u7a0b\u5e8f\u4e2d\u7684\u952e\u76d8\u8f93\u51fa\u548c\u6e32\u67d3\u6587\u672c\uff0c\u7136\u540e\u7531\u6df7\u5408\u5668\u6a21\u5757\u540c\u6b65\u4e3a\u53cc\u91cd\u8f68\u8ff9\u3002", "result": "\u5728\u6982\u5ff5\u9a8c\u8bc1\u7814\u7a76\u4e2d\u6210\u529f\u6355\u83b7\u4e86\u6309\u952e\u3001\u62c9\u4e01\u5b57\u6bcd\u3001\u4e2d\u6587\u5b57\u7b26\u548cIME\u786e\u8ba4\u4e4b\u95f4\u7684\u65f6\u95f4\u95f4\u9694\uff0c\u8fd9\u4e9b\u6d4b\u91cf\u4f20\u7edf\u952e\u76d8\u8bb0\u5f55\u5668\u65e0\u6cd5\u83b7\u53d6\u3002", "conclusion": "Hylog\u80fd\u591f\u652f\u6301\u5173\u4e8eIME\u4e2d\u4ecb\u6253\u5b57\u4e2d\u4e0d\u540c\u8bed\u8a00\u5c42\u8ba4\u77e5\u9650\u5236\u548c\u53ef\u4f9b\u6027\u7684\u65b0\u5047\u8bbe\uff0c\u5176\u63d2\u4ef6\u67b6\u6784\u53ef\u6269\u5c55\u5230\u5176\u4ed6IME\u7cfb\u7edf\uff0c\u4fc3\u8fdb\u66f4\u5305\u5bb9\u7684\u591a\u8bed\u8a00\u6587\u672c\u751f\u4ea7\u7814\u7a76\u3002"}}
{"id": "2601.17755", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17755", "abs": "https://arxiv.org/abs/2601.17755", "authors": ["Jinyoung Park", "Sanghyeok Lee", "Omar Zia Khan", "Hyunwoo J. Kim", "Joo-Kyung Kim"], "title": "ProGraph-R1: Progress-aware Reinforcement Learning for Graph Retrieval Augmented Generation", "comment": "In progress", "summary": "Graph Retrieval-Augmented Generation (GraphRAG) has been successfully applied in various knowledge-intensive question answering tasks by organizing external knowledge into structured graphs of entities and relations. It enables large language models (LLMs) to perform complex reasoning beyond text-chunk retrieval. Recent works have employed reinforcement learning (RL) to train agentic GraphRAG frameworks that perform iterative interactions between LLMs and knowledge graphs. However, existing RL-based frameworks such as Graph-R1 suffer from two key limitations: (1) they primarily depend on semantic similarity for retrieval, often overlooking the underlying graph structure, and (2) they rely on sparse, outcome-level rewards, failing to capture the quality of intermediate retrieval steps and their dependencies. To address these limitations, we propose ProGraph-R1, a progress-aware agentic framework for graph-based retrieval and multi-step reasoning. ProGraph-R1 introduces a structure-aware hypergraph retrieval mechanism that jointly considers semantic relevance and graph connectivity, encouraging coherent traversal along multi-hop reasoning paths. We also design a progress-based step-wise policy optimization, which provides dense learning signals by modulating advantages according to intermediate reasoning progress within a graph, rather than relying solely on final outcomes. Experiments on multi-hop question answering benchmarks demonstrate that ProGraph-R1 consistently improves reasoning accuracy and generation quality over existing GraphRAG methods.", "AI": {"tldr": "ProGraph-R1\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fdb\u5ea6\u7684\u56fe\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u611f\u77e5\u7684\u8d85\u56fe\u68c0\u7d22\u673a\u5236\u548c\u57fa\u4e8e\u8fdb\u5ea6\u7684\u9010\u6b65\u7b56\u7565\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u73b0\u6709RL-based GraphRAG\u65b9\u6cd5\u5728\u7ed3\u6784\u5229\u7528\u548c\u5956\u52b1\u7a00\u758f\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684GraphRAG\u6846\u67b6\uff08\u5982Graph-R1\uff09\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a1\uff09\u4e3b\u8981\u4f9d\u8d56\u8bed\u4e49\u76f8\u4f3c\u6027\u8fdb\u884c\u68c0\u7d22\uff0c\u5ffd\u89c6\u4e86\u5e95\u5c42\u7684\u56fe\u7ed3\u6784\uff1b2\uff09\u4f9d\u8d56\u7a00\u758f\u7684\u7ed3\u679c\u7ea7\u5956\u52b1\uff0c\u65e0\u6cd5\u6355\u6349\u4e2d\u95f4\u68c0\u7d22\u6b65\u9aa4\u7684\u8d28\u91cf\u53ca\u5176\u4f9d\u8d56\u5173\u7cfb\u3002\u8fd9\u4e9b\u9650\u5236\u5f71\u54cd\u4e86\u591a\u6b65\u63a8\u7406\u7684\u6027\u80fd\u3002", "method": "ProGraph-R1\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u7ed3\u6784\u611f\u77e5\u7684\u8d85\u56fe\u68c0\u7d22\u673a\u5236\uff0c\u8054\u5408\u8003\u8651\u8bed\u4e49\u76f8\u5173\u6027\u548c\u56fe\u8fde\u63a5\u6027\uff0c\u9f13\u52b1\u6cbf\u7740\u591a\u8df3\u63a8\u7406\u8def\u5f84\u8fdb\u884c\u8fde\u8d2f\u904d\u5386\uff1b2\uff09\u57fa\u4e8e\u8fdb\u5ea6\u7684\u9010\u6b65\u7b56\u7565\u4f18\u5316\uff0c\u901a\u8fc7\u6839\u636e\u56fe\u4e2d\u4e2d\u95f4\u63a8\u7406\u8fdb\u5ea6\u8c03\u6574\u4f18\u52bf\u51fd\u6570\u6765\u63d0\u4f9b\u5bc6\u96c6\u5b66\u4e60\u4fe1\u53f7\uff0c\u800c\u4e0d\u662f\u4ec5\u4f9d\u8d56\u6700\u7ec8\u7ed3\u679c\u3002", "result": "\u5728\u591a\u8df3\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cProGraph-R1\u5728\u63a8\u7406\u51c6\u786e\u6027\u548c\u751f\u6210\u8d28\u91cf\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u7684GraphRAG\u65b9\u6cd5\u3002", "conclusion": "ProGraph-R1\u901a\u8fc7\u7ed3\u5408\u7ed3\u6784\u611f\u77e5\u68c0\u7d22\u548c\u57fa\u4e8e\u8fdb\u5ea6\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709GraphRAG\u6846\u67b6\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u77e5\u8bc6\u5bc6\u96c6\u578b\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u591a\u6b65\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17764", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17764", "abs": "https://arxiv.org/abs/2601.17764", "authors": ["Md Asgor Hossain Reaj", "Rajan Das Gupta", "Jui Saha Pritha", "Abdullah Al Noman", "Abir Ahmed", "Golam Md Mohiuddin", "Tze Hui Liew"], "title": "Cross-Lingual Probing and Community-Grounded Analysis of Gender Bias in Low-Resource Bengali", "comment": "Accepted in 2025 4th International Conference on Smart Cities, Automation & Intelligent Computing Systems (ICON-SONICS)", "summary": "Large Language Models (LLMs) have achieved significant success in recent years; yet, issues of intrinsic gender bias persist, especially in non-English languages. Although current research mostly emphasizes English, the linguistic and cultural biases inherent in Global South languages, like Bengali, are little examined. This research seeks to examine the characteristics and magnitude of gender bias in Bengali, evaluating the efficacy of current approaches in identifying and alleviating bias. We use several methods to extract gender-biased utterances, including lexicon-based mining, computational classification models, translation-based comparison analysis, and GPT-based bias creation. Our research indicates that the straight application of English-centric bias detection frameworks to Bengali is severely constrained by language disparities and socio-cultural factors that impact implicit biases. To tackle these difficulties, we executed two field investigations inside rural and low-income areas, gathering authentic insights on gender bias. The findings demonstrate that gender bias in Bengali presents distinct characteristics relative to English, requiring a more localized and context-sensitive methodology. Additionally, our research emphasizes the need of integrating community-driven research approaches to identify culturally relevant biases often neglected by automated systems. Our research enhances the ongoing discussion around gender bias in AI by illustrating the need to create linguistic tools specifically designed for underrepresented languages. This study establishes a foundation for further investigations into bias reduction in Bengali and other Indic languages, promoting the development of more inclusive and fair NLP systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u5b5f\u52a0\u62c9\u8bed\u4e2dLLMs\u7684\u6027\u522b\u504f\u89c1\u7279\u5f81\uff0c\u53d1\u73b0\u82f1\u8bed\u4e2d\u5fc3\u7684\u504f\u89c1\u68c0\u6d4b\u6846\u67b6\u5728\u5b5f\u52a0\u62c9\u8bed\u4e2d\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u57fa\u4e8e\u672c\u5730\u6587\u5316\u548c\u8bed\u5883\u7684\u5b9a\u5236\u5316\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5173\u4e8eLLMs\u6027\u522b\u504f\u89c1\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u4e8e\u82f1\u8bed\uff0c\u800c\u5bf9\u5168\u7403\u5357\u65b9\u8bed\u8a00\uff08\u5982\u5b5f\u52a0\u62c9\u8bed\uff09\u4e2d\u7684\u8bed\u8a00\u548c\u6587\u5316\u504f\u89c1\u7814\u7a76\u4e0d\u8db3\u3002\u8be5\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u8bc4\u4f30\u5b5f\u52a0\u62c9\u8bed\u4e2d\u6027\u522b\u504f\u89c1\u7684\u7279\u5f81\u548c\u7a0b\u5ea6\uff0c\u5e76\u68c0\u9a8c\u73b0\u6709\u504f\u89c1\u68c0\u6d4b\u548c\u7f13\u89e3\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "method": "\u91c7\u7528\u591a\u79cd\u65b9\u6cd5\u63d0\u53d6\u6027\u522b\u504f\u89c1\u8bdd\u8bed\uff1a\u57fa\u4e8e\u8bcd\u5178\u7684\u6316\u6398\u3001\u8ba1\u7b97\u5206\u7c7b\u6a21\u578b\u3001\u57fa\u4e8e\u7ffb\u8bd1\u7684\u6bd4\u8f83\u5206\u6790\u3001GPT\u9a71\u52a8\u7684\u504f\u89c1\u751f\u6210\u3002\u540c\u65f6\u8fdb\u884c\u4e86\u4e24\u9879\u5b9e\u5730\u8c03\u67e5\uff0c\u5728\u4e61\u6751\u548c\u4f4e\u6536\u5165\u5730\u533a\u6536\u96c6\u771f\u5b9e\u504f\u89c1\u6570\u636e\uff0c\u4ee5\u5f25\u8865\u81ea\u52a8\u5316\u7cfb\u7edf\u7684\u4e0d\u8db3\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u82f1\u8bed\u4e2d\u5fc3\u7684\u504f\u89c1\u68c0\u6d4b\u6846\u67b6\u76f4\u63a5\u5e94\u7528\u4e8e\u5b5f\u52a0\u62c9\u8bed\u65f6\u53d7\u5230\u4e25\u91cd\u9650\u5236\uff0c\u4e3b\u8981\u53d7\u8bed\u8a00\u5dee\u5f02\u548c\u793e\u4f1a\u6587\u5316\u56e0\u7d20\u5f71\u54cd\u3002\u5b5f\u52a0\u62c9\u8bed\u7684\u6027\u522b\u504f\u89c1\u8868\u73b0\u51fa\u4e0e\u82f1\u8bed\u4e0d\u540c\u7684\u7279\u5f81\uff0c\u9700\u8981\u66f4\u672c\u5730\u5316\u548c\u8bed\u5883\u654f\u611f\u7684\u65b9\u6cd5\u3002\u793e\u533a\u9a71\u52a8\u7684\u7814\u7a76\u65b9\u6cd5\u80fd\u8bc6\u522b\u81ea\u52a8\u5316\u7cfb\u7edf\u5e38\u5ffd\u7565\u7684\u6587\u5316\u76f8\u5173\u504f\u89c1\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u4e3a\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u8bed\u8a00\u5f00\u53d1\u4e13\u95e8\u8bed\u8a00\u5de5\u5177\u7684\u5fc5\u8981\u6027\uff0c\u4e3a\u5b5f\u52a0\u62c9\u8bed\u548c\u5176\u4ed6\u5370\u5ea6\u8bed\u8a00\u4e2d\u7684\u504f\u89c1\u51cf\u5c11\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u4fc3\u8fdb\u4e86\u66f4\u5305\u5bb9\u548c\u516c\u5e73\u7684NLP\u7cfb\u7edf\u53d1\u5c55\u3002"}}
{"id": "2601.18217", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18217", "abs": "https://arxiv.org/abs/2601.18217", "authors": ["Zhihan Liu", "Lin Guan", "Yixin Nie", "Kai Zhang", "Zhuoqun Hao", "Lin Chen", "Asli Celikyilmaz", "Zhaoran Wang", "Na Zhang"], "title": "Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents", "comment": null, "summary": "Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization.", "AI": {"tldr": "\u7814\u7a76LLM\u667a\u80fd\u4f53\u5728\u672a\u77e5\u6d4b\u8bd5\u9886\u57df\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u53d1\u73b0\u73af\u5883\u72b6\u6001\u4fe1\u606f\u4e30\u5bcc\u5ea6\u548c\u89c4\u5212\u590d\u6742\u5ea6\u662f\u5f71\u54cd\u8de8\u57df\u6cdb\u5316\u7684\u5173\u952e\u56e0\u7d20\uff0c\u800c\u975e\u9886\u57df\u771f\u5b9e\u6027\u6216\u6587\u672c\u76f8\u4f3c\u5ea6", "motivation": "\u901a\u7528LLM\u667a\u80fd\u4f53\u901a\u5e38\u5728\u72ed\u7a84\u73af\u5883\u96c6\u4e0a\u8fdb\u884c\u540e\u8bad\u7ec3\uff0c\u4f46\u90e8\u7f72\u5230\u66f4\u5e7f\u6cdb\u7684\u672a\u77e5\u9886\u57df\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5f53\u6700\u7ec8\u6d4b\u8bd5\u9886\u57df\u672a\u77e5\u65f6\uff0c\u667a\u80fd\u4f53\u540e\u8bad\u7ec3\u9762\u4e34\u7684\u6311\u6218\uff0c\u5206\u6790\u54ea\u4e9bRL\u73af\u5883\u5c5e\u6027\u548c\u5efa\u6a21\u9009\u62e9\u5bf9\u8de8\u57df\u6027\u80fd\u5f71\u54cd\u6700\u5927", "method": "\u9996\u5148\u8bc6\u522b\u4e0e\u8de8\u57df\u6cdb\u5316\u5f3a\u76f8\u5173\u7684\u4e24\u4e2a\u73af\u5883\u8f74\uff1a\u72b6\u6001\u4fe1\u606f\u4e30\u5bcc\u5ea6\uff08agent\u9700\u8981\u5904\u7406\u7684\u72b6\u6001\u4fe1\u606f\u91cf\uff09\u548c\u89c4\u5212\u590d\u6742\u5ea6\uff08\u901a\u8fc7\u57fa\u7840\u7b56\u7565\u4e0b\u7684\u76ee\u6807\u53ef\u8fbe\u6027\u548c\u8f68\u8ff9\u957f\u5ea6\u4f30\u8ba1\uff09\u3002\u63d0\u51fa\u968f\u673a\u5316\u6280\u672f\uff1a\u5411\u72b6\u6001\u6dfb\u52a0\u5c11\u91cf\u5206\u6563\u6ce8\u610f\u529b\u7684\u76ee\u6807\u65e0\u5173\u7279\u5f81\u6765\u589e\u52a0\u72b6\u6001\u4e30\u5bcc\u5ea6\u800c\u4e0d\u6539\u53d8\u4efb\u52a1\u3002\u540c\u65f6\u8003\u5bdf\u5efa\u6a21\u9009\u62e9\uff1aSFT\u9884\u70ed\u6216\u4e2d\u671f\u8bad\u7ec3\u7684\u5f71\u54cd\uff0c\u4ee5\u53caRL\u671f\u95f4\u542f\u7528\u9010\u6b65\u601d\u8003\u7684\u4f5c\u7528", "result": "\u53d1\u73b0\u72b6\u6001\u4fe1\u606f\u4e30\u5bcc\u5ea6\u548c\u89c4\u5212\u590d\u6742\u5ea6\u662f\u8de8\u57df\u6cdb\u5316\u7684\u5173\u952e\u56e0\u7d20\uff0c\u9886\u57df\u771f\u5b9e\u6027\u548c\u6587\u672c\u76f8\u4f3c\u5ea6\u5e76\u975e\u4e3b\u8981\u56e0\u7d20\u3002\u589e\u52a0\u72b6\u6001\u4fe1\u606f\u4e30\u5bcc\u5ea6\u80fd\u6709\u6548\u63d0\u9ad8\u8de8\u57df\u9c81\u68d2\u6027\u3002SFT\u9884\u70ed/\u4e2d\u671f\u8bad\u7ec3\u6709\u52a9\u4e8e\u9632\u6b62RL\u671f\u95f4\u7684\u707e\u96be\u6027\u9057\u5fd8\uff0c\u4f46\u4f1a\u524a\u5f31\u5bf9\u672a\u5305\u542b\u5728\u4e2d\u671f\u8bad\u7ec3\u6570\u636e\u6df7\u5408\u4e2d\u7684\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\u3002\u542f\u7528\u9010\u6b65\u601d\u8003\u5728RL\u671f\u95f4\u867d\u4e0d\u603b\u80fd\u63d0\u9ad8\u57df\u5185\u6027\u80fd\uff0c\u4f46\u5bf9\u4fdd\u6301\u6cdb\u5316\u80fd\u529b\u81f3\u5173\u91cd\u8981", "conclusion": "\u4e3a\u63d0\u5347LLM\u667a\u80fd\u4f53\u5728\u672a\u77e5\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e94\u5173\u6ce8\u73af\u5883\u72b6\u6001\u4fe1\u606f\u4e30\u5bcc\u5ea6\u548c\u89c4\u5212\u590d\u6742\u5ea6\uff0c\u800c\u975e\u9886\u57df\u771f\u5b9e\u6027\u3002\u63d0\u51fa\u7684\u968f\u673a\u5316\u6280\u672f\u662f\u4f4e\u5f00\u9500\u4e14\u5e7f\u6cdb\u9002\u7528\u7684\u65b9\u6cd5\u3002\u5728\u5efa\u6a21\u65b9\u9762\uff0c\u9700\u8981\u6743\u8861SFT\u8bad\u7ec3\u4e0e\u6cdb\u5316\u80fd\u529b\u7684\u5173\u7cfb\uff0c\u5e76\u91cd\u89c6\u9010\u6b65\u601d\u8003\u5728\u4fdd\u6301\u8de8\u57df\u6cdb\u5316\u4e2d\u7684\u4f5c\u7528"}}
{"id": "2601.17777", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17777", "abs": "https://arxiv.org/abs/2601.17777", "authors": ["Xiaoyu Liu", "Xiaoyu Guan", "Di Liang", "Xianjie Wu"], "title": "DPI: Exploiting Parameter Heterogeneity for Interference-Free Fine-Tuning", "comment": null, "summary": "Supervised fine-tuning (SFT) is a crucial step for adapting large language models (LLMs) to downstream tasks. However, conflicting objectives across heterogeneous SFT tasks often induce the \"seesaw effect\": optimizing for one task may degrade performance on others, particularly when model parameters are updated indiscriminately. In this paper, we propose a principled approach to disentangle and isolate task-specific parameter regions, motivated by the hypothesis that parameter heterogeneity underlies cross-task interference. Specifically, we first independently fine-tune LLMs on diverse SFT tasks and identify each task's core parameter region as the subset of parameters exhibiting the largest updates. Tasks with highly overlapping core parameter regions are merged for joint training, while disjoint tasks are organized into different stages. During multi-stage SFT, core parameters acquired in prior tasks are frozen, thereby preventing overwriting by subsequent tasks. To verify the effectiveness of our method, we conducted intensive experiments on multiple public datasets. The results showed that our dynamic parameter isolation strategy consistently reduced data conflicts and achieved consistent performance improvements compared to multi-stage and multi-task tuning baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u52a8\u6001\u53c2\u6570\u9694\u79bb\u7b56\u7565\u6765\u89e3\u51b3SFT\u4e2d\u7684\u8df7\u8df7\u677f\u6548\u5e94\uff0c\u901a\u8fc7\u8bc6\u522b\u4efb\u52a1\u6838\u5fc3\u53c2\u6570\u533a\u57df\u5e76\u5206\u9636\u6bb5\u51bb\u7ed3\u6765\u51cf\u5c11\u4efb\u52a1\u95f4\u5e72\u6270", "motivation": "\u76d1\u7763\u5fae\u8c03(SFT)\u4e2d\uff0c\u5f02\u6784\u4efb\u52a1\u95f4\u7684\u51b2\u7a81\u76ee\u6807\u4f1a\u5bfc\u81f4\"\u8df7\u8df7\u677f\u6548\u5e94\"\uff1a\u4f18\u5316\u4e00\u4e2a\u4efb\u52a1\u53ef\u80fd\u964d\u4f4e\u5176\u4ed6\u4efb\u52a1\u6027\u80fd\uff0c\u7279\u522b\u662f\u5f53\u6a21\u578b\u53c2\u6570\u88ab\u65e0\u5dee\u522b\u66f4\u65b0\u65f6\u3002\u53c2\u6570\u5f02\u8d28\u6027\u88ab\u8ba4\u4e3a\u662f\u8de8\u4efb\u52a1\u5e72\u6270\u7684\u6839\u672c\u539f\u56e0\u3002", "method": "1. \u5728\u4e0d\u540cSFT\u4efb\u52a1\u4e0a\u72ec\u7acb\u5fae\u8c03LLMs\uff0c\u8bc6\u522b\u6bcf\u4e2a\u4efb\u52a1\u7684\u6838\u5fc3\u53c2\u6570\u533a\u57df\uff08\u66f4\u65b0\u5e45\u5ea6\u6700\u5927\u7684\u53c2\u6570\u5b50\u96c6\uff09\uff1b2. \u5408\u5e76\u6838\u5fc3\u53c2\u6570\u533a\u57df\u9ad8\u5ea6\u91cd\u53e0\u7684\u4efb\u52a1\u8fdb\u884c\u8054\u5408\u8bad\u7ec3\uff0c\u5c06\u4e0d\u76f8\u4ea4\u7684\u4efb\u52a1\u7ec4\u7ec7\u5230\u4e0d\u540c\u9636\u6bb5\uff1b3. \u5728\u591a\u9636\u6bb5SFT\u4e2d\uff0c\u51bb\u7ed3\u5148\u524d\u4efb\u52a1\u83b7\u5f97\u7684\u6838\u5fc3\u53c2\u6570\uff0c\u9632\u6b62\u88ab\u540e\u7eed\u4efb\u52a1\u8986\u76d6\u3002", "result": "\u5728\u591a\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5bc6\u96c6\u5b9e\u9a8c\u8868\u660e\uff0c\u52a8\u6001\u53c2\u6570\u9694\u79bb\u7b56\u7565\u80fd\u6301\u7eed\u51cf\u5c11\u6570\u636e\u51b2\u7a81\uff0c\u76f8\u6bd4\u591a\u9636\u6bb5\u548c\u591a\u4efb\u52a1\u8c03\u4f18\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u6301\u7eed\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u8bc6\u522b\u548c\u9694\u79bb\u4efb\u52a1\u7279\u5b9a\u53c2\u6570\u533a\u57df\uff0c\u53ef\u4ee5\u6709\u6548\u7f13\u89e3SFT\u4e2d\u7684\u8df7\u8df7\u677f\u6548\u5e94\uff0c\u8be5\u65b9\u6cd5\u4e3a\u5904\u7406\u5f02\u6784\u4efb\u52a1\u95f4\u7684\u53c2\u6570\u51b2\u7a81\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18225", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18225", "abs": "https://arxiv.org/abs/2601.18225", "authors": ["Pei Wang", "Yanan Wu", "Xiaoshuai Song", "Weixun Wang", "Gengru Chen", "Zhongwen Li", "Kezhong Yan", "Ken Deng", "Qi Liu", "Shuaibing Zhao", "Shaopan Xiong", "Xuepeng Liu", "Xuefeng Chen", "Wanxi Deng", "Wenbo Su", "Bo Zheng"], "title": "ShopSimulator: Evaluating and Exploring RL-Driven LLM Agent for Shopping Assistants", "comment": null, "summary": "Large language model (LLM)-based agents are increasingly deployed in e-commerce shopping. To perform thorough, user-tailored product searches, agents should interpret personal preferences, engage in multi-turn dialogues, and ultimately retrieve and discriminate among highly similar products. However, existing research has yet to provide a unified simulation environment that consistently captures all of these aspects, and always focuses solely on evaluation benchmarks without training support. In this paper, we introduce ShopSimulator, a large-scale and challenging Chinese shopping environment. Leveraging ShopSimulator, we evaluate LLMs across diverse scenarios, finding that even the best-performing models achieve less than 40% full-success rate. Error analysis reveals that agents struggle with deep search and product selection in long trajectories, fail to balance the use of personalization cues, and to effectively engage with users. Further training exploration provides practical guidance for overcoming these weaknesses, with the combination of supervised fine-tuning (SFT) and reinforcement learning (RL) yielding significant performance improvements. Code and data will be released at https://github.com/ShopAgent-Team/ShopSimulator.", "code_url": "https://github.com/ShopAgent-Team/ShopSimulator", "code_stars": 3, "code_last_update": "2026-01-27", "AI": {"tldr": "ShopSimulator\uff1a\u4e00\u4e2a\u5927\u89c4\u6a21\u4e2d\u6587\u7535\u5546\u8d2d\u7269\u6a21\u62df\u73af\u5883\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u8bad\u7ec3LLM\u667a\u80fd\u4f53\u5728\u4e2a\u6027\u5316\u4ea7\u54c1\u641c\u7d22\u3001\u591a\u8f6e\u5bf9\u8bdd\u548c\u76f8\u4f3c\u4ea7\u54c1\u8fa8\u522b\u65b9\u9762\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u7edf\u4e00\u7684\u6a21\u62df\u73af\u5883\u6765\u5168\u9762\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u5728\u7535\u5546\u8d2d\u7269\u4e2d\u7684\u5173\u952e\u80fd\u529b\uff0c\u5305\u62ec\uff1a\u7406\u89e3\u4e2a\u4eba\u504f\u597d\u3001\u8fdb\u884c\u591a\u8f6e\u5bf9\u8bdd\u3001\u68c0\u7d22\u548c\u533a\u5206\u9ad8\u5ea6\u76f8\u4f3c\u7684\u4ea7\u54c1\u3002\u73b0\u6709\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u8bc4\u4f30\u57fa\u51c6\uff0c\u7f3a\u4e4f\u8bad\u7ec3\u652f\u6301\u3002", "method": "\u63d0\u51faShopSimulator\u2014\u2014\u4e00\u4e2a\u5927\u89c4\u6a21\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u4e2d\u6587\u8d2d\u7269\u73af\u5883\u3002\u5229\u7528\u8be5\u73af\u5883\u8bc4\u4f30LLM\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u8fdb\u884c\u9519\u8bef\u5206\u6790\u3002\u8fdb\u4e00\u6b65\u63a2\u7d22\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5305\u62ec\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u548c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7684\u7ec4\u5408\u3002", "result": "\u8bc4\u4f30\u53d1\u73b0\u5373\u4f7f\u8868\u73b0\u6700\u597d\u7684\u6a21\u578b\u5b8c\u6574\u6210\u529f\u7387\u4e5f\u4e0d\u523040%\u3002\u9519\u8bef\u5206\u6790\u663e\u793a\u667a\u80fd\u4f53\u5728\u957f\u8f68\u8ff9\u4e2d\u7684\u6df1\u5ea6\u641c\u7d22\u548c\u4ea7\u54c1\u9009\u62e9\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u65e0\u6cd5\u5e73\u8861\u4e2a\u6027\u5316\u7ebf\u7d22\u7684\u4f7f\u7528\uff0c\u4e14\u4e0e\u7528\u6237\u4e92\u52a8\u6548\u679c\u4e0d\u4f73\u3002SFT\u548cRL\u7684\u7ec4\u5408\u8bad\u7ec3\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "ShopSimulator\u4e3aLLM\u667a\u80fd\u4f53\u5728\u7535\u5546\u8d2d\u7269\u4e2d\u7684\u5168\u9762\u8bc4\u4f30\u548c\u8bad\u7ec3\u63d0\u4f9b\u4e86\u7edf\u4e00\u73af\u5883\u3002\u5b9e\u9a8c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u8bc1\u660e\u7ed3\u5408SFT\u548cRL\u7684\u8bad\u7ec3\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u667a\u80fd\u4f53\u5728\u590d\u6742\u8d2d\u7269\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2601.17781", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17781", "abs": "https://arxiv.org/abs/2601.17781", "authors": ["Andreas S\u00e4uberli", "Darja Jepifanova", "Diego Frassinelli", "Barbara Plank"], "title": "Controlling Reading Ease with Gaze-Guided Text Generation", "comment": "Accepted for publication at EACL 2026", "summary": "The way our eyes move while reading can tell us about the cognitive effort required to process the text. In the present study, we use this fact to generate texts with controllable reading ease. Our method employs a model that predicts human gaze patterns to steer language model outputs towards eliciting certain reading behaviors. We evaluate the approach in an eye-tracking experiment with native and non-native speakers of English. The results demonstrate that the method is effective at making the generated texts easier or harder to read, measured both in terms of reading times and perceived difficulty of the texts. A statistical analysis reveals that the changes in reading behavior are mostly due to features that affect lexical processing. Possible applications of our approach include text simplification for information accessibility and generation of personalized educational material for language learning.", "AI": {"tldr": "\u4f7f\u7528\u773c\u52a8\u9884\u6d4b\u6a21\u578b\u63a7\u5236\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u672c\u7684\u9605\u8bfb\u96be\u5ea6\uff0c\u901a\u8fc7\u773c\u52a8\u8ffd\u8e2a\u5b9e\u9a8c\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027", "motivation": "\u5229\u7528\u9605\u8bfb\u65f6\u7684\u773c\u52a8\u6a21\u5f0f\u53cd\u6620\u8ba4\u77e5\u8d1f\u8377\u7684\u7279\u6027\uff0c\u5f00\u53d1\u80fd\u591f\u63a7\u5236\u6587\u672c\u9605\u8bfb\u96be\u5ea6\u7684\u751f\u6210\u65b9\u6cd5\uff0c\u4ee5\u6539\u5584\u4fe1\u606f\u53ef\u53ca\u6027\u548c\u8bed\u8a00\u5b66\u4e60\u6750\u6599", "method": "\u91c7\u7528\u9884\u6d4b\u4eba\u7c7b\u6ce8\u89c6\u6a21\u5f0f\u7684\u6a21\u578b\u6765\u5f15\u5bfc\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\uff0c\u4f7f\u5176\u4ea7\u751f\u7279\u5b9a\u7684\u9605\u8bfb\u884c\u4e3a\uff0c\u901a\u8fc7\u773c\u52a8\u8ffd\u8e2a\u5b9e\u9a8c\u8bc4\u4f30\u65b9\u6cd5\u6548\u679c", "result": "\u65b9\u6cd5\u80fd\u6709\u6548\u4f7f\u751f\u6210\u6587\u672c\u53d8\u5f97\u66f4\u6613\u6216\u66f4\u96be\u9605\u8bfb\uff0c\u4f53\u73b0\u5728\u9605\u8bfb\u65f6\u95f4\u548c\u611f\u77e5\u96be\u5ea6\u4e0a\uff1b\u7edf\u8ba1\u5206\u6790\u663e\u793a\u9605\u8bfb\u884c\u4e3a\u53d8\u5316\u4e3b\u8981\u6e90\u4e8e\u5f71\u54cd\u8bcd\u6c47\u5904\u7406\u7684\u7279\u5f81", "conclusion": "\u57fa\u4e8e\u773c\u52a8\u9884\u6d4b\u7684\u6587\u672c\u751f\u6210\u65b9\u6cd5\u80fd\u6709\u6548\u63a7\u5236\u9605\u8bfb\u96be\u5ea6\uff0c\u5728\u4fe1\u606f\u53ef\u53ca\u6027\u6587\u672c\u7b80\u5316\u548c\u4e2a\u6027\u5316\u8bed\u8a00\u5b66\u4e60\u6750\u6599\u751f\u6210\u65b9\u9762\u5177\u6709\u5e94\u7528\u6f5c\u529b"}}
{"id": "2601.18226", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18226", "abs": "https://arxiv.org/abs/2601.18226", "authors": ["Haotian Li", "Shijun Yang", "Weizhen Qi", "Silei Zhao", "Rui Hua", "Mingzhu Song", "Xiaojian Yang", "Chao Peng"], "title": "Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks", "comment": null, "summary": "Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.", "AI": {"tldr": "\u63d0\u51faIn-Situ Self-Evolving\u8303\u5f0f\uff0c\u901a\u8fc7\u5de5\u5177\u6f14\u5316\u5b9e\u73b0\u667a\u80fd\u4f53\u5728\u5f00\u653e\u73af\u5883\u4e2d\u7684\u6301\u7eed\u80fd\u529b\u6269\u5c55\uff0c\u65e0\u9700\u771f\u5b9e\u6807\u7b7e\u76d1\u7763", "motivation": "\u4f20\u7edf\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u5f00\u653e\u73af\u5883\u4e2d\u9762\u4e34\u4efb\u52a1\u5206\u5e03\u6301\u7eed\u6f02\u79fb\u548c\u5916\u90e8\u76d1\u7763\u7a00\u7f3a\u7684\u6311\u6218\uff0c\u4f9d\u8d56\u9759\u6001\u5de5\u5177\u96c6\u6216\u79bb\u7ebf\u8bad\u7ec3\u5bfc\u81f4\u80fd\u529b\u8fb9\u754c\u50f5\u5316\u4e14\u672a\u77e5", "method": "\u63d0\u51faIn-Situ Self-Evolving\u8303\u5f0f\uff0c\u5c06\u987a\u5e8f\u4efb\u52a1\u4ea4\u4e92\u89c6\u4e3a\u8fde\u7eed\u7ecf\u9a8c\u6d41\uff0c\u5c06\u77ed\u671f\u6267\u884c\u53cd\u9988\u63d0\u70bc\u4e3a\u957f\u671f\u53ef\u91cd\u7528\u80fd\u529b\uff1b\u5f00\u53d1Yunjue Agent\u7cfb\u7edf\uff0c\u901a\u8fc7\u8fed\u4ee3\u5408\u6210\u3001\u4f18\u5316\u548c\u91cd\u7528\u5de5\u5177\u5e94\u5bf9\u65b0\u6311\u6218\uff1b\u5f15\u5165Parallel Batch Evolution\u7b56\u7565\u4f18\u5316\u6f14\u5316\u6548\u7387", "result": "\u5728\u4e94\u4e2a\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u7684\u96f6\u8d77\u70b9\u8bbe\u7f6e\u4e0b\uff0c\u76f8\u6bd4\u4e13\u6709\u57fa\u7ebf\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\uff1b\u8865\u5145\u7684\u6696\u542f\u52a8\u8bc4\u4f30\u8bc1\u5b9e\u79ef\u7d2f\u7684\u901a\u7528\u77e5\u8bc6\u53ef\u65e0\u7f1d\u8fc1\u79fb\u5230\u65b0\u9886\u57df\uff1b\u63d0\u51fa\u76d1\u6d4b\u6f14\u5316\u6536\u655b\u7684\u65b0\u6307\u6807", "conclusion": "In-Situ Self-Evolving\u8303\u5f0f\u901a\u8fc7\u5de5\u5177\u6f14\u5316\u5b9e\u73b0\u667a\u80fd\u4f53\u5728\u5f00\u653e\u73af\u5883\u4e2d\u7684\u6301\u7eed\u80fd\u529b\u6269\u5c55\uff0c\u4e3a\u5f39\u6027\u81ea\u6f14\u5316\u667a\u80fd\u7814\u7a76\u63d0\u4f9b\u65b0\u65b9\u5411\uff0c\u5e76\u5f00\u6e90\u4ee3\u7801\u5e93\u3001\u7cfb\u7edf\u8f68\u8ff9\u548c\u6f14\u5316\u5de5\u5177"}}
{"id": "2601.17786", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17786", "abs": "https://arxiv.org/abs/2601.17786", "authors": ["Yixin Liu", "Kehan Yan", "Shiyuan Li", "Qingfeng Chen", "Shirui Pan"], "title": "Beyond a Single Perspective: Text Anomaly Detection with Multi-View Language Representations", "comment": "17 pages, 7 tables, and 5 figures", "summary": "Text anomaly detection (TAD) plays a critical role in various language-driven real-world applications, including harmful content moderation, phishing detection, and spam review filtering. While two-step \"embedding-detector\" TAD methods have shown state-of-the-art performance, their effectiveness is often limited by the use of a single embedding model and the lack of adaptability across diverse datasets and anomaly types. To address these limitations, we propose to exploit the embeddings from multiple pretrained language models and integrate them into $MCA^2$, a multi-view TAD framework. $MCA^2$ adopts a multi-view reconstruction model to effectively extract normal textual patterns from multiple embedding perspectives. To exploit inter-view complementarity, a contrastive collaboration module is designed to leverage and strengthen the interactions across different views. Moreover, an adaptive allocation module is developed to automatically assign the contribution weight of each view, thereby improving the adaptability to diverse datasets. Extensive experiments on 10 benchmark datasets verify the effectiveness of $MCA^2$ against strong baselines. The source code of $MCA^2$ is available at https://github.com/yankehan/MCA2.", "code_url": "https://github.com/yankehan/MCA2", "code_stars": 3, "code_last_update": "2026-01-27", "AI": {"tldr": "MCA\u00b2\u662f\u4e00\u4e2a\u591a\u89c6\u56fe\u6587\u672c\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u591a\u4e2a\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u5d4c\u5165\uff0c\u91c7\u7528\u591a\u89c6\u56fe\u91cd\u5efa\u6a21\u578b\u63d0\u53d6\u6b63\u5e38\u6587\u672c\u6a21\u5f0f\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5bf9\u6bd4\u534f\u4f5c\u6a21\u5757\u548c\u81ea\u9002\u5e94\u5206\u914d\u6a21\u5757\u6765\u63d0\u9ad8\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u4e24\u6b65\u5f0f\"\u5d4c\u5165-\u68c0\u6d4b\u5668\"\u6587\u672c\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u901a\u5e38\u53ea\u4f7f\u7528\u5355\u4e00\u5d4c\u5165\u6a21\u578b\uff0c\u7f3a\u4e4f\u8de8\u4e0d\u540c\u6570\u636e\u96c6\u548c\u5f02\u5e38\u7c7b\u578b\u7684\u9002\u5e94\u6027\uff0c\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faMCA\u00b2\u6846\u67b6\uff1a1) \u5229\u7528\u591a\u4e2a\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u5d4c\u5165\u6784\u5efa\u591a\u89c6\u56fe\u8868\u793a\uff1b2) \u91c7\u7528\u591a\u89c6\u56fe\u91cd\u5efa\u6a21\u578b\u4ece\u591a\u4e2a\u5d4c\u5165\u89c6\u89d2\u63d0\u53d6\u6b63\u5e38\u6587\u672c\u6a21\u5f0f\uff1b3) \u8bbe\u8ba1\u5bf9\u6bd4\u534f\u4f5c\u6a21\u5757\u52a0\u5f3a\u4e0d\u540c\u89c6\u56fe\u95f4\u7684\u4ea4\u4e92\u548c\u4e92\u8865\u6027\uff1b4) \u5f00\u53d1\u81ea\u9002\u5e94\u5206\u914d\u6a21\u5757\u81ea\u52a8\u5206\u914d\u6bcf\u4e2a\u89c6\u56fe\u7684\u8d21\u732e\u6743\u91cd\uff0c\u63d0\u9ad8\u5bf9\u591a\u6837\u5316\u6570\u636e\u96c6\u7684\u9002\u5e94\u6027\u3002", "result": "\u572810\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86MCA\u00b2\u76f8\u5bf9\u4e8e\u5f3a\u57fa\u7ebf\u7684\u6709\u6548\u6027\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u5347\u6587\u672c\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u3002", "conclusion": "MCA\u00b2\u901a\u8fc7\u96c6\u6210\u591a\u4e2a\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u5d4c\u5165\u3001\u8bbe\u8ba1\u591a\u89c6\u56fe\u91cd\u5efa\u3001\u5bf9\u6bd4\u534f\u4f5c\u548c\u81ea\u9002\u5e94\u5206\u914d\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u6587\u672c\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u4e2d\u5355\u4e00\u5d4c\u5165\u6a21\u578b\u548c\u7f3a\u4e4f\u9002\u5e94\u6027\u7684\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18282", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18282", "abs": "https://arxiv.org/abs/2601.18282", "authors": ["Lei Wei", "Jinpeng Ou", "Xiao Peng", "Bin Wang"], "title": "Think-Augmented Function Calling: Improving LLM Parameter Accuracy Through Embedded Reasoning", "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in function calling for autonomous agents, yet current mechanisms lack explicit reasoning transparency during parameter generation, particularly for complex functions with interdependent parameters. While existing approaches like chain-of-thought prompting operate at the agent level, they fail to provide fine-grained reasoning guidance for individual function parameters. To address these limitations, we propose Think-Augmented Function Calling (TAFC), a novel framework that enhances function calling accuracy through explicit reasoning at both function and parameter levels. Our method introduces a universal \"think\" parameter augmentation that enables models to articulate their decision-making process, with dynamic optimization for parameter descriptions to improve reasoning quality. For complex parameters, TAFC automatically triggers granular reasoning based on complexity scoring, ensuring appropriate justification for critical decisions. Additionally, we propose reasoning-guided optimization to align generated reasoning with human expectations. TAFC requires no architectural modifications to existing LLMs while maintaining full API compatibility. Evaluation on ToolBench across proprietary and open-source models demonstrates significant improvements in parameter generation accuracy and reasoning coherence for multi-parameter functions, while providing enhanced interpretability for debugging AI agent behaviors.", "AI": {"tldr": "TAFC\u6846\u67b6\u901a\u8fc7\u51fd\u6570\u548c\u53c2\u6570\u7ea7\u522b\u7684\u663e\u5f0f\u63a8\u7406\u589e\u5f3aLLM\u51fd\u6570\u8c03\u7528\u51c6\u786e\u6027\uff0c\u5f15\u5165\u901a\u7528\"think\"\u53c2\u6570\u589e\u5f3a\u548c\u52a8\u6001\u4f18\u5316\uff0c\u65e0\u9700\u4fee\u6539\u6a21\u578b\u67b6\u6784", "motivation": "\u5f53\u524dLLM\u51fd\u6570\u8c03\u7528\u673a\u5236\u7f3a\u4e4f\u53c2\u6570\u751f\u6210\u7684\u663e\u5f0f\u63a8\u7406\u900f\u660e\u5ea6\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5177\u6709\u76f8\u4e92\u4f9d\u8d56\u53c2\u6570\u7684\u590d\u6742\u51fd\u6570\u3002\u73b0\u6709\u65b9\u6cd5\u5982\u601d\u7ef4\u94fe\u63d0\u793a\u5728\u667a\u80fd\u4f53\u7ea7\u522b\u64cd\u4f5c\uff0c\u65e0\u6cd5\u4e3a\u5355\u4e2a\u51fd\u6570\u53c2\u6570\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u63a8\u7406\u6307\u5bfc", "method": "\u63d0\u51faThink-Augmented Function Calling\u6846\u67b6\uff1a1) \u5f15\u5165\u901a\u7528\"think\"\u53c2\u6570\u589e\u5f3a\uff0c\u8ba9\u6a21\u578b\u9610\u8ff0\u51b3\u7b56\u8fc7\u7a0b\uff1b2) \u52a8\u6001\u4f18\u5316\u53c2\u6570\u63cf\u8ff0\u4ee5\u63d0\u9ad8\u63a8\u7406\u8d28\u91cf\uff1b3) \u57fa\u4e8e\u590d\u6742\u5ea6\u8bc4\u5206\u81ea\u52a8\u89e6\u53d1\u7ec6\u7c92\u5ea6\u63a8\u7406\uff1b4) \u63d0\u51fa\u63a8\u7406\u5f15\u5bfc\u4f18\u5316\u4ee5\u5bf9\u9f50\u4eba\u7c7b\u671f\u671b", "result": "\u5728ToolBench\u4e0a\u5bf9\u4e13\u6709\u548c\u5f00\u6e90\u6a21\u578b\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u591a\u53c2\u6570\u51fd\u6570\u7684\u53c2\u6570\u751f\u6210\u51c6\u786e\u6027\u548c\u63a8\u7406\u8fde\u8d2f\u6027\u663e\u8457\u63d0\u5347\uff0c\u540c\u65f6\u4e3a\u8c03\u8bd5AI\u667a\u80fd\u4f53\u884c\u4e3a\u63d0\u4f9b\u589e\u5f3a\u7684\u53ef\u89e3\u91ca\u6027", "conclusion": "TAFC\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u63a8\u7406\u589e\u5f3a\u51fd\u6570\u8c03\u7528\u51c6\u786e\u6027\uff0c\u65e0\u9700\u4fee\u6539\u73b0\u6709LLM\u67b6\u6784\u4e14\u4fdd\u6301\u5b8c\u5168API\u517c\u5bb9\u6027\uff0c\u5728\u4fdd\u6301\u5b9e\u7528\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027"}}
{"id": "2601.18308", "categories": ["cs.AI", "cs.SI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.18308", "abs": "https://arxiv.org/abs/2601.18308", "authors": ["Geunsik Lim"], "title": "A Generative AI-Driven Reliability Layer for Action-Oriented Disaster Resilience", "comment": "19 pages", "summary": "As climate-related hazards intensify, conventional early warning systems (EWS) disseminate alerts rapidly but often fail to trigger timely protective actions, leading to preventable losses and inequities. We introduce Climate RADAR (Risk-Aware, Dynamic, and Action Recommendation system), a generative AI-based reliability layer that reframes disaster communication from alerts delivered to actions executed. It integrates meteorological, hydrological, vulnerability, and social data into a composite risk index and employs guardrail-embedded large language models (LLMs) to deliver personalized recommendations across citizen, volunteer, and municipal interfaces. Evaluation through simulations, user studies, and a municipal pilot shows improved outcomes, including higher protective action execution, reduced response latency, and increased usability and trust. By combining predictive analytics, behavioral science, and responsible AI, Climate RADAR advances people-centered, transparent, and equitable early warning systems, offering practical pathways toward compliance-ready disaster resilience infrastructures.", "AI": {"tldr": "Climate RADAR\u662f\u4e00\u4e2a\u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684\u53ef\u9760\u6027\u5c42\uff0c\u5c06\u4f20\u7edf\u9884\u8b66\u7cfb\u7edf\u4ece\u8b66\u62a5\u4f20\u9012\u8f6c\u53d8\u4e3a\u884c\u52a8\u6267\u884c\uff0c\u901a\u8fc7\u6574\u5408\u591a\u6e90\u6570\u636e\u548cLLM\u63d0\u4f9b\u4e2a\u6027\u5316\u5efa\u8bae\uff0c\u63d0\u9ad8\u4fdd\u62a4\u884c\u52a8\u6267\u884c\u7387\u3001\u51cf\u5c11\u54cd\u5e94\u5ef6\u8fdf\u5e76\u589e\u5f3a\u4fe1\u4efb\u3002", "motivation": "\u4f20\u7edf\u9884\u8b66\u7cfb\u7edf\u867d\u7136\u80fd\u5feb\u901f\u4f20\u64ad\u8b66\u62a5\uff0c\u4f46\u5f80\u5f80\u65e0\u6cd5\u89e6\u53d1\u53ca\u65f6\u7684\u4fdd\u62a4\u884c\u52a8\uff0c\u5bfc\u81f4\u53ef\u9884\u9632\u7684\u635f\u5931\u548c\u4e0d\u516c\u5e73\u73b0\u8c61\u3002\u9700\u8981\u5c06\u707e\u5bb3\u901a\u4fe1\u4ece\"\u8b66\u62a5\u4f20\u9012\"\u91cd\u65b0\u5b9a\u4e49\u4e3a\"\u884c\u52a8\u6267\u884c\"\uff0c\u4ee5\u5e94\u5bf9\u65e5\u76ca\u52a0\u5267\u7684\u6c14\u5019\u76f8\u5173\u707e\u5bb3\u3002", "method": "\u5f15\u5165Climate RADAR\u7cfb\u7edf\uff0c\u6574\u5408\u6c14\u8c61\u3001\u6c34\u6587\u3001\u8106\u5f31\u6027\u548c\u793e\u4f1a\u6570\u636e\u5f62\u6210\u7efc\u5408\u98ce\u9669\u6307\u6570\uff0c\u91c7\u7528\u5e26\u6709\u62a4\u680f\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e3a\u516c\u6c11\u3001\u5fd7\u613f\u8005\u548c\u5e02\u653f\u90e8\u95e8\u63d0\u4f9b\u4e2a\u6027\u5316\u884c\u52a8\u5efa\u8bae\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u3001\u7528\u6237\u7814\u7a76\u548c\u5e02\u653f\u8bd5\u70b9\u8bc4\u4f30\u663e\u793a\uff0c\u7cfb\u7edf\u6539\u5584\u4e86\u591a\u9879\u6307\u6807\uff1a\u63d0\u9ad8\u4e86\u4fdd\u62a4\u884c\u52a8\u6267\u884c\u7387\u3001\u51cf\u5c11\u4e86\u54cd\u5e94\u5ef6\u8fdf\u3001\u589e\u5f3a\u4e86\u53ef\u7528\u6027\u548c\u4fe1\u4efb\u5ea6\u3002", "conclusion": "Climate RADAR\u901a\u8fc7\u7ed3\u5408\u9884\u6d4b\u5206\u6790\u3001\u884c\u4e3a\u79d1\u5b66\u548c\u8d1f\u8d23\u4efbAI\uff0c\u63a8\u8fdb\u4e86\u4ee5\u4eba\u4e3a\u672c\u3001\u900f\u660e\u548c\u516c\u5e73\u7684\u9884\u8b66\u7cfb\u7edf\uff0c\u4e3a\u7b26\u5408\u8981\u6c42\u7684\u707e\u5bb3\u97e7\u6027\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2601.18353", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.18353", "abs": "https://arxiv.org/abs/2601.18353", "authors": ["Tuhin Chakrabarty", "Paramveer S. Dhillon"], "title": "Can Good Writing Be Generative? Expert-Level AI Writing Emerges through Fine-Tuning on High-Quality Books", "comment": "Proceedings of CHI 2026 Conference (To Appear)", "summary": "Creative writing has long been considered a uniquely human endeavor, requiring voice and style that machines could not replicate. This assumption is challenged by Generative AI that can emulate thousands of author styles in seconds with negligible marginal labor. To understand this better, we conducted a behavioral experiment where 28 MFA writers (experts) competed against three LLMs in emulating 50 critically acclaimed authors. Based on blind pairwise comparisons by 28 expert judges and 131 lay judges, we find that experts preferred human writing in 82.7% of cases under the in-context prompting condition but this reversed to 62% preference for AI after fine-tuning on authors' complete works. Lay judges, however, consistently preferred AI writing. Debrief interviews with expert writers revealed that their preference for AI writing triggered an identity crisis, eroding aesthetic confidence and questioning what constitutes \"good writing.\" These findings challenge discourse about AI's creative limitations and raise fundamental questions about the future of creative labor.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\uff0c\u7ecf\u8fc7\u5fae\u8c03\u7684AI\u5728\u6a21\u4eff\u8457\u540d\u4f5c\u5bb6\u98ce\u683c\u65b9\u9762\u5df2\u8d85\u8d8a\u4eba\u7c7b\u4e13\u5bb6\uff0c\u8fd9\u5f15\u53d1\u4e86\u4e13\u4e1a\u4f5c\u5bb6\u7684\u8eab\u4efd\u5371\u673a\uff0c\u5e76\u5bf9\u521b\u610f\u52b3\u52a8\u7684\u672a\u6765\u63d0\u51fa\u6839\u672c\u6027\u95ee\u9898\u3002", "motivation": "\u6311\u6218\"\u521b\u610f\u5199\u4f5c\u662f\u72ec\u7279\u4eba\u7c7b\u80fd\u529b\"\u7684\u4f20\u7edf\u5047\u8bbe\uff0c\u63a2\u7a76\u751f\u6210\u5f0fAI\u5728\u6a21\u4eff\u4f5c\u5bb6\u98ce\u683c\u65b9\u9762\u7684\u80fd\u529b\u8fb9\u754c\uff0c\u4ee5\u53caAI\u5bf9\u521b\u610f\u52b3\u52a8\u7684\u5f71\u54cd\u3002", "method": "\u884c\u4e3a\u5b9e\u9a8c\u8bbe\u8ba1\uff1a28\u540dMFA\u4f5c\u5bb6\uff08\u4e13\u5bb6\uff09\u4e0e3\u4e2aLLM\u7ade\u4e89\u6a21\u4eff50\u4f4d\u5907\u53d7\u597d\u8bc4\u7684\u4f5c\u5bb6\u98ce\u683c\uff1b\u91c7\u7528\u76f2\u6d4b\u6210\u5bf9\u6bd4\u8f83\uff0c\u753128\u540d\u4e13\u5bb6\u8bc4\u59d4\u548c131\u540d\u975e\u4e13\u4e1a\u8bc4\u59d4\u8bc4\u4f30\uff1b\u5bf9\u6bd4\u4e0a\u4e0b\u6587\u63d0\u793a\u548c\u57fa\u4e8e\u4f5c\u8005\u5b8c\u6574\u4f5c\u54c1\u5fae\u8c03\u4e24\u79cd\u6761\u4ef6\u3002", "result": "\u4e0a\u4e0b\u6587\u63d0\u793a\u6761\u4ef6\u4e0b\uff0c\u4e13\u5bb6\u8bc4\u59d482.7%\u504f\u597d\u4eba\u7c7b\u5199\u4f5c\uff1b\u4f46\u7ecf\u8fc7\u5fae\u8c03\u540e\uff0c\u4e13\u5bb6\u504f\u597d\u53cd\u8f6c\uff0c62%\u504f\u597dAI\u5199\u4f5c\uff1b\u975e\u4e13\u4e1a\u8bc4\u59d4\u59cb\u7ec8\u504f\u597dAI\u5199\u4f5c\uff1b\u4e13\u5bb6\u4f5c\u5bb6\u8bbf\u8c08\u663e\u793aAI\u504f\u597d\u5f15\u53d1\u4e86\u8eab\u4efd\u5371\u673a\u548c\u7f8e\u5b66\u81ea\u4fe1\u4fb5\u8680\u3002", "conclusion": "AI\u5728\u6a21\u4eff\u4f5c\u5bb6\u98ce\u683c\u65b9\u9762\u5df2\u8d85\u8d8a\u4eba\u7c7b\u4e13\u5bb6\uff0c\u6311\u6218\u4e86AI\u521b\u610f\u5c40\u9650\u6027\u7684\u4f20\u7edf\u8bba\u8ff0\uff0c\u5bf9\u521b\u610f\u52b3\u52a8\u7684\u672a\u6765\u3001\u4f5c\u5bb6\u8eab\u4efd\u8ba4\u540c\u548c\"\u4f18\u79c0\u5199\u4f5c\"\u7684\u5b9a\u4e49\u63d0\u51fa\u4e86\u6839\u672c\u6027\u95ee\u9898\u3002"}}
{"id": "2601.18383", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18383", "abs": "https://arxiv.org/abs/2601.18383", "authors": ["Zhenyuan Guo", "Tong Chen", "Wenlong Meng", "Chen Gong", "Xin Yu", "Chengkun Wei", "Wenzhi Chen"], "title": "Dynamic Thinking-Token Selection for Efficient Reasoning in Large Reasoning Models", "comment": null, "summary": "Large Reasoning Models (LRMs) excel at solving complex problems by explicitly generating a reasoning trace before deriving the final answer. However, these extended generations incur substantial memory footprint and computational overhead, bottlenecking LRMs' efficiency. This work uses attention maps to analyze the influence of reasoning traces and uncover an interesting phenomenon: only some decision-critical tokens in a reasoning trace steer the model toward the final answer, while the remaining tokens contribute negligibly. Building on this observation, we propose Dynamic Thinking-Token Selection (DynTS). This method identifies decision-critical tokens and retains only their associated Key-Value (KV) cache states during inference, evicting the remaining redundant entries to optimize efficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faDynTS\u65b9\u6cd5\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u56fe\u5206\u6790\u63a8\u7406\u8f68\u8ff9\uff0c\u8bc6\u522b\u5173\u952e\u51b3\u7b56token\u5e76\u4ec5\u4fdd\u7559\u5176KV\u7f13\u5b58\uff0c\u4f18\u5316\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u6548\u7387", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b(LRMs)\u5728\u89e3\u51b3\u590d\u6742\u95ee\u9898\u65f6\u9700\u8981\u663e\u5f0f\u751f\u6210\u63a8\u7406\u8f68\u8ff9\uff0c\u8fd9\u5e26\u6765\u4e86\u5de8\u5927\u7684\u5185\u5b58\u5360\u7528\u548c\u8ba1\u7b97\u5f00\u9500\uff0c\u6210\u4e3a\u6a21\u578b\u6548\u7387\u7684\u74f6\u9888\u3002\u7814\u7a76\u53d1\u73b0\u63a8\u7406\u8f68\u8ff9\u4e2d\u53ea\u6709\u90e8\u5206\u51b3\u7b56\u5173\u952etoken\u5bf9\u6700\u7ec8\u7b54\u6848\u6709\u51b3\u5b9a\u6027\u5f71\u54cd\uff0c\u5176\u4f59token\u8d21\u732e\u53ef\u5ffd\u7565\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u601d\u7ef4token\u9009\u62e9(DynTS)\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u6ce8\u610f\u529b\u56fe\u5206\u6790\u63a8\u7406\u8f68\u8ff9\u4e2d\u5404token\u7684\u5f71\u54cd\uff1b2) \u8bc6\u522b\u51b3\u7b56\u5173\u952etoken\uff1b3) \u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4ec5\u4fdd\u7559\u8fd9\u4e9b\u5173\u952etoken\u7684KV\u7f13\u5b58\u72b6\u6001\uff0c\u5254\u9664\u5197\u4f59\u6761\u76ee\u3002", "result": "DynTS\u65b9\u6cd5\u901a\u8fc7\u9009\u62e9\u6027\u4fdd\u7559\u5173\u952etoken\u7684KV\u7f13\u5b58\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5185\u5b58\u5360\u7528\u548c\u8ba1\u7b97\u5f00\u9500\uff0c\u4f18\u5316\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u63a8\u7406\u8f68\u8ff9\u4e2d\u5b58\u5728\u5927\u91cf\u5197\u4f59token\uff0c\u4ec5\u5c11\u6570\u51b3\u7b56\u5173\u952etoken\u5bf9\u6700\u7ec8\u7b54\u6848\u6709\u5b9e\u8d28\u6027\u5f71\u54cd\u3002DynTS\u65b9\u6cd5\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u5e76\u4fdd\u7559\u8fd9\u4e9b\u5173\u952etoken\u7684KV\u7f13\u5b58\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u6548\u7387\uff0c\u4e3a\u4f18\u5316\u63a8\u7406\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.17869", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17869", "abs": "https://arxiv.org/abs/2601.17869", "authors": ["Michelle Chao Chen", "Moritz Miller", "Bernhard Sch\u00f6lkopf", "Siyuan Guo"], "title": "On the Emergence and Test-Time Use of Structural Information in Large Language Models", "comment": null, "summary": "Learning structural information from observational data is central to producing new knowledge outside the training corpus. This holds for mechanistic understanding in scientific discovery as well as flexible test-time compositional generation. We thus study how language models learn abstract structures and utilize the learnt structural information at test-time. To ensure a controlled setup, we design a natural language dataset based on linguistic structural transformations. We empirically show that the emergence of learning structural information correlates with complex reasoning tasks, and that the ability to perform test-time compositional generation remains limited.", "AI": {"tldr": "\u8bed\u8a00\u6a21\u578b\u5b66\u4e60\u7ed3\u6784\u4fe1\u606f\u7684\u80fd\u529b\u4e0e\u590d\u6742\u63a8\u7406\u4efb\u52a1\u76f8\u5173\uff0c\u4f46\u6d4b\u8bd5\u65f6\u7ec4\u5408\u751f\u6210\u80fd\u529b\u6709\u9650", "motivation": "\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u5b66\u4e60\u62bd\u8c61\u7ed3\u6784\u4fe1\u606f\uff0c\u8fd9\u5bf9\u4e8e\u79d1\u5b66\u53d1\u73b0\u4e2d\u7684\u673a\u5236\u7406\u89e3\u548c\u7075\u6d3b\u6d4b\u8bd5\u65f6\u7ec4\u5408\u751f\u6210\u81f3\u5173\u91cd\u8981", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u8bed\u8a00\u7ed3\u6784\u8f6c\u6362\u7684\u81ea\u7136\u8bed\u8a00\u6570\u636e\u96c6\uff0c\u5728\u53d7\u63a7\u8bbe\u7f6e\u4e0b\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u5b66\u4e60\u7ed3\u6784\u4fe1\u606f\u7684\u80fd\u529b", "result": "\u5b66\u4e60\u7ed3\u6784\u4fe1\u606f\u7684\u51fa\u73b0\u4e0e\u590d\u6742\u63a8\u7406\u4efb\u52a1\u76f8\u5173\uff0c\u4f46\u6a21\u578b\u5728\u6d4b\u8bd5\u65f6\u8fdb\u884c\u7ec4\u5408\u751f\u6210\u7684\u80fd\u529b\u4ecd\u7136\u6709\u9650", "conclusion": "\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u7ed3\u6784\u4fe1\u606f\uff0c\u4f46\u5728\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u8fdb\u884c\u6d4b\u8bd5\u65f6\u7ec4\u5408\u751f\u6210\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6539\u8fdb"}}
{"id": "2601.18467", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18467", "abs": "https://arxiv.org/abs/2601.18467", "authors": ["Yuhang Zhou", "Kai Zheng", "Qiguang Chen", "Mengkang Hu", "Qingfeng Sun", "Can Xu", "Jingjing Chen"], "title": "OffSeeker: Online Reinforcement Learning Is Not All You Need for Deep Research Agents", "comment": null, "summary": "Deep research agents have shown remarkable potential in handling long-horizon tasks. However, state-of-the-art performance typically relies on online reinforcement learning (RL), which is financially expensive due to extensive API calls. While offline training offers a more efficient alternative, its progress is hindered by the scarcity of high-quality research trajectories. In this paper, we demonstrate that expensive online reinforcement learning is not all you need to build powerful research agents. To bridge this gap, we introduce a fully open-source suite designed for effective offline training. Our core contributions include DeepForge, a ready-to-use task synthesis framework that generates large-scale research queries without heavy preprocessing; and a curated collection of 66k QA pairs, 33k SFT trajectories, and 21k DPO pairs. Leveraging these resources, we train OffSeeker (8B), a model developed entirely offline. Extensive evaluations across six benchmarks show that OffSeeker not only leads among similar-sized agents but also remains competitive with 30B-parameter systems trained via heavy online RL.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u79bb\u7ebf\u7684\u7814\u7a76\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f00\u6e90\u5957\u4ef6\u751f\u6210\u5927\u89c4\u6a21\u7814\u7a76\u6570\u636e\uff0c\u8bad\u7ec3\u51fa\u6027\u80fd\u4e0e\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u76f8\u5f53\u4f46\u6210\u672c\u66f4\u4f4e\u76848B\u53c2\u6570\u7814\u7a76\u667a\u80fd\u4f53\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u6700\u5148\u8fdb\u7684\u6027\u80fd\u901a\u5e38\u4f9d\u8d56\u6602\u8d35\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\uff0c\u9700\u8981\u5927\u91cfAPI\u8c03\u7528\u3002\u79bb\u7ebf\u8bad\u7ec3\u867d\u7136\u66f4\u9ad8\u6548\uff0c\u4f46\u53d7\u9650\u4e8e\u9ad8\u8d28\u91cf\u7814\u7a76\u8f68\u8ff9\u7684\u7a00\u7f3a\u6027\u3002\u4f5c\u8005\u65e8\u5728\u8bc1\u660e\u6602\u8d35\u7684\u5728\u7ebfRL\u5e76\u975e\u6784\u5efa\u5f3a\u5927\u7814\u7a76\u667a\u80fd\u4f53\u7684\u552f\u4e00\u9014\u5f84\u3002", "method": "\u5f15\u5165\u5b8c\u5168\u5f00\u6e90\u5957\u4ef6\u8fdb\u884c\u6709\u6548\u79bb\u7ebf\u8bad\u7ec3\uff1a1) DeepForge - \u5373\u7528\u578b\u4efb\u52a1\u5408\u6210\u6846\u67b6\uff0c\u65e0\u9700\u7e41\u91cd\u9884\u5904\u7406\u5373\u53ef\u751f\u6210\u5927\u89c4\u6a21\u7814\u7a76\u67e5\u8be2\uff1b2) \u7cbe\u5fc3\u7b56\u5212\u7684\u6570\u636e\u96c6\uff1a66k QA\u5bf9\u300133k SFT\u8f68\u8ff9\u548c21k DPO\u5bf9\u3002\u5229\u7528\u8fd9\u4e9b\u8d44\u6e90\u8bad\u7ec3OffSeeker\uff088B\u53c2\u6570\u6a21\u578b\uff09\uff0c\u5b8c\u5168\u79bb\u7ebf\u5f00\u53d1\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cOffSeeker\u4e0d\u4ec5\u5728\u540c\u5c3a\u5bf8\u667a\u80fd\u4f53\u4e2d\u9886\u5148\uff0c\u800c\u4e14\u4e0e\u901a\u8fc7\u5927\u91cf\u5728\u7ebfRL\u8bad\u7ec3\u768430B\u53c2\u6570\u7cfb\u7edf\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u79bb\u7ebf\u8bad\u7ec3\u53ef\u4ee5\u66ff\u4ee3\u6602\u8d35\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u6765\u6784\u5efa\u5f3a\u5927\u7684\u7814\u7a76\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u5f00\u6e90\u5de5\u5177\u548c\u6570\u636e\u96c6\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u590d\u73b0\u7684\u7814\u7a76\u6846\u67b6\u3002"}}
{"id": "2601.17898", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17898", "abs": "https://arxiv.org/abs/2601.17898", "authors": ["Qi Zhan", "Yile Wang", "Hui Huang"], "title": "Assessment of Generative Named Entity Recognition in the Era of Large Language Models", "comment": null, "summary": "Named entity recognition (NER) is evolving from a sequence labeling task into a generative paradigm with the rise of large language models (LLMs). We conduct a systematic evaluation of open-source LLMs on both flat and nested NER tasks. We investigate several research questions including the performance gap between generative NER and traditional NER models, the impact of output formats, whether LLMs rely on memorization, and the preservation of general capabilities after fine-tuning. Through experiments across eight LLMs of varying scales and four standard NER datasets, we find that: (1) With parameter-efficient fine-tuning and structured formats like inline bracketed or XML, open-source LLMs achieve performance competitive with traditional encoder-based models and surpass closed-source LLMs like GPT-3; (2) The NER capability of LLMs stems from instruction-following and generative power, not mere memorization of entity-label pairs; and (3) Applying NER instruction tuning has minimal impact on general capabilities of LLMs, even improving performance on datasets like DROP due to enhanced entity understanding. These findings demonstrate that generative NER with LLMs is a promising, user-friendly alternative to traditional methods. We release the data and code at https://github.com/szu-tera/LLMs4NER.", "code_url": "https://github.com/szu-tera/LLMs4NER", "code_stars": 1, "code_last_update": "2026-01-27", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5e73\u9762\u548c\u5d4c\u5957\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u548c\u7ed3\u6784\u5316\u8f93\u51fa\u683c\u5f0f\uff0c\u5f00\u6e90LLMs\u80fd\u8fbe\u5230\u4e0e\u4f20\u7edf\u7f16\u7801\u5668\u6a21\u578b\u7ade\u4e89\u7684\u6027\u80fd\uff0c\u4e14\u5176NER\u80fd\u529b\u6e90\u4e8e\u6307\u4ee4\u9075\u5faa\u548c\u751f\u6210\u80fd\u529b\u800c\u975e\u8bb0\u5fc6\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5174\u8d77\uff0c\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6b63\u4ece\u5e8f\u5217\u6807\u6ce8\u4efb\u52a1\u8f6c\u5411\u751f\u6210\u8303\u5f0f\u3002\u4f5c\u8005\u65e8\u5728\u7cfb\u7edf\u8bc4\u4f30\u5f00\u6e90LLMs\u5728\u5e73\u9762\u548c\u5d4c\u5957NER\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u7814\u7a76\u751f\u6210\u5f0fNER\u4e0e\u4f20\u7edfNER\u6a21\u578b\u7684\u6027\u80fd\u5dee\u8ddd\u3001\u8f93\u51fa\u683c\u5f0f\u5f71\u54cd\u3001LLMs\u662f\u5426\u4f9d\u8d56\u8bb0\u5fc6\u4ee5\u53ca\u5fae\u8c03\u540e\u901a\u7528\u80fd\u529b\u4fdd\u6301\u7b49\u95ee\u9898\u3002", "method": "\u91c7\u75288\u4e2a\u4e0d\u540c\u89c4\u6a21\u7684\u5f00\u6e90LLMs\u548c4\u4e2a\u6807\u51c6NER\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u9a8c\u3002\u7814\u7a76\u5185\u5bb9\u5305\u62ec\uff1a1) \u6bd4\u8f83\u751f\u6210\u5f0fNER\u4e0e\u4f20\u7edf\u7f16\u7801\u5668\u6a21\u578b\u6027\u80fd\uff1b2) \u5206\u6790\u4e0d\u540c\u8f93\u51fa\u683c\u5f0f\uff08\u5982\u5185\u8054\u62ec\u53f7\u6216XML\uff09\u7684\u5f71\u54cd\uff1b3) \u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1LLMs\u662f\u5426\u4f9d\u8d56\u5b9e\u4f53-\u6807\u7b7e\u5bf9\u7684\u8bb0\u5fc6\uff1b4) \u8bc4\u4f30NER\u6307\u4ee4\u5fae\u8c03\u5bf9LLMs\u901a\u7528\u80fd\u529b\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff1a1) \u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u548c\u7ed3\u6784\u5316\u8f93\u51fa\u683c\u5f0f\uff0c\u5f00\u6e90LLMs\u80fd\u8fbe\u5230\u4e0e\u4f20\u7edf\u7f16\u7801\u5668\u6a21\u578b\u7ade\u4e89\u7684\u6027\u80fd\uff0c\u751a\u81f3\u8d85\u8d8aGPT-3\u7b49\u95ed\u6e90\u6a21\u578b\uff1b2) LLMs\u7684NER\u80fd\u529b\u6e90\u4e8e\u6307\u4ee4\u9075\u5faa\u548c\u751f\u6210\u80fd\u529b\uff0c\u800c\u975e\u7b80\u5355\u7684\u5b9e\u4f53-\u6807\u7b7e\u5bf9\u8bb0\u5fc6\uff1b3) NER\u6307\u4ee4\u5fae\u8c03\u5bf9LLMs\u7684\u901a\u7528\u80fd\u529b\u5f71\u54cd\u6781\u5c0f\uff0c\u751a\u81f3\u56e0\u589e\u5f3a\u5b9e\u4f53\u7406\u89e3\u800c\u63d0\u5347\u5728DROP\u7b49\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002", "conclusion": "\u751f\u6210\u5f0fNER\u7ed3\u5408LLMs\u662f\u4f20\u7edf\u65b9\u6cd5\u7684\u6709\u524d\u666f\u4e14\u7528\u6237\u53cb\u597d\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u5f00\u6e90LLMs\u901a\u8fc7\u9002\u5f53\u5fae\u8c03\u548c\u8f93\u51fa\u683c\u5f0f\u8bbe\u8ba1\uff0c\u5728NER\u4efb\u52a1\u4e0a\u5c55\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u4e14\u4e0d\u635f\u5bb3\u5176\u901a\u7528\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u3002\u7814\u7a76\u7ed3\u679c\u652f\u6301\u4e86\u751f\u6210\u5f0fNER\u8303\u5f0f\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2601.18496", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18496", "abs": "https://arxiv.org/abs/2601.18496", "authors": ["Zihan wang", "Hao Wang", "Shi Feng", "Xiaocui Yang", "Daling Wang", "Yiqun Zhang", "Jinghao Lin", "Haihua Yang", "Xiaozhong Ji"], "title": "DEEPMED: Building a Medical DeepResearch Agent via Multi-hop Med-Search Data and Turn-Controlled Agentic Training & Inference", "comment": null, "summary": "Medical reasoning models remain constrained by parametric knowledge and are thus susceptible to forgetting and hallucinations. DeepResearch (DR) models ground outputs in verifiable evidence from tools and perform strongly in general domains, but their direct transfer to medical field yields relatively limited gains. We attribute this to two gaps: task characteristic and tool-use scaling. Medical questions require evidence interpretation in a knowledge-intensive clinical context; while general DR models can retrieve information, they often lack clinical-context reasoning and thus \"find it but fail to use it,\" leaving performance limited by medical abilities. Moreover, in medical scenarios, blindly scaling tool-call can inject noisy context, derailing sensitive medical reasoning and prompting repetitive evidence-seeking along incorrect paths. Therefore, we propose DeepMed. For data, we deploy a multi-hop med-search QA synthesis method supporting the model to apply the DR paradigm in medical contexts. For training, we introduce a difficulty-aware turn-penalty to suppress excessive tool-call growth. For inference, we bring a monitor to help validate hypotheses within a controlled number of steps and avoid context rot. Overall, on seven medical benchmarks, DeepMed improves its base model by 9.79\\% on average and outperforms larger medical reasoning and DR models.", "AI": {"tldr": "DeepMed\uff1a\u9488\u5bf9\u533b\u5b66\u9886\u57df\u7684\u6df1\u5ea6\u7814\u7a76\u6a21\u578b\uff0c\u901a\u8fc7\u89e3\u51b3\u4efb\u52a1\u7279\u6027\u548c\u5de5\u5177\u4f7f\u7528\u6269\u5c55\u4e24\u5927\u5dee\u8ddd\uff0c\u5728\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd", "motivation": "\u73b0\u6709\u533b\u5b66\u63a8\u7406\u6a21\u578b\u53d7\u9650\u4e8e\u53c2\u6570\u77e5\u8bc6\uff0c\u6613\u51fa\u73b0\u9057\u5fd8\u548c\u5e7b\u89c9\u95ee\u9898\u3002\u901a\u7528\u6df1\u5ea6\u7814\u7a76\u6a21\u578b\u867d\u80fd\u57fa\u4e8e\u5de5\u5177\u8bc1\u636e\u751f\u6210\u8f93\u51fa\uff0c\u4f46\u76f4\u63a5\u5e94\u7528\u4e8e\u533b\u5b66\u9886\u57df\u6548\u679c\u6709\u9650\uff0c\u4e3b\u8981\u5b58\u5728\u4e24\u5927\u5dee\u8ddd\uff1a\u4efb\u52a1\u7279\u6027\u5dee\u8ddd\uff08\u533b\u5b66\u95ee\u9898\u9700\u8981\u77e5\u8bc6\u5bc6\u96c6\u7684\u4e34\u5e8a\u4e0a\u4e0b\u6587\u63a8\u7406\uff09\u548c\u5de5\u5177\u4f7f\u7528\u6269\u5c55\u5dee\u8ddd\uff08\u76f2\u76ee\u6269\u5c55\u5de5\u5177\u8c03\u7528\u4f1a\u5f15\u5165\u566a\u58f0\u4e0a\u4e0b\u6587\uff0c\u5e72\u6270\u654f\u611f\u533b\u5b66\u63a8\u7406\uff09", "method": "\u63d0\u51faDeepMed\u6846\u67b6\uff1a1) \u6570\u636e\u5c42\u9762\uff1a\u91c7\u7528\u591a\u8df3\u533b\u5b66\u641c\u7d22QA\u5408\u6210\u65b9\u6cd5\uff0c\u652f\u6301\u6a21\u578b\u5728\u533b\u5b66\u4e0a\u4e0b\u6587\u4e2d\u5e94\u7528\u6df1\u5ea6\u7814\u7a76\u8303\u5f0f\uff1b2) \u8bad\u7ec3\u5c42\u9762\uff1a\u5f15\u5165\u96be\u5ea6\u611f\u77e5\u7684\u8f6e\u6b21\u60e9\u7f5a\u673a\u5236\uff0c\u6291\u5236\u8fc7\u5ea6\u5de5\u5177\u8c03\u7528\u589e\u957f\uff1b3) \u63a8\u7406\u5c42\u9762\uff1a\u5f15\u5165\u76d1\u63a7\u5668\u5e2e\u52a9\u5728\u53ef\u63a7\u6b65\u9aa4\u5185\u9a8c\u8bc1\u5047\u8bbe\uff0c\u907f\u514d\u4e0a\u4e0b\u6587\u8150\u5316", "result": "\u5728\u4e03\u4e2a\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDeepMed\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u5e73\u5747\u63d0\u53479.79%\uff0c\u5e76\u4f18\u4e8e\u66f4\u5927\u7684\u533b\u5b66\u63a8\u7406\u548c\u6df1\u5ea6\u7814\u7a76\u6a21\u578b", "conclusion": "DeepMed\u901a\u8fc7\u4e13\u95e8\u8bbe\u8ba1\u7684\u533b\u5b66\u6df1\u5ea6\u7814\u7a76\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u901a\u7528\u6df1\u5ea6\u7814\u7a76\u6a21\u578b\u5728\u533b\u5b66\u9886\u57df\u5e94\u7528\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u533b\u5b66\u63a8\u7406\u6027\u80fd\uff0c\u4e3a\u533b\u5b66AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u8bc1\u636e\u57fa\u7840\u63a8\u7406\u80fd\u529b"}}
{"id": "2601.17921", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17921", "abs": "https://arxiv.org/abs/2601.17921", "authors": ["Yi Zhao", "Qinghua Yao", "Xinyuan song", "Wei Zhu"], "title": "ShapLoRA: Allocation of Low-rank Adaption on Large Language Models via Shapley Value Inspired Importance Estimation", "comment": "accepted by CPAL", "summary": "Low-rank adaption (LoRA) is a representative method in the field of parameter-efficient fine-tuning (PEFT), and is key to Democratizating the modern large language models (LLMs). The vanilla LoRA is implemented with uniform ranks, and the recent literature have found that properly allocating ranks on the LLM backbones results in performance boosts. However, the previous rank allocation methods have limitations since they rely on inexplanable and unreliable importance measures for the LoRA ranks. To address the above issues, we propose the ShapLoRA framework. Inspired by the explanable attribution measure Shapley Value, we combine the sensitivity-based measures with the idea of coalitions in the collaborative games among LoRA ranks, and propose a more explainable importance measure called Shapley sensitivity. In addition, we optimize the workflow of the existing works by: (a) calculating Shapley sensitivity on a separate validation set; (b) Setting up the allocating-retraining procedures for fair comparisons. We have conducted experiments on various challenging tasks, and the experimental results demonstrate that our ShapLoRA method can outperform the recent baselines with comparable tunable parameters.\\footnote{Codes and fine-tuned models will be open-sourced to facilitate future research.", "AI": {"tldr": "ShapLoRA\uff1a\u57fa\u4e8eShapley\u503c\u7684\u53ef\u89e3\u91caLoRA\u79e9\u5206\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u654f\u611f\u5ea6\u5ea6\u91cf\u548c\u534f\u4f5c\u535a\u5f08\u601d\u60f3\uff0c\u63d0\u51fa\u66f4\u53ef\u89e3\u91ca\u7684\u91cd\u8981\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5728\u591a\u79cd\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709LoRA\u79e9\u5206\u914d\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4e3b\u8981\u4f9d\u8d56\u4e8e\u4e0d\u53ef\u89e3\u91ca\u4e14\u4e0d\u53ef\u9760\u7684\u91cd\u8981\u6027\u5ea6\u91cf\u3002\u4f20\u7edf\u5747\u5300\u79e9\u5206\u914d\u7684LoRA\u65b9\u6cd5\u6548\u7387\u6709\u9650\uff0c\u800c\u73b0\u6709\u7684\u79e9\u5206\u914d\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u91cd\u8981\u6027\u5ea6\u91cf\u6765\u4f18\u5316\u53c2\u6570\u5206\u914d\u3002", "method": "\u63d0\u51faShapLoRA\u6846\u67b6\uff0c\u53d7\u53ef\u89e3\u91ca\u5f52\u56e0\u5ea6\u91cfShapley\u503c\u7684\u542f\u53d1\uff0c\u5c06\u57fa\u4e8e\u654f\u611f\u5ea6\u7684\u5ea6\u91cf\u4e0eLoRA\u79e9\u4e4b\u95f4\u534f\u4f5c\u535a\u5f08\u7684\u8054\u76df\u601d\u60f3\u76f8\u7ed3\u5408\uff0c\u63d0\u51fa\u79f0\u4e3aShapley\u654f\u611f\u5ea6\u7684\u66f4\u53ef\u89e3\u91ca\u91cd\u8981\u6027\u5ea6\u91cf\u3002\u4f18\u5316\u73b0\u6709\u5de5\u4f5c\u6d41\u7a0b\uff1a\u5728\u5355\u72ec\u9a8c\u8bc1\u96c6\u4e0a\u8ba1\u7b97Shapley\u654f\u611f\u5ea6\uff1b\u5efa\u7acb\u5206\u914d-\u91cd\u8bad\u7ec3\u7a0b\u5e8f\u4ee5\u786e\u4fdd\u516c\u5e73\u6bd4\u8f83\u3002", "result": "\u5728\u591a\u79cd\u6311\u6218\u6027\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cShapLoRA\u65b9\u6cd5\u80fd\u591f\u5728\u53ef\u6bd4\u8f83\u7684\u53ef\u8c03\u53c2\u6570\u6570\u91cf\u4e0b\uff0c\u4f18\u4e8e\u6700\u8fd1\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ShapLoRA\u901a\u8fc7\u5f15\u5165\u57fa\u4e8eShapley\u503c\u7684\u53ef\u89e3\u91ca\u91cd\u8981\u6027\u5ea6\u91cf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LoRA\u79e9\u5206\u914d\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u548c\u53ef\u89e3\u91ca\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u53c2\u6570\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2601.18554", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18554", "abs": "https://arxiv.org/abs/2601.18554", "authors": ["Alberto Purpura", "Li Wang", "Sahil Badyal", "Eugenio Beaufrand", "Adam Faulkner"], "title": "Deconstructing Instruction-Following: A New Benchmark for Granular Evaluation of Large Language Model Instruction Compliance Abilities", "comment": "Paper accepted to EACL 2026", "summary": "Reliably ensuring Large Language Models (LLMs) follow complex instructions is a critical challenge, as existing benchmarks often fail to reflect real-world use or isolate compliance from task success. We introduce MOSAIC (MOdular Synthetic Assessment of Instruction Compliance), a modular framework that uses a dynamically generated dataset with up to 20 application-oriented generation constraints to enable a granular and independent analysis of this capability. Our evaluation of five LLMs from different families based on this new benchmark demonstrates that compliance is not a monolithic capability but varies significantly with constraint type, quantity, and position. The analysis reveals model-specific weaknesses, uncovers synergistic and conflicting interactions between instructions, and identifies distinct positional biases such as primacy and recency effects. These granular insights are critical for diagnosing model failures and developing more reliable LLMs for systems that demand strict adherence to complex instructions.", "AI": {"tldr": "MOSAIC\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u4f7f\u7528\u5305\u542b\u6700\u591a20\u4e2a\u5e94\u7528\u5bfc\u5411\u751f\u6210\u7ea6\u675f\u7684\u52a8\u6001\u751f\u6210\u6570\u636e\u96c6\uff0c\u5bf9LLM\u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u8fdb\u884c\u7ec6\u7c92\u5ea6\u72ec\u7acb\u5206\u6790\uff0c\u53d1\u73b0\u5408\u89c4\u6027\u53d7\u7ea6\u675f\u7c7b\u578b\u3001\u6570\u91cf\u548c\u4f4d\u7f6e\u5f71\u54cd\u663e\u8457\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5f80\u5f80\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u4f7f\u7528\u60c5\u51b5\uff0c\u6216\u672a\u80fd\u5c06\u5408\u89c4\u6027\u4e0e\u4efb\u52a1\u6210\u529f\u5206\u79bb\uff0c\u53ef\u9760\u786e\u4fddLLM\u9075\u5faa\u590d\u6742\u6307\u4ee4\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u5f15\u5165MOSAIC\u6a21\u5757\u5316\u6846\u67b6\uff0c\u4f7f\u7528\u52a8\u6001\u751f\u6210\u7684\u6570\u636e\u96c6\uff08\u5305\u542b\u6700\u591a20\u4e2a\u5e94\u7528\u5bfc\u5411\u7684\u751f\u6210\u7ea6\u675f\uff09\uff0c\u5bf9\u4e94\u4e2a\u4e0d\u540c\u5bb6\u65cf\u7684LLM\u8fdb\u884c\u7ec6\u7c92\u5ea6\u72ec\u7acb\u5206\u6790\u3002", "result": "\u5408\u89c4\u6027\u4e0d\u662f\u5355\u4e00\u80fd\u529b\uff0c\u800c\u662f\u968f\u7ea6\u675f\u7c7b\u578b\u3001\u6570\u91cf\u548c\u4f4d\u7f6e\u663e\u8457\u53d8\u5316\uff1b\u63ed\u793a\u4e86\u6a21\u578b\u7279\u5b9a\u5f31\u70b9\u3001\u6307\u4ee4\u95f4\u7684\u534f\u540c\u4e0e\u51b2\u7a81\u4ea4\u4e92\uff0c\u4ee5\u53ca\u9996\u56e0\u6548\u5e94\u548c\u8fd1\u56e0\u6548\u5e94\u7b49\u4f4d\u7f6e\u504f\u5dee\u3002", "conclusion": "\u8fd9\u4e9b\u7ec6\u7c92\u5ea6\u6d1e\u5bdf\u5bf9\u4e8e\u8bca\u65ad\u6a21\u578b\u5931\u8d25\u548c\u5f00\u53d1\u66f4\u53ef\u9760\u7684LLM\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u4e25\u683c\u9075\u5faa\u590d\u6742\u6307\u4ee4\u7684\u7cfb\u7edf\u4e2d\u3002"}}
{"id": "2601.17952", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17952", "abs": "https://arxiv.org/abs/2601.17952", "authors": ["Michail Mamalakis", "Tiago Azevedo", "Cristian Cosentino", "Chiara D'Ercoli", "Subati Abulikemu", "Zhongtian Sun", "Richard Bethlehem", "Pietro Lio"], "title": "A Monosemantic Attribution Framework for Stable Interpretability in Clinical Neuroscience Large Language Models", "comment": null, "summary": "Interpretability remains a key challenge for deploying large language models (LLMs) in clinical settings such as Alzheimer's disease progression diagnosis, where early and trustworthy predictions are essential. Existing attribution methods exhibit high inter-method variability and unstable explanations due to the polysemantic nature of LLM representations, while mechanistic interpretability approaches lack direct alignment with model inputs and outputs and do not provide explicit importance scores. We introduce a unified interpretability framework that integrates attributional and mechanistic perspectives through monosemantic feature extraction. By constructing a monosemantic embedding space at the level of an LLM layer and optimizing the framework to explicitly reduce inter-method variability, our approach produces stable input-level importance scores and highlights salient features via a decompressed representation of the layer of interest, advancing the safe and trustworthy application of LLMs in cognitive health and neurodegenerative disease.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u53ef\u89e3\u91ca\u6027\u6846\u67b6\uff0c\u7ed3\u5408\u5f52\u56e0\u548c\u673a\u5236\u89c6\u89d2\uff0c\u901a\u8fc7\u5355\u4e49\u7279\u5f81\u63d0\u53d6\u51cf\u5c11\u65b9\u6cd5\u95f4\u53d8\u5f02\uff0c\u4e3a\u4e34\u5e8aLLM\u5e94\u7528\u63d0\u4f9b\u7a33\u5b9a\u91cd\u8981\u6027\u8bc4\u5206", "motivation": "\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7b49\u4e34\u5e8a\u73af\u5883\u4e2d\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u53ef\u89e3\u91ca\u6027\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u5f52\u56e0\u65b9\u6cd5\u5b58\u5728\u9ad8\u65b9\u6cd5\u95f4\u53d8\u5f02\u6027\u548c\u4e0d\u7a33\u5b9a\u89e3\u91ca\uff0c\u800c\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u7f3a\u4e4f\u4e0e\u6a21\u578b\u8f93\u5165\u8f93\u51fa\u7684\u76f4\u63a5\u5bf9\u9f50\uff0c\u65e0\u6cd5\u63d0\u4f9b\u660e\u786e\u7684\u91cd\u8981\u6027\u8bc4\u5206\u3002", "method": "\u5f15\u5165\u7edf\u4e00\u53ef\u89e3\u91ca\u6027\u6846\u67b6\uff0c\u901a\u8fc7\u5355\u4e49\u7279\u5f81\u63d0\u53d6\u6574\u5408\u5f52\u56e0\u548c\u673a\u5236\u89c6\u89d2\u3002\u5728LLM\u5c42\u7ea7\u522b\u6784\u5efa\u5355\u4e49\u5d4c\u5165\u7a7a\u95f4\uff0c\u4f18\u5316\u6846\u67b6\u4ee5\u663e\u5f0f\u51cf\u5c11\u65b9\u6cd5\u95f4\u53d8\u5f02\u6027\uff0c\u751f\u6210\u7a33\u5b9a\u7684\u8f93\u5165\u7ea7\u91cd\u8981\u6027\u8bc4\u5206\uff0c\u5e76\u901a\u8fc7\u611f\u5174\u8da3\u5c42\u7684\u89e3\u538b\u7f29\u8868\u793a\u7a81\u51fa\u663e\u8457\u7279\u5f81\u3002", "result": "\u8be5\u65b9\u6cd5\u4ea7\u751f\u7a33\u5b9a\u7684\u8f93\u5165\u7ea7\u91cd\u8981\u6027\u8bc4\u5206\uff0c\u901a\u8fc7\u89e3\u538b\u7f29\u8868\u793a\u7a81\u51fa\u663e\u8457\u7279\u5f81\uff0c\u63a8\u8fdbLLM\u5728\u8ba4\u77e5\u5065\u5eb7\u548c\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\u4e2d\u7684\u5b89\u5168\u53ef\u4fe1\u5e94\u7528\u3002", "conclusion": "\u63d0\u51fa\u7684\u7edf\u4e00\u6846\u67b6\u901a\u8fc7\u5355\u4e49\u7279\u5f81\u63d0\u53d6\u6574\u5408\u4e86\u5f52\u56e0\u548c\u673a\u5236\u89c6\u89d2\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u4e34\u5e8aLLM\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u7a33\u5b9a\u53ef\u9760\u7684\u53ef\u89e3\u91ca\u6027\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18588", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18588", "abs": "https://arxiv.org/abs/2601.18588", "authors": ["Xianzhe Meng", "Qiangsheng Zeng", "Ling Luo", "Qinghan Yang", "Jiarui Hao", "Wenbo Wu", "Qinyu Wang", "Rui Yin", "Lin Qi", "Renzhi Lu"], "title": "Stability as a Liability:Systematic Breakdown of Linguistic Structure in LLMs", "comment": null, "summary": "Training stability is typically regarded as a prerequisite for reliable optimization in large language models. In this work, we analyze how stabilizing training dynamics affects the induced generation distribution. We show that under standard maximum likelihood training, stable parameter trajectories lead stationary solutions to approximately minimize the forward KL divergence to the empirical distribution, while implicitly reducing generative entropy. As a consequence, the learned model can concentrate probability mass on a limited subset of empirical modes, exhibiting systematic degeneration despite smooth loss convergence. We empirically validate this effect using a controlled feedback-based training framework that stabilizes internal generation statistics, observing consistent low-entropy outputs and repetitive behavior across architectures and random seeds. It indicates that optimization stability and generative expressivity are not inherently aligned, and that stability alone is an insufficient indicator of generative quality.", "AI": {"tldr": "\u7a33\u5b9a\u8bad\u7ec3\u52a8\u6001\u4f1a\u5bfc\u81f4\u751f\u6210\u5206\u5e03\u71b5\u964d\u4f4e\uff0c\u4f7f\u6a21\u578b\u96c6\u4e2d\u5728\u6709\u9650\u7684\u7ecf\u9a8c\u6a21\u5f0f\u4e0a\uff0c\u4ea7\u751f\u91cd\u590d\u6027\u9000\u5316\u884c\u4e3a\uff0c\u8868\u660e\u4f18\u5316\u7a33\u5b9a\u6027\u4e0e\u751f\u6210\u8868\u8fbe\u80fd\u529b\u5e76\u4e0d\u4e00\u81f4", "motivation": "\u5206\u6790\u8bad\u7ec3\u7a33\u5b9a\u6027\u5bf9\u751f\u6210\u5206\u5e03\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u7a33\u5b9a\u53c2\u6570\u8f68\u8ff9\u5982\u4f55\u5bfc\u81f4\u751f\u6210\u71b5\u964d\u4f4e\u548c\u6a21\u5f0f\u96c6\u4e2d\u73b0\u8c61\uff0c\u6311\u6218\"\u7a33\u5b9a\u8bad\u7ec3\u786e\u4fdd\u53ef\u9760\u4f18\u5316\"\u7684\u4f20\u7edf\u89c2\u70b9", "method": "\u7406\u8bba\u5206\u6790\u6807\u51c6\u6700\u5927\u4f3c\u7136\u8bad\u7ec3\u4e0b\u7a33\u5b9a\u53c2\u6570\u8f68\u8ff9\u7684\u7edf\u8ba1\u7279\u6027\uff0c\u4f7f\u7528\u57fa\u4e8e\u53cd\u9988\u7684\u8bad\u7ec3\u6846\u67b6\u7a33\u5b9a\u5185\u90e8\u751f\u6210\u7edf\u8ba1\u91cf\uff0c\u5728\u4e0d\u540c\u67b6\u6784\u548c\u968f\u673a\u79cd\u5b50\u4e0b\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1", "result": "\u7a33\u5b9a\u8bad\u7ec3\u5bfc\u81f4\u6a21\u578b\u8fd1\u4f3c\u6700\u5c0f\u5316\u524d\u5411KL\u6563\u5ea6\uff0c\u540c\u65f6\u9690\u5f0f\u51cf\u5c11\u751f\u6210\u71b5\uff0c\u4f7f\u6982\u7387\u8d28\u91cf\u96c6\u4e2d\u5728\u6709\u9650\u7684\u7ecf\u9a8c\u6a21\u5f0f\u4e0a\uff0c\u4ea7\u751f\u4f4e\u71b5\u8f93\u51fa\u548c\u91cd\u590d\u884c\u4e3a", "conclusion": "\u4f18\u5316\u7a33\u5b9a\u6027\u548c\u751f\u6210\u8868\u8fbe\u80fd\u529b\u5e76\u4e0d\u5185\u5728\u4e00\u81f4\uff0c\u7a33\u5b9a\u6027\u672c\u8eab\u4e0d\u8db3\u4ee5\u6307\u793a\u751f\u6210\u8d28\u91cf\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6307\u6807\u6765\u5e73\u8861\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u751f\u6210\u591a\u6837\u6027"}}
{"id": "2601.18595", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18595", "abs": "https://arxiv.org/abs/2601.18595", "authors": ["Joseph Cotnareanu", "Didier Chetelat", "Yingxue Zhang", "Mark Coates"], "title": "A Balanced Neuro-Symbolic Approach for Commonsense Abductive Logic", "comment": null, "summary": "Although Large Language Models (LLMs) have demonstrated impressive formal reasoning abilities, they often break down when problems require complex proof planning. One promising approach for improving LLM reasoning abilities involves translating problems into formal logic and using a logic solver. Although off-the-shelf logic solvers are in principle substantially more efficient than LLMs at logical reasoning, they assume that all relevant facts are provided in a question and are unable to deal with missing commonsense relations. In this work, we propose a novel method that uses feedback from the logic solver to augment a logic problem with commonsense relations provided by the LLM, in an iterative manner. This involves a search procedure through potential commonsense assumptions to maximize the chance of finding useful facts while keeping cost tractable. On a collection of pure-logical reasoning datasets, from which some commonsense information has been removed, our method consistently achieves considerable improvements over existing techniques, demonstrating the value in balancing neural and symbolic elements when working in human contexts.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408LLM\u4e0e\u903b\u8f91\u6c42\u89e3\u5668\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u53cd\u9988\u673a\u5236\u8865\u5145\u7f3a\u5931\u7684\u5e38\u8bc6\u5173\u7cfb\uff0c\u63d0\u5347\u590d\u6742\u63a8\u7406\u95ee\u9898\u7684\u89e3\u51b3\u80fd\u529b", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9700\u8981\u590d\u6742\u8bc1\u660e\u89c4\u5212\u7684\u95ee\u9898\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u4f20\u7edf\u903b\u8f91\u6c42\u89e3\u5668\u867d\u7136\u63a8\u7406\u6548\u7387\u9ad8\uff0c\u4f46\u65e0\u6cd5\u5904\u7406\u7f3a\u5931\u7684\u5e38\u8bc6\u5173\u7cfb\u3002\u9700\u8981\u4e00\u79cd\u5e73\u8861\u795e\u7ecf\u4e0e\u7b26\u53f7\u5143\u7d20\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u4eba\u7c7b\u4e0a\u4e0b\u6587\u4e2d\u7684\u63a8\u7406\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u8fed\u4ee3\u65b9\u6cd5\uff1a1) \u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u5f62\u5f0f\u903b\u8f91\uff1b2) \u4f7f\u7528\u903b\u8f91\u6c42\u89e3\u5668\u5206\u6790\uff1b3) \u6839\u636e\u6c42\u89e3\u5668\u7684\u53cd\u9988\uff0c\u8ba9LLM\u63d0\u4f9b\u7f3a\u5931\u7684\u5e38\u8bc6\u5173\u7cfb\uff1b4) \u901a\u8fc7\u641c\u7d22\u6f5c\u5728\u5e38\u8bc6\u5047\u8bbe\u6765\u6700\u5927\u5316\u627e\u5230\u6709\u7528\u4e8b\u5b9e\u7684\u6982\u7387\uff0c\u540c\u65f6\u63a7\u5236\u6210\u672c\uff1b5) \u8fed\u4ee3\u8fdb\u884c\u76f4\u5230\u95ee\u9898\u89e3\u51b3\u3002", "result": "\u5728\u79fb\u9664\u4e86\u90e8\u5206\u5e38\u8bc6\u4fe1\u606f\u7684\u7eaf\u903b\u8f91\u63a8\u7406\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u59cb\u7ec8\u53d6\u5f97\u663e\u8457\u6539\u8fdb\uff0c\u8bc1\u660e\u4e86\u5728\u4eba\u7c7b\u4e0a\u4e0b\u6587\u4e2d\u5e73\u8861\u795e\u7ecf\u4e0e\u7b26\u53f7\u5143\u7d20\u7684\u4ef7\u503c\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408LLM\u7684\u5e38\u8bc6\u63a8\u7406\u80fd\u529b\u548c\u903b\u8f91\u6c42\u89e3\u5668\u7684\u5f62\u5f0f\u63a8\u7406\u6548\u7387\uff0c\u63d0\u51fa\u7684\u8fed\u4ee3\u53cd\u9988\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u63a8\u7406\u95ee\u9898\u4e2d\u7f3a\u5931\u5e38\u8bc6\u5173\u7cfb\u7684\u6311\u6218\uff0c\u4e3a\u6df7\u5408\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2601.17993", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17993", "abs": "https://arxiv.org/abs/2601.17993", "authors": ["Marina Zavertiaeva", "Petr Parshakov", "Mikhail Usanin", "Aleksei Smirnov", "Sofia Paklina", "Anastasiia Kibardina"], "title": "AI-based approach to burnout identification from textual data", "comment": "9 pages, 2 figures", "summary": "This study introduces an AI-based methodology that utilizes natural language processing (NLP) to detect burnout from textual data. The approach relies on a RuBERT model originally trained for sentiment analysis and subsequently fine-tuned for burnout detection using two data sources: synthetic sentences generated with ChatGPT and user comments collected from Russian YouTube videos about burnout. The resulting model assigns a burnout probability to input texts and can be applied to process large volumes of written communication for monitoring burnout-related language signals in high-stress work environments.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eRuBERT\u6a21\u578b\u7684AI\u65b9\u6cd5\uff0c\u5229\u7528NLP\u6280\u672f\u4ece\u6587\u672c\u6570\u636e\u4e2d\u68c0\u6d4b\u804c\u4e1a\u5026\u6020\uff0c\u901a\u8fc7ChatGPT\u751f\u6210\u5408\u6210\u53e5\u5b50\u548cYouTube\u7528\u6237\u8bc4\u8bba\u8fdb\u884c\u5fae\u8c03\uff0c\u53ef\u8bc4\u4f30\u6587\u672c\u7684\u5026\u6020\u6982\u7387\u3002", "motivation": "\u5f00\u53d1\u81ea\u52a8\u5316\u5de5\u5177\u6765\u76d1\u6d4b\u9ad8\u538b\u5de5\u4f5c\u73af\u5883\u4e2d\u7684\u804c\u4e1a\u5026\u6020\u8ff9\u8c61\uff0c\u901a\u8fc7\u5206\u6790\u6587\u672c\u6570\u636e\u5b9e\u73b0\u65e9\u671f\u8bc6\u522b\u548c\u5e72\u9884\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u95ee\u5377\u8c03\u67e5\u7684\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u9884\u8bad\u7ec3\u7684RuBERT\u6a21\u578b\uff08\u539f\u7528\u4e8e\u60c5\u611f\u5206\u6790\uff09\uff0c\u4f7f\u7528ChatGPT\u751f\u6210\u7684\u5408\u6210\u53e5\u5b50\u548c\u4fc4\u7f57\u65afYouTube\u89c6\u9891\u4e2d\u5173\u4e8e\u5026\u6020\u7684\u7528\u6237\u8bc4\u8bba\u8fdb\u884c\u5fae\u8c03\uff0c\u6784\u5efa\u5026\u6020\u68c0\u6d4b\u6a21\u578b\u3002", "result": "\u6210\u529f\u5f00\u53d1\u51fa\u80fd\u591f\u4e3a\u8f93\u5165\u6587\u672c\u5206\u914d\u5026\u6020\u6982\u7387\u7684\u6a21\u578b\uff0c\u53ef\u5904\u7406\u5927\u91cf\u4e66\u9762\u901a\u4fe1\u6570\u636e\uff0c\u8bc6\u522b\u9ad8\u538b\u5de5\u4f5c\u73af\u5883\u4e2d\u7684\u5026\u6020\u76f8\u5173\u8bed\u8a00\u4fe1\u53f7\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86AI\u5728\u5fc3\u7406\u5065\u5eb7\u76d1\u6d4b\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u4e3a\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u5de5\u5177\u6765\u68c0\u6d4b\u548c\u9884\u9632\u804c\u4e1a\u5026\u6020\uff0c\u7279\u522b\u662f\u5728\u9ad8\u538b\u5de5\u4f5c\u73af\u5883\u4e2d\u3002"}}
{"id": "2601.18630", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.18630", "abs": "https://arxiv.org/abs/2601.18630", "authors": ["Abeer Badawi", "Md Tahmid Rahman Laskar", "Elahe Rahimi", "Sheri Grach", "Lindsay Bertrand", "Lames Danok", "Frank Rudzicz", "Jimmy Huang", "Elham Dolatabadi"], "title": "Assessing the Quality of Mental Health Support in LLM Responses through Multi-Attribute Human Evaluation", "comment": null, "summary": "The escalating global mental health crisis, marked by persistent treatment gaps, availability, and a shortage of qualified therapists, positions Large Language Models (LLMs) as a promising avenue for scalable support. While LLMs offer potential for accessible emotional assistance, their reliability, therapeutic relevance, and alignment with human standards remain challenging to address. This paper introduces a human-grounded evaluation methodology designed to assess LLM generated responses in therapeutic dialogue. Our approach involved curating a dataset of 500 mental health conversations from datasets with real-world scenario questions and evaluating the responses generated by nine diverse LLMs, including closed source and open source models. More specifically, these responses were evaluated by two psychiatric trained experts, who independently rated each on a 5 point Likert scale across a comprehensive 6 attribute rubric. This rubric captures Cognitive Support and Affective Resonance, providing a multidimensional perspective on therapeutic quality. Our analysis reveals that LLMs provide strong cognitive reliability by producing safe, coherent, and clinically appropriate information, but they demonstrate unstable affective alignment. Although closed source models (e.g., GPT-4o) offer balanced therapeutic responses, open source models show greater variability and emotional flatness. We reveal a persistent cognitive-affective gap and highlight the need for failure aware, clinically grounded evaluation frameworks that prioritize relational sensitivity alongside informational accuracy in mental health oriented LLMs. We advocate for balanced evaluation protocols with human in the loop that center on therapeutic sensitivity and provide a framework to guide the responsible design and clinical oversight of mental health oriented conversational AI.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4eba\u7c7b\u4e13\u5bb6\u8bc4\u4f30\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5fc3\u7406\u5065\u5eb7\u5bf9\u8bdd\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0LLMs\u5728\u8ba4\u77e5\u652f\u6301\u65b9\u9762\u8868\u73b0\u53ef\u9760\u4f46\u5728\u60c5\u611f\u5171\u9e23\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u63ed\u793a\u4e86\u8ba4\u77e5-\u60c5\u611f\u5dee\u8ddd\u3002", "motivation": "\u5168\u7403\u5fc3\u7406\u5065\u5eb7\u5371\u673a\u65e5\u76ca\u4e25\u91cd\uff0c\u5b58\u5728\u6cbb\u7597\u7f3a\u53e3\u548c\u5408\u683c\u6cbb\u7597\u5e08\u77ed\u7f3a\u95ee\u9898\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6709\u671b\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u5fc3\u7406\u652f\u6301\uff0c\u4f46\u5176\u53ef\u9760\u6027\u3001\u6cbb\u7597\u76f8\u5173\u6027\u548c\u4e0e\u4eba\u7c7b\u6807\u51c6\u7684\u5bf9\u9f50\u6027\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u5efa\u7acb\u6709\u6548\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4eba\u7c7b\u4e13\u5bb6\u7684\u8bc4\u4f30\u65b9\u6cd5\uff1a1\uff09\u4ece\u771f\u5b9e\u573a\u666f\u6570\u636e\u96c6\u4e2d\u6574\u7406500\u4e2a\u5fc3\u7406\u5065\u5eb7\u5bf9\u8bdd\uff1b2\uff09\u8bc4\u4f309\u4e2a\u4e0d\u540cLLMs\uff08\u5305\u62ec\u95ed\u6e90\u548c\u5f00\u6e90\u6a21\u578b\uff09\u751f\u6210\u7684\u54cd\u5e94\uff1b3\uff09\u7531\u4e24\u4f4d\u7cbe\u795e\u75c5\u5b66\u4e13\u5bb6\u72ec\u7acb\u4f7f\u75285\u70b9\u674e\u514b\u7279\u91cf\u8868\uff0c\u57fa\u4e8e\u5305\u542b6\u4e2a\u5c5e\u6027\u7684\u8bc4\u4f30\u6846\u67b6\uff08\u6db5\u76d6\u8ba4\u77e5\u652f\u6301\u548c\u60c5\u611f\u5171\u9e23\uff09\u8fdb\u884c\u8bc4\u5206\u3002", "result": "LLMs\u5728\u8ba4\u77e5\u53ef\u9760\u6027\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u80fd\u63d0\u4f9b\u5b89\u5168\u3001\u8fde\u8d2f\u4e14\u4e34\u5e8a\u9002\u5f53\u7684\u4fe1\u606f\uff0c\u4f46\u5728\u60c5\u611f\u5bf9\u9f50\u65b9\u9762\u8868\u73b0\u4e0d\u7a33\u5b9a\u3002\u95ed\u6e90\u6a21\u578b\uff08\u5982GPT-4o\uff09\u63d0\u4f9b\u66f4\u5e73\u8861\u7684\u6cbb\u7597\u54cd\u5e94\uff0c\u5f00\u6e90\u6a21\u578b\u5219\u8868\u73b0\u51fa\u66f4\u5927\u7684\u53d8\u5f02\u6027\u548c\u60c5\u611f\u5e73\u6de1\u6027\u3002\u7814\u7a76\u63ed\u793a\u4e86\u6301\u7eed\u7684\u8ba4\u77e5-\u60c5\u611f\u5dee\u8ddd\u3002", "conclusion": "\u9700\u8981\u5efa\u7acb\u5177\u6709\u5931\u8d25\u610f\u8bc6\u3001\u4e34\u5e8a\u57fa\u7840\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u5fc3\u7406\u5065\u5eb7\u5bfc\u5411\u7684LLMs\u4e2d\u4f18\u5148\u8003\u8651\u5173\u7cfb\u654f\u611f\u6027\u800c\u4e0d\u4ec5\u4ec5\u662f\u4fe1\u606f\u51c6\u786e\u6027\u3002\u5021\u5bfc\u91c7\u7528\u4eba\u7c7b\u5728\u73af\u7684\u5e73\u8861\u8bc4\u4f30\u534f\u8bae\uff0c\u4ee5\u6cbb\u7597\u654f\u611f\u6027\u4e3a\u4e2d\u5fc3\uff0c\u4e3a\u5fc3\u7406\u5065\u5eb7\u5bf9\u8bddAI\u7684\u8d1f\u8d23\u4efb\u8bbe\u8ba1\u548c\u4e34\u5e8a\u76d1\u7763\u63d0\u4f9b\u6307\u5bfc\u6846\u67b6\u3002"}}
{"id": "2601.18012", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18012", "abs": "https://arxiv.org/abs/2601.18012", "authors": ["Hendrika Maclean", "Mert Can Cakmak", "Muzakkiruddin Ahmed Mohammed", "Shames Al Mandalawi", "John Talburt"], "title": "Evaluating Semantic and Syntactic Understanding in Large Language Models for Payroll Systems", "comment": null, "summary": "Large language models are now used daily for writing, search, and analysis, and their natural language understanding continues to improve. However, they remain unreliable on exact numerical calculation and on producing outputs that are straightforward to audit. We study synthetic payroll system as a focused, high-stakes example and evaluate whether models can understand a payroll schema, apply rules in the right order, and deliver cent-accurate results. Our experiments span a tiered dataset from basic to complex cases, a spectrum of prompts from minimal baselines to schema-guided and reasoning variants, and multiple model families including GPT, Claude, Perplexity, Grok and Gemini. Results indicate clear regimes where careful prompting is sufficient and regimes where explicit computation is required. The work offers a compact, reproducible framework and practical guidance for deploying LLMs in settings that demand both accuracy and assurance.", "AI": {"tldr": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7cbe\u786e\u6570\u503c\u8ba1\u7b97\u548c\u53ef\u5ba1\u8ba1\u8f93\u51fa\u65b9\u9762\u7684\u53ef\u9760\u6027\uff0c\u4ee5\u5de5\u8d44\u5355\u7cfb\u7edf\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u53d1\u73b0\u9700\u8981\u7ed3\u5408\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u548c\u663e\u5f0f\u8ba1\u7b97\u624d\u80fd\u8fbe\u5230\u5206\u5e01\u7ea7\u7cbe\u5ea6", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65e5\u5e38\u5199\u4f5c\u3001\u641c\u7d22\u548c\u5206\u6790\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5728\u7cbe\u786e\u6570\u503c\u8ba1\u7b97\u548c\u53ef\u5ba1\u8ba1\u8f93\u51fa\u65b9\u9762\u4ecd\u4e0d\u53ef\u9760\uff0c\u9700\u8981\u7814\u7a76\u5728\u9ad8\u98ce\u9669\u573a\u666f\uff08\u5982\u5de5\u8d44\u5355\u7cfb\u7edf\uff09\u4e2d\u7684\u8868\u73b0", "method": "\u4f7f\u7528\u5206\u5c42\u6570\u636e\u96c6\uff08\u4ece\u57fa\u7840\u5230\u590d\u6742\u6848\u4f8b\uff09\u3001\u591a\u79cd\u63d0\u793a\u7b56\u7565\uff08\u4ece\u6700\u5c0f\u57fa\u7ebf\u5230\u6a21\u5f0f\u5f15\u5bfc\u548c\u63a8\u7406\u53d8\u4f53\uff09\u4ee5\u53ca\u591a\u4e2a\u6a21\u578b\u5bb6\u65cf\uff08GPT\u3001Claude\u3001Perplexity\u3001Grok\u3001Gemini\uff09\u8fdb\u884c\u7cfb\u7edf\u6027\u8bc4\u4f30", "result": "\u7ed3\u679c\u8868\u660e\u5b58\u5728\u660e\u786e\u7684\u5de5\u4f5c\u6a21\u5f0f\uff1a\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u8db3\u591f\uff0c\u800c\u5728\u5176\u4ed6\u60c5\u51b5\u4e0b\u9700\u8981\u663e\u5f0f\u8ba1\u7b97\uff1b\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u6846\u67b6\u548c\u5b9e\u7528\u90e8\u7f72\u6307\u5357", "conclusion": "\u4e3a\u5728\u8981\u6c42\u51c6\u786e\u6027\u548c\u4fdd\u8bc1\u6027\u7684\u573a\u666f\u4e2d\u90e8\u7f72LLMs\u63d0\u4f9b\u4e86\u7d27\u51d1\u3001\u53ef\u590d\u73b0\u7684\u6846\u67b6\u548c\u5b9e\u7528\u6307\u5bfc\uff0c\u5f3a\u8c03\u4e86\u7ed3\u5408\u63d0\u793a\u7b56\u7565\u548c\u663e\u5f0f\u8ba1\u7b97\u7684\u91cd\u8981\u6027"}}
{"id": "2601.18631", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.18631", "abs": "https://arxiv.org/abs/2601.18631", "authors": ["Mingyang Song", "Haoyu Sun", "Jiawei Gu", "Linjie Li", "Luxin Xu", "Ranjay Krishna", "Yu Cheng"], "title": "AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning", "comment": "28 pages, 10 figures and 13 tables", "summary": "When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce \\textbf{AdaReasoner}, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw.", "AI": {"tldr": "AdaReasoner\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u6a21\u578b\u5bb6\u65cf\uff0c\u901a\u8fc7\u5c06\u5de5\u5177\u4f7f\u7528\u4f5c\u4e3a\u901a\u7528\u63a8\u7406\u6280\u80fd\u800c\u975e\u7279\u5b9a\u5de5\u5177\u884c\u4e3a\u6765\u5b66\u4e60\uff0c\u5b9e\u73b0\u81ea\u4e3b\u5de5\u5177\u9009\u62e9\u3001\u7ec4\u5408\u548c\u9002\u5e94\u65b0\u5de5\u5177\u7684\u80fd\u529b\u3002", "motivation": "\u4eba\u7c7b\u5728\u9762\u5bf9\u8d85\u51fa\u81ea\u8eab\u80fd\u529b\u7684\u95ee\u9898\u65f6\u4f1a\u4f9d\u8d56\u5de5\u5177\uff0c\u8fd9\u4e3a\u63d0\u9ad8\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u7684\u89c6\u89c9\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u8303\u5f0f\u3002\u6709\u6548\u63a8\u7406\u7684\u5173\u952e\u5728\u4e8e\u77e5\u9053\u4f7f\u7528\u54ea\u4e9b\u5de5\u5177\u3001\u4f55\u65f6\u8c03\u7528\u5b83\u4eec\u4ee5\u53ca\u5982\u4f55\u5728\u591a\u6b65\u9aa4\u4e2d\u7ec4\u5408\u5b83\u4eec\uff0c\u5373\u4f7f\u9762\u5bf9\u65b0\u5de5\u5177\u6216\u65b0\u4efb\u52a1\u65f6\u4e5f\u662f\u5982\u6b64\u3002", "method": "AdaReasoner\u901a\u8fc7\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\u5b9e\u73b0\uff1a(1) \u53ef\u6269\u5c55\u7684\u6570\u636e\u6574\u7406\u6d41\u7a0b\uff0c\u8ba9\u6a21\u578b\u63a5\u89e6\u957f\u89c6\u91ce\u3001\u591a\u6b65\u9aa4\u7684\u5de5\u5177\u4ea4\u4e92\uff1b(2) Tool-GRPO\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u57fa\u4e8e\u6700\u7ec8\u4efb\u52a1\u6210\u529f\u4f18\u5316\u5de5\u5177\u9009\u62e9\u548c\u5e8f\u5217\uff1b(3) \u81ea\u9002\u5e94\u5b66\u4e60\u673a\u5236\uff0c\u52a8\u6001\u8c03\u8282\u5de5\u5177\u4f7f\u7528\u3002\u8fd9\u4e9b\u7ec4\u4ef6\u4f7f\u6a21\u578b\u80fd\u591f\u4ece\u4efb\u52a1\u4e0a\u4e0b\u6587\u548c\u4e2d\u95f4\u7ed3\u679c\u63a8\u65ad\u5de5\u5177\u6548\u7528\uff0c\u5b9e\u73b0\u591a\u5de5\u5177\u534f\u8c03\u548c\u5bf9\u672a\u89c1\u5de5\u5177\u7684\u6cdb\u5316\u3002", "result": "AdaReasoner\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u5de5\u5177\u9002\u5e94\u548c\u6cdb\u5316\u884c\u4e3a\uff1a\u81ea\u4e3b\u91c7\u7528\u6709\u76ca\u5de5\u5177\u3001\u6291\u5236\u65e0\u5173\u5de5\u5177\u3001\u6839\u636e\u4efb\u52a1\u9700\u6c42\u8c03\u6574\u5de5\u5177\u4f7f\u7528\u9891\u7387\uff0c\u5c3d\u7ba1\u4ece\u672a\u88ab\u660e\u786e\u8bad\u7ec3\u8fd9\u6837\u505a\u3002\u8fd9\u4e9b\u80fd\u529b\u8f6c\u5316\u4e3a\u5728\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5c067B\u57fa\u7840\u6a21\u578b\u5e73\u5747\u63d0\u534724.9%\uff0c\u5e76\u5728VSP\u548cJigsaw\u7b49\u591a\u4e2a\u4efb\u52a1\u4e0a\u8d85\u8d8aGPT-5\u7b49\u5f3a\u5927\u7684\u4e13\u6709\u7cfb\u7edf\u3002", "conclusion": "AdaReasoner\u6210\u529f\u5730\u5c06\u5de5\u5177\u4f7f\u7528\u4f5c\u4e3a\u901a\u7528\u63a8\u7406\u6280\u80fd\u8fdb\u884c\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u81ea\u4e3b\u5de5\u5177\u9009\u62e9\u3001\u7ec4\u5408\u548c\u9002\u5e94\u80fd\u529b\uff0c\u5728\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u5728\u9762\u5bf9\u65b0\u5de5\u5177\u548c\u65b0\u4efb\u52a1\u65f6\u7684\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2601.18014", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18014", "abs": "https://arxiv.org/abs/2601.18014", "authors": ["Adeeba Tarannum", "Muzakkiruddin Ahmed Mohammed", "Mert Can Cakmak", "Shames Al Mandalawi", "John Talburt"], "title": "A System for Name and Address Parsing with Large Language Models", "comment": null, "summary": "Reliable transformation of unstructured person and address text into structured data remains a key challenge in large-scale information systems. Traditional rule-based and probabilistic approaches perform well on clean inputs but fail under noisy or multilingual conditions, while neural and large language models (LLMs) often lack deterministic control and reproducibility. This paper introduces a prompt-driven, validation-centered framework that converts free-text records into a consistent 17-field schema without fine-tuning. The method integrates input normalisation, structured prompting, constrained decoding, and strict rule-based validation under fixed experimental settings to ensure reproducibility. Evaluations on heterogeneous real-world address data show high field-level accuracy, strong schema adherence, and stable confidence calibration. The results demonstrate that combining deterministic validation with generative prompting provides a robust, interpretable, and scalable solution for structured information extraction, offering a practical alternative to training-heavy or domain-specific models.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u4e0e\u786e\u5b9a\u6027\u9a8c\u8bc1\u7684\u6846\u67b6\uff0c\u5c06\u975e\u7ed3\u6784\u5316\u4eba\u5458\u5730\u5740\u6587\u672c\u8f6c\u6362\u4e3a17\u5b57\u6bb5\u7ed3\u6784\u5316\u6570\u636e\uff0c\u65e0\u9700\u5fae\u8c03\uff0c\u786e\u4fdd\u53ef\u590d\u73b0\u6027", "motivation": "\u4f20\u7edf\u89c4\u5219\u65b9\u6cd5\u548c\u6982\u7387\u65b9\u6cd5\u5728\u5e72\u51c0\u8f93\u5165\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u566a\u58f0\u6216\u591a\u8bed\u8a00\u6761\u4ef6\u4e0b\u5931\u6548\uff1b\u795e\u7ecf\u6a21\u578b\u548cLLM\u7f3a\u4e4f\u786e\u5b9a\u6027\u63a7\u5236\u548c\u53ef\u590d\u73b0\u6027\u3002\u9700\u8981\u4e00\u79cd\u65e2\u7075\u6d3b\u53c8\u53ef\u9760\u7684\u7ed3\u6784\u5316\u4fe1\u606f\u63d0\u53d6\u65b9\u6848", "method": "\u96c6\u6210\u8f93\u5165\u6807\u51c6\u5316\u3001\u7ed3\u6784\u5316\u63d0\u793a\u3001\u7ea6\u675f\u89e3\u7801\u548c\u4e25\u683c\u89c4\u5219\u9a8c\u8bc1\u7684\u63d0\u793a\u9a71\u52a8\u9a8c\u8bc1\u4e2d\u5fc3\u6846\u67b6\uff0c\u5728\u56fa\u5b9a\u5b9e\u9a8c\u8bbe\u7f6e\u4e0b\u786e\u4fdd\u53ef\u590d\u73b0\u6027", "result": "\u5728\u5f02\u6784\u771f\u5b9e\u5730\u5740\u6570\u636e\u4e0a\u8bc4\u4f30\u663e\u793a\u9ad8\u5b57\u6bb5\u7ea7\u51c6\u786e\u7387\u3001\u5f3a\u6a21\u5f0f\u9075\u4ece\u6027\u548c\u7a33\u5b9a\u7f6e\u4fe1\u5ea6\u6821\u51c6\uff0c\u8bc1\u660e\u7ed3\u5408\u786e\u5b9a\u6027\u9a8c\u8bc1\u4e0e\u751f\u6210\u63d0\u793a\u7684\u4f18\u8d8a\u6027", "conclusion": "\u7ed3\u5408\u786e\u5b9a\u6027\u9a8c\u8bc1\u4e0e\u751f\u6210\u63d0\u793a\u63d0\u4f9b\u4e86\u9c81\u68d2\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u6269\u5c55\u7684\u7ed3\u6784\u5316\u4fe1\u606f\u63d0\u53d6\u65b9\u6848\uff0c\u662f\u8bad\u7ec3\u5bc6\u96c6\u578b\u6216\u9886\u57df\u7279\u5b9a\u6a21\u578b\u7684\u5b9e\u7528\u66ff\u4ee3\u65b9\u6848"}}
{"id": "2601.18700", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18700", "abs": "https://arxiv.org/abs/2601.18700", "authors": ["Xingyu Sui", "Yanyan Zhao", "Yulin Hu", "Jiahe Guo", "Weixiang Zhao", "Bing Qin"], "title": "TEA-Bench: A Systematic Benchmarking of Tool-enhanced Emotional Support Dialogue Agent", "comment": null, "summary": "Emotional Support Conversation requires not only affective expression but also grounded instrumental support to provide trustworthy guidance. However, existing ESC systems and benchmarks largely focus on affective support in text-only settings, overlooking how external tools can enable factual grounding and reduce hallucination in multi-turn emotional support. We introduce TEA-Bench, the first interactive benchmark for evaluating tool-augmented agents in ESC, featuring realistic emotional scenarios, an MCP-style tool environment, and process-level metrics that jointly assess the quality and factual grounding of emotional support. Experiments on nine LLMs show that tool augmentation generally improves emotional support quality and reduces hallucination, but the gains are strongly capacity-dependent: stronger models use tools more selectively and effectively, while weaker models benefit only marginally. We further release TEA-Dialog, a dataset of tool-enhanced ESC dialogues, and find that supervised fine-tuning improves in-distribution support but generalizes poorly. Our results underscore the importance of tool use in building reliable emotional support agents.", "AI": {"tldr": "TEA-Bench\uff1a\u9996\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5de5\u5177\u589e\u5f3a\u578b\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u7cfb\u7edf\u7684\u4ea4\u4e92\u5f0f\u57fa\u51c6\uff0c\u5305\u542b\u771f\u5b9e\u60c5\u611f\u573a\u666f\u3001\u5de5\u5177\u73af\u5883\u548c\u8fc7\u7a0b\u7ea7\u8bc4\u4f30\u6307\u6807\uff0c\u5b9e\u9a8c\u663e\u793a\u5de5\u5177\u589e\u5f3a\u80fd\u63d0\u5347\u652f\u6301\u8d28\u91cf\u5e76\u51cf\u5c11\u5e7b\u89c9\uff0c\u4f46\u6548\u679c\u4e0e\u6a21\u578b\u80fd\u529b\u76f8\u5173\u3002", "motivation": "\u73b0\u6709\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u7cfb\u7edf\u548c\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u6587\u672c\u73af\u5883\u4e0b\u7684\u60c5\u611f\u652f\u6301\uff0c\u5ffd\u89c6\u4e86\u5916\u90e8\u5de5\u5177\u5982\u4f55\u5b9e\u73b0\u4e8b\u5b9e\u57fa\u7840\u5e76\u51cf\u5c11\u591a\u8f6e\u60c5\u611f\u652f\u6301\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u9700\u8981\u5efa\u7acb\u5de5\u5177\u589e\u5f3a\u7684\u60c5\u611f\u652f\u6301\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51faTEA-Bench\u4ea4\u4e92\u5f0f\u57fa\u51c6\uff0c\u5305\u542b\u771f\u5b9e\u60c5\u611f\u573a\u666f\u3001MCP\u98ce\u683c\u5de5\u5177\u73af\u5883\uff0c\u4ee5\u53ca\u540c\u65f6\u8bc4\u4f30\u60c5\u611f\u652f\u6301\u8d28\u91cf\u548c\u4e8b\u5b9e\u57fa\u7840\u7684\u8fc7\u7a0b\u7ea7\u6307\u6807\uff1b\u57289\u4e2aLLM\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u53d1\u5e03TEA-Dialog\u5de5\u5177\u589e\u5f3a\u7684\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u6570\u636e\u96c6\u3002", "result": "\u5de5\u5177\u589e\u5f3a\u666e\u904d\u63d0\u5347\u60c5\u611f\u652f\u6301\u8d28\u91cf\u5e76\u51cf\u5c11\u5e7b\u89c9\uff0c\u4f46\u6548\u679c\u5f3a\u70c8\u4f9d\u8d56\u4e8e\u6a21\u578b\u80fd\u529b\uff1a\u5f3a\u6a21\u578b\u80fd\u66f4\u9009\u62e9\u6027\u548c\u6709\u6548\u5730\u4f7f\u7528\u5de5\u5177\uff0c\u800c\u5f31\u6a21\u578b\u83b7\u76ca\u6709\u9650\uff1b\u76d1\u7763\u5fae\u8c03\u80fd\u63d0\u5347\u5206\u5e03\u5185\u652f\u6301\u6548\u679c\u4f46\u6cdb\u5316\u80fd\u529b\u5dee\u3002", "conclusion": "\u5de5\u5177\u4f7f\u7528\u5bf9\u4e8e\u6784\u5efa\u53ef\u9760\u7684\u60c5\u611f\u652f\u6301\u667a\u80fd\u4f53\u81f3\u5173\u91cd\u8981\uff0cTEA-Bench\u4e3a\u8bc4\u4f30\u5de5\u5177\u589e\u5f3a\u7684\u60c5\u611f\u652f\u6301\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9996\u4e2a\u7efc\u5408\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u80fd\u529b\u4e0e\u5de5\u5177\u4f7f\u7528\u6548\u679c\u4e4b\u95f4\u7684\u91cd\u8981\u5173\u7cfb\u3002"}}
{"id": "2601.18053", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18053", "abs": "https://arxiv.org/abs/2601.18053", "authors": ["Pulin Agrawal", "Prasoon Goyal"], "title": "Addressing LLM Diversity by Infusing Random Concepts", "comment": null, "summary": "Large language models (LLMs) are known to produce outputs with limited diversity. In this work, we study whether infusing random concepts in the prompts can improve the diversity of the generated outputs. To benchmark the approach, we design a systematic evaluation protocol which involves prompting an LLM with questions of the form \"Name 10 Hollywood actors\", and analyzing diversity measures of the resulting LLM outputs. Our experiments on multiple LLMs show that prepending random words/sentences unrelated to the prompt result in greater diversity in the outputs of LLMs. We believe that this promising result and the evaluation protocol opens up interesting avenues for future work, such as how infusing randomness into LLMs could be applied to other domains. Further, the evaluation protocol could also inspire research into benchmarking LLM diversity more systematically.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u63d0\u793a\u8bcd\u4e2d\u6ce8\u5165\u968f\u673a\u6982\u5ff5\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7684\u591a\u6837\u6027", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8f93\u51fa\u591a\u6837\u6027\u6709\u9650\uff0c\u9700\u8981\u63a2\u7d22\u63d0\u5347\u591a\u6837\u6027\u7684\u65b9\u6cd5", "method": "\u5728\u63d0\u793a\u8bcd\u524d\u6dfb\u52a0\u4e0e\u95ee\u9898\u65e0\u5173\u7684\u968f\u673a\u5355\u8bcd/\u53e5\u5b50\uff0c\u8bbe\u8ba1\u7cfb\u7edf\u8bc4\u4f30\u534f\u8bae\uff0c\u901a\u8fc7\"\u5217\u4e3e10\u4f4d\u597d\u83b1\u575e\u6f14\u5458\"\u7b49\u4efb\u52a1\u6d4b\u8bd5\u591a\u6837\u6027\u6307\u6807", "result": "\u5728\u591a\u4e2aLLMs\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6dfb\u52a0\u968f\u673a\u5185\u5bb9\u80fd\u663e\u8457\u63d0\u9ad8\u8f93\u51fa\u591a\u6837\u6027", "conclusion": "\u968f\u673a\u6027\u6ce8\u5165\u662f\u63d0\u5347LLM\u591a\u6837\u6027\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u8bc4\u4f30\u534f\u8bae\u4e3a\u7cfb\u7edf\u5316\u57fa\u51c6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2601.18706", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18706", "abs": "https://arxiv.org/abs/2601.18706", "authors": ["Zhichao Yang", "Sepehr Janghorbani", "Dongxu Zhang", "Jun Han", "Qian Qian", "Andrew Ressler", "Gregory D. Lyng", "Sanjit Singh Batra", "Robert E. Tillman"], "title": "Health-SCORE: Towards Scalable Rubrics for Improving Health-LLMs", "comment": null, "summary": "Rubrics are essential for evaluating open-ended LLM responses, especially in safety-critical domains such as healthcare. However, creating high-quality and domain-specific rubrics typically requires significant human expertise time and development cost, making rubric-based evaluation and training difficult to scale. In this work, we introduce Health-SCORE, a generalizable and scalable rubric-based training and evaluation framework that substantially reduces rubric development costs without sacrificing performance. We show that Health-SCORE provides two practical benefits beyond standalone evaluation: it can be used as a structured reward signal to guide reinforcement learning with safety-aware supervision, and it can be incorporated directly into prompts to improve response quality through in-context learning. Across open-ended healthcare tasks, Health-SCORE achieves evaluation quality comparable to human-created rubrics while significantly lowering development effort, making rubric-based evaluation and training more scalable.", "AI": {"tldr": "Health-SCORE\uff1a\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u57fa\u4e8e\u91cf\u89c4\u7684\u533b\u7597LLM\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u6846\u67b6\uff0c\u663e\u8457\u964d\u4f4e\u91cf\u89c4\u5f00\u53d1\u6210\u672c", "motivation": "\u5728\u533b\u7597\u7b49\u5b89\u5168\u5173\u952e\u9886\u57df\uff0c\u91cf\u89c4\u5bf9\u4e8e\u8bc4\u4f30\u5f00\u653e\u5f0fLLM\u54cd\u5e94\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u521b\u5efa\u9ad8\u8d28\u91cf\u3001\u9886\u57df\u7279\u5b9a\u7684\u91cf\u89c4\u9700\u8981\u5927\u91cf\u4e13\u5bb6\u65f6\u95f4\u548c\u5f00\u53d1\u6210\u672c\uff0c\u4f7f\u5f97\u57fa\u4e8e\u91cf\u89c4\u7684\u8bc4\u4f30\u548c\u8bad\u7ec3\u96be\u4ee5\u6269\u5c55\u3002", "method": "\u63d0\u51faHealth-SCORE\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u901a\u7528\u4e14\u53ef\u6269\u5c55\u7684\u57fa\u4e8e\u91cf\u89c4\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u663e\u8457\u964d\u4f4e\u91cf\u89c4\u5f00\u53d1\u6210\u672c\u800c\u4e0d\u727a\u7272\u6027\u80fd\u3002\u8be5\u6846\u67b6\u63d0\u4f9b\u4e24\u79cd\u5b9e\u7528\u529f\u80fd\uff1a1) \u4f5c\u4e3a\u7ed3\u6784\u5316\u5956\u52b1\u4fe1\u53f7\u6307\u5bfc\u5177\u6709\u5b89\u5168\u611f\u77e5\u76d1\u7763\u7684\u5f3a\u5316\u5b66\u4e60\uff1b2) \u76f4\u63a5\u878d\u5165\u63d0\u793a\u4e2d\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u63d0\u9ad8\u54cd\u5e94\u8d28\u91cf\u3002", "result": "\u5728\u5f00\u653e\u5f0f\u533b\u7597\u4efb\u52a1\u4e2d\uff0cHealth-SCORE\u5b9e\u73b0\u4e86\u4e0e\u4eba\u5de5\u521b\u5efa\u91cf\u89c4\u76f8\u5f53\u7684\u8bc4\u4f30\u8d28\u91cf\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u5f00\u53d1\u5de5\u4f5c\u91cf\uff0c\u4f7f\u57fa\u4e8e\u91cf\u89c4\u7684\u8bc4\u4f30\u548c\u8bad\u7ec3\u66f4\u5177\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "Health-SCORE\u662f\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u663e\u8457\u964d\u4f4e\u533b\u7597\u9886\u57df\u91cf\u89c4\u5f00\u53d1\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u8bc4\u4f30\u8d28\u91cf\uff0c\u4e3a\u57fa\u4e8e\u91cf\u89c4\u7684LLM\u8bc4\u4f30\u548c\u8bad\u7ec3\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u6846\u67b6\u3002"}}
{"id": "2601.18056", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18056", "abs": "https://arxiv.org/abs/2601.18056", "authors": ["Ahmet Yavuz Uluslu", "Elliot Murphy"], "title": "Neurocomputational Mechanisms of Syntactic Transfer in Bilingual Sentence Production", "comment": null, "summary": "We discuss the benefits of incorporating into the study of bilingual production errors and their traditionally documented timing signatures (e.g., event-related potentials) certain types of oscillatory signatures, which can offer new implementational-level constraints for theories of bilingualism. We argue that a recent neural model of language, ROSE, can offer a neurocomputational account of syntactic transfer in bilingual production, capturing some of its formal properties and the scope of morphosyntactic sequencing failure modes. We take as a case study cross-linguistic influence (CLI) and attendant theories of functional inhibition/competition, and present these as being driven by specific oscillatory failure modes during L2 sentence planning. We argue that modeling CLI in this way not only offers the kind of linking hypothesis ROSE was built to encourage, but also licenses the exploration of more spatiotemporally complex biomarkers of language dysfunction than more commonly discussed neural signatures.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3b\u5f20\u5c06\u632f\u8361\u7279\u5f81\u7eb3\u5165\u53cc\u8bed\u4ea7\u751f\u9519\u8bef\u7814\u7a76\uff0c\u5229\u7528ROSE\u795e\u7ecf\u6a21\u578b\u89e3\u91ca\u53e5\u6cd5\u8fc1\u79fb\uff0c\u4ee5\u8de8\u8bed\u8a00\u5f71\u54cd\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u63a2\u7d22\u66f4\u590d\u6742\u7684\u8bed\u8a00\u529f\u80fd\u969c\u788d\u751f\u7269\u6807\u5fd7\u7269\u3002", "motivation": "\u4f20\u7edf\u53cc\u8bed\u4ea7\u751f\u9519\u8bef\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4e8b\u4ef6\u76f8\u5173\u7535\u4f4d\u7b49\u65f6\u5e8f\u7279\u5f81\uff0c\u7f3a\u4e4f\u5b9e\u73b0\u5c42\u9762\u7684\u795e\u7ecf\u8ba1\u7b97\u7ea6\u675f\u3002\u9700\u8981\u65b0\u7684\u795e\u7ecf\u6a21\u578b\u6765\u89e3\u91ca\u53e5\u6cd5\u8fc1\u79fb\u7684\u5f62\u5f0f\u7279\u6027\u548c\u5f62\u6001\u53e5\u6cd5\u5e8f\u5217\u5931\u8d25\u6a21\u5f0f\u3002", "method": "\u91c7\u7528ROSE\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\uff0c\u5c06\u8de8\u8bed\u8a00\u5f71\u54cd\u548c\u529f\u80fd\u6291\u5236/\u7ade\u4e89\u7406\u8bba\u89e3\u91ca\u4e3aL2\u53e5\u5b50\u89c4\u5212\u671f\u95f4\u7684\u7279\u5b9a\u632f\u8361\u5931\u8d25\u6a21\u5f0f\uff0c\u5efa\u7acb\u795e\u7ecf\u8ba1\u7b97\u4e0e\u884c\u4e3a\u8868\u73b0\u4e4b\u95f4\u7684\u8fde\u63a5\u5047\u8bbe\u3002", "result": "ROSE\u6a21\u578b\u80fd\u591f\u6355\u6349\u53cc\u8bed\u4ea7\u751f\u4e2d\u53e5\u6cd5\u8fc1\u79fb\u7684\u5f62\u5f0f\u7279\u6027\u548c\u5f62\u6001\u53e5\u6cd5\u5e8f\u5217\u5931\u8d25\u6a21\u5f0f\u7684\u8303\u56f4\uff0c\u4e3a\u8de8\u8bed\u8a00\u5f71\u54cd\u63d0\u4f9b\u4e86\u795e\u7ecf\u8ba1\u7b97\u89e3\u91ca\uff0c\u5e76\u652f\u6301\u63a2\u7d22\u66f4\u590d\u6742\u7684\u65f6\u7a7a\u751f\u7269\u6807\u5fd7\u7269\u3002", "conclusion": "\u5c06\u632f\u8361\u7279\u5f81\u7eb3\u5165\u53cc\u8bed\u7814\u7a76\u4e0d\u4ec5\u4e3aROSE\u6a21\u578b\u63d0\u4f9b\u4e86\u9a8c\u8bc1\u673a\u4f1a\uff0c\u8fd8\u5141\u8bb8\u63a2\u7d22\u6bd4\u4f20\u7edf\u795e\u7ecf\u7279\u5f81\u66f4\u590d\u6742\u7684\u8bed\u8a00\u529f\u80fd\u969c\u788d\u751f\u7269\u6807\u5fd7\u7269\uff0c\u63a8\u52a8\u4e86\u53cc\u8bed\u795e\u7ecf\u8ba1\u7b97\u7406\u8bba\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.18716", "categories": ["cs.AI", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2601.18716", "abs": "https://arxiv.org/abs/2601.18716", "authors": ["Naeyma N. Islam", "Thomas R. Caulfield"], "title": "Conditioned Generative Modeling of Molecular Glues: A Realistic AI Approach for Synthesizable Drug-like Molecules", "comment": "30 pages, 8 figures", "summary": "Alzheimer's disease (AD) is marked by the pathological accumulation of amyloid beta-42 (Abeta-42), contributing to synaptic dysfunction and neurodegeneration. While extracellular amyloid plaques are well-studied, increasing evidence highlights intracellular Abeta-42 as an early and toxic driver of disease progression. In this study, we present a novel, AI-assisted drug design approach to promote targeted degradation of Abeta-42 via the ubiquitin-proteasome system (UPS), using E3 ligase-directed molecular glues. We systematically evaluated the ternary complex formation potential of Abeta-42 with three E3 ligases: CRBN, VHL, and MDM2, through structure-based modeling, ADMET screening, and docking. We then developed a Ligase-Conditioned Junction Tree Variational Autoencoder (LC-JT-VAE) to generate ligase-specific small molecules, incorporating protein sequence embeddings and torsional angle-aware molecular graphs. Our results demonstrate that this generative model can produce chemically valid, novel, and target-specific molecular glues capable of facilitating Abeta-42 degradation. This integrated approach offers a promising framework for designing UPS-targeted therapies for neurodegenerative diseases.", "AI": {"tldr": "AI\u8f85\u52a9\u836f\u7269\u8bbe\u8ba1\u65b0\u65b9\u6cd5\uff1a\u5229\u7528E3\u8fde\u63a5\u9176\u5bfc\u5411\u7684\u5206\u5b50\u80f6\u4fc3\u8fdbA\u03b2-42\u9776\u5411\u964d\u89e3\uff0c\u4e3a\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\u6cbb\u7597\u63d0\u4f9b\u65b0\u6846\u67b6", "motivation": "\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u4e2d\u7ec6\u80de\u5185A\u03b2-42\u7684\u79ef\u7d2f\u662f\u75be\u75c5\u65e9\u671f\u548c\u6bd2\u6027\u9a71\u52a8\u56e0\u7d20\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7ec6\u80de\u5916\u6dc0\u7c89\u6837\u6591\u5757\u3002\u9700\u8981\u5f00\u53d1\u65b0\u7b56\u7565\u9776\u5411\u964d\u89e3\u7ec6\u80de\u5185A\u03b2-42\uff0c\u800c\u6cdb\u7d20-\u86cb\u767d\u9176\u4f53\u7cfb\u7edf\u901a\u8fc7\u5206\u5b50\u80f6\u4ecb\u5bfc\u7684\u964d\u89e3\u662f\u6f5c\u5728\u6cbb\u7597\u9014\u5f84\u3002", "method": "1. \u7cfb\u7edf\u8bc4\u4f30A\u03b2-42\u4e0e\u4e09\u79cdE3\u8fde\u63a5\u9176\uff08CRBN\u3001VHL\u3001MDM2\uff09\u7684\u4e09\u5143\u590d\u5408\u7269\u5f62\u6210\u6f5c\u529b\uff0c\u91c7\u7528\u57fa\u4e8e\u7ed3\u6784\u7684\u5efa\u6a21\u3001ADMET\u7b5b\u9009\u548c\u5206\u5b50\u5bf9\u63a5\uff1b2. \u5f00\u53d1\u8fde\u63a5\u9176\u6761\u4ef6\u5316\u8fde\u63a5\u6811\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08LC-JT-VAE\uff09\uff0c\u6574\u5408\u86cb\u767d\u8d28\u5e8f\u5217\u5d4c\u5165\u548c\u626d\u8f6c\u89d2\u611f\u77e5\u5206\u5b50\u56fe\uff0c\u751f\u6210\u8fde\u63a5\u9176\u7279\u5f02\u6027\u5c0f\u5206\u5b50\u3002", "result": "\u751f\u6210\u6a21\u578b\u80fd\u591f\u4ea7\u751f\u5316\u5b66\u6709\u6548\u3001\u65b0\u9896\u4e14\u9776\u5411\u7279\u5f02\u6027\u7684\u5206\u5b50\u80f6\uff0c\u80fd\u591f\u4fc3\u8fdbA\u03b2-42\u964d\u89e3\u3002\u8be5\u65b9\u6cd5\u4e3a\u8bbe\u8ba1UPS\u9776\u5411\u7597\u6cd5\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u6846\u67b6\u3002", "conclusion": "\u8be5AI\u8f85\u52a9\u836f\u7269\u8bbe\u8ba1\u65b9\u6cd5\u901a\u8fc7\u5206\u5b50\u80f6\u4ecb\u5bfc\u7684\u9776\u5411\u964d\u89e3\uff0c\u4e3a\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\uff08\u7279\u522b\u662f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff09\u7684\u6cbb\u7597\u63d0\u4f9b\u4e86\u521b\u65b0\u7b56\u7565\uff0c\u5c55\u793a\u4e86\u751f\u6210\u6a21\u578b\u5728\u5f00\u53d1UPS\u9776\u5411\u7597\u6cd5\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.18065", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18065", "abs": "https://arxiv.org/abs/2601.18065", "authors": ["Aryan Roy", "Zekun Wang", "Christopher J. MacLellan"], "title": "Grounded Concreteness: Human-Like Concreteness Sensitivity in Vision-Language Models", "comment": null, "summary": "Do vision--language models (VLMs) develop more human-like sensitivity to linguistic concreteness than text-only large language models (LLMs) when both are evaluated with text-only prompts? We study this question with a controlled comparison between matched Llama text backbones and their Llama Vision counterparts across multiple model scales, treating multimodal pretraining as an ablation on perceptual grounding rather than access to images at inference. We measure concreteness effects at three complementary levels: (i) output behavior, by relating question-level concreteness to QA accuracy; (ii) embedding geometry, by testing whether representations organize along a concreteness axis; and (iii) attention dynamics, by quantifying context reliance via attention-entropy measures. In addition, we elicit token-level concreteness ratings from models and evaluate alignment to human norm distributions, testing whether multimodal training yields more human-consistent judgments. Across benchmarks and scales, VLMs show larger gains on more concrete inputs, exhibit clearer concreteness-structured representations, produce ratings that better match human norms, and display systematically different attention patterns consistent with increased grounding.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b(VLMs)\u4e0e\u7eaf\u6587\u672c\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u5bf9\u8bed\u8a00\u5177\u4f53\u6027\u7684\u654f\u611f\u5ea6\uff0c\u53d1\u73b0VLMs\u5728\u591a\u6a21\u6001\u9884\u8bad\u7ec3\u540e\u8868\u73b0\u51fa\u66f4\u63a5\u8fd1\u4eba\u7c7b\u7684\u8ba4\u77e5\u6a21\u5f0f", "motivation": "\u63a2\u7a76\u591a\u6a21\u6001\u9884\u8bad\u7ec3\u662f\u5426\u80fd\u8ba9\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u6bd4\u7eaf\u6587\u672c\u6a21\u578b\u53d1\u5c55\u51fa\u66f4\u63a5\u8fd1\u4eba\u7c7b\u7684\u5bf9\u8bed\u8a00\u5177\u4f53\u6027\u7684\u654f\u611f\u5ea6\uff0c\u5c06\u591a\u6a21\u6001\u8bad\u7ec3\u89c6\u4e3a\u611f\u77e5\u57fa\u7840\u7684\u4e00\u79cd\u6d88\u878d\u5b9e\u9a8c", "method": "\u4f7f\u7528\u5339\u914d\u7684Llama\u6587\u672c\u6a21\u578b\u53ca\u5176\u89c6\u89c9\u5bf9\u5e94\u7248\u672c\u8fdb\u884c\u63a7\u5236\u6bd4\u8f83\uff0c\u5728\u4e09\u4e2a\u5c42\u9762\u6d4b\u91cf\u5177\u4f53\u6027\u6548\u5e94\uff1a\u8f93\u51fa\u884c\u4e3a\u3001\u5d4c\u5165\u51e0\u4f55\u3001\u6ce8\u610f\u529b\u52a8\u6001\uff0c\u5e76\u8bc4\u4f30\u6a21\u578b\u751f\u6210\u7684\u5177\u4f53\u6027\u8bc4\u5206\u4e0e\u4eba\u7c7b\u89c4\u8303\u7684\u5339\u914d\u5ea6", "result": "VLMs\u5728\u66f4\u5177\u4f53\u7684\u8f93\u5165\u4e0a\u8868\u73b0\u63d0\u5347\u66f4\u5927\uff0c\u5177\u6709\u66f4\u6e05\u6670\u7684\u5177\u4f53\u6027\u7ed3\u6784\u5316\u8868\u793a\uff0c\u4ea7\u751f\u7684\u8bc4\u5206\u66f4\u7b26\u5408\u4eba\u7c7b\u89c4\u8303\uff0c\u6ce8\u610f\u529b\u6a21\u5f0f\u663e\u793a\u66f4\u5f3a\u7684\u611f\u77e5\u57fa\u7840", "conclusion": "\u591a\u6a21\u6001\u9884\u8bad\u7ec3\u4f7fVLMs\u53d1\u5c55\u51fa\u6bd4\u7eaf\u6587\u672cLLMs\u66f4\u63a5\u8fd1\u4eba\u7c7b\u7684\u5bf9\u8bed\u8a00\u5177\u4f53\u6027\u7684\u654f\u611f\u5ea6\uff0c\u5373\u4f7f\u5728\u4f7f\u7528\u7eaf\u6587\u672c\u63d0\u793a\u65f6\u4e5f\u662f\u5982\u6b64\uff0c\u8868\u660e\u611f\u77e5\u57fa\u7840\u5bf9\u8bed\u8a00\u7406\u89e3\u6709\u91cd\u8981\u5f71\u54cd"}}
{"id": "2601.18077", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18077", "abs": "https://arxiv.org/abs/2601.18077", "authors": ["Mahesh Ramesh", "Kaousheik Jayakumar", "Aswinkumar Ramkumar", "Pavan Thodima", "Aniket Rege"], "title": "Sparks of Cooperative Reasoning: LLMs as Strategic Hanabi Agents", "comment": null, "summary": "Cooperative reasoning under incomplete information remains challenging for both humans and multi-agent systems. The card game Hanabi embodies this challenge, requiring theory-of-mind reasoning and strategic communication. We benchmark 17 state-of-the-art LLM agents in 2-5 player games and study the impact of context engineering across model scales (4B to 600B+) to understand persistent coordination failures and robustness to scaffolding: from a minimal prompt with only explicit card details (Watson setting), to scaffolding with programmatic, Bayesian-motivated deductions (Sherlock setting), to multi-turn state tracking via working memory (Mycroft setting). We show that (1) agents can maintain an internal working memory for state tracking and (2) cross-play performance between different LLMs smoothly interpolates with model strength. In the Sherlock setting, the strongest reasoning models exceed 15 points on average across player counts, yet still trail experienced humans and specialist Hanabi agents, both consistently scoring above 20. We release the first public Hanabi datasets with annotated trajectories and move utilities: (1) HanabiLogs, containing 1,520 full game logs for instruction tuning, and (2) HanabiRewards, containing 560 games with dense move-level value annotations for all candidate moves. Supervised and RL finetuning of a 4B open-weight model (Qwen3-Instruct) on our datasets improves cooperative Hanabi play by 21% and 156% respectively, bringing performance to within ~3 points of a strong proprietary reasoning model (o4-mini) and surpassing the best non-reasoning model (GPT-4.1) by 52%. The HanabiRewards RL-finetuned model further generalizes beyond Hanabi, improving performance on a cooperative group-guessing benchmark by 11%, temporal reasoning on EventQA by 6.4%, instruction-following on IFBench-800K by 1.7 Pass@10, and matching AIME 2025 mathematical reasoning Pass@10.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e8617\u4e2a\u5148\u8fdbLLM\u5728Hanabi\u6e38\u620f\u4e2d\u7684\u5408\u4f5c\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u4e09\u79cd\u4e0a\u4e0b\u6587\u5de5\u7a0b\u8bbe\u7f6e\uff08Watson\u3001Sherlock\u3001Mycroft\uff09\u5206\u6790\u6a21\u578b\u89c4\u6a21\u5bf9\u534f\u8c03\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u53d1\u5e03\u9996\u4e2a\u516c\u5f00Hanabi\u6570\u636e\u96c6\u7528\u4e8e\u6307\u4ee4\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e864B\u5f00\u6e90\u6a21\u578b\u7684\u5408\u4f5c\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u4e0d\u5b8c\u5168\u4fe1\u606f\u4e0b\u7684\u5408\u4f5c\u63a8\u7406\u6311\u6218\uff0cHanabi\u6e38\u620f\u4f5c\u4e3a\u5178\u578b\u6d4b\u8bd5\u5e73\u53f0\uff0c\u9700\u8981\u5fc3\u667a\u7406\u8bba\u548c\u6218\u7565\u6c9f\u901a\u80fd\u529b\u3002\u73b0\u6709LLM\u5728\u590d\u6742\u591a\u667a\u80fd\u4f53\u534f\u8c03\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u8db3\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u5176\u80fd\u529b\u8fb9\u754c\u5e76\u63a2\u7d22\u63d0\u5347\u65b9\u6cd5\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u57282-5\u4ebaHanabi\u6e38\u620f\u4e2d\u8bc4\u4f3017\u4e2aSOTA LLM\uff1b2\uff09\u8bbe\u8ba1\u4e09\u79cd\u4e0a\u4e0b\u6587\u5de5\u7a0b\u8bbe\u7f6e\uff1aWatson\uff08\u4ec5\u663e\u5f0f\u5361\u7247\u4fe1\u606f\uff09\u3001Sherlock\uff08\u7a0b\u5e8f\u5316\u8d1d\u53f6\u65af\u63a8\u7406\uff09\u3001Mycroft\uff08\u591a\u8f6e\u72b6\u6001\u8ddf\u8e2a\u5de5\u4f5c\u8bb0\u5fc6\uff09\uff1b3\uff09\u521b\u5efa\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\uff1aHanabiLogs\uff081520\u4e2a\u5b8c\u6574\u6e38\u620f\u65e5\u5fd7\uff09\u548cHanabiRewards\uff08560\u4e2a\u5e26\u5bc6\u96c6\u52a8\u4f5c\u4ef7\u503c\u6807\u6ce8\u7684\u6e38\u620f\uff09\uff1b4\uff09\u5bf94B\u5f00\u6e90\u6a21\u578b\u8fdb\u884c\u76d1\u7763\u5b66\u4e60\u548cRL\u5fae\u8c03\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a1\uff09LLM\u80fd\u591f\u7ef4\u62a4\u5185\u90e8\u5de5\u4f5c\u8bb0\u5fc6\u8fdb\u884c\u72b6\u6001\u8ddf\u8e2a\uff1b2\uff09\u4e0d\u540cLLM\u95f4\u7684\u4ea4\u53c9\u6e38\u620f\u6027\u80fd\u968f\u6a21\u578b\u5f3a\u5ea6\u5e73\u6ed1\u63d2\u503c\uff1b3\uff09\u5728Sherlock\u8bbe\u7f6e\u4e0b\uff0c\u6700\u5f3a\u63a8\u7406\u6a21\u578b\u5e73\u5747\u5f97\u5206\u8d85\u8fc715\u5206\uff0c\u4f46\u4ecd\u843d\u540e\u4e8e\u7ecf\u9a8c\u4eba\u7c7b\u73a9\u5bb6\uff08>20\u5206\uff09\uff1b4\uff09\u76d1\u7763\u5fae\u8c03\u63d0\u5347\u5408\u4f5c\u6027\u80fd21%\uff0cRL\u5fae\u8c03\u63d0\u5347156%\uff0c\u63a5\u8fd1\u6700\u5f3a\u4e13\u6709\u63a8\u7406\u6a21\u578b\uff08o4-mini\uff09\u5e76\u5728\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u5c55\u73b0\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660e\uff1a1\uff09\u4e0a\u4e0b\u6587\u5de5\u7a0b\u548c\u6a21\u578b\u89c4\u6a21\u5bf9\u5408\u4f5c\u63a8\u7406\u81f3\u5173\u91cd\u8981\uff1b2\uff09\u4e13\u7528\u6570\u636e\u96c6\u5fae\u8c03\u80fd\u663e\u8457\u63d0\u5347LLM\u7684\u5408\u4f5c\u80fd\u529b\uff1b3\uff09HanabiRewards RL\u5fae\u8c03\u6a21\u578b\u5c55\u73b0\u51fa\u8d85\u8d8aHanabi\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u7fa4\u4f53\u731c\u6d4b\u3001\u65f6\u5e8f\u63a8\u7406\u3001\u6307\u4ee4\u8ddf\u968f\u548c\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u5747\u6709\u63d0\u5347\uff1b4\uff09\u7814\u7a76\u4e3a\u4e0d\u5b8c\u5168\u4fe1\u606f\u4e0b\u7684\u591a\u667a\u80fd\u4f53\u5408\u4f5c\u63a8\u7406\u63d0\u4f9b\u4e86\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\u548c\u6709\u6548\u63d0\u5347\u65b9\u6cd5\u3002"}}
{"id": "2601.18744", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18744", "abs": "https://arxiv.org/abs/2601.18744", "authors": ["Fangxu Yu", "Xingang Guo", "Lingzhi Yuan", "Haoqiang Kang", "Hongyu Zhao", "Lianhui Qin", "Furong Huang", "Bin Hu", "Tianyi Zhou"], "title": "TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models", "comment": null, "summary": "Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/.", "code_url": "https://tsrbench.github.io/", "AI": {"tldr": "TSRBench\u662f\u4e00\u4e2a\u5168\u9762\u7684\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b4125\u4e2a\u95ee\u9898\u300114\u4e2a\u9886\u57df\u30014\u4e2a\u7ef4\u5ea6\uff08\u611f\u77e5\u3001\u63a8\u7406\u3001\u9884\u6d4b\u3001\u51b3\u7b56\uff09\uff0c\u8bc4\u4f30\u4e8630\u591a\u4e2a\u9886\u5148\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u65e0\u5904\u4e0d\u5728\u4e14\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u901a\u7528\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\u7f3a\u4e4f\u65f6\u95f4\u5e8f\u5217\u7ef4\u5ea6\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30\u901a\u7528\u6a21\u578b\u7684\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5f15\u5165TSRBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b4125\u4e2a\u95ee\u9898\uff0c\u8986\u76d614\u4e2a\u9886\u57df\uff0c\u5206\u4e3a4\u4e2a\u4e3b\u8981\u7ef4\u5ea6\uff08\u611f\u77e5\u3001\u63a8\u7406\u3001\u9884\u6d4b\u3001\u51b3\u7b56\uff09\uff0c\u5305\u542b15\u4e2a\u4efb\u52a1\u8bc4\u4f30\u57fa\u672c\u63a8\u7406\u80fd\u529b\u3002\u5bf930\u591a\u4e2a\u9886\u5148\u7684\u4e13\u6709\u548c\u5f00\u6e90LLM\u3001VLM\u3001TSLLM\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u7f29\u653e\u5b9a\u5f8b\u9002\u7528\u4e8e\u611f\u77e5\u548c\u63a8\u7406\u4f46\u5728\u9884\u6d4b\u4e2d\u5931\u6548\uff1b2\uff09\u5f3a\u63a8\u7406\u80fd\u529b\u4e0d\u80fd\u4fdd\u8bc1\u51c6\u786e\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u9884\u6d4b\uff0c\u8868\u660e\u8bed\u4e49\u7406\u89e3\u548c\u6570\u503c\u9884\u6d4b\u4e4b\u95f4\u5b58\u5728\u89e3\u8026\uff1b3\uff09\u5c3d\u7ba1\u65f6\u95f4\u5e8f\u5217\u7684\u6587\u672c\u548c\u89c6\u89c9\u8868\u793a\u5177\u6709\u4e92\u8865\u6027\uff0c\u4f46\u5f53\u524d\u591a\u6a21\u6001\u6a21\u578b\u672a\u80fd\u6709\u6548\u878d\u5408\u5b83\u4eec\u4ee5\u83b7\u5f97\u76f8\u4e92\u6027\u80fd\u589e\u76ca\u3002", "conclusion": "TSRBench\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6807\u51c6\u5316\u8bc4\u4f30\u5e73\u53f0\uff0c\u4e0d\u4ec5\u7a81\u51fa\u4e86\u73b0\u6709\u6311\u6218\uff0c\u8fd8\u4e3a\u63a8\u8fdb\u901a\u7528\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\u3002\u57fa\u51c6\u6d4b\u8bd5\u63ed\u793a\u4e86\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u4e2d\u8bed\u4e49\u7406\u89e3\u4e0e\u6570\u503c\u9884\u6d4b\u4e4b\u95f4\u7684\u5173\u952e\u5dee\u8ddd\uff0c\u4ee5\u53ca\u591a\u6a21\u6001\u878d\u5408\u7684\u4e0d\u8db3\u3002"}}
{"id": "2601.18102", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18102", "abs": "https://arxiv.org/abs/2601.18102", "authors": ["Stephanie Fong", "Zimu Wang", "Guilherme C. Oliveira", "Xiangyu Zhao", "Yiwen Jiang", "Jiahe Liu", "Beau-Luke Colton", "Scott Woods", "Martha E. Shenton", "Barnaby Nelson", "Zongyuan Ge", "Dominic Dwyer"], "title": "CHiRPE: A Step Towards Real-World Clinical NLP with Clinician-Oriented Model Explanations", "comment": "This paper is accepted at EACL 2026", "summary": "The medical adoption of NLP tools requires interpretability by end users, yet traditional explainable AI (XAI) methods are misaligned with clinical reasoning and lack clinician input. We introduce CHiRPE (Clinical High-Risk Prediction with Explainability), an NLP pipeline that takes transcribed semi-structured clinical interviews to: (i) predict psychosis risk; and (ii) generate novel SHAP explanation formats co-developed with clinicians. Trained on 944 semi-structured interview transcripts across 24 international clinics of the AMP-SCZ study, the CHiRPE pipeline integrates symptom-domain mapping, LLM summarisation, and BERT classification. CHiRPE achieved over 90% accuracy across three BERT variants and outperformed baseline models. Explanation formats were evaluated by 28 clinical experts who indicated a strong preference for our novel concept-guided explanations, especially hybrid graph-and-text summary formats. CHiRPE demonstrates that clinically-guided model development produces both accurate and interpretable results. Our next step is focused on real-world testing across our 24 international sites.", "AI": {"tldr": "CHiRPE\u662f\u4e00\u4e2a\u4e34\u5e8aNLP\u7ba1\u9053\uff0c\u901a\u8fc7\u8f6c\u5f55\u7684\u534a\u7ed3\u6784\u5316\u4e34\u5e8a\u8bbf\u8c08\u9884\u6d4b\u7cbe\u795e\u75c5\u98ce\u9669\uff0c\u5e76\u751f\u6210\u4e0e\u4e34\u5e8a\u533b\u751f\u5171\u540c\u5f00\u53d1\u7684\u65b0\u578bSHAP\u89e3\u91ca\u683c\u5f0f\uff0c\u5b9e\u73b0\u8d85\u8fc790%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u4f20\u7edf\u53ef\u89e3\u91caAI\u65b9\u6cd5\u4e0e\u4e34\u5e8a\u63a8\u7406\u4e0d\u5339\u914d\uff0c\u7f3a\u4e4f\u4e34\u5e8a\u533b\u751f\u8f93\u5165\uff0c\u800c\u533b\u7597NLP\u5de5\u5177\u7684\u91c7\u7528\u9700\u8981\u6700\u7ec8\u7528\u6237\u7684\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u6574\u5408\u75c7\u72b6\u9886\u57df\u6620\u5c04\u3001LLM\u6458\u8981\u548cBERT\u5206\u7c7b\u7684NLP\u7ba1\u9053\uff0c\u4f7f\u7528944\u4efd\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u8f6c\u5f55\u672c\u8bad\u7ec3\uff0c\u751f\u6210\u4e0e\u4e34\u5e8a\u533b\u751f\u5171\u540c\u5f00\u53d1\u7684\u65b0\u578bSHAP\u89e3\u91ca\u683c\u5f0f\u3002", "result": "\u5728\u4e09\u4e2aBERT\u53d8\u4f53\u4e0a\u5747\u8fbe\u5230\u8d85\u8fc790%\u7684\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff1b28\u540d\u4e34\u5e8a\u4e13\u5bb6\u8bc4\u4f30\u663e\u793a\u5bf9\u65b0\u578b\u6982\u5ff5\u5f15\u5bfc\u89e3\u91ca\uff08\u7279\u522b\u662f\u6df7\u5408\u56fe-\u6587\u672c\u6458\u8981\u683c\u5f0f\uff09\u6709\u5f3a\u70c8\u504f\u597d\u3002", "conclusion": "\u4e34\u5e8a\u5f15\u5bfc\u7684\u6a21\u578b\u5f00\u53d1\u80fd\u4ea7\u751f\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u7ed3\u679c\uff1b\u4e0b\u4e00\u6b65\u5c06\u572824\u4e2a\u56fd\u9645\u7ad9\u70b9\u8fdb\u884c\u771f\u5b9e\u4e16\u754c\u6d4b\u8bd5\u3002"}}
{"id": "2601.18116", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18116", "abs": "https://arxiv.org/abs/2601.18116", "authors": ["Lin Sun", "Linglin Zhang", "Jingang Huang", "Change Jia", "Zhengwei Cheng", "Xiangzheng Zhang"], "title": "FABLE: Forest-Based Adaptive Bi-Path LLM-Enhanced Retrieval for Multi-Document Reasoning", "comment": null, "summary": "The rapid expansion of long-context Large Language Models (LLMs) has reignited debate on whether Retrieval-Augmented Generation (RAG) remains necessary. However, empirical evidence reveals persistent limitations of long-context inference, including the lost-in-the-middle phenomenon, high computational cost, and poor scalability for multi-document reasoning. Conversely, traditional RAG systems, while efficient, are constrained by flat chunk-level retrieval that introduces semantic noise and fails to support structured cross-document synthesis.\n  We present \\textbf{FABLE}, a \\textbf{F}orest-based \\textbf{A}daptive \\textbf{B}i-path \\textbf{L}LM-\\textbf{E}nhanced retrieval framework that integrates LLMs into both knowledge organization and retrieval. FABLE constructs LLM-enhanced hierarchical forest indexes with multi-granularity semantic structures, then employs a bi-path strategy combining LLM-guided hierarchical traversal with structure-aware propagation for fine-grained evidence acquisition, with explicit budget control for adaptive efficiency trade-offs.\n  Extensive experiments demonstrate that FABLE consistently outperforms SOTA RAG methods and achieves comparable accuracy to full-context LLM inference with up to 94\\% token reduction, showing that long-context LLMs amplify rather than fully replace the need for structured retrieval.", "AI": {"tldr": "FABLE\u662f\u4e00\u4e2a\u57fa\u4e8e\u68ee\u6797\u7684\u81ea\u9002\u5e94\u53cc\u8def\u5f84LLM\u589e\u5f3a\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efaLLM\u589e\u5f3a\u7684\u5c42\u6b21\u5316\u68ee\u6797\u7d22\u5f15\u548c\u53cc\u8def\u5f84\u68c0\u7d22\u7b56\u7565\uff0c\u5728\u663e\u8457\u51cf\u5c11token\u6d88\u8017\u7684\u540c\u65f6\u8fbe\u5230\u4e0e\u5168\u4e0a\u4e0b\u6587LLM\u63a8\u7406\u76f8\u5f53\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u957f\u4e0a\u4e0b\u6587LLM\u5b58\u5728\u4e2d\u95f4\u4fe1\u606f\u4e22\u5931\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u591a\u6587\u6863\u63a8\u7406\u6269\u5c55\u6027\u5dee\u7b49\u95ee\u9898\uff0c\u800c\u4f20\u7edfRAG\u7cfb\u7edf\u53d7\u9650\u4e8e\u5e73\u9762\u5206\u5757\u68c0\u7d22\uff0c\u5b58\u5728\u8bed\u4e49\u566a\u58f0\u4e14\u65e0\u6cd5\u652f\u6301\u7ed3\u6784\u5316\u8de8\u6587\u6863\u5408\u6210\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u5229\u7528LLM\u80fd\u529b\u53c8\u80fd\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u7684\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u3002", "method": "FABLE\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) LLM\u589e\u5f3a\u7684\u5c42\u6b21\u5316\u68ee\u6797\u7d22\u5f15\u6784\u5efa\uff0c\u521b\u5efa\u591a\u7c92\u5ea6\u8bed\u4e49\u7ed3\u6784\uff1b2) \u53cc\u8def\u5f84\u68c0\u7d22\u7b56\u7565\uff0c\u7ed3\u5408LLM\u5f15\u5bfc\u7684\u5c42\u6b21\u904d\u5386\u548c\u7ed3\u6784\u611f\u77e5\u4f20\u64ad\u8fdb\u884c\u7ec6\u7c92\u5ea6\u8bc1\u636e\u83b7\u53d6\uff0c\u5e76\u5177\u6709\u663e\u5f0f\u9884\u7b97\u63a7\u5236\u4ee5\u5b9e\u73b0\u81ea\u9002\u5e94\u6548\u7387\u6743\u8861\u3002", "result": "\u5b9e\u9a8c\u8868\u660eFABLE\u6301\u7eed\u4f18\u4e8eSOTA RAG\u65b9\u6cd5\uff0c\u5728\u51cf\u5c11\u9ad8\u8fbe94% token\u6d88\u8017\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u4e0e\u5168\u4e0a\u4e0b\u6587LLM\u63a8\u7406\u76f8\u5f53\u7684\u51c6\u786e\u7387\uff0c\u8bc1\u660e\u957f\u4e0a\u4e0b\u6587LLM\u653e\u5927\u4e86\u800c\u975e\u5b8c\u5168\u66ff\u4ee3\u7ed3\u6784\u5316\u68c0\u7d22\u7684\u9700\u6c42\u3002", "conclusion": "\u957f\u4e0a\u4e0b\u6587LLM\u5e76\u672a\u4f7fRAG\u8fc7\u65f6\uff0c\u800c\u662f\u5f3a\u8c03\u4e86\u7ed3\u6784\u5316\u68c0\u7d22\u7684\u91cd\u8981\u6027\u3002FABLE\u901a\u8fc7\u96c6\u6210LLM\u5230\u77e5\u8bc6\u7ec4\u7ec7\u548c\u68c0\u7d22\u4e2d\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff0c\u4e3a\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18129", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18129", "abs": "https://arxiv.org/abs/2601.18129", "authors": ["Kunat Pipatanakul", "Pittawat Taveekitworachai"], "title": "Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models", "comment": "19 pages. Code is publicly available at https://github.com/scb-10x/typhoon-s . Datasets and model weights are available at https://huggingface.co/collections/typhoon-ai/typhoon-s", "summary": "Large language models (LLMs) have progressed rapidly; however, most state-of-the-art models are trained and evaluated primarily in high-resource languages such as English and Chinese, and are often developed by a small number of organizations with access to large-scale compute and data. This gatekeeping creates a practical barrier for sovereign settings in which a regional- or national-scale institution or domain owner must retain control and understanding of model weights, training data, and deployment while operating under limited resources and strict transparency constraints. To this end, we identify two core requirements: (1) adoptability, the ability to transform a base model into a general-purpose assistant, and (2) sovereign capability, the ability to perform high-stakes, region-specific tasks (e.g., legal reasoning in local languages and cultural knowledge). We investigate whether these requirements can be achieved without scaling massive instruction corpora or relying on complex preference tuning pipelines and large-scale reinforcement fine-tuning (RFT). We present Typhoon S, a minimal and open post-training recipe that combines supervised fine-tuning, on-policy distillation, and small-scale RFT. Using Thai as a representative case study, we demonstrate that our approach transforms both sovereign-adapted and general-purpose base models into instruction-tuned models with strong general performance. We further show that small-scale RFT with InK-GRPO -- an extension of GRPO that augments the GRPO loss with a next-word prediction loss -- improves Thai legal reasoning and Thai-specific knowledge while preserving general capabilities. Our results suggest that a carefully designed post-training strategy can reduce the required scale of instruction data and computation, providing a practical path toward high-quality sovereign LLMs under academic-scale resources.", "AI": {"tldr": "Typhoon S\uff1a\u4e00\u79cd\u9762\u5411\u4e3b\u6743LLM\u7684\u8f7b\u91cf\u7ea7\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u3001\u7b56\u7565\u84b8\u998f\u548c\u5c0f\u89c4\u6a21RFT\uff0c\u5728\u6709\u9650\u8d44\u6e90\u4e0b\u5b9e\u73b0\u6cf0\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u9002\u914d\u6027\u548c\u4e3b\u6743\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41LLM\u4e3b\u8981\u9762\u5411\u82f1\u8bed\u548c\u4e2d\u6587\u7b49\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u7531\u5c11\u6570\u62e5\u6709\u5927\u89c4\u6a21\u8ba1\u7b97\u548c\u6570\u636e\u7684\u7ec4\u7ec7\u5f00\u53d1\uff0c\u5f62\u6210\u4e86\u6280\u672f\u58c1\u5792\u3002\u4e3b\u6743\u573a\u666f\uff08\u5982\u533a\u57df\u6216\u56fd\u5bb6\u7ea7\u673a\u6784\uff09\u9700\u8981\u5728\u6709\u9650\u8d44\u6e90\u3001\u4e25\u683c\u900f\u660e\u5ea6\u7ea6\u675f\u4e0b\u4fdd\u6301\u5bf9\u6a21\u578b\u6743\u91cd\u3001\u8bad\u7ec3\u6570\u636e\u548c\u90e8\u7f72\u7684\u63a7\u5236\u4e0e\u7406\u89e3\uff0c\u56e0\u6b64\u9700\u8981\u89e3\u51b3\u9002\u914d\u6027\uff08\u5c06\u57fa\u7840\u6a21\u578b\u8f6c\u5316\u4e3a\u901a\u7528\u52a9\u624b\uff09\u548c\u4e3b\u6743\u80fd\u529b\uff08\u6267\u884c\u9ad8\u98ce\u9669\u3001\u533a\u57df\u7279\u5b9a\u4efb\u52a1\uff09\u4e24\u5927\u6838\u5fc3\u9700\u6c42\u3002", "method": "\u63d0\u51faTyphoon S\u540e\u8bad\u7ec3\u65b9\u6cd5\uff1a1\uff09\u76d1\u7763\u5fae\u8c03\uff1b2\uff09\u7b56\u7565\u84b8\u998f\uff1b3\uff09\u5c0f\u89c4\u6a21\u5f3a\u5316\u5fae\u8c03\uff08RFT\uff09\uff0c\u5176\u4e2d\u4f7f\u7528InK-GRPO\u6269\u5c55GRPO\u635f\u5931\u51fd\u6570\uff0c\u589e\u52a0\u4e0b\u4e00\u8bcd\u9884\u6d4b\u635f\u5931\u3002\u8be5\u65b9\u6cd5\u907f\u514d\u5927\u89c4\u6a21\u6307\u4ee4\u6570\u636e\u6536\u96c6\u548c\u590d\u6742\u504f\u597d\u8c03\u4f18\u6d41\u7a0b\uff0c\u4ee5\u6cf0\u8bed\u4e3a\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u6210\u529f\u5c06\u4e3b\u6743\u9002\u5e94\u548c\u901a\u7528\u57fa\u7840\u6a21\u578b\u8f6c\u5316\u4e3a\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\uff0c\u5177\u6709\u5f3a\u5927\u7684\u901a\u7528\u6027\u80fd\u3002\u5c0f\u89c4\u6a21RFT\u7ed3\u5408InK-GRPO\u663e\u8457\u63d0\u5347\u6cf0\u8bed\u6cd5\u5f8b\u63a8\u7406\u548c\u6cf0\u8bed\u7279\u5b9a\u77e5\u8bc6\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u901a\u7528\u80fd\u529b\u3002\u7ed3\u679c\u8868\u660e\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u540e\u8bad\u7ec3\u7b56\u7565\u53ef\u4ee5\u51cf\u5c11\u6307\u4ee4\u6570\u636e\u548c\u8ba1\u7b97\u89c4\u6a21\u9700\u6c42\u3002", "conclusion": "Typhoon S\u4e3a\u5728\u5b66\u672f\u89c4\u6a21\u8d44\u6e90\u4e0b\u5f00\u53d1\u9ad8\u8d28\u91cf\u4e3b\u6743LLM\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u8bc1\u660e\u901a\u8fc7\u8f7b\u91cf\u7ea7\u540e\u8bad\u7ec3\u65b9\u6cd5\u53ef\u4ee5\u5728\u6709\u9650\u8d44\u6e90\u4e0b\u5b9e\u73b0\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u9002\u914d\u6027\u548c\u4e3b\u6743\u80fd\u529b\uff0c\u964d\u4f4e\u5bf9\u5927\u89c4\u6a21\u6570\u636e\u548c\u8ba1\u7b97\u7684\u4f9d\u8d56\u3002"}}
{"id": "2601.18162", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18162", "abs": "https://arxiv.org/abs/2601.18162", "authors": ["Ani Harutyunyan", "Sachin Kumar"], "title": "Fine-Grained Emotion Detection on GoEmotions: Experimental Comparison of Classical Machine Learning, BiLSTM, and Transformer Models", "comment": null, "summary": "Fine-grained emotion recognition is a challenging multi-label NLP task due to label overlap and class imbalance. In this work, we benchmark three modeling families on the GoEmotions dataset: a TF-IDF-based logistic regression system trained with binary relevance, a BiLSTM with attention, and a BERT model fine-tuned for multi-label classification. Experiments follow the official train/validation/test split, and imbalance is mitigated using inverse-frequency class weights. Across several metrics, namely Micro-F1, Macro-F1, Hamming Loss, and Subset Accuracy, we observe that logistic regression attains the highest Micro-F1 of 0.51, while BERT achieves the best overall balance surpassing the official paper's reported results, reaching Macro-F1 0.49, Hamming Loss 0.036, and Subset Accuracy 0.36. This suggests that frequent emotions often rely on surface lexical cues, whereas contextual representations improve performance on rarer emotions and more ambiguous examples.", "AI": {"tldr": "\u8bba\u6587\u5728GoEmotions\u6570\u636e\u96c6\u4e0a\u5bf9\u6bd4\u4e86\u4e09\u79cd\u7ec6\u7c92\u5ea6\u60c5\u611f\u8bc6\u522b\u6a21\u578b\uff1a\u57fa\u4e8eTF-IDF\u7684\u903b\u8f91\u56de\u5f52\u3001\u5e26\u6ce8\u610f\u529b\u7684BiLSTM\u548c\u5fae\u8c03\u7684BERT\u6a21\u578b\uff0c\u53d1\u73b0\u903b\u8f91\u56de\u5f52\u5728Micro-F1\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u800cBERT\u5728\u6574\u4f53\u5e73\u8861\u6027\u4e0a\u6700\u4f18\u3002", "motivation": "\u7ec6\u7c92\u5ea6\u60c5\u611f\u8bc6\u522b\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u591a\u6807\u7b7eNLP\u4efb\u52a1\uff0c\u9762\u4e34\u6807\u7b7e\u91cd\u53e0\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u95ee\u9898\u3002\u7814\u7a76\u65e8\u5728\u6bd4\u8f83\u4e0d\u540c\u5efa\u6a21\u65b9\u6cd5\u5728GoEmotions\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u63a2\u7d22\u4e0d\u540c\u6a21\u578b\u5728\u5904\u7406\u8868\u9762\u8bcd\u6c47\u7ebf\u7d22\u4e0e\u4e0a\u4e0b\u6587\u4f9d\u8d56\u60c5\u611f\u65b9\u9762\u7684\u80fd\u529b\u5dee\u5f02\u3002", "method": "\u4f7f\u7528GoEmotions\u6570\u636e\u96c6\u7684\u5b98\u65b9\u8bad\u7ec3/\u9a8c\u8bc1/\u6d4b\u8bd5\u5212\u5206\uff0c\u91c7\u7528\u4e09\u79cd\u6a21\u578b\u67b6\u6784\uff1a1) \u57fa\u4e8eTF-IDF\u7279\u5f81\u548c\u4e8c\u5143\u76f8\u5173\u6027\u7684\u903b\u8f91\u56de\u5f52\u7cfb\u7edf\uff1b2) \u5e26\u6ce8\u610f\u529b\u7684\u53cc\u5411LSTM\uff1b3) \u4e3a\u591a\u6807\u7b7e\u5206\u7c7b\u5fae\u8c03\u7684BERT\u6a21\u578b\u3002\u4f7f\u7528\u9006\u9891\u7387\u7c7b\u522b\u6743\u91cd\u7f13\u89e3\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "\u903b\u8f91\u56de\u5f52\u83b7\u5f97\u6700\u9ad8\u7684Micro-F1\u5206\u65700.51\uff0c\u800cBERT\u5728\u6574\u4f53\u5e73\u8861\u6027\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u8fbe\u5230Macro-F1 0.49\u3001Hamming Loss 0.036\u548cSubset Accuracy 0.36\uff0c\u8d85\u8d8a\u4e86\u539f\u8bba\u6587\u62a5\u544a\u7684\u7ed3\u679c\u3002\u8fd9\u8868\u660e\u9ad8\u9891\u60c5\u611f\u5e38\u4f9d\u8d56\u8868\u9762\u8bcd\u6c47\u7ebf\u7d22\uff0c\u800c\u4e0a\u4e0b\u6587\u8868\u793a\u80fd\u63d0\u5347\u5bf9\u7a00\u6709\u60c5\u611f\u548c\u6a21\u7cca\u793a\u4f8b\u7684\u8bc6\u522b\u80fd\u529b\u3002", "conclusion": "\u4e0d\u540c\u6a21\u578b\u5728\u7ec6\u7c92\u5ea6\u60c5\u611f\u8bc6\u522b\u4efb\u52a1\u4e2d\u5404\u6709\u4f18\u52bf\uff1a\u903b\u8f91\u56de\u5f52\u5728\u6355\u6349\u9ad8\u9891\u60c5\u611f\u7684\u8868\u9762\u8bcd\u6c47\u6a21\u5f0f\u65b9\u9762\u6709\u6548\uff0c\u800cBERT\u7684\u4e0a\u4e0b\u6587\u8868\u793a\u80fd\u529b\u5728\u5904\u7406\u7a00\u6709\u60c5\u611f\u548c\u6a21\u7cca\u6848\u4f8b\u65f6\u8868\u73b0\u66f4\u4f18\u3002\u7814\u7a76\u4e3a\u591a\u6807\u7b7e\u60c5\u611f\u5206\u7c7b\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5efa\u6a21\u57fa\u51c6\u3002"}}
{"id": "2601.18204", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18204", "abs": "https://arxiv.org/abs/2601.18204", "authors": ["Juexiang Ye", "Xue Li", "Xinyu Yang", "Chengkai Huang", "Lanshun Nie", "Lina Yao", "Dechen Zhan"], "title": "MemWeaver: Weaving Hybrid Memories for Traceable Long-Horizon Agentic Reasoning", "comment": null, "summary": "Large language model-based agents operating in long-horizon interactions require memory systems that support temporal consistency, multi-hop reasoning, and evidence-grounded reuse across sessions. Existing approaches largely rely on unstructured retrieval or coarse abstractions, which often lead to temporal conflicts, brittle reasoning, and limited traceability. We propose MemWeaver, a unified memory framework that consolidates long-term agent experiences into three interconnected components: a temporally grounded graph memory for structured relational reasoning, an experience memory that abstracts recurring interaction patterns from repeated observations, and a passage memory that preserves original textual evidence. MemWeaver employs a dual-channel retrieval strategy that jointly retrieves structured knowledge and supporting evidence to construct compact yet information-dense contexts for reasoning. Experiments on the LoCoMo benchmark demonstrate that MemWeaver substantially improves multi-hop and temporal reasoning accuracy while reducing input context length by over 95\\% compared to long-context baselines.", "AI": {"tldr": "MemWeaver\u662f\u4e00\u4e2a\u7edf\u4e00\u8bb0\u5fc6\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u56fe\u8bb0\u5fc6\u3001\u7ecf\u9a8c\u8bb0\u5fc6\u548c\u6587\u672c\u8bc1\u636e\u8bb0\u5fc6\u4e09\u4e2a\u7ec4\u4ef6\uff0c\u7ed3\u5408\u53cc\u901a\u9053\u68c0\u7d22\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u957f\u671f\u4ea4\u4e92\u4e2d\u667a\u80fd\u4f53\u7684\u591a\u8df3\u63a8\u7406\u548c\u65f6\u95f4\u4e00\u81f4\u6027\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u5728\u957f\u671f\u4ea4\u4e92\u4e2d\u9762\u4e34\u8bb0\u5fc6\u7cfb\u7edf\u4e0d\u8db3\u7684\u95ee\u9898\uff1a\u975e\u7ed3\u6784\u5316\u68c0\u7d22\u6216\u7c97\u7c92\u5ea6\u62bd\u8c61\u5bfc\u81f4\u65f6\u95f4\u51b2\u7a81\u3001\u63a8\u7406\u8106\u5f31\u548c\u53ef\u8ffd\u6eaf\u6027\u6709\u9650\u3002\u9700\u8981\u652f\u6301\u65f6\u95f4\u4e00\u81f4\u6027\u3001\u591a\u8df3\u63a8\u7406\u548c\u8de8\u4f1a\u8bdd\u8bc1\u636e\u91cd\u7528\u7684\u8bb0\u5fc6\u7cfb\u7edf\u3002", "method": "\u63d0\u51faMemWeaver\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u4e92\u8054\u7ec4\u4ef6\uff1a1)\u65f6\u95f4\u57fa\u7840\u56fe\u8bb0\u5fc6\u7528\u4e8e\u7ed3\u6784\u5316\u5173\u7cfb\u63a8\u7406\uff1b2)\u7ecf\u9a8c\u8bb0\u5fc6\u4ece\u91cd\u590d\u89c2\u5bdf\u4e2d\u62bd\u8c61\u51fa\u4ea4\u4e92\u6a21\u5f0f\uff1b3)\u6bb5\u843d\u8bb0\u5fc6\u4fdd\u7559\u539f\u59cb\u6587\u672c\u8bc1\u636e\u3002\u91c7\u7528\u53cc\u901a\u9053\u68c0\u7d22\u7b56\u7565\u8054\u5408\u68c0\u7d22\u7ed3\u6784\u5316\u77e5\u8bc6\u548c\u652f\u6301\u8bc1\u636e\uff0c\u6784\u5efa\u7d27\u51d1\u4e14\u4fe1\u606f\u5bc6\u96c6\u7684\u63a8\u7406\u4e0a\u4e0b\u6587\u3002", "result": "\u5728LoCoMo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMemWeaver\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u8df3\u63a8\u7406\u548c\u65f6\u95f4\u63a8\u7406\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u76f8\u6bd4\u957f\u4e0a\u4e0b\u6587\u57fa\u7ebf\u51cf\u5c11\u4e86\u8d85\u8fc795%\u7684\u8f93\u5165\u4e0a\u4e0b\u6587\u957f\u5ea6\u3002", "conclusion": "MemWeaver\u901a\u8fc7\u7edf\u4e00\u7684\u7ed3\u6784\u5316\u8bb0\u5fc6\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u957f\u671f\u4ea4\u4e92\u667a\u80fd\u4f53\u4e2d\u7684\u8bb0\u5fc6\u6311\u6218\uff0c\u5728\u4fdd\u6301\u9ad8\u63a8\u7406\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\uff0c\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u7684\u957f\u671f\u4ea4\u4e92\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2601.18238", "categories": ["cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18238", "abs": "https://arxiv.org/abs/2601.18238", "authors": ["Tafazzul Nadeem", "Bhavik Shangari", "Manish Rai", "Gagan Raj Gupta", "Ashutosh Modi"], "title": "TechING: Towards Real World Technical Image Understanding via VLMs", "comment": "Accepted at Findings of EACL 2026, 30 Pages (9 Pages main paper + 4 pages references + 17 pages appendix)", "summary": "Professionals working in technical domain typically hand-draw (on whiteboard, paper, etc.) technical diagrams (e.g., flowcharts, block diagrams, etc.) during discussions; however, if they want to edit these later, it needs to be drawn from scratch. Modern day VLMs have made tremendous progress in image understanding but they struggle when it comes to understanding technical diagrams. One way to overcome this problem is to fine-tune on real world hand-drawn images, but it is not practically possible to generate large number of such images. In this paper, we introduce a large synthetically generated corpus (reflective of real world images) for training VLMs and subsequently evaluate VLMs on a smaller corpus of hand-drawn images (with the help of humans). We introduce several new self-supervision tasks for training and perform extensive experiments with various baseline models and fine-tune Llama 3.2 11B-instruct model on synthetic images on these tasks to obtain LLama-VL-TUG, which significantly improves the ROUGE-L performance of Llama 3.2 11B-instruct by 2.14x and achieves the best all-round performance across all baseline models. On real-world images, human evaluation reveals that we achieve minimum compilation errors across all baselines in 7 out of 8 diagram types and improve the average F1 score of Llama 3.2 11B-instruct by 6.97x.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5408\u6210\u6570\u636e\u8bad\u7ec3VLM\u7684\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u624b\u7ed8\u6280\u672f\u56fe\u8868\u7406\u89e3\u96be\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u4e13\u4e1a\u4eba\u58eb\u5728\u8ba8\u8bba\u4e2d\u5e38\u624b\u7ed8\u6280\u672f\u56fe\u8868\uff08\u5982\u6d41\u7a0b\u56fe\u3001\u6846\u56fe\u7b49\uff09\uff0c\u4f46\u8fd9\u4e9b\u56fe\u8868\u96be\u4ee5\u7f16\u8f91\u3002\u73b0\u6709VLM\u5728\u7406\u89e3\u6280\u672f\u56fe\u8868\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u6536\u96c6\u5927\u91cf\u771f\u5b9e\u624b\u7ed8\u56fe\u50cf\u8fdb\u884c\u5fae\u8c03\u53c8\u4e0d\u73b0\u5b9e\u3002", "method": "1. \u521b\u5efa\u5927\u89c4\u6a21\u5408\u6210\u6570\u636e\u96c6\uff08\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u56fe\u50cf\u7279\u5f81\uff09\uff1b2. \u5f15\u5165\u591a\u79cd\u65b0\u7684\u81ea\u76d1\u7763\u4efb\u52a1\u8fdb\u884c\u8bad\u7ec3\uff1b3. \u5728\u5408\u6210\u56fe\u50cf\u4e0a\u5bf9Llama 3.2 11B-instruct\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u5f97\u5230LLama-VL-TUG\u6a21\u578b\uff1b4. \u5728\u5c0f\u89c4\u6a21\u771f\u5b9e\u624b\u7ed8\u56fe\u50cf\u8bed\u6599\u5e93\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff08\u501f\u52a9\u4eba\u5de5\u6807\u6ce8\uff09\u3002", "result": "1. LLama-VL-TUG\u5c06Llama 3.2 11B-instruct\u7684ROUGE-L\u6027\u80fd\u63d0\u5347\u4e862.14\u500d\uff1b2. \u5728\u6240\u6709\u57fa\u7ebf\u6a21\u578b\u4e2d\u53d6\u5f97\u6700\u4f73\u7efc\u5408\u6027\u80fd\uff1b3. \u5728\u771f\u5b9e\u56fe\u50cf\u4e0a\uff0c8\u79cd\u56fe\u8868\u7c7b\u578b\u4e2d\u67097\u79cd\u5b9e\u73b0\u4e86\u6700\u4f4e\u7f16\u8bd1\u9519\u8bef\uff1b4. \u5c06Llama 3.2 11B-instruct\u7684\u5e73\u5747F1\u5206\u6570\u63d0\u5347\u4e866.97\u500d\u3002", "conclusion": "\u901a\u8fc7\u5408\u6210\u6570\u636e\u8bad\u7ec3VLM\u662f\u89e3\u51b3\u624b\u7ed8\u6280\u672f\u56fe\u8868\u7406\u89e3\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18253", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18253", "abs": "https://arxiv.org/abs/2601.18253", "authors": ["Peng Sun", "Xiangyu Zhang", "Duan Wu"], "title": "BoRP: Bootstrapped Regression Probing for Scalable and Human-Aligned LLM Evaluation", "comment": "This is a pre-print", "summary": "Accurate evaluation of user satisfaction is critical for iterative development of conversational AI. However, for open-ended assistants, traditional A/B testing lacks reliable metrics: explicit feedback is sparse, while implicit metrics are ambiguous. To bridge this gap, we introduce BoRP (Bootstrapped Regression Probing), a scalable framework for high-fidelity satisfaction evaluation. Unlike generative approaches, BoRP leverages the geometric properties of LLM latent space. It employs a polarization-index-based bootstrapping mechanism to automate rubric generation and utilizes Partial Least Squares (PLS) to map hidden states to continuous scores. Experiments on industrial datasets show that BoRP (Qwen3-8B/14B) significantly outperforms generative baselines (even Qwen3-Max) in alignment with human judgments. Furthermore, BoRP reduces inference costs by orders of magnitude, enabling full-scale monitoring and highly sensitive A/B testing via CUPED.", "AI": {"tldr": "BoRP\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u6f5c\u5728\u7a7a\u95f4\u51e0\u4f55\u7279\u6027\u7684\u53ef\u6269\u5c55\u6ee1\u610f\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u6781\u5316\u6307\u6570\u5f15\u5bfc\u7684\u81ea\u52a8\u6807\u6ce8\u751f\u6210\u548c\u504f\u6700\u5c0f\u4e8c\u4e58\u56de\u5f52\u6620\u5c04\u9690\u85cf\u72b6\u6001\u5230\u8fde\u7eed\u5206\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u751f\u6210\u5f0f\u57fa\u7ebf\u4e14\u5927\u5e45\u964d\u4f4e\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u5f00\u653e\u57df\u5bf9\u8bdd\u52a9\u624b\u7684\u6ee1\u610f\u5ea6\u8bc4\u4f30\u9762\u4e34\u6311\u6218\uff1a\u663e\u5f0f\u53cd\u9988\u7a00\u758f\uff0c\u9690\u5f0f\u6307\u6807\u6a21\u7cca\uff0c\u4f20\u7edfA/B\u6d4b\u8bd5\u7f3a\u4e4f\u53ef\u9760\u6307\u6807\u3002\u9700\u8981\u4e00\u79cd\u9ad8\u4fdd\u771f\u3001\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u652f\u6301\u8fed\u4ee3\u5f00\u53d1\u3002", "method": "\u63d0\u51faBoRP\u6846\u67b6\uff1a1\uff09\u5229\u7528LLM\u6f5c\u5728\u7a7a\u95f4\u7684\u51e0\u4f55\u7279\u6027\uff1b2\uff09\u57fa\u4e8e\u6781\u5316\u6307\u6570\u7684\u5f15\u5bfc\u673a\u5236\u81ea\u52a8\u751f\u6210\u6807\u6ce8\u89c4\u5219\uff1b3\uff09\u4f7f\u7528\u504f\u6700\u5c0f\u4e8c\u4e58\u56de\u5f52\u5c06\u9690\u85cf\u72b6\u6001\u6620\u5c04\u5230\u8fde\u7eed\u6ee1\u610f\u5ea6\u5206\u6570\u3002\u4e0d\u540c\u4e8e\u751f\u6210\u5f0f\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u66f4\u9ad8\u6548\u4e14\u6210\u672c\u66f4\u4f4e\u3002", "result": "\u5728\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cBoRP\uff08\u57fa\u4e8eQwen3-8B/14B\uff09\u5728\u4e0e\u4eba\u5224\u65ad\u7684\u4e00\u81f4\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u751f\u6210\u5f0f\u57fa\u7ebf\uff08\u5305\u62ecQwen3-Max\uff09\u3002\u540c\u65f6\uff0c\u63a8\u7406\u6210\u672c\u964d\u4f4e\u6570\u4e2a\u6570\u91cf\u7ea7\uff0c\u652f\u6301\u5168\u89c4\u6a21\u76d1\u63a7\u548c\u901a\u8fc7CUPED\u5b9e\u73b0\u9ad8\u7075\u654f\u5ea6A/B\u6d4b\u8bd5\u3002", "conclusion": "BoRP\u4e3a\u5f00\u653e\u57df\u5bf9\u8bdd\u52a9\u624b\u7684\u6ee1\u610f\u5ea6\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u4fdd\u771f\u3001\u53ef\u6269\u5c55\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u652f\u6301\u9ad8\u6548\u7684\u8fed\u4ee3\u5f00\u53d1\u548cA/B\u6d4b\u8bd5\u3002"}}
{"id": "2601.18281", "categories": ["cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.18281", "abs": "https://arxiv.org/abs/2601.18281", "authors": ["Yuhang Jia", "Pei Liu", "Haoqin Sun", "Jiaming Zhou", "Xuxin Cheng", "Cao Liu", "Ke Zeng", "Xunliang Cai", "Yong Qin"], "title": "Reflecting Twice before Speaking with Empathy: Self-Reflective Alternating Inference for Empathy-Aware End-to-End Spoken Dialogue", "comment": null, "summary": "End-to-end Spoken Language Models (SLMs) hold great potential for paralinguistic perception, and numerous studies have aimed to enhance their capabilities, particularly for empathetic dialogue. However, current approaches largely depend on rigid supervised signals, such as ground-truth response in supervised fine-tuning or preference scores in reinforcement learning. Such reliance is fundamentally limited for modeling complex empathy, as there is no single \"correct\" response and a simple numerical score cannot fully capture the nuances of emotional expression or the appropriateness of empathetic behavior. To address these limitations, we sequentially introduce EmpathyEval, a descriptive natural-language-based evaluation model for assessing empathetic quality in spoken dialogues. Building upon EmpathyEval, we propose ReEmpathy, an end-to-end SLM that enhances empathetic dialogue through a novel Empathetic Self-Reflective Alternating Inference mechanism, which interleaves spoken response generation with free-form, empathy-related reflective reasoning. Extensive experiments demonstrate that ReEmpathy substantially improves empathy-sensitive spoken dialogue by enabling reflective reasoning, offering a promising approach toward more emotionally intelligent and empathy-aware human-computer interactions.", "AI": {"tldr": "\u63d0\u51faReEmpathy\u6a21\u578b\uff0c\u901a\u8fc7\u5f15\u5165\u63cf\u8ff0\u6027\u81ea\u7136\u8bed\u8a00\u8bc4\u4f30\u6a21\u578bEmpathyEval\u548c\u81ea\u53cd\u601d\u4ea4\u66ff\u63a8\u7406\u673a\u5236\uff0c\u589e\u5f3a\u7aef\u5230\u7aef\u53e3\u8bed\u8bed\u8a00\u6a21\u578b\u5728\u5171\u60c5\u5bf9\u8bdd\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u7aef\u5230\u7aef\u53e3\u8bed\u8bed\u8a00\u6a21\u578b\u5728\u5171\u60c5\u5bf9\u8bdd\u4e2d\u4e3b\u8981\u4f9d\u8d56\u521a\u6027\u76d1\u7763\u4fe1\u53f7\uff08\u5982\u76d1\u7763\u5fae\u8c03\u4e2d\u7684\u771f\u5b9e\u54cd\u5e94\u6216\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u504f\u597d\u5206\u6570\uff09\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u5efa\u6a21\u590d\u6742\u7684\u5171\u60c5\uff0c\u56e0\u4e3a\u4e0d\u5b58\u5728\u5355\u4e00\u7684\"\u6b63\u786e\"\u54cd\u5e94\uff0c\u4e14\u7b80\u5355\u7684\u6570\u503c\u5206\u6570\u65e0\u6cd5\u6355\u6349\u60c5\u611f\u8868\u8fbe\u7684\u7ec6\u5fae\u5dee\u522b\u6216\u5171\u60c5\u884c\u4e3a\u7684\u9002\u5f53\u6027\u3002", "method": "1. \u5f15\u5165EmpathyEval\uff1a\u57fa\u4e8e\u63cf\u8ff0\u6027\u81ea\u7136\u8bed\u8a00\u7684\u8bc4\u4f30\u6a21\u578b\uff0c\u7528\u4e8e\u8bc4\u4f30\u53e3\u8bed\u5bf9\u8bdd\u4e2d\u7684\u5171\u60c5\u8d28\u91cf\uff1b2. \u63d0\u51faReEmpathy\u6a21\u578b\uff1a\u57fa\u4e8eEmpathyEval\uff0c\u91c7\u7528\u65b0\u9896\u7684\u5171\u60c5\u81ea\u53cd\u601d\u4ea4\u66ff\u63a8\u7406\u673a\u5236\uff0c\u4ea4\u66ff\u8fdb\u884c\u53e3\u8bed\u54cd\u5e94\u751f\u6210\u548c\u81ea\u7531\u5f62\u5f0f\u7684\u5171\u60c5\u76f8\u5173\u53cd\u601d\u63a8\u7406\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cReEmpathy\u901a\u8fc7\u542f\u7528\u53cd\u601d\u63a8\u7406\uff0c\u663e\u8457\u6539\u5584\u4e86\u5171\u60c5\u654f\u611f\u7684\u53e3\u8bed\u5bf9\u8bdd\uff0c\u4e3a\u5b9e\u73b0\u66f4\u5177\u60c5\u611f\u667a\u80fd\u548c\u5171\u60c5\u610f\u8bc6\u7684\u4eba\u673a\u4ea4\u4e92\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u6cd5\u3002", "conclusion": "ReEmpathy\u6a21\u578b\u901a\u8fc7\u7ed3\u5408\u63cf\u8ff0\u6027\u8bc4\u4f30\u548c\u81ea\u53cd\u601d\u63a8\u7406\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u5efa\u6a21\u590d\u6742\u5171\u60c5\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u7aef\u5230\u7aef\u53e3\u8bed\u8bed\u8a00\u6a21\u578b\u7684\u5171\u60c5\u80fd\u529b\u63d0\u5347\u63d0\u4f9b\u4e86\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18302", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18302", "abs": "https://arxiv.org/abs/2601.18302", "authors": ["Keigo Shibata", "Kazuki Yano", "Ryosuke Takahashi", "Jaesung Lee", "Wataru Ikeda", "Jun Suzuki"], "title": "Suppressing Final Layer Hidden State Jumps in Transformer Pretraining", "comment": "Accepted to the Findings of EACL 2026", "summary": "This paper discusses the internal behavior of Transformer language models. Many recent pre-trained models have been reported to exhibit only slight changes in the angular distance between the input and output hidden state vectors in the middle Transformer layers, despite a disproportionately large ``jump'' in the angular distance occurring in or around the final Transformer layer. To characterize this, we first introduce a quantitative metric for the jump strength around the final layer, and then demonstrate its prevalence across many open-weight models, as well as its amplification throughout pre-training. Assuming such jumps indicate an undesirable property, we propose the jump-suppressing regularizer (JREG) which penalizes this jump during pre-training, thereby encouraging more balanced capability usage across the middle layers. Empirical evaluations of three model sizes of Llama-based models, trained with the proposed JREG method, reveal improved task performance compared to the baseline without altering the model architecture.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86Transformer\u8bed\u8a00\u6a21\u578b\u7684\u5185\u90e8\u884c\u4e3a\uff0c\u53d1\u73b0\u8bb8\u591a\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u4e2d\u95f4\u5c42\u8f93\u5165\u8f93\u51fa\u9690\u85cf\u72b6\u6001\u5411\u91cf\u7684\u89d2\u5ea6\u8ddd\u79bb\u53d8\u5316\u5f88\u5c0f\uff0c\u4f46\u5728\u6700\u540e\u4e00\u5c42\u9644\u8fd1\u4f1a\u51fa\u73b0\u4e0d\u6210\u6bd4\u4f8b\u7684\"\u8df3\u8dc3\"\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u6291\u5236\u8fd9\u79cd\u8df3\u8dc3\u7684\u6b63\u5219\u5316\u65b9\u6cd5JREG\uff0c\u5e76\u5728Llama\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u8bb8\u591a\u9884\u8bad\u7ec3Transformer\u8bed\u8a00\u6a21\u578b\u5728\u4e2d\u95f4\u5c42\u7684\u9690\u85cf\u72b6\u6001\u53d8\u5316\u5f88\u5c0f\uff0c\u800c\u5728\u6700\u540e\u4e00\u5c42\u9644\u8fd1\u51fa\u73b0\u4e0d\u6210\u6bd4\u4f8b\u7684\"\u8df3\u8dc3\"\u73b0\u8c61\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u79cd\u8df3\u8dc3\u53ef\u80fd\u8868\u660e\u6a21\u578b\u80fd\u529b\u4f7f\u7528\u4e0d\u5747\u8861\uff0c\u4e2d\u95f4\u5c42\u672a\u80fd\u5145\u5206\u5229\u7528\uff0c\u800c\u8fc7\u5ea6\u4f9d\u8d56\u6700\u540e\u4e00\u5c42\uff0c\u8fd9\u53ef\u80fd\u662f\u4e00\u79cd\u4e0d\u826f\u7279\u6027\u3002", "method": "\u9996\u5148\u5f15\u5165\u91cf\u5316\u6700\u540e\u4e00\u5c42\u9644\u8fd1\u8df3\u8dc3\u5f3a\u5ea6\u7684\u5ea6\u91cf\u6307\u6807\uff0c\u5e76\u9a8c\u8bc1\u5176\u5728\u591a\u4e2a\u5f00\u6e90\u6a21\u578b\u4e2d\u7684\u666e\u904d\u6027\u3002\u7136\u540e\u63d0\u51fa\u8df3\u8dc3\u6291\u5236\u6b63\u5219\u5316\u5668(JREG)\uff0c\u5728\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u60e9\u7f5a\u8fd9\u79cd\u8df3\u8dc3\uff0c\u9f13\u52b1\u6a21\u578b\u5728\u4e2d\u95f4\u5c42\u66f4\u5747\u8861\u5730\u4f7f\u7528\u80fd\u529b\u3002\u5728\u4e09\u79cd\u4e0d\u540c\u89c4\u6a21\u7684Llama\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "JREG\u65b9\u6cd5\u5728\u591a\u4e2aLlama\u6a21\u578b\u89c4\u6a21\u4e0a\u90fd\u663e\u793a\u51fa\u6539\u8fdb\u7684\u4efb\u52a1\u6027\u80fd\uff0c\u4e14\u4e0d\u6539\u53d8\u6a21\u578b\u67b6\u6784\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u6291\u5236\u6700\u540e\u4e00\u5c42\u7684\u8df3\u8dc3\u73b0\u8c61\uff0c\u4fc3\u8fdb\u6a21\u578b\u5728\u4e2d\u95f4\u5c42\u66f4\u5747\u8861\u5730\u4f7f\u7528\u80fd\u529b\u3002", "conclusion": "Transformer\u8bed\u8a00\u6a21\u578b\u5728\u6700\u540e\u4e00\u5c42\u9644\u8fd1\u5b58\u5728\u4e0d\u6210\u6bd4\u4f8b\u7684\u8df3\u8dc3\u73b0\u8c61\uff0c\u8fd9\u53ef\u80fd\u8868\u660e\u6a21\u578b\u80fd\u529b\u4f7f\u7528\u4e0d\u5747\u8861\u3002\u901a\u8fc7JREG\u6b63\u5219\u5316\u65b9\u6cd5\u53ef\u4ee5\u6291\u5236\u8fd9\u79cd\u8df3\u8dc3\uff0c\u6539\u5584\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u4f18\u5316Transformer\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.18306", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18306", "abs": "https://arxiv.org/abs/2601.18306", "authors": ["Everlyn Asiko Chimoto", "Mostafa Elhoushi", "Bruce A. Bassett"], "title": "Calibrating Beyond English: Language Diversity for Better Quantized Multilingual LLM", "comment": "Accepted to EACL 2026 Main Conference", "summary": "Quantization is an effective technique for reducing the storage footprint and computational costs of Large Language Models (LLMs), but it often results in performance degradation. Existing post-training quantization methods typically use small, English-only calibration sets; however, their impact on multilingual models remains underexplored. We systematically evaluate eight calibration settings (five single-language and three multilingual mixes) on two quantizers (GPTQ, AWQ) on data from 10 languages. Our findings reveal a consistent trend: non-English and multilingual calibration sets significantly improve perplexity compared to English-only baselines. Specifically, we observe notable average perplexity gains across both quantizers on Llama3.1 8B and Qwen2.5 7B, with multilingual mixes achieving the largest overall reductions of up to 3.52 points in perplexity. Furthermore, our analysis indicates that tailoring calibration sets to the evaluation language yields the largest improvements for individual languages, underscoring the importance of linguistic alignment. We also identify specific failure cases where certain language-quantizer combinations degrade performance, which we trace to differences in activation range distributions across languages. These results highlight that static one-size-fits-all calibration is suboptimal and that tailoring calibration data, both in language and diversity, plays a crucial role in robustly quantizing multilingual LLMs.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u91cf\u5316\u4e2d\u6821\u51c6\u96c6\u8bed\u8a00\u9009\u62e9\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u975e\u82f1\u8bed\u548c\u591a\u8bed\u8a00\u6821\u51c6\u96c6\u76f8\u6bd4\u82f1\u8bed\u57fa\u7ebf\u80fd\u663e\u8457\u964d\u4f4e\u56f0\u60d1\u5ea6\uff0c\u8bed\u8a00\u5bf9\u9f50\u662f\u5173\u952e\u56e0\u7d20\u3002", "motivation": "\u73b0\u6709\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u5c0f\u578b\u82f1\u8bed\u6821\u51c6\u96c6\uff0c\u4f46\u5b83\u4eec\u5bf9\u591a\u8bed\u8a00\u6a21\u578b\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u91cf\u5316\u867d\u7136\u80fd\u51cf\u5c11\u5b58\u50a8\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u4f46\u5e38\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u7279\u522b\u662f\u5728\u591a\u8bed\u8a00\u573a\u666f\u4e0b\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u4e868\u79cd\u6821\u51c6\u8bbe\u7f6e\uff085\u79cd\u5355\u8bed\u8a00\u548c3\u79cd\u591a\u8bed\u8a00\u6df7\u5408\uff09\u5728\u4e24\u79cd\u91cf\u5316\u5668\uff08GPTQ\u3001AWQ\uff09\u4e0a\u7684\u8868\u73b0\uff0c\u4f7f\u7528\u6765\u81ea10\u79cd\u8bed\u8a00\u7684\u6570\u636e\uff0c\u5728Llama3.1 8B\u548cQwen2.5 7B\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u975e\u82f1\u8bed\u548c\u591a\u8bed\u8a00\u6821\u51c6\u96c6\u76f8\u6bd4\u82f1\u8bed\u57fa\u7ebf\u663e\u8457\u6539\u5584\u56f0\u60d1\u5ea6\uff0c\u591a\u8bed\u8a00\u6df7\u5408\u5b9e\u73b0\u6700\u5927\u56f0\u60d1\u5ea6\u964d\u4f4e\u8fbe3.52\u70b9\u3002\u9488\u5bf9\u8bc4\u4f30\u8bed\u8a00\u5b9a\u5236\u6821\u51c6\u96c6\u5bf9\u5355\u4e2a\u8bed\u8a00\u6539\u8fdb\u6700\u5927\u3002\u67d0\u4e9b\u8bed\u8a00-\u91cf\u5316\u5668\u7ec4\u5408\u51fa\u73b0\u6027\u80fd\u4e0b\u964d\uff0c\u5f52\u56e0\u4e8e\u4e0d\u540c\u8bed\u8a00\u95f4\u6fc0\u6d3b\u8303\u56f4\u5206\u5e03\u7684\u5dee\u5f02\u3002", "conclusion": "\u9759\u6001\u7684\"\u4e00\u5200\u5207\"\u6821\u51c6\u65b9\u6cd5\u5bf9\u591a\u8bed\u8a00LLM\u91cf\u5316\u662f\u6b21\u4f18\u7684\u3002\u5b9a\u5236\u6821\u51c6\u6570\u636e\uff08\u5305\u62ec\u8bed\u8a00\u548c\u591a\u6837\u6027\uff09\u5bf9\u7a33\u5065\u91cf\u5316\u591a\u8bed\u8a00LLM\u81f3\u5173\u91cd\u8981\uff0c\u8bed\u8a00\u5bf9\u9f50\u5728\u91cf\u5316\u6027\u80fd\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2601.18320", "categories": ["cs.CL", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2601.18320", "abs": "https://arxiv.org/abs/2601.18320", "authors": ["Jinwei Lu", "Yuanfeng Song", "Chen Zhang", "Raymond Chi-Wing Wong"], "title": "MultiVis-Agent: A Multi-Agent Framework with Logic Rules for Reliable and Comprehensive Cross-Modal Data Visualization", "comment": "Accepted to SIGMOD 2026", "summary": "Real-world visualization tasks involve complex, multi-modal requirements that extend beyond simple text-to-chart generation, requiring reference images, code examples, and iterative refinement. Current systems exhibit fundamental limitations: single-modality input, one-shot generation, and rigid workflows. While LLM-based approaches show potential for these complex requirements, they introduce reliability challenges including catastrophic failures and infinite loop susceptibility. To address this gap, we propose MultiVis-Agent, a logic rule-enhanced multi-agent framework for reliable multi-modal and multi-scenario visualization generation. Our approach introduces a four-layer logic rule framework that provides mathematical guarantees for system reliability while maintaining flexibility. Unlike traditional rule-based systems, our logic rules are mathematical constraints that guide LLM reasoning rather than replacing it. We formalize the MultiVis task spanning four scenarios from basic generation to iterative refinement, and develop MultiVis-Bench, a benchmark with over 1,000 cases for multi-modal visualization evaluation. Extensive experiments demonstrate that our approach achieves 75.63% visualization score on challenging tasks, significantly outperforming baselines (57.54-62.79%), with task completion rates of 99.58% and code execution success rates of 94.56% (vs. 74.48% and 65.10% without logic rules), successfully addressing both complexity and reliability challenges in automated visualization generation.", "AI": {"tldr": "MultiVis-Agent\uff1a\u57fa\u4e8e\u903b\u8f91\u89c4\u5219\u589e\u5f3a\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u53ef\u9760\u7684\u591a\u6a21\u6001\u591a\u573a\u666f\u53ef\u89c6\u5316\u751f\u6210\uff0c\u89e3\u51b3\u73b0\u6709\u7cfb\u7edf\u5355\u6a21\u6001\u8f93\u5165\u3001\u4e00\u6b21\u6027\u751f\u6210\u548c\u53ef\u9760\u6027\u95ee\u9898", "motivation": "\u73b0\u5b9e\u4e16\u754c\u53ef\u89c6\u5316\u4efb\u52a1\u6d89\u53ca\u590d\u6742\u591a\u6a21\u6001\u9700\u6c42\uff0c\u9700\u8981\u53c2\u8003\u56fe\u50cf\u3001\u4ee3\u7801\u793a\u4f8b\u548c\u8fed\u4ee3\u4f18\u5316\u3002\u73b0\u6709\u7cfb\u7edf\u5b58\u5728\u6839\u672c\u9650\u5236\uff1a\u5355\u6a21\u6001\u8f93\u5165\u3001\u4e00\u6b21\u6027\u751f\u6210\u548c\u50f5\u5316\u5de5\u4f5c\u6d41\u7a0b\u3002LLM\u65b9\u6cd5\u867d\u6709\u6f5c\u529b\u4f46\u5f15\u5165\u53ef\u9760\u6027\u6311\u6218\uff0c\u5305\u62ec\u707e\u96be\u6027\u6545\u969c\u548c\u65e0\u9650\u5faa\u73af\u98ce\u9669\u3002", "method": "\u63d0\u51faMultiVis-Agent\uff0c\u4e00\u4e2a\u903b\u8f91\u89c4\u5219\u589e\u5f3a\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u91c7\u7528\u56db\u5c42\u903b\u8f91\u89c4\u5219\u6846\u67b6\u4e3a\u7cfb\u7edf\u53ef\u9760\u6027\u63d0\u4f9b\u6570\u5b66\u4fdd\u8bc1\uff0c\u540c\u65f6\u4fdd\u6301\u7075\u6d3b\u6027\u3002\u903b\u8f91\u89c4\u5219\u662f\u6307\u5bfcLLM\u63a8\u7406\u7684\u6570\u5b66\u7ea6\u675f\u800c\u975e\u66ff\u4ee3\u3002\u5f62\u5f0f\u5316MultiVis\u4efb\u52a1\u6db5\u76d6\u4ece\u57fa\u7840\u751f\u6210\u5230\u8fed\u4ee3\u4f18\u5316\u7684\u56db\u4e2a\u573a\u666f\uff0c\u5e76\u5f00\u53d1\u5305\u542b1000+\u6848\u4f8b\u7684MultiVis-Bench\u57fa\u51c6\u3002", "result": "\u5728\u6311\u6218\u6027\u4efb\u52a1\u4e0a\u8fbe\u523075.63%\u7684\u53ef\u89c6\u5316\u5206\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff0857.54-62.79%\uff09\u3002\u4efb\u52a1\u5b8c\u6210\u738799.58%\uff0c\u4ee3\u7801\u6267\u884c\u6210\u529f\u738794.56%\uff08\u65e0\u903b\u8f91\u89c4\u5219\u65f6\u4e3a74.48%\u548c65.10%\uff09\u3002\u6210\u529f\u89e3\u51b3\u4e86\u81ea\u52a8\u5316\u53ef\u89c6\u5316\u751f\u6210\u7684\u590d\u6742\u6027\u548c\u53ef\u9760\u6027\u6311\u6218\u3002", "conclusion": "MultiVis-Agent\u901a\u8fc7\u903b\u8f91\u89c4\u5219\u589e\u5f3a\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u53ef\u89c6\u5316\u751f\u6210\u7684\u53ef\u9760\u6027\u548c\u590d\u6742\u6027\u6311\u6218\uff0c\u5728\u4efb\u52a1\u5b8c\u6210\u7387\u3001\u4ee3\u7801\u6267\u884c\u6210\u529f\u7387\u548c\u53ef\u89c6\u5316\u8d28\u91cf\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2601.18350", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18350", "abs": "https://arxiv.org/abs/2601.18350", "authors": ["Junyi Zou"], "title": "When Domain Pretraining Interferes with Instruction Alignment: An Empirical Study of Adapter Merging in Medical LLMs", "comment": null, "summary": "Large language models (LLMs) show strong general capability but often struggle with medical terminology precision and safety-critical instruction following. We present a case study for adapter interference in safety-critical domains using a 14B-parameter base model through a two-stage LoRA pipeline: (1) domain-adaptive pre-training (PT) to inject broad medical knowledge via continued pre-training (DAPT), and (2) supervised fine-tuning (SFT) to align the model with medical question-answering behaviors through instruction-style data. To balance instruction-following ability and domain knowledge retention, we propose Weighted Adapter Merging, linearly combining SFT and PT adapters before exporting a merged base-model checkpoint. On a held-out medical validation set (F5/F6), the merged model achieves BLEU-4 = 16.38, ROUGE-1 = 20.42, ROUGE-2 = 4.60, and ROUGE-L = 11.54 under a practical decoding configuration. We further analyze decoding sensitivity and training stability with loss curves and controlled decoding comparisons.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u672f\u8bed\u7cbe\u786e\u6027\u548c\u5b89\u5168\u5173\u952e\u6307\u4ee4\u9075\u5faa\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5LoRA\u7ba1\u9053\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a0\u6743\u9002\u914d\u5668\u5408\u5e76\u6280\u672f\u5e73\u8861\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u548c\u9886\u57df\u77e5\u8bc6\u4fdd\u7559\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5177\u5907\u5f3a\u5927\u7684\u901a\u7528\u80fd\u529b\uff0c\u4f46\u5728\u533b\u5b66\u672f\u8bed\u7cbe\u786e\u6027\u548c\u5b89\u5168\u5173\u952e\u6307\u4ee4\u9075\u5faa\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u8fd9\u5728\u533b\u7597\u7b49\u5b89\u5168\u5173\u952e\u9886\u57df\u5c24\u4e3a\u5173\u952e\uff0c\u9700\u8981\u4e13\u95e8\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u7684\u8868\u73b0\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5LoRA\u7ba1\u9053\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u9886\u57df\u81ea\u9002\u5e94\u9884\u8bad\u7ec3\uff08DAPT\uff09\u6ce8\u5165\u5e7f\u6cdb\u7684\u533b\u5b66\u77e5\u8bc6\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u4f7f\u7528\u6307\u4ee4\u5f0f\u6570\u636e\u5bf9\u9f50\u6a21\u578b\u7684\u533b\u5b66\u95ee\u7b54\u884c\u4e3a\u3002\u63d0\u51fa\u52a0\u6743\u9002\u914d\u5668\u5408\u5e76\u6280\u672f\uff0c\u5728\u5bfc\u51fa\u5408\u5e76\u7684\u57fa\u7840\u6a21\u578b\u68c0\u67e5\u70b9\u524d\u7ebf\u6027\u7ec4\u5408SFT\u548cPT\u9002\u914d\u5668\u3002", "result": "\u5728\u4fdd\u7559\u7684\u533b\u7597\u9a8c\u8bc1\u96c6\uff08F5/F6\uff09\u4e0a\uff0c\u5408\u5e76\u6a21\u578b\u5728\u5b9e\u7528\u89e3\u7801\u914d\u7f6e\u4e0b\u8fbe\u5230BLEU-4=16.38\u3001ROUGE-1=20.42\u3001ROUGE-2=4.60\u3001ROUGE-L=11.54\u3002\u8fdb\u4e00\u6b65\u901a\u8fc7\u635f\u5931\u66f2\u7ebf\u548c\u53d7\u63a7\u89e3\u7801\u6bd4\u8f83\u5206\u6790\u4e86\u89e3\u7801\u654f\u611f\u6027\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u901a\u8fc7\u4e24\u9636\u6bb5\u9002\u914d\u5668\u8bad\u7ec3\u548c\u52a0\u6743\u5408\u5e76\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u5e73\u8861\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u548c\u9886\u57df\u77e5\u8bc6\u4fdd\u7559\uff0c\u4e3a\u533b\u7597\u9886\u57df\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6280\u672f\u65b9\u6848\u3002"}}
{"id": "2601.18352", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18352", "abs": "https://arxiv.org/abs/2601.18352", "authors": ["Manjie Xu", "Isabella Yin", "Xinyi Tu", "Chi Zhang", "Yixin Zhu"], "title": "Code over Words: Overcoming Semantic Inertia via Code-Grounded Reasoning", "comment": null, "summary": "LLMs struggle with Semantic Inertia: the inability to inhibit pre-trained priors (e.g., \"Lava is Dangerous\") when dynamic, in-context rules contradict them. We probe this phenomenon using Baba Is You, where physical laws are mutable text rules, enabling precise evaluation of models' ability to override learned priors when rules change. We quantatively observe that larger models can exhibit inverse scaling: they perform worse than smaller models when natural language reasoning requires suppressing pre-trained associations (e.g., accepting \"Lava is Safe\"). Our analysis attributes this to natural language encoding, which entangles descriptive semantics and logical rules, leading to persistent hallucinations of familiar physics despite explicit contradictory rules. Here we show that representing dynamics as executable code, rather than descriptive text, reverses this trend and enables effective prior inhibition. We introduce Code-Grounded Vistas (LCV), which fine-tunes models on counterfactual pairs and identifies states with contradictory rules, thereby forcing attention to logical constraints rather than visual semantics. This training-time approach outperforms expensive inference-time search methods in both efficiency and accuracy. Our results demonstrate that representation fundamentally determines whether scaling improves or impairs contextual reasoning. This challenges the assumption that larger models are universally better, with implications for domains that require dynamic overriding of learned priors.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b58\u5728\"\u8bed\u4e49\u60ef\u6027\"\u95ee\u9898\uff0c\u96be\u4ee5\u6291\u5236\u9884\u8bad\u7ec3\u5148\u9a8c\u77e5\u8bc6\uff0c\u5f53\u4e0a\u4e0b\u6587\u89c4\u5219\u4e0e\u5148\u9a8c\u77db\u76fe\u65f6\u8868\u73b0\u66f4\u5dee\u3002\u901a\u8fc7\u5c06\u52a8\u6001\u89c4\u5219\u8868\u793a\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\u800c\u975e\u63cf\u8ff0\u6027\u6587\u672c\uff0c\u53ef\u4ee5\u9006\u8f6c\u8fd9\u4e00\u8d8b\u52bf\u5e76\u5b9e\u73b0\u6709\u6548\u7684\u5148\u9a8c\u6291\u5236\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u7684\"\u8bed\u4e49\u60ef\u6027\"\u95ee\u9898\uff0c\u5373\u6a21\u578b\u96be\u4ee5\u6291\u5236\u9884\u8bad\u7ec3\u5148\u9a8c\u77e5\u8bc6\uff08\u5982\"\u5ca9\u6d46\u662f\u5371\u9669\u7684\"\uff09\uff0c\u5f53\u52a8\u6001\u4e0a\u4e0b\u6587\u89c4\u5219\u4e0e\u8fd9\u4e9b\u5148\u9a8c\u77db\u76fe\u65f6\u3002\u8fd9\u79cd\u73b0\u8c61\u5728\u9700\u8981\u52a8\u6001\u8986\u76d6\u5b66\u4e60\u5148\u9a8c\u7684\u9886\u57df\u4e2d\u5c24\u4e3a\u91cd\u8981\u3002", "method": "\u4f7f\u7528Baba Is You\u6e38\u620f\u4f5c\u4e3a\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5176\u4e2d\u7269\u7406\u89c4\u5219\u662f\u53ef\u53d8\u7684\u6587\u672c\u89c4\u5219\u3002\u63d0\u51faCode-Grounded Vistas (LCV)\u65b9\u6cd5\uff0c\u5c06\u52a8\u6001\u89c4\u5219\u8868\u793a\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\u800c\u975e\u63cf\u8ff0\u6027\u6587\u672c\uff0c\u901a\u8fc7\u5fae\u8c03\u6a21\u578b\u5904\u7406\u53cd\u4e8b\u5b9e\u5bf9\uff0c\u5e76\u8bc6\u522b\u5177\u6709\u77db\u76fe\u89c4\u5219\u7684\u72b6\u6001\uff0c\u5f3a\u5236\u6a21\u578b\u5173\u6ce8\u903b\u8f91\u7ea6\u675f\u800c\u975e\u89c6\u89c9\u8bed\u4e49\u3002", "result": "\u53d1\u73b0\u5927\u578b\u6a21\u578b\u53ef\u80fd\u8868\u73b0\u51fa\u9006\u7f29\u653e\u73b0\u8c61\uff1a\u5f53\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u9700\u8981\u6291\u5236\u9884\u8bad\u7ec3\u5173\u8054\u65f6\uff0c\u66f4\u5927\u6a21\u578b\u7684\u8868\u73b0\u53cd\u800c\u6bd4\u5c0f\u6a21\u578b\u66f4\u5dee\u3002\u5c06\u52a8\u6001\u8868\u793a\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\u53ef\u4ee5\u9006\u8f6c\u8fd9\u4e00\u8d8b\u52bf\uff0c\u4f7f\u7f29\u653e\u80fd\u591f\u6539\u5584\u4e0a\u4e0b\u6587\u63a8\u7406\u3002LCV\u65b9\u6cd5\u5728\u6548\u7387\u548c\u51c6\u786e\u6027\u4e0a\u90fd\u4f18\u4e8e\u6602\u8d35\u7684\u63a8\u7406\u65f6\u641c\u7d22\u65b9\u6cd5\u3002", "conclusion": "\u8868\u793a\u5f62\u5f0f\u4ece\u6839\u672c\u4e0a\u51b3\u5b9a\u4e86\u7f29\u653e\u662f\u6539\u5584\u8fd8\u662f\u635f\u5bb3\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\u3002\u8fd9\u6311\u6218\u4e86\"\u66f4\u5927\u6a21\u578b\u603b\u662f\u66f4\u597d\"\u7684\u5047\u8bbe\uff0c\u5bf9\u9700\u8981\u52a8\u6001\u8986\u76d6\u5b66\u4e60\u5148\u9a8c\u7684\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u901a\u8fc7\u5c06\u89c4\u5219\u7f16\u7801\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u8bed\u4e49\u60ef\u6027\u95ee\u9898\u3002"}}
{"id": "2601.18375", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18375", "abs": "https://arxiv.org/abs/2601.18375", "authors": ["Jonas Golde", "Nicolaas Jedema", "Ravi Krishnan", "Phong Le"], "title": "Hierarchical Text Classification with LLM-Refined Taxonomies", "comment": null, "summary": "Hierarchical text classification (HTC) depends on taxonomies that organize labels into structured hierarchies. However, many real-world taxonomies introduce ambiguities, such as identical leaf names under similar parent nodes, which prevent language models (LMs) from learning clear decision boundaries. In this paper, we present TaxMorph, a framework that uses large language models (LLMs) to transform entire taxonomies through operations such as renaming, merging, splitting, and reordering. Unlike prior work, our method revises the full hierarchy to better match the semantics encoded by LMs. Experiments across three HTC benchmarks show that LLM-refined taxonomies consistently outperform human-curated ones in various settings up to +2.9pp. in F1. To better understand these improvements, we compare how well LMs can assign leaf nodes to parent nodes and vice versa across human-curated and LLM-refined taxonomies. We find that human-curated taxonomies lead to more easily separable clusters in embedding space. However, the LLM-refined taxonomies align more closely with the model's actual confusion patterns during classification. In other words, even though they are harder to separate, they better reflect the model's inductive biases. These findings suggest that LLM-guided refinement creates taxonomies that are more compatible with how models learn, improving HTC performance.", "AI": {"tldr": "TaxMorph\uff1a\u4f7f\u7528LLMs\u91cd\u6784\u5206\u7c7b\u5b66\u5c42\u6b21\u7ed3\u6784\u4ee5\u63d0\u5347\u5c42\u6b21\u6587\u672c\u5206\u7c7b\u6027\u80fd\u7684\u6846\u67b6", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5206\u7c7b\u5b66\u5b58\u5728\u6a21\u7cca\u6027\uff08\u5982\u76f8\u4f3c\u7236\u8282\u70b9\u4e0b\u7684\u76f8\u540c\u53f6\u8282\u70b9\u540d\u79f0\uff09\uff0c\u8fd9\u963b\u788d\u4e86\u8bed\u8a00\u6a21\u578b\u5b66\u4e60\u6e05\u6670\u7684\u51b3\u7b56\u8fb9\u754c\uff0c\u9700\u8981\u6539\u8fdb\u5206\u7c7b\u5b66\u7ed3\u6784\u4ee5\u66f4\u597d\u5730\u5339\u914d\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u7f16\u7801", "method": "\u63d0\u51faTaxMorph\u6846\u67b6\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u91cd\u547d\u540d\u3001\u5408\u5e76\u3001\u62c6\u5206\u548c\u91cd\u65b0\u6392\u5e8f\u7b49\u64cd\u4f5c\u91cd\u6784\u6574\u4e2a\u5206\u7c7b\u5b66\u5c42\u6b21\u7ed3\u6784\uff0c\u4f7f\u5206\u7c7b\u5b66\u66f4\u597d\u5730\u4e0e\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u7f16\u7801\u5bf9\u9f50", "result": "\u5728\u4e09\u4e2aHTC\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLLM\u4f18\u5316\u7684\u5206\u7c7b\u5b66\u5728\u5404\u79cd\u8bbe\u7f6e\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u4eba\u5de5\u7b56\u5212\u7684\u5206\u7c7b\u5b66\uff0cF1\u5206\u6570\u6700\u9ad8\u63d0\u5347+2.9\u4e2a\u767e\u5206\u70b9\u3002\u5206\u6790\u53d1\u73b0\uff0c\u867d\u7136\u4eba\u5de5\u5206\u7c7b\u5b66\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u5f62\u6210\u66f4\u6613\u5206\u79bb\u7684\u7c07\uff0c\u4f46LLM\u4f18\u5316\u7684\u5206\u7c7b\u5b66\u66f4\u8d34\u8fd1\u6a21\u578b\u5728\u5206\u7c7b\u8fc7\u7a0b\u4e2d\u7684\u5b9e\u9645\u6df7\u6dc6\u6a21\u5f0f", "conclusion": "LLM\u5f15\u5bfc\u7684\u5206\u7c7b\u5b66\u4f18\u5316\u80fd\u591f\u521b\u5efa\u66f4\u7b26\u5408\u6a21\u578b\u5b66\u4e60\u65b9\u5f0f\u7684\u5206\u7c7b\u5b66\u7ed3\u6784\uff0c\u901a\u8fc7\u66f4\u597d\u5730\u53cd\u6620\u6a21\u578b\u7684\u5f52\u7eb3\u504f\u5dee\u6765\u63d0\u5347\u5c42\u6b21\u6587\u672c\u5206\u7c7b\u6027\u80fd\uff0c\u8fd9\u8868\u660e\u5206\u7c7b\u5b66\u8bbe\u8ba1\u5e94\u8003\u8651\u4e0e\u6a21\u578b\u5b66\u4e60\u673a\u5236\u7684\u517c\u5bb9\u6027"}}
{"id": "2601.18395", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18395", "abs": "https://arxiv.org/abs/2601.18395", "authors": ["Mikel Zubillaga", "Oscar Sainz", "Oier Lopez de Lacalle", "Eneko Agirre"], "title": "Do not be greedy, Think Twice: Sampling and Selection for Document-level Information Extraction", "comment": "Submitted to IJCAI-ECAI 2026", "summary": "Document-level Information Extraction (DocIE) aims to produce an output template with the entities and relations of interest occurring in the given document. Standard practices include prompting decoder-only LLMs using greedy decoding to avoid output variability. Rather than treating this variability as a limitation, we show that sampling can produce substantially better solutions than greedy decoding, especially when using reasoning models. We thus propose ThinkTwice, a sampling and selection framework in which the LLM generates multiple candidate templates for a given document, and a selection module chooses the most suitable one. We introduce both an unsupervised method that exploits agreement across generated outputs, and a supervised selection method using reward models trained on labeled DocIE data. To address the scarcity of golden reasoning trajectories for DocIE, we propose a rejection-sampling-based method to generate silver training data that pairs output templates with reasoning traces. Our experiments show the validity of unsupervised and supervised ThinkTwice, consistently outperforming greedy baselines and the state-of-the-art.", "AI": {"tldr": "ThinkTwice\u6846\u67b6\u901a\u8fc7\u91c7\u6837\u751f\u6210\u591a\u4e2a\u5019\u9009\u6a21\u677f\u5e76\u4f7f\u7528\u9009\u62e9\u6a21\u5757\u9009\u53d6\u6700\u4f73\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u6587\u6863\u7ea7\u4fe1\u606f\u62bd\u53d6\u6027\u80fd\uff0c\u8d85\u8d8a\u8d2a\u5a6a\u89e3\u7801\u65b9\u6cd5", "motivation": "\u4f20\u7edf\u6587\u6863\u7ea7\u4fe1\u606f\u62bd\u53d6\u4f7f\u7528\u8d2a\u5a6a\u89e3\u7801\u4ee5\u907f\u514d\u8f93\u51fa\u53d8\u5f02\u6027\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u79cd\u53d8\u5f02\u6027\u53ef\u4ee5\u88ab\u5229\u7528\u6765\u83b7\u5f97\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u4f7f\u7528\u63a8\u7406\u6a21\u578b\u65f6", "method": "\u63d0\u51faThinkTwice\u6846\u67b6\uff1a1) LLM\u4e3a\u7ed9\u5b9a\u6587\u6863\u751f\u6210\u591a\u4e2a\u5019\u9009\u6a21\u677f\uff1b2) \u9009\u62e9\u6a21\u5757\u9009\u53d6\u6700\u5408\u9002\u7684\u6a21\u677f\u3002\u5305\u542b\u65e0\u76d1\u7763\u65b9\u6cd5\uff08\u5229\u7528\u751f\u6210\u8f93\u51fa\u95f4\u7684\u4e00\u81f4\u6027\uff09\u548c\u76d1\u7763\u65b9\u6cd5\uff08\u4f7f\u7528\u5728\u6807\u6ce8\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u5956\u52b1\u6a21\u578b\uff09\u3002\u4e3a\u89e3\u51b3DocIE\u4e2d\u9ec4\u91d1\u63a8\u7406\u8f68\u8ff9\u7a00\u7f3a\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u62d2\u7edd\u91c7\u6837\u7684\u65b9\u6cd5\u751f\u6210\u5305\u542b\u8f93\u51fa\u6a21\u677f\u548c\u63a8\u7406\u8f68\u8ff9\u7684\u94f6\u8bad\u7ec3\u6570\u636e", "result": "\u5b9e\u9a8c\u8bc1\u660e\u65e0\u76d1\u7763\u548c\u76d1\u7763ThinkTwice\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e00\u81f4\u4f18\u4e8e\u8d2a\u5a6a\u57fa\u7ebf\u548c\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5", "conclusion": "\u91c7\u6837\u65b9\u6cd5\u80fd\u591f\u4ea7\u751f\u6bd4\u8d2a\u5a6a\u89e3\u7801\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\uff0cThinkTwice\u6846\u67b6\u901a\u8fc7\u5229\u7528\u8f93\u51fa\u53d8\u5f02\u6027\u663e\u8457\u63d0\u5347\u4e86\u6587\u6863\u7ea7\u4fe1\u606f\u62bd\u53d6\u7684\u6027\u80fd"}}
{"id": "2601.18415", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.18415", "abs": "https://arxiv.org/abs/2601.18415", "authors": ["Ivan Bondarenko", "Daniil Grebenkin", "Oleg Sedukhin", "Mikhail Klementev", "Roman Derunets", "Lyudmila Budneva"], "title": "Pisets: A Robust Speech Recognition System for Lectures and Interviews", "comment": null, "summary": "This work presents a speech-to-text system \"Pisets\" for scientists and journalists which is based on a three-component architecture aimed at improving speech recognition accuracy while minimizing errors and hallucinations associated with the Whisper model. The architecture comprises primary recognition using Wav2Vec2, false positive filtering via the Audio Spectrogram Transformer (AST), and final speech recognition through Whisper. The implementation of curriculum learning methods and the utilization of diverse Russian-language speech corpora significantly enhanced the system's effectiveness. Additionally, advanced uncertainty modeling techniques were introduced, contributing to further improvements in transcription quality. The proposed approaches ensure robust transcribing of long audio data across various acoustic conditions compared to WhisperX and the usual Whisper model. The source code of \"Pisets\" system is publicly available at GitHub: https://github.com/bond005/pisets.", "code_url": "https://github.com/bond005/pisets", "code_stars": 73, "code_last_update": "2024-11-30", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e09\u7ec4\u4ef6\u67b6\u6784\u7684\u8bed\u97f3\u8f6c\u6587\u672c\u7cfb\u7edf\"Pisets\"\uff0c\u901a\u8fc7Wav2Vec2\u3001AST\u548cWhisper\u7684\u7ec4\u5408\u63d0\u5347\u4fc4\u8bed\u8bed\u97f3\u8bc6\u522b\u7cbe\u5ea6\uff0c\u51cf\u5c11\u5e7b\u89c9\u9519\u8bef\uff0c\u4f18\u4e8eWhisperX\u548c\u6807\u51c6Whisper\u6a21\u578b", "motivation": "\u89e3\u51b3Whisper\u6a21\u578b\u5728\u8bed\u97f3\u8bc6\u522b\u4e2d\u5b58\u5728\u7684\u9519\u8bef\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u7279\u522b\u662f\u9488\u5bf9\u4fc4\u8bed\u79d1\u5b66\u548c\u65b0\u95fb\u9886\u57df\u7684\u957f\u97f3\u9891\u8f6c\u5f55\u9700\u6c42\uff0c\u63d0\u9ad8\u5728\u4e0d\u540c\u58f0\u5b66\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027", "method": "\u91c7\u7528\u4e09\u7ec4\u4ef6\u67b6\u6784\uff1a1) Wav2Vec2\u8fdb\u884c\u521d\u6b65\u8bc6\u522b\uff1b2) Audio Spectrogram Transformer (AST)\u8fdb\u884c\u8bef\u62a5\u8fc7\u6ee4\uff1b3) Whisper\u8fdb\u884c\u6700\u7ec8\u8bed\u97f3\u8bc6\u522b\u3002\u7ed3\u5408\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6cd5\u548c\u591a\u6837\u5316\u7684\u4fc4\u8bed\u8bed\u97f3\u8bed\u6599\u5e93\uff0c\u5f15\u5165\u5148\u8fdb\u7684\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u6280\u672f", "result": "\u7cfb\u7edf\u5728\u957f\u97f3\u9891\u6570\u636e\u8f6c\u5f55\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u76f8\u6bd4WhisperX\u548c\u6807\u51c6Whisper\u6a21\u578b\uff0c\u5728\u5404\u79cd\u58f0\u5b66\u6761\u4ef6\u4e0b\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\uff0c\u51cf\u5c11\u4e86\u9519\u8bef\u548c\u5e7b\u89c9\u73b0\u8c61", "conclusion": "\u63d0\u51fa\u7684\u4e09\u7ec4\u4ef6\u67b6\u6784\u7ed3\u5408\u8bfe\u7a0b\u5b66\u4e60\u548c\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4fc4\u8bed\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u4e3a\u79d1\u5b66\u5bb6\u548c\u8bb0\u8005\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u7684\u8bed\u97f3\u8f6c\u6587\u672c\u5de5\u5177\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90"}}
{"id": "2601.18468", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18468", "abs": "https://arxiv.org/abs/2601.18468", "authors": ["Daniel B. Hier", "Tayo Obafemi-Ajayi"], "title": "Latent Knowledge as a Predictor of Fact Acquisition in Fine-Tuned Large Language Models", "comment": null, "summary": "Large language models store biomedical facts with uneven strength after pretraining: some facts are present in the weights but are not reliably accessible under deterministic decoding (latent knowledge), while others are scarcely represented. We fine tuned Llama 3.1 8B Instruct to learn ontology term identifier mappings from the Human Phenotype Ontology (800 pairs) and the Gene Ontology (400 training pairs), withholding 400 GO pairs to test generalization. Treating learning as a time to event process across 20 epochs, we used stochastic decoding to detect latent knowledge at baseline and Cox proportional hazards models to identify predictors of acquisition, generalization, and degradation. Baseline deterministic recall for HPO was 2.8%, rising to 71.9% after fine-tuning. Latent knowledge was the strongest predictor of faster fact acquisition (HR 2.6) and was associated with earlier, higher peak learning rates and faster convergence; identifier frequency and curated annotation counts had smaller effects. Generalization to withheld GO facts was uncommon (5.8%) but more likely when latent knowledge was present. Previously correct GO mappings degraded more often for withheld (unseen) terms than for trained (seen) terms, suggesting a protective effect of reinforcement during training. These results show that latent knowledge predicts both the speed of factual learning during fine-tuning and the limited generalization of unseen ontology facts, while resistance to degradation depends on whether facts are reinforced.", "AI": {"tldr": "\u7814\u7a76\u663e\u793a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9884\u8bad\u7ec3\u540e\u5b58\u50a8\u751f\u7269\u533b\u5b66\u4e8b\u5b9e\u7684\u5f3a\u5ea6\u4e0d\u5747\uff0c\u901a\u8fc7\u5fae\u8c03Llama 3.1 8B\u5b66\u4e60\u672c\u4f53\u672f\u8bed\u6620\u5c04\uff0c\u53d1\u73b0\u6f5c\u5728\u77e5\u8bc6\u662f\u4e8b\u5b9e\u83b7\u53d6\u901f\u5ea6\u548c\u6709\u9650\u6cdb\u5316\u7684\u6700\u5f3a\u9884\u6d4b\u56e0\u5b50", "motivation": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9884\u8bad\u7ec3\u540e\u5b58\u50a8\u751f\u7269\u533b\u5b66\u4e8b\u5b9e\u7684\u4e0d\u5747\u5300\u6027\uff0c\u63a2\u7d22\u6f5c\u5728\u77e5\u8bc6\u5bf9\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u4e8b\u5b9e\u83b7\u53d6\u3001\u6cdb\u5316\u548c\u9000\u5316\u7684\u5f71\u54cd\u673a\u5236", "method": "\u5fae\u8c03Llama 3.1 8B Instruct\u6a21\u578b\u5b66\u4e60\u4eba\u7c7b\u8868\u578b\u672c\u4f53(800\u5bf9)\u548c\u57fa\u56e0\u672c\u4f53(400\u8bad\u7ec3\u5bf9)\u7684\u672f\u8bed\u6807\u8bc6\u7b26\u6620\u5c04\uff0c\u4fdd\u7559400\u4e2aGO\u5bf9\u6d4b\u8bd5\u6cdb\u5316\u80fd\u529b\uff1b\u5c06\u5b66\u4e60\u89c6\u4e3a\u65f6\u95f4\u4e8b\u4ef6\u8fc7\u7a0b\uff0c\u4f7f\u7528\u968f\u673a\u89e3\u7801\u68c0\u6d4b\u57fa\u7ebf\u6f5c\u5728\u77e5\u8bc6\uff0c\u5e94\u7528Cox\u6bd4\u4f8b\u98ce\u9669\u6a21\u578b\u8bc6\u522b\u83b7\u53d6\u3001\u6cdb\u5316\u548c\u9000\u5316\u7684\u9884\u6d4b\u56e0\u5b50", "result": "HPO\u7684\u57fa\u7ebf\u786e\u5b9a\u6027\u53ec\u56de\u7387\u4e3a2.8%\uff0c\u5fae\u8c03\u540e\u63d0\u5347\u81f371.9%\uff1b\u6f5c\u5728\u77e5\u8bc6\u662f\u4e8b\u5b9e\u83b7\u53d6\u901f\u5ea6\u7684\u6700\u5f3a\u9884\u6d4b\u56e0\u5b50(HR 2.6)\uff0c\u4e0e\u66f4\u65e9\u3001\u66f4\u9ad8\u7684\u5cf0\u503c\u5b66\u4e60\u7387\u548c\u66f4\u5feb\u6536\u655b\u76f8\u5173\uff1b\u6cdb\u5316\u5230\u4fdd\u7559GO\u4e8b\u5b9e\u7684\u60c5\u51b5\u8f83\u5c11(5.8%)\uff0c\u4f46\u6f5c\u5728\u77e5\u8bc6\u5b58\u5728\u65f6\u66f4\u53ef\u80fd\u53d1\u751f\uff1b\u672a\u89c1\u8fc7\u672f\u8bed\u7684\u6b63\u786e\u6620\u5c04\u6bd4\u8bad\u7ec3\u8fc7\u672f\u8bed\u66f4\u5bb9\u6613\u9000\u5316", "conclusion": "\u6f5c\u5728\u77e5\u8bc6\u9884\u6d4b\u5fae\u8c03\u671f\u95f4\u4e8b\u5b9e\u5b66\u4e60\u7684\u901f\u5ea6\u548c\u672a\u89c1\u672c\u4f53\u4e8b\u5b9e\u7684\u6709\u9650\u6cdb\u5316\uff0c\u800c\u62b5\u6297\u9000\u5316\u53d6\u51b3\u4e8e\u4e8b\u5b9e\u662f\u5426\u5728\u8bad\u7ec3\u4e2d\u5f97\u5230\u5f3a\u5316"}}
{"id": "2601.18483", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18483", "abs": "https://arxiv.org/abs/2601.18483", "authors": ["Arya Labroo", "Ivaxi Sheth", "Vyas Raina", "Amaani Ahmed", "Mario Fritz"], "title": "Funny or Persuasive, but Not Both: Evaluating Fine-Grained Multi-Concept Control in LLMs", "comment": "Accepted for publication at EACL main conference", "summary": "Large Language Models (LLMs) offer strong generative capabilities, but many applications require explicit and \\textit{fine-grained} control over specific textual concepts, such as humor, persuasiveness, or formality. Prior approaches in prompting and representation engineering can provide coarse or single-attribute control, but systematic evaluation of multi-attribute settings remains limited. We introduce an evaluation framework for fine-grained controllability for both single- and dual-concept scenarios, focusing on linguistically distinct concept pairs (e.g., persuasiveness vs.~humor). Surprisingly, across multiple LLMs and generative tasks, we find that performance often drops in the dual-concept setting, even though the chosen concepts should in principle be separable. This reveals a fundamental limitation of naive prompting-based control: models struggle with compositionality even when concepts are intuitively independent. Our framework provides systematic evidence of this gap and offers a principled approach for measuring the ability of future methods for multi-concept control.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u8bc4\u4f30\u6846\u67b6\uff0c\u53d1\u73b0LLMs\u5728\u591a\u6982\u5ff5\u63a7\u5236\u4e2d\u8868\u73b0\u4e0b\u964d\uff0c\u63ed\u793a\u57fa\u4e8e\u63d0\u793a\u7684\u63a7\u5236\u7684\u7ec4\u5408\u6027\u9650\u5236", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u6709\u5f3a\u5927\u7684\u751f\u6210\u80fd\u529b\uff0c\u4f46\u8bb8\u591a\u5e94\u7528\u9700\u8981\u5bf9\u7279\u5b9a\u6587\u672c\u6982\u5ff5\uff08\u5982\u5e7d\u9ed8\u3001\u8bf4\u670d\u529b\u3001\u6b63\u5f0f\u6027\uff09\u8fdb\u884c\u7cbe\u7ec6\u63a7\u5236\u3002\u73b0\u6709\u65b9\u6cd5\u53ea\u80fd\u63d0\u4f9b\u7c97\u7565\u6216\u5355\u5c5e\u6027\u63a7\u5236\uff0c\u7f3a\u4e4f\u5bf9\u591a\u5c5e\u6027\u8bbe\u7f6e\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5355\u6982\u5ff5\u548c\u53cc\u6982\u5ff5\u573a\u666f\u4e0b\u7684\u7cbe\u7ec6\u53ef\u63a7\u6027\uff0c\u91cd\u70b9\u5173\u6ce8\u8bed\u8a00\u5b66\u4e0a\u4e0d\u540c\u7684\u6982\u5ff5\u5bf9\uff08\u5982\u8bf4\u670d\u529bvs\u5e7d\u9ed8\uff09\u3002", "result": "\u5728\u591a\u4e2aLLM\u548c\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u53cc\u6982\u5ff5\u8bbe\u7f6e\u4e0b\u7684\u6027\u80fd\u901a\u5e38\u4f1a\u4e0b\u964d\uff0c\u5373\u4f7f\u6240\u9009\u6982\u5ff5\u5728\u539f\u5219\u4e0a\u662f\u53ef\u5206\u79bb\u7684\u3002\u8fd9\u63ed\u793a\u4e86\u57fa\u4e8e\u63d0\u793a\u7684\u6734\u7d20\u63a7\u5236\u7684\u57fa\u672c\u9650\u5236\uff1a\u5373\u4f7f\u6982\u5ff5\u5728\u76f4\u89c9\u4e0a\u662f\u72ec\u7acb\u7684\uff0c\u6a21\u578b\u4e5f\u96be\u4ee5\u5904\u7406\u7ec4\u5408\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u591a\u6982\u5ff5\u63a7\u5236\u80fd\u529b\u7684\u7cfb\u7edf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u57fa\u4e8e\u63d0\u793a\u7684\u63a7\u5236\u65b9\u6cd5\u5728\u7ec4\u5408\u6027\u65b9\u9762\u7684\u6839\u672c\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u6539\u8fdb\u65b9\u6cd5\u63d0\u4f9b\u4e86\u57fa\u51c6\u3002"}}
{"id": "2601.18486", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.18486", "abs": "https://arxiv.org/abs/2601.18486", "authors": ["Manuel Tonneau", "Neil K. R. Seghal", "Niyati Malhotra", "Victor Orozco-Olvera", "Ana Mar\u00eda Mu\u00f1oz Boudet", "Lakshmi Subramanian", "Sharath Chandra Guntuku", "Valentin Hofmann"], "title": "Demographic Probing of Large Language Models Lacks Construct Validity", "comment": null, "summary": "Demographic probing is widely used to study how large language models (LLMs) adapt their behavior to signaled demographic attributes. This approach typically uses a single demographic cue in isolation (e.g., a name or dialect) as a signal for group membership, implicitly assuming strong construct validity: that such cues are interchangeable operationalizations of the same underlying, demographically conditioned behavior. We test this assumption in realistic advice-seeking interactions, focusing on race and gender in a U.S. context. We find that cues intended to represent the same demographic group induce only partially overlapping changes in model behavior, while differentiation between groups within a given cue is weak and uneven. Consequently, estimated disparities are unstable, with both magnitude and direction varying across cues. We further show that these inconsistencies partly arise from variation in how strongly cues encode demographic attributes and from linguistic confounders that independently shape model behavior. Together, our findings suggest that demographic probing lacks construct validity: it does not yield a single, stable characterization of how LLMs condition on demographic information, which may reflect a misspecified or fragmented construct. We conclude by recommending the use of multiple, ecologically valid cues and explicit control of confounders to support more defensible claims about demographic effects in LLMs.", "AI": {"tldr": "\u672c\u6587\u8d28\u7591\u4eba\u53e3\u7edf\u8ba1\u5b66\u63a2\u6d4b\u65b9\u6cd5\u7684\u5efa\u6784\u6548\u5ea6\uff0c\u53d1\u73b0\u4e0d\u540c\u4eba\u53e3\u7ebf\u7d22\uff08\u5982\u59d3\u540d\u3001\u65b9\u8a00\uff09\u5728LLMs\u4e2d\u5f15\u53d1\u4e0d\u4e00\u81f4\u7684\u884c\u4e3a\u53d8\u5316\uff0c\u5bfc\u81f4\u4f30\u8ba1\u7684\u7fa4\u4f53\u5dee\u5f02\u4e0d\u7a33\u5b9a\uff0c\u5efa\u8bae\u4f7f\u7528\u591a\u79cd\u751f\u6001\u6548\u5ea6\u9ad8\u7684\u7ebf\u7d22\u5e76\u63a7\u5236\u6df7\u6dc6\u56e0\u7d20\u3002", "motivation": "\u5f53\u524d\u4eba\u53e3\u7edf\u8ba1\u5b66\u63a2\u6d4b\u7814\u7a76\u901a\u5e38\u4f7f\u7528\u5355\u4e00\u4eba\u53e3\u7ebf\u7d22\uff08\u5982\u59d3\u540d\u6216\u65b9\u8a00\uff09\u6765\u4ee3\u8868\u7fa4\u4f53\u8eab\u4efd\uff0c\u9690\u542b\u5047\u8bbe\u8fd9\u4e9b\u7ebf\u7d22\u5177\u6709\u5f3a\u5efa\u6784\u6548\u5ea6\u2014\u2014\u5373\u5b83\u4eec\u662f\u540c\u4e00\u6f5c\u5728\u4eba\u53e3\u6761\u4ef6\u884c\u4e3a\u7684\u53ef\u4e92\u6362\u64cd\u4f5c\u5316\u3002\u672c\u6587\u65e8\u5728\u68c0\u9a8c\u8fd9\u4e00\u5047\u8bbe\u5728\u73b0\u5b9e\u5efa\u8bae\u5bfb\u6c42\u4e92\u52a8\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u5728\u73b0\u5b9e\u5efa\u8bae\u5bfb\u6c42\u4e92\u52a8\u4e2d\u6d4b\u8bd5\u4eba\u53e3\u7edf\u8ba1\u5b66\u63a2\u6d4b\u7684\u5efa\u6784\u6548\u5ea6\uff0c\u805a\u7126\u7f8e\u56fd\u8bed\u5883\u4e0b\u7684\u79cd\u65cf\u548c\u6027\u522b\u3002\u4f7f\u7528\u4e0d\u540c\u7684\u4eba\u53e3\u7ebf\u7d22\uff08\u5982\u59d3\u540d\u3001\u65b9\u8a00\u7b49\uff09\u4f5c\u4e3a\u7fa4\u4f53\u8eab\u4efd\u4fe1\u53f7\uff0c\u5206\u6790\u8fd9\u4e9b\u7ebf\u7d22\u5982\u4f55\u5f71\u54cdLLMs\u7684\u884c\u4e3a\u53d8\u5316\uff0c\u5e76\u63a2\u7a76\u4e0d\u4e00\u81f4\u6027\u7684\u6765\u6e90\u3002", "result": "1. \u610f\u56fe\u4ee3\u8868\u540c\u4e00\u4eba\u53e3\u7fa4\u4f53\u7684\u7ebf\u7d22\u4ec5\u5f15\u53d1\u90e8\u5206\u91cd\u53e0\u7684\u6a21\u578b\u884c\u4e3a\u53d8\u5316\uff1b2. \u540c\u4e00\u7ebf\u7d22\u5185\u4e0d\u540c\u7fa4\u4f53\u95f4\u7684\u533a\u5206\u5ea6\u5f31\u4e14\u4e0d\u5747\u5300\uff1b3. \u4f30\u8ba1\u7684\u7fa4\u4f53\u5dee\u5f02\u4e0d\u7a33\u5b9a\uff0c\u5176\u5927\u5c0f\u548c\u65b9\u5411\u968f\u7ebf\u7d22\u53d8\u5316\uff1b4. \u4e0d\u4e00\u81f4\u6027\u90e8\u5206\u6e90\u4e8e\u7ebf\u7d22\u7f16\u7801\u4eba\u53e3\u5c5e\u6027\u7684\u5f3a\u5ea6\u5dee\u5f02\u4ee5\u53ca\u72ec\u7acb\u5f71\u54cd\u6a21\u578b\u884c\u4e3a\u7684\u8bed\u8a00\u6df7\u6dc6\u56e0\u7d20\u3002", "conclusion": "\u4eba\u53e3\u7edf\u8ba1\u5b66\u63a2\u6d4b\u7f3a\u4e4f\u5efa\u6784\u6548\u5ea6\uff1a\u5b83\u65e0\u6cd5\u4ea7\u751f\u5173\u4e8eLLMs\u5982\u4f55\u57fa\u4e8e\u4eba\u53e3\u4fe1\u606f\u8fdb\u884c\u6761\u4ef6\u5316\u7684\u5355\u4e00\u7a33\u5b9a\u8868\u5f81\uff0c\u8fd9\u53ef\u80fd\u53cd\u6620\u4e86\u5efa\u6784\u7684\u9519\u8bef\u8bbe\u5b9a\u6216\u788e\u7247\u5316\u3002\u5efa\u8bae\u4f7f\u7528\u591a\u79cd\u751f\u6001\u6548\u5ea6\u9ad8\u7684\u7ebf\u7d22\u5e76\u660e\u786e\u63a7\u5236\u6df7\u6dc6\u56e0\u7d20\uff0c\u4ee5\u652f\u6301\u5173\u4e8eLLMs\u4e2d\u4eba\u53e3\u6548\u5e94\u7684\u66f4\u53ef\u9760\u4e3b\u5f20\u3002"}}
{"id": "2601.18512", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18512", "abs": "https://arxiv.org/abs/2601.18512", "authors": ["Antonio Garzon-Vico", "Krithika Sharon Komalapati", "Arsalan Shahid", "Jan Rosier"], "title": "Using Large Language Models to Construct Virtual Top Managers: A Method for Organizational Research", "comment": null, "summary": "This study introduces a methodological framework that uses large language models to create virtual personas of real top managers. Drawing on real CEO communications and Moral Foundations Theory, we construct LLM-based participants that simulate the decision-making of individual leaders. Across three phases, we assess construct validity, reliability, and behavioral fidelity by benchmarking these virtual CEOs against human participants. Our results indicate that theoretically scaffolded personas approximate the moral judgements observed in human samples, suggesting that LLM-based personas can serve as credible and complementary tools for organizational research in contexts where direct access to executives is limited. We conclude by outlining implications for future research using LLM-based personas in organizational settings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u521b\u5efa\u771f\u5b9e\u9ad8\u7ba1\u865a\u62df\u4eba\u683c\u7684\u65b9\u6cd5\u6846\u67b6\uff0c\u901a\u8fc7CEO\u6c9f\u901a\u6570\u636e\u548c\u9053\u5fb7\u57fa\u7840\u7406\u8bba\u6784\u5efa\u6a21\u62df\u9886\u5bfc\u8005\u51b3\u7b56\u7684LLM\u53c2\u4e0e\u8005\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u7ec4\u7ec7\u7814\u7a76\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5728\u96be\u4ee5\u76f4\u63a5\u63a5\u89e6\u9ad8\u7ba1\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6a21\u62df\u771f\u5b9e\u9886\u5bfc\u8005\u51b3\u7b56\u7684\u5de5\u5177\u6765\u652f\u6301\u7ec4\u7ec7\u7814\u7a76\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u6355\u6349\u4e2a\u4f53\u9886\u5bfc\u8005\u7279\u8d28\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u56e0\u6b64\u9700\u8981\u521b\u5efa\u53ef\u4fe1\u7684\u865a\u62df\u4eba\u683c\u6765\u8865\u5145\u4f20\u7edf\u7814\u7a76\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u771f\u5b9eCEO\u6c9f\u901a\u6570\u636e\u548c\u9053\u5fb7\u57fa\u7840\u7406\u8bba\uff0c\u6784\u5efaLLM\u9a71\u52a8\u7684\u865a\u62dfCEO\u4eba\u683c\u3002\u7814\u7a76\u5206\u4e3a\u4e09\u4e2a\u9636\u6bb5\uff1a\u7ed3\u6784\u6548\u5ea6\u8bc4\u4f30\u3001\u53ef\u9760\u6027\u6d4b\u8bd5\u548c\u884c\u4e3a\u4fdd\u771f\u5ea6\u9a8c\u8bc1\uff0c\u901a\u8fc7\u5c06\u865a\u62dfCEO\u4e0e\u4eba\u7c7b\u53c2\u4e0e\u8005\u8fdb\u884c\u57fa\u51c6\u6bd4\u8f83\u6765\u8bc4\u4f30\u5176\u6027\u80fd\u3002", "result": "\u7406\u8bba\u6846\u67b6\u652f\u6491\u7684\u865a\u62df\u4eba\u683c\u80fd\u591f\u8fd1\u4f3c\u4eba\u7c7b\u6837\u672c\u4e2d\u89c2\u5bdf\u5230\u7684\u9053\u5fb7\u5224\u65ad\uff0c\u8868\u660eLLM\u57fa\u7840\u7684\u4eba\u683c\u53ef\u4ee5\u4f5c\u4e3a\u7ec4\u7ec7\u7814\u7a76\u4e2d\u53ef\u4fe1\u4e14\u4e92\u8865\u7684\u5de5\u5177\uff0c\u7279\u522b\u662f\u5728\u96be\u4ee5\u76f4\u63a5\u63a5\u89e6\u9ad8\u7ba1\u7684\u60c5\u51b5\u4e0b\u3002", "conclusion": "LLM\u57fa\u7840\u7684\u865a\u62df\u4eba\u683c\u4e3a\u7ec4\u7ec7\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u6cd5\u8bba\u5de5\u5177\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ba1\u53ef\u53ca\u6027\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u3002\u7814\u7a76\u4e3a\u672a\u6765\u5728\u7ec4\u7ec7\u73af\u5883\u4e2d\u4f7f\u7528LLM\u4eba\u683c\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u6846\u67b6\u548c\u542f\u793a\u3002"}}
{"id": "2601.18517", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18517", "abs": "https://arxiv.org/abs/2601.18517", "authors": ["James Sungarda", "Hongkai Liu", "Zilong Zhou", "Tien-Hsuan Wu", "Johnson Chun-Sing Cheung", "Ben Kao"], "title": "GenAI for Social Work Field Education: Client Simulation with Real-Time Feedback", "comment": "2025 IEEE International Conference on Big Data. ISBN: 979-8-3315-9447-3/25. Page numbers: 3544-3553", "summary": "Field education is the signature pedagogy of social work, yet providing timely and objective feedback during training is constrained by the availability of instructors and counseling clients. In this paper, we present SWITCH, the Social Work Interactive Training Chatbot. SWITCH integrates realistic client simulation, real-time counseling skill classification, and a Motivational Interviewing (MI) progression system into the training workflow. To model a client, SWITCH uses a cognitively grounded profile comprising static fields (e.g., background, beliefs) and dynamic fields (e.g., emotions, automatic thoughts, openness), allowing the agent's behavior to evolve throughout a session realistically. The skill classification module identifies the counseling skills from the user utterances, and feeds the result to the MI controller that regulates the MI stage transitions. To enhance classification accuracy, we study in-context learning with retrieval over annotated transcripts, and a fine-tuned BERT multi-label classifier. In the experiments, we demonstrated that both BERT-based approach and in-context learning outperforms the baseline with big margin. SWITCH thereby offers a scalable, low-cost, and consistent training workflow that complements field education, and allows supervisors to focus on higher-level mentorship.", "AI": {"tldr": "SWITCH\u662f\u4e00\u4e2a\u793e\u4f1a\u5de5\u4f5c\u4ea4\u4e92\u5f0f\u57f9\u8bad\u804a\u5929\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u6a21\u62df\u771f\u5b9e\u5ba2\u6237\u3001\u5b9e\u65f6\u54a8\u8be2\u6280\u80fd\u5206\u7c7b\u548c\u52a8\u673a\u8bbf\u8c08\u8fdb\u5c55\u7cfb\u7edf\uff0c\u4e3a\u793e\u5de5\u5b66\u751f\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u4f4e\u6210\u672c\u3001\u4e00\u81f4\u7684\u57f9\u8bad\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u793e\u4f1a\u5de5\u4f5c\u5b9e\u5730\u6559\u80b2\u662f\u6838\u5fc3\u6559\u5b66\u65b9\u6cd5\uff0c\u4f46\u4f20\u7edf\u57f9\u8bad\u53d7\u9650\u4e8e\u6559\u5e08\u53ef\u7528\u6027\u548c\u54a8\u8be2\u5ba2\u6237\u8d44\u6e90\uff0c\u96be\u4ee5\u53ca\u65f6\u63d0\u4f9b\u5ba2\u89c2\u53cd\u9988\u3002\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u4f4e\u6210\u672c\u7684\u66ff\u4ee3\u65b9\u6848\u6765\u8865\u5145\u5b9e\u5730\u6559\u80b2\u3002", "method": "SWITCH\u91c7\u7528\u8ba4\u77e5\u57fa\u7840\u5ba2\u6237\u6a21\u578b\uff08\u5305\u542b\u9759\u6001\u548c\u52a8\u6001\u5b57\u6bb5\uff09\uff0c\u7ed3\u5408\u5b9e\u65f6\u54a8\u8be2\u6280\u80fd\u5206\u7c7b\u6a21\u5757\u548c\u52a8\u673a\u8bbf\u8c08\u8fdb\u5c55\u63a7\u5236\u7cfb\u7edf\u3002\u6280\u80fd\u5206\u7c7b\u91c7\u7528\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u68c0\u7d22\u5b66\u4e60\u548c\u5fae\u8c03BERT\u591a\u6807\u7b7e\u5206\u7c7b\u5668\u4e24\u79cd\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cBERT\u65b9\u6cd5\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\u90fd\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86SWITCH\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002\u7cfb\u7edf\u80fd\u591f\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u4f4e\u6210\u672c\u3001\u4e00\u81f4\u7684\u57f9\u8bad\u5de5\u4f5c\u6d41\u7a0b\u3002", "conclusion": "SWITCH\u4f5c\u4e3a\u793e\u4f1a\u5de5\u4f5c\u4ea4\u4e92\u5f0f\u57f9\u8bad\u804a\u5929\u673a\u5668\u4eba\uff0c\u80fd\u591f\u8865\u5145\u5b9e\u5730\u6559\u80b2\uff0c\u8ba9\u7763\u5bfc\u4e13\u6ce8\u4e8e\u66f4\u9ad8\u5c42\u6b21\u7684\u6307\u5bfc\uff0c\u4e3a\u793e\u5de5\u57f9\u8bad\u63d0\u4f9b\u4e86\u521b\u65b0\u7684\u6280\u672f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18527", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18527", "abs": "https://arxiv.org/abs/2601.18527", "authors": ["Francesco Maria Molfese", "Momchil Hardalov", "Rexhina Blloshmi", "Bill Byrne", "Adri\u00e0 de Gispert"], "title": "Exploring Fine-Tuning for In-Context Retrieval and Efficient KV-Caching in Long-Context Language Models", "comment": "European Chapter of the Association for Computational Linguistics EACL 2026", "summary": "With context windows of millions of tokens, Long-Context Language Models (LCLMs) can encode entire document collections, offering a strong alternative to conventional retrieval-augmented generation (RAG). However, it remains unclear whether fine-tuning strategies can improve long-context performance and translate to greater robustness under KV-cache compression techniques. In this work, we investigate which training strategies most effectively enhance LCLMs' ability to identify and use relevant information, as well as enhancing their robustness under KV-cache compression. Our experiments show substantial in-domain improvements, achieving gains of up to +20 points over the base model. However, out-of-domain generalization remains task dependent with large variance -- LCLMs excels on finance questions (+9 points), while RAG shows stronger performance on multiple-choice questions (+6 points) over the baseline models. Finally, we show that our fine-tuning approaches bring moderate improvements in robustness under KV-cache compression, with gains varying across tasks.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u957f\u4e0a\u4e0b\u6587\u8bed\u8a00\u6a21\u578b\uff08LCLMs\uff09\u7684\u5fae\u8c03\u7b56\u7565\u5982\u4f55\u63d0\u5347\u5176\u5728\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u7b56\u7565\u5bf9KV\u7f13\u5b58\u538b\u7f29\u6280\u672f\u9c81\u68d2\u6027\u7684\u5f71\u54cd\u3002", "motivation": "\u968f\u7740\u957f\u4e0a\u4e0b\u6587\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5904\u7406\u6570\u767e\u4e07token\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\uff0c\u5b83\u4eec\u53ef\u4ee5\u4f5c\u4e3a\u4f20\u7edf\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u7136\u800c\uff0c\u5c1a\u4e0d\u6e05\u695a\u5fae\u8c03\u7b56\u7565\u662f\u5426\u80fd\u63d0\u5347\u957f\u4e0a\u4e0b\u6587\u6027\u80fd\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u6539\u8fdb\u662f\u5426\u80fd\u8f6c\u5316\u4e3a\u5728KV\u7f13\u5b58\u538b\u7f29\u6280\u672f\u4e0b\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "method": "\u7814\u7a76\u8c03\u67e5\u4e86\u54ea\u4e9b\u8bad\u7ec3\u7b56\u7565\u80fd\u6700\u6709\u6548\u5730\u589e\u5f3aLCLMs\u8bc6\u522b\u548c\u4f7f\u7528\u76f8\u5173\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u4ee5\u53ca\u63d0\u5347\u5b83\u4eec\u5728KV\u7f13\u5b58\u538b\u7f29\u4e0b\u7684\u9c81\u68d2\u6027\u3002\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83\u4e0d\u540c\u5fae\u8c03\u65b9\u6cd5\u7684\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff1a1\uff09\u5728\u9886\u57df\u5185\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u6539\u8fdb\uff0c\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u63d0\u5347\u9ad8\u8fbe+20\u5206\uff1b2\uff09\u9886\u57df\u5916\u6cdb\u5316\u80fd\u529b\u56e0\u4efb\u52a1\u800c\u5f02\uff0cLCLMs\u5728\u91d1\u878d\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u5f02\uff08+9\u5206\uff09\uff0c\u800cRAG\u5728\u591a\u9879\u9009\u62e9\u9898\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff08+6\u5206\uff09\uff1b3\uff09\u5fae\u8c03\u65b9\u6cd5\u5728KV\u7f13\u5b58\u538b\u7f29\u4e0b\u5e26\u6765\u9002\u5ea6\u7684\u9c81\u68d2\u6027\u63d0\u5347\uff0c\u4f46\u589e\u76ca\u56e0\u4efb\u52a1\u800c\u5f02\u3002", "conclusion": "\u5fae\u8c03\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347LCLMs\u5728\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u9886\u57df\u5185\u4efb\u52a1\u4e0a\u3002\u7136\u800c\uff0c\u9886\u57df\u5916\u6cdb\u5316\u80fd\u529b\u5177\u6709\u4efb\u52a1\u4f9d\u8d56\u6027\uff0c\u4e14\u5fae\u8c03\u5bf9KV\u7f13\u5b58\u538b\u7f29\u9c81\u68d2\u6027\u7684\u6539\u5584\u6709\u9650\u4e14\u4e0d\u7a33\u5b9a\u3002"}}
{"id": "2601.18533", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18533", "abs": "https://arxiv.org/abs/2601.18533", "authors": ["Yuxin Jiang", "Yufei Wang", "Qiyuan Zhang", "Xingshan Zeng", "Liangyou Li", "Jierun Chen", "Chaofan Tao", "Haoli Bai", "Lifeng Shang"], "title": "From Verifiable Dot to Reward Chain: Harnessing Verifiable Reference-based Rewards for Reinforcement Learning of Open-ended Generation", "comment": "19 pages, 8 figures, 12 tables. Accepted at ICLR 2026", "summary": "Reinforcement learning with verifiable rewards (RLVR) succeeds in reasoning tasks (e.g., math and code) by checking the final verifiable answer (i.e., a verifiable dot signal). However, extending this paradigm to open-ended generation is challenging because there is no unambiguous ground truth. Relying on single-dot supervision often leads to inefficiency and reward hacking. To address these issues, we propose reinforcement learning with verifiable reference-based rewards (RLVRR). Instead of checking the final answer, RLVRR extracts an ordered linguistic signal from high-quality references (i.e, reward chain). Specifically, RLVRR decomposes rewards into two dimensions: content, which preserves deterministic core concepts (e.g., keywords), and style, which evaluates adherence to stylistic properties through LLM-based verification. In this way, RLVRR combines the exploratory strength of RL with the efficiency and reliability of supervised fine-tuning (SFT). Extensive experiments on more than 10 benchmarks with Qwen and Llama models confirm the advantages of our approach. RLVRR (1) substantially outperforms SFT trained with ten times more data and advanced reward models, (2) unifies the training of structured reasoning and open-ended generation, and (3) generalizes more effectively while preserving output diversity. These results establish RLVRR as a principled and efficient path toward verifiable reinforcement learning for general-purpose LLM alignment. We release our code and data at https://github.com/YJiangcm/RLVRR.", "code_url": "https://github.com/YJiangcm/RLVRR", "AI": {"tldr": "RLVRR\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u53c2\u8003\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u9ad8\u8d28\u91cf\u53c2\u8003\u4e2d\u63d0\u53d6\u6709\u5e8f\u8bed\u8a00\u4fe1\u53f7\uff08\u5956\u52b1\u94fe\uff09\uff0c\u5c06\u5956\u52b1\u5206\u89e3\u4e3a\u5185\u5bb9\u548c\u98ce\u683c\u4e24\u4e2a\u7ef4\u5ea6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfRLVR\u5728\u5f00\u653e\u5f0f\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLVR\uff09\u5728\u63a8\u7406\u4efb\u52a1\uff08\u5982\u6570\u5b66\u548c\u4ee3\u7801\uff09\u4e2d\u6709\u6548\uff0c\u4f46\u5728\u5f00\u653e\u5f0f\u751f\u6210\u4efb\u52a1\u4e2d\u5b58\u5728\u6311\u6218\uff0c\u56e0\u4e3a\u7f3a\u4e4f\u660e\u786e\u7684\u5730\u9762\u771f\u503c\u3002\u5355\u4e00\u76d1\u7763\u4fe1\u53f7\u5e38\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u548c\u5956\u52b1\u9ed1\u5ba2\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u7ed3\u5408RL\u63a2\u7d22\u80fd\u529b\u548c\u76d1\u7763\u5fae\u8c03\u6548\u7387\u7684\u65b9\u6cd5\u3002", "method": "RLVRR\u4ece\u9ad8\u8d28\u91cf\u53c2\u8003\u4e2d\u63d0\u53d6\u6709\u5e8f\u8bed\u8a00\u4fe1\u53f7\uff08\u5956\u52b1\u94fe\uff09\uff0c\u5c06\u5956\u52b1\u5206\u89e3\u4e3a\u4e24\u4e2a\u7ef4\u5ea6\uff1a1\uff09\u5185\u5bb9\u7ef4\u5ea6\uff1a\u4fdd\u7559\u786e\u5b9a\u6027\u6838\u5fc3\u6982\u5ff5\uff08\u5982\u5173\u952e\u8bcd\uff09\uff1b2\uff09\u98ce\u683c\u7ef4\u5ea6\uff1a\u901a\u8fc7\u57fa\u4e8eLLM\u7684\u9a8c\u8bc1\u8bc4\u4f30\u5bf9\u98ce\u683c\u5c5e\u6027\u7684\u9075\u5faa\u7a0b\u5ea6\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86RL\u7684\u63a2\u7d22\u80fd\u529b\u548c\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u7684\u6548\u7387\u4e0e\u53ef\u9760\u6027\u3002", "result": "\u5728\u8d85\u8fc710\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f7f\u7528Qwen\u548cLlama\u6a21\u578b\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\uff1a1\uff09RLVRR\u663e\u8457\u4f18\u4e8e\u4f7f\u7528\u5341\u500d\u6570\u636e\u8bad\u7ec3\u7684\u9ad8\u7ea7\u5956\u52b1\u6a21\u578b\u7684SFT\uff1b2\uff09\u7edf\u4e00\u4e86\u7ed3\u6784\u5316\u63a8\u7406\u548c\u5f00\u653e\u5f0f\u751f\u6210\u7684\u8bad\u7ec3\uff1b3\uff09\u5728\u4fdd\u6301\u8f93\u51fa\u591a\u6837\u6027\u7684\u540c\u65f6\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "RLVRR\u4e3a\u901a\u7528LLM\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u79cd\u539f\u5219\u6027\u4e14\u9ad8\u6548\u7684\u53ef\u9a8c\u8bc1\u5f3a\u5316\u5b66\u4e60\u8def\u5f84\uff0c\u901a\u8fc7\u57fa\u4e8e\u53c2\u8003\u7684\u5956\u52b1\u5206\u89e3\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f00\u653e\u5f0f\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u76d1\u7763\u4fe1\u53f7\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86RL\u63a2\u7d22\u80fd\u529b\u4e0eSFT\u6548\u7387\u7684\u5e73\u8861\u3002"}}
{"id": "2601.18536", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18536", "abs": "https://arxiv.org/abs/2601.18536", "authors": ["Abishek Stephen", "Jind\u0159ich Libovick\u00fd"], "title": "Evaluating Morphological Plausibility of Subword Tokenization via Statistical Alignment with Morpho-Syntactic Features", "comment": "Accepted to Findings of EACL 2026, 9 pages, 6 figures", "summary": "We present a novel metric for the evaluation of the morphological plausibility of subword segmentation. Unlike the typically used morpheme boundary or retrieval F-score, which requires gold segmentation data that is either unavailable or of inconsistent quality across many languages, our approach utilizes morpho-syntactic features. These are available in resources such as Universal Dependencies or UniMorph for a much wider range of languages. The metric works by probabilistically aligning subwords with morphological features through an IBM Model 1. Our experiments show that the metric correlates well with traditional morpheme boundary recall while being more broadly applicable across languages with different morphological systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5f62\u6001\u53e5\u6cd5\u7279\u5f81\u8bc4\u4f30\u5b50\u8bcd\u5207\u5206\u5f62\u6001\u5408\u7406\u6027\u7684\u65b0\u6307\u6807\uff0c\u65e0\u9700\u9ec4\u91d1\u5207\u5206\u6570\u636e\uff0c\u9002\u7528\u4e8e\u66f4\u591a\u8bed\u8a00", "motivation": "\u4f20\u7edf\u8bc4\u4f30\u6307\u6807\uff08\u5982\u8bed\u7d20\u8fb9\u754cF\u503c\uff09\u9700\u8981\u9ec4\u91d1\u5207\u5206\u6570\u636e\uff0c\u4f46\u8fd9\u7c7b\u6570\u636e\u5728\u8bb8\u591a\u8bed\u8a00\u4e2d\u4e0d\u53ef\u5f97\u6216\u8d28\u91cf\u4e0d\u4e00\u81f4\u3002\u9700\u8981\u4e00\u79cd\u66f4\u5e7f\u6cdb\u9002\u7528\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5229\u7528\u66f4\u6613\u83b7\u5f97\u7684\u5f62\u6001\u53e5\u6cd5\u7279\u5f81\u8d44\u6e90\u3002", "method": "\u5229\u7528Universal Dependencies\u6216UniMorph\u7b49\u8d44\u6e90\u4e2d\u7684\u5f62\u6001\u53e5\u6cd5\u7279\u5f81\uff0c\u901a\u8fc7IBM Model 1\u6982\u7387\u6027\u5730\u5bf9\u9f50\u5b50\u8bcd\u4e0e\u5f62\u6001\u7279\u5f81\uff0c\u4ece\u800c\u8bc4\u4f30\u5b50\u8bcd\u5207\u5206\u7684\u5f62\u6001\u5408\u7406\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6307\u6807\u4e0e\u4f20\u7edf\u8bed\u7d20\u8fb9\u754c\u53ec\u56de\u7387\u6709\u826f\u597d\u76f8\u5173\u6027\uff0c\u540c\u65f6\u5728\u4e0d\u540c\u5f62\u6001\u7cfb\u7edf\u7684\u8bed\u8a00\u4e2d\u5177\u6709\u66f4\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b0\u6307\u6807\u4e3a\u5b50\u8bcd\u5207\u5206\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u5b9e\u7528\u3001\u66f4\u5e7f\u6cdb\u9002\u7528\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u5408\u8d44\u6e90\u532e\u4e4f\u7684\u8bed\u8a00\uff0c\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u5207\u5206\u7ed3\u679c\u7684\u5f62\u6001\u5408\u7406\u6027\u3002"}}
{"id": "2601.18552", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18552", "abs": "https://arxiv.org/abs/2601.18552", "authors": ["Devansh Srivastav", "David Pape", "Lea Sch\u00f6nherr"], "title": "Unknown Unknowns: Why Hidden Intentions in LLMs Evade Detection", "comment": null, "summary": "LLMs are increasingly embedded in everyday decision-making, yet their outputs can encode subtle, unintended behaviours that shape user beliefs and actions. We refer to these covert, goal-directed behaviours as hidden intentions, which may arise from training and optimisation artefacts, or be deliberately induced by an adversarial developer, yet remain difficult to detect in practice. We introduce a taxonomy of ten categories of hidden intentions, grounded in social science research and organised by intent, mechanism, context, and impact, shifting attention from surface-level behaviours to design-level strategies of influence. We show how hidden intentions can be easily induced in controlled models, providing both testbeds for evaluation and demonstrations of potential misuse. We systematically assess detection methods, including reasoning and non-reasoning LLM judges, and find that detection collapses in realistic open-world settings, particularly under low-prevalence conditions, where false positives overwhelm precision and false negatives conceal true risks. Stress tests on precision-prevalence and precision-FNR trade-offs reveal why auditing fails without vanishingly small false positive rates or strong priors on manipulation types. Finally, a qualitative case study shows that all ten categories manifest in deployed, state-of-the-art LLMs, emphasising the urgent need for robust frameworks. Our work provides the first systematic analysis of detectability failures of hidden intentions in LLMs under open-world settings, offering a foundation for understanding, inducing, and stress-testing such behaviours, and establishing a flexible taxonomy for anticipating evolving threats and informing governance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u5206\u6790\u4e86LLM\u4e2d\u7684\"\u9690\u85cf\u610f\u56fe\"\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5341\u7c7b\u9690\u85cf\u610f\u56fe\u7684\u5206\u7c7b\u6cd5\uff0c\u5c55\u793a\u4e86\u68c0\u6d4b\u65b9\u6cd5\u5728\u5f00\u653e\u4e16\u754c\u8bbe\u7f6e\u4e2d\u7684\u5931\u6548\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8bc1\u5b9e\u4e86\u8fd9\u4e9b\u610f\u56fe\u5728\u73b0\u6709LLM\u4e2d\u7684\u5b58\u5728\u3002", "motivation": "LLM\u8d8a\u6765\u8d8a\u591a\u5730\u5d4c\u5165\u65e5\u5e38\u51b3\u7b56\uff0c\u4f46\u5176\u8f93\u51fa\u53ef\u80fd\u7f16\u7801\u5fae\u5999\u7684\u3001\u975e\u9884\u671f\u7684\u884c\u4e3a\uff0c\u8fd9\u4e9b\u884c\u4e3a\u4f1a\u5f71\u54cd\u7528\u6237\u4fe1\u5ff5\u548c\u884c\u52a8\u3002\u8fd9\u4e9b\u9690\u853d\u7684\u3001\u76ee\u6807\u5bfc\u5411\u7684\u884c\u4e3a\u88ab\u79f0\u4e3a\"\u9690\u85cf\u610f\u56fe\"\uff0c\u53ef\u80fd\u6e90\u4e8e\u8bad\u7ec3\u548c\u4f18\u5316\u4f2a\u5f71\uff0c\u6216\u88ab\u5bf9\u6297\u6027\u5f00\u53d1\u8005\u6545\u610f\u8bf1\u5bfc\uff0c\u4f46\u5728\u5b9e\u8df5\u4e2d\u96be\u4ee5\u68c0\u6d4b\u3002", "method": "1. \u63d0\u51fa\u4e86\u57fa\u4e8e\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u7684\u5341\u7c7b\u9690\u85cf\u610f\u56fe\u5206\u7c7b\u6cd5\uff0c\u6309\u610f\u56fe\u3001\u673a\u5236\u3001\u4e0a\u4e0b\u6587\u548c\u5f71\u54cd\u7ec4\u7ec7\uff1b2. \u5c55\u793a\u4e86\u5982\u4f55\u5728\u53d7\u63a7\u6a21\u578b\u4e2d\u8f7b\u677e\u8bf1\u5bfc\u9690\u85cf\u610f\u56fe\uff1b3. \u7cfb\u7edf\u8bc4\u4f30\u4e86\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5305\u62ec\u63a8\u7406\u548c\u975e\u63a8\u7406LLM\u5224\u65ad\u5668\uff1b4. \u5728\u5f00\u653e\u4e16\u754c\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u538b\u529b\u6d4b\u8bd5\uff0c\u5206\u6790\u7cbe\u5ea6-\u6d41\u884c\u7387\u548c\u7cbe\u5ea6-FNR\u6743\u8861\uff1b5. \u901a\u8fc7\u5b9a\u6027\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u5341\u7c7b\u610f\u56fe\u5728\u5df2\u90e8\u7f72\u7684SOTA LLM\u4e2d\u7684\u5b58\u5728\u3002", "result": "1. \u68c0\u6d4b\u65b9\u6cd5\u5728\u73b0\u5b9e\u5f00\u653e\u4e16\u754c\u8bbe\u7f6e\u4e2d\u5931\u6548\uff0c\u7279\u522b\u662f\u5728\u4f4e\u6d41\u884c\u7387\u6761\u4ef6\u4e0b\uff0c\u5047\u9633\u6027\u538b\u5012\u7cbe\u5ea6\uff0c\u5047\u9634\u6027\u63a9\u76d6\u771f\u5b9e\u98ce\u9669\uff1b2. \u538b\u529b\u6d4b\u8bd5\u663e\u793a\uff0c\u6ca1\u6709\u6781\u5c0f\u7684\u5047\u9633\u6027\u7387\u6216\u5bf9\u64cd\u7eb5\u7c7b\u578b\u7684\u5f3a\u5148\u9a8c\uff0c\u5ba1\u8ba1\u5c31\u4f1a\u5931\u8d25\uff1b3. \u6848\u4f8b\u7814\u7a76\u8bc1\u5b9e\u6240\u6709\u5341\u7c7b\u9690\u85cf\u610f\u56fe\u90fd\u5728\u5df2\u90e8\u7f72\u7684SOTA LLM\u4e2d\u663e\u73b0\uff1b4. \u63d0\u4f9b\u4e86\u7b2c\u4e00\u4e2a\u5728\u5f00\u653e\u4e16\u754c\u8bbe\u7f6e\u4e0b\u7cfb\u7edf\u5206\u6790LLM\u9690\u85cf\u610f\u56fe\u53ef\u68c0\u6d4b\u6027\u5931\u8d25\u7684\u5de5\u4f5c\u3002", "conclusion": "LLM\u4e2d\u7684\u9690\u85cf\u610f\u56fe\u662f\u4e00\u4e2a\u7d27\u8feb\u95ee\u9898\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5728\u5f00\u653e\u4e16\u754c\u8bbe\u7f6e\u4e2d\u4e25\u91cd\u5931\u6548\u3002\u9700\u8981\u5efa\u7acb\u5f3a\u5927\u7684\u6846\u67b6\u6765\u7406\u89e3\u3001\u8bf1\u5bfc\u548c\u538b\u529b\u6d4b\u8bd5\u8fd9\u4e9b\u884c\u4e3a\uff0c\u5efa\u7acb\u7075\u6d3b\u7684\u5206\u7c7b\u6cd5\u6765\u9884\u6d4b\u4e0d\u65ad\u6f14\u53d8\u7684\u5a01\u80c1\u5e76\u6307\u5bfc\u6cbb\u7406\u3002"}}
{"id": "2601.18572", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18572", "abs": "https://arxiv.org/abs/2601.18572", "authors": ["Franziska Weeber", "Vera Neplenbroek", "Jan Batzner", "Sebastian Pad\u00f3"], "title": "One Persona, Many Cues, Different Results: How Sociodemographic Cues Impact LLM Personalization", "comment": null, "summary": "Personalization of LLMs by sociodemographic subgroup often improves user experience, but can also introduce or amplify biases and unfair outcomes across groups. Prior work has employed so-called personas, sociodemographic user attributes conveyed to a model, to study bias in LLMs by relying on a single cue to prompt a persona, such as user names or explicit attribute mentions. This disregards LLM sensitivity to prompt variations (robustness) and the rarity of some cues in real interactions (external validity). We compare six commonly used persona cues across seven open and proprietary LLMs on four writing and advice tasks. While cues are overall highly correlated, they produce substantial variance in responses across personas. We therefore caution against claims from a single persona cue and recommend future personalization research to evaluate multiple externally valid cues.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u516d\u79cd\u5e38\u7528\u4eba\u7269\u63d0\u793a\u7ebf\u7d22\u5728\u4e03\u4e2aLLM\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u4e0d\u540c\u7ebf\u7d22\u4f1a\u4ea7\u751f\u663e\u8457\u5dee\u5f02\uff0c\u5efa\u8bae\u672a\u6765\u4e2a\u6027\u5316\u7814\u7a76\u5e94\u8bc4\u4f30\u591a\u79cd\u5916\u90e8\u6709\u6548\u7684\u7ebf\u7d22", "motivation": "LLM\u7684\u4e2a\u6027\u5316\u867d\u7136\u80fd\u6539\u5584\u7528\u6237\u4f53\u9a8c\uff0c\u4f46\u53ef\u80fd\u5f15\u5165\u6216\u653e\u5927\u7fa4\u4f53\u504f\u89c1\u3002\u5148\u524d\u7814\u7a76\u4f9d\u8d56\u5355\u4e00\u4eba\u7269\u63d0\u793a\u7ebf\u7d22\uff08\u5982\u7528\u6237\u540d\u6216\u663e\u5f0f\u5c5e\u6027\uff09\uff0c\u5ffd\u89c6\u4e86LLM\u5bf9\u63d0\u793a\u53d8\u5316\u7684\u654f\u611f\u6027\u548c\u67d0\u4e9b\u7ebf\u7d22\u5728\u771f\u5b9e\u4ea4\u4e92\u4e2d\u7684\u7f55\u89c1\u6027", "method": "\u6bd4\u8f83\u516d\u79cd\u5e38\u7528\u4eba\u7269\u63d0\u793a\u7ebf\u7d22\u5728\u4e03\u4e2a\u5f00\u6e90\u548c\u4e13\u6709LLM\u4e0a\u7684\u8868\u73b0\uff0c\u6db5\u76d6\u56db\u4e2a\u5199\u4f5c\u548c\u5efa\u8bae\u4efb\u52a1\uff0c\u5206\u6790\u7ebf\u7d22\u95f4\u7684\u76f8\u5173\u6027\u548c\u54cd\u5e94\u65b9\u5dee", "result": "\u867d\u7136\u7ebf\u7d22\u6574\u4f53\u9ad8\u5ea6\u76f8\u5173\uff0c\u4f46\u4e0d\u540c\u7ebf\u7d22\u5728\u4e0d\u540c\u4eba\u7269\u8bbe\u5b9a\u4e0b\u4f1a\u4ea7\u751f\u663e\u8457\u54cd\u5e94\u65b9\u5dee\uff0c\u5355\u4e00\u4eba\u7269\u63d0\u793a\u7ebf\u7d22\u7684\u7ed3\u8bba\u53ef\u80fd\u4e0d\u53ef\u9760", "conclusion": "\u5e94\u8c28\u614e\u57fa\u4e8e\u5355\u4e00\u4eba\u7269\u63d0\u793a\u7ebf\u7d22\u505a\u51fa\u7ed3\u8bba\uff0c\u5efa\u8bae\u672a\u6765\u4e2a\u6027\u5316\u7814\u7a76\u8bc4\u4f30\u591a\u79cd\u5916\u90e8\u6709\u6548\u7684\u7ebf\u7d22\u4ee5\u63d0\u9ad8\u9c81\u68d2\u6027\u548c\u5916\u90e8\u6548\u5ea6"}}
{"id": "2601.18582", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18582", "abs": "https://arxiv.org/abs/2601.18582", "authors": ["Yuan Cao", "Feixiang Liu", "Xinyue Wang", "Yihan Zhu", "Hui Xu", "Zheng Wang", "Qiang Qiu"], "title": "From Classification to Ranking: Enhancing LLM Reasoning Capabilities for MBTI Personality Detection", "comment": "9 pages, 4 figures, AAAI 2026 Bridge", "summary": "Personality detection aims to measure an individual's corresponding personality traits through their social media posts. The advancements in Large Language Models (LLMs) offer novel perspectives for personality detection tasks. Existing approaches enhance personality trait analysis by leveraging LLMs to extract semantic information from textual posts as prompts, followed by training classifiers for categorization. However, accurately classifying personality traits remains challenging due to the inherent complexity of human personality and subtle inter-trait distinctions. Moreover, prompt-based methods often exhibit excessive dependency on expert-crafted knowledge without autonomous pattern-learning capacity. To address these limitations, we view personality detection as a ranking task rather than a classification and propose a corresponding reinforcement learning training paradigm. First, we employ supervised fine-tuning (SFT) to establish personality trait ranking capabilities while enforcing standardized output formats, creating a robust initialization. Subsequently, we introduce Group Relative Policy Optimization (GRPO) with a specialized ranking-based reward function. Unlike verification tasks with definitive solutions, personality assessment involves subjective interpretations and blurred boundaries between trait categories. Our reward function explicitly addresses this challenge by training LLMs to learn optimal answer rankings. Comprehensive experiments have demonstrated that our method achieves state-of-the-art performance across multiple personality detection benchmarks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6027\u683c\u68c0\u6d4b\u65b0\u65b9\u6cd5\uff0c\u5c06\u6027\u683c\u68c0\u6d4b\u89c6\u4e3a\u6392\u5e8f\u4efb\u52a1\u800c\u975e\u5206\u7c7b\u4efb\u52a1\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u5206\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u683c\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u4eba\u7c7b\u6027\u683c\u7684\u590d\u6742\u6027\u548c\u7279\u8d28\u95f4\u7684\u7ec6\u5fae\u5dee\u5f02\u4f7f\u5f97\u51c6\u786e\u5206\u7c7b\u56f0\u96be\uff1b2) \u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\uff0c\u7f3a\u4e4f\u81ea\u4e3b\u6a21\u5f0f\u5b66\u4e60\u80fd\u529b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u66f4\u597d\u5904\u7406\u6027\u683c\u8bc4\u4f30\u4e3b\u89c2\u6027\u548c\u6a21\u7cca\u8fb9\u754c\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u76d1\u7763\u5fae\u8c03(SFT)\u5efa\u7acb\u6027\u683c\u7279\u8d28\u6392\u5e8f\u80fd\u529b\u5e76\u6807\u51c6\u5316\u8f93\u51fa\u683c\u5f0f\uff0c\u63d0\u4f9b\u7a33\u5065\u521d\u59cb\u5316\uff1b2) \u5f15\u5165\u5206\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(GRPO)\u548c\u4e13\u95e8\u7684\u57fa\u4e8e\u6392\u5e8f\u7684\u5956\u52b1\u51fd\u6570\uff0c\u8bad\u7ec3LLM\u5b66\u4e60\u6700\u4f18\u7b54\u6848\u6392\u5e8f\u800c\u975e\u7b80\u5355\u5206\u7c7b\u3002", "result": "\u5728\u591a\u4e2a\u6027\u683c\u68c0\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u6027\u683c\u8bc4\u4f30\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5c06\u6027\u683c\u68c0\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u6392\u5e8f\u4efb\u52a1\u5e76\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8303\u5f0f\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u6027\u683c\u8bc4\u4f30\u7684\u4e3b\u89c2\u6027\u548c\u6a21\u7cca\u8fb9\u754c\uff0c\u76f8\u6bd4\u4f20\u7edf\u5206\u7c7b\u65b9\u6cd5\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2601.18722", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18722", "abs": "https://arxiv.org/abs/2601.18722", "authors": ["Lintang Sutawika", "Gokul Swamy", "Zhiwei Steven Wu", "Graham Neubig"], "title": "Gained in Translation: Privileged Pairwise Judges Enhance Multilingual Reasoning", "comment": "Code available at https://github.com/lintangsutawika/SP3F", "summary": "When asked a question in a language less seen in its training data, current reasoning large language models (RLMs) often exhibit dramatically lower performance than when asked the same question in English. In response, we introduce \\texttt{SP3F} (Self-Play with Privileged Pairwise Feedback), a two-stage framework for enhancing multilingual reasoning without \\textit{any} data in the target language(s). First, we supervise fine-tune (SFT) on translated versions of English question-answer pairs to raise base model correctness. Second, we perform RL with feedback from a pairwise judge in a self-play fashion, with the judge receiving the English reference response as \\textit{privileged information}. Thus, even when none of the model's responses are completely correct, the privileged pairwise judge can still tell which response is better. End-to-end, \\texttt{SP3F} greatly improves base model performance, even outperforming fully post-trained models on multiple math and non-math tasks with less than\n  of the training data across the single-language, multilingual, and generalization to unseen language settings.", "AI": {"tldr": "SP3F\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u6211\u5bf9\u5f08\u548c\u7279\u6743\u6210\u5bf9\u53cd\u9988\uff0c\u65e0\u9700\u76ee\u6807\u8bed\u8a00\u6570\u636e\u5373\u53ef\u63d0\u5347\u591a\u8bed\u8a00\u63a8\u7406\u80fd\u529b", "motivation": "\u5f53\u524d\u63a8\u7406\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u8f83\u5c11\u89c1\u7684\u8bed\u8a00\u4e0a\u8868\u73b0\u663e\u8457\u4f4e\u4e8e\u82f1\u8bed\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u76ee\u6807\u8bed\u8a00\u6570\u636e\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u591a\u8bed\u8a00\u63a8\u7406\u80fd\u529b", "method": "\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) \u5728\u7ffb\u8bd1\u7684\u82f1\u6587\u95ee\u7b54\u5bf9\u4e0a\u76d1\u7763\u5fae\u8c03\u63d0\u5347\u57fa\u7840\u6a21\u578b\u6b63\u786e\u6027\uff1b2) \u901a\u8fc7\u7279\u6743\u6210\u5bf9\u6cd5\u5b98\u8fdb\u884c\u81ea\u6211\u5bf9\u5f08\u5f3a\u5316\u5b66\u4e60\uff0c\u6cd5\u5b98\u53ef\u83b7\u5f97\u82f1\u6587\u53c2\u8003\u7b54\u6848\u4f5c\u4e3a\u7279\u6743\u4fe1\u606f", "result": "SP3F\u663e\u8457\u63d0\u5347\u57fa\u7840\u6a21\u578b\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u6570\u5b66\u548c\u975e\u6570\u5b66\u4efb\u52a1\u4e0a\u751a\u81f3\u4f18\u4e8e\u5b8c\u5168\u540e\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u4e14\u8bad\u7ec3\u6570\u636e\u91cf\u4e0d\u52301%", "conclusion": "SP3F\u6846\u67b6\u901a\u8fc7\u81ea\u6211\u5bf9\u5f08\u548c\u7279\u6743\u53cd\u9988\u673a\u5236\uff0c\u65e0\u9700\u76ee\u6807\u8bed\u8a00\u6570\u636e\u5373\u53ef\u6709\u6548\u63d0\u5347\u591a\u8bed\u8a00\u63a8\u7406\u80fd\u529b\uff0c\u5728\u5355\u8bed\u8a00\u3001\u591a\u8bed\u8a00\u548c\u672a\u89c1\u8bed\u8a00\u6cdb\u5316\u8bbe\u7f6e\u4e2d\u5747\u8868\u73b0\u4f18\u5f02"}}
{"id": "2601.18724", "categories": ["cs.CL", "cs.AI", "cs.DL"], "pdf": "https://arxiv.org/pdf/2601.18724", "abs": "https://arxiv.org/abs/2601.18724", "authors": ["Yusuke Sakai", "Hidetaka Kamigaito", "Taro Watanabe"], "title": "HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences", "comment": "Work In Progress", "summary": "Recently, we have often observed hallucinated citations or references that do not correspond to any existing work in papers under review, preprints, or published papers. Such hallucinated citations pose a serious concern to scientific reliability. When they appear in accepted papers, they may also negatively affect the credibility of conferences. In this study, we refer to hallucinated citations as \"HalluCitation\" and systematically investigate their prevalence and impact. We analyze all papers published at ACL, NAACL, and EMNLP in 2024 and 2025, including main conference, Findings, and workshop papers. Our analysis reveals that nearly 300 papers contain at least one HalluCitation, most of which were published in 2025. Notably, half of these papers were identified at EMNLP 2025, the most recent conference, indicating that this issue is rapidly increasing. Moreover, more than 100 such papers were accepted as main conference and Findings papers at EMNLP 2025, affecting the credibility.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u8c03\u67e5\u4e86AI\u751f\u6210\u8bba\u6587\u4e2d\u5e7b\u89c9\u5f15\u7528\uff08HalluCitation\uff09\u7684\u666e\u904d\u6027\u548c\u5f71\u54cd\uff0c\u53d1\u73b0ACL\u3001NAACL\u548cEMNLP\u4f1a\u8bae2024-2025\u5e74\u53d1\u8868\u7684\u8fd1300\u7bc7\u8bba\u6587\u5305\u542b\u81f3\u5c11\u4e00\u4e2a\u5e7b\u89c9\u5f15\u7528\uff0c\u4e14\u95ee\u9898\u5728EMNLP 2025\u5e74\u6025\u5267\u589e\u52a0\u3002", "motivation": "\u8fd1\u5e74\u6765\u5728\u5ba1\u7a3f\u3001\u9884\u5370\u672c\u548c\u5df2\u53d1\u8868\u8bba\u6587\u4e2d\u9891\u7e41\u89c2\u5bdf\u5230\u5e7b\u89c9\u5f15\u7528\uff08\u5f15\u7528\u4e0d\u5b58\u5728\u7684\u6587\u732e\uff09\uff0c\u8fd9\u4e25\u91cd\u5a01\u80c1\u79d1\u5b66\u53ef\u9760\u6027\uff0c\u5f53\u8fd9\u4e9b\u5f15\u7528\u51fa\u73b0\u5728\u5df2\u63a5\u53d7\u8bba\u6587\u4e2d\u65f6\uff0c\u8fd8\u4f1a\u635f\u5bb3\u4f1a\u8bae\u4fe1\u8a89\u3002", "method": "\u5206\u6790\u4e86ACL\u3001NAACL\u548cEMNLP\u57282024\u5e74\u548c2025\u5e74\u53d1\u8868\u7684\u6240\u6709\u8bba\u6587\uff0c\u5305\u62ec\u4e3b\u4f1a\u8bae\u8bba\u6587\u3001Findings\u8bba\u6587\u548c\u7814\u8ba8\u4f1a\u8bba\u6587\uff0c\u7cfb\u7edf\u8bc6\u522b\u548c\u7edf\u8ba1\u5e7b\u89c9\u5f15\u7528\u3002", "result": "\u53d1\u73b0\u8fd1300\u7bc7\u8bba\u6587\u5305\u542b\u81f3\u5c11\u4e00\u4e2a\u5e7b\u89c9\u5f15\u7528\uff0c\u5176\u4e2d\u5927\u90e8\u5206\u53d1\u8868\u4e8e2025\u5e74\uff1b\u7279\u522b\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u534a\u6570\u95ee\u9898\u8bba\u6587\u51fa\u73b0\u5728EMNLP 2025\uff08\u6700\u8fd1\u7684\u4f1a\u8bae\uff09\uff0c\u8868\u660e\u95ee\u9898\u6b63\u5728\u8fc5\u901f\u6076\u5316\uff1b\u8d85\u8fc7100\u7bc7\u8fd9\u6837\u7684\u8bba\u6587\u5728EMNLP 2025\u88ab\u63a5\u53d7\u4e3a\u4e3b\u4f1a\u8bae\u548cFindings\u8bba\u6587\u3002", "conclusion": "\u5e7b\u89c9\u5f15\u7528\u5728\u8ba1\u7b97\u8bed\u8a00\u5b66\u9886\u57df\u5df2\u6784\u6210\u4e25\u91cd\u4e14\u65e5\u76ca\u589e\u957f\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728EMNLP 2025\u4f1a\u8bae\u4e0a\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\uff0c\u8fd9\u5bf9\u79d1\u5b66\u53ef\u9760\u6027\u548c\u4f1a\u8bae\u4fe1\u8a89\u9020\u6210\u4e86\u5b9e\u8d28\u6027\u5f71\u54cd\u3002"}}
{"id": "2601.18730", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18730", "abs": "https://arxiv.org/abs/2601.18730", "authors": ["Henry Bell", "Caroline Zhang", "Mohammed Mobasserul Haque", "Dhaval Potdar", "Samia Zaman", "Brandon Fain"], "title": "Reflect: Transparent Principle-Guided Reasoning for Constitutional Alignment at Scale", "comment": null, "summary": "The constitutional framework of alignment aims to align large language models (LLMs) with value-laden principles written in natural language (such as to avoid using biased language). Prior work has focused on parameter fine-tuning techniques, such as reinforcement learning from human feedback (RLHF), to instill these principles. However, these approaches are computationally demanding, require careful engineering and tuning, and often require difficult-to-obtain human annotation data. We propose \\textsc{reflect}, an inference-time framework for constitutional alignment that does not require any training or data, providing a plug-and-play approach for aligning an instruction-tuned model to a set of principles. \\textsc{reflect} operates entirely in-context, combining a (i) constitution-conditioned base response with post-generation (ii) self-evaluation, (iii)(a) self-critique, and (iii)(b) final revision. \\textsc{reflect}'s technique of explicit in-context reasoning over principles during post-generation outperforms standard few-shot prompting and provides transparent reasoning traces. Our results demonstrate that \\textsc{reflect} significantly improves LLM conformance to diverse and complex principles, including principles quite distinct from those emphasized in the model's original parameter fine-tuning, without sacrificing factual reasoning. \\textsc{reflect} is particularly effective at reducing the rate of rare but significant violations of principles, thereby improving safety and robustness in the tail end of the distribution of generations. Finally, we show that \\textsc{reflect} naturally generates useful training data for traditional parameter fine-tuning techniques, allowing for efficient scaling and the reduction of inference-time computational overhead in long-term deployment scenarios.", "AI": {"tldr": "REFLECT\uff1a\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u6216\u6570\u636e\u7684\u63a8\u7406\u65f6\u5baa\u6cd5\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u4e2d\u7684\u81ea\u6211\u8bc4\u4f30\u3001\u81ea\u6211\u6279\u5224\u548c\u6700\u7ec8\u4fee\u8ba2\u6765\u5bf9\u9f50\u8bed\u8a00\u6a21\u578b\u4e0e\u81ea\u7136\u8bed\u8a00\u539f\u5219", "motivation": "\u73b0\u6709\u7684\u5baa\u6cd5\u5bf9\u9f50\u65b9\u6cd5\uff08\u5982RLHF\uff09\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u3001\u7cbe\u5fc3\u5de5\u7a0b\u8c03\u6574\u548c\u96be\u4ee5\u83b7\u53d6\u7684\u4eba\u5de5\u6807\u6ce8\u6570\u636e\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u8f7b\u91cf\u3001\u5373\u63d2\u5373\u7528\u7684\u5bf9\u9f50\u65b9\u6cd5", "method": "REFLECT\u662f\u5b8c\u5168\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u63a8\u7406\u65f6\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6b65\u9aa4\uff1a(i) \u57fa\u4e8e\u5baa\u6cd5\u7684\u57fa\u672c\u54cd\u5e94\u751f\u6210\uff0c(ii) \u540e\u751f\u6210\u81ea\u6211\u8bc4\u4f30\uff0c(iii)(a) \u81ea\u6211\u6279\u5224\u548c(iii)(b) \u6700\u7ec8\u4fee\u8ba2\uff0c\u901a\u8fc7\u663e\u5f0f\u7684\u539f\u5219\u63a8\u7406\u63d0\u4f9b\u900f\u660e\u63a8\u7406\u8f68\u8ff9", "result": "REFLECT\u663e\u8457\u63d0\u9ad8\u4e86LLM\u5bf9\u591a\u6837\u590d\u6742\u539f\u5219\u7684\u7b26\u5408\u5ea6\uff0c\u5305\u62ec\u4e0e\u539f\u59cb\u53c2\u6570\u5fae\u8c03\u5f3a\u8c03\u7684\u539f\u5219\u5b8c\u5168\u4e0d\u540c\u7684\u539f\u5219\uff0c\u540c\u65f6\u4e0d\u727a\u7272\u4e8b\u5b9e\u63a8\u7406\u80fd\u529b\uff1b\u7279\u522b\u6709\u6548\u51cf\u5c11\u7f55\u89c1\u4f46\u4e25\u91cd\u7684\u539f\u5219\u8fdd\u53cd\uff0c\u63d0\u9ad8\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\uff1b\u8fd8\u80fd\u81ea\u7136\u751f\u6210\u7528\u4e8e\u4f20\u7edf\u53c2\u6570\u5fae\u8c03\u7684\u6709\u7528\u8bad\u7ec3\u6570\u636e", "conclusion": "REFLECT\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u6216\u6570\u636e\u7684\u5373\u63d2\u5373\u7528\u5baa\u6cd5\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5728\u63a8\u7406\u65f6\u901a\u8fc7\u663e\u5f0f\u539f\u5219\u63a8\u7406\u5b9e\u73b0\u66f4\u597d\u7684\u5bf9\u9f50\u6548\u679c\uff0c\u540c\u65f6\u4e3a\u957f\u671f\u90e8\u7f72\u4e2d\u7684\u9ad8\u6548\u6269\u5c55\u548c\u63a8\u7406\u8ba1\u7b97\u5f00\u9500\u51cf\u5c11\u63d0\u4f9b\u4e86\u53ef\u80fd"}}
{"id": "2601.18731", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18731", "abs": "https://arxiv.org/abs/2601.18731", "authors": ["Hongru Cai", "Yongqi Li", "Tiezheng Yu", "Fengbin Zhu", "Wenjie Wang", "Fuli Feng", "Wenjie Li"], "title": "One Adapts to Any: Meta Reward Modeling for Personalized LLM Alignment", "comment": null, "summary": "Alignment of Large Language Models (LLMs) aims to align outputs with human preferences, and personalized alignment further adapts models to individual users. This relies on personalized reward models that capture user-specific preferences and automatically provide individualized feedback. However, developing these models faces two critical challenges: the scarcity of feedback from individual users and the need for efficient adaptation to unseen users. We argue that addressing these constraints requires a paradigm shift from fitting data to learn user preferences to learn the process of preference adaptation. To realize this, we propose Meta Reward Modeling (MRM), which reformulates personalized reward modeling as a meta-learning problem. Specifically, we represent each user's reward model as a weighted combination of base reward functions, and optimize the initialization of these weights using a Model-Agnostic Meta-Learning (MAML)-style framework to support fast adaptation under limited feedback. To ensure robustness, we introduce the Robust Personalization Objective (RPO), which places greater emphasis on hard-to-learn users during meta optimization. Extensive experiments on personalized preference datasets validate that MRM enhances few-shot personalization, improves user robustness, and consistently outperforms baselines.", "AI": {"tldr": "\u63d0\u51fa\u5143\u5956\u52b1\u5efa\u6a21\uff08MRM\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5143\u5b66\u4e60\u89e3\u51b3\u4e2a\u6027\u5316\u5956\u52b1\u5efa\u6a21\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u548c\u5feb\u901f\u9002\u5e94\u65b0\u7528\u6237\u95ee\u9898\uff0c\u5f15\u5165\u9c81\u68d2\u4e2a\u6027\u5316\u76ee\u6807\uff08RPO\uff09\u63d0\u5347\u6a21\u578b\u5bf9\u96be\u5b66\u4e60\u7528\u6237\u7684\u9002\u5e94\u6027\u3002", "motivation": "\u4e2a\u6027\u5316\u5bf9\u9f50LLMs\u9700\u8981\u4e2a\u6027\u5316\u5956\u52b1\u6a21\u578b\uff0c\u4f46\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a\u4e2a\u4f53\u7528\u6237\u53cd\u9988\u7a00\u7f3a\u548c\u9700\u8981\u9ad8\u6548\u9002\u5e94\u672a\u89c1\u7528\u6237\u3002\u4f20\u7edf\u65b9\u6cd5\u76f4\u63a5\u62df\u5408\u6570\u636e\u5b66\u4e60\u7528\u6237\u504f\u597d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u8f6c\u5411\u5b66\u4e60\u504f\u597d\u9002\u5e94\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u5143\u5956\u52b1\u5efa\u6a21\uff08MRM\uff09\uff0c\u5c06\u4e2a\u6027\u5316\u5956\u52b1\u5efa\u6a21\u91cd\u6784\u4e3a\u5143\u5b66\u4e60\u95ee\u9898\u3002\u5c06\u6bcf\u4e2a\u7528\u6237\u7684\u5956\u52b1\u6a21\u578b\u8868\u793a\u4e3a\u57fa\u5956\u52b1\u51fd\u6570\u7684\u52a0\u6743\u7ec4\u5408\uff0c\u4f7f\u7528MAML\u98ce\u683c\u6846\u67b6\u4f18\u5316\u6743\u91cd\u521d\u59cb\u5316\u4ee5\u652f\u6301\u6709\u9650\u53cd\u9988\u4e0b\u7684\u5feb\u901f\u9002\u5e94\u3002\u5f15\u5165\u9c81\u68d2\u4e2a\u6027\u5316\u76ee\u6807\uff08RPO\uff09\uff0c\u5728\u5143\u4f18\u5316\u4e2d\u66f4\u91cd\u89c6\u96be\u5b66\u4e60\u7528\u6237\u3002", "result": "\u5728\u4e2a\u6027\u5316\u504f\u597d\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\uff1aMRM\u589e\u5f3a\u4e86\u5c11\u6837\u672c\u4e2a\u6027\u5316\u80fd\u529b\uff0c\u63d0\u9ad8\u4e86\u7528\u6237\u9c81\u68d2\u6027\uff0c\u5e76\u6301\u7eed\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "MRM\u901a\u8fc7\u5143\u5b66\u4e60\u8303\u5f0f\u6709\u6548\u89e3\u51b3\u4e86\u4e2a\u6027\u5316\u5956\u52b1\u5efa\u6a21\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u548c\u5feb\u901f\u9002\u5e94\u95ee\u9898\uff0cRPO\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u96be\u5b66\u4e60\u7528\u6237\u7684\u9c81\u68d2\u6027\uff0c\u4e3aLLMs\u7684\u4e2a\u6027\u5316\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18788", "categories": ["cs.CL", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.18788", "abs": "https://arxiv.org/abs/2601.18788", "authors": ["Mumin Jia", "Jairo Diaz-Rodriguez"], "title": "Unsupervised Text Segmentation via Kernel Change-Point Detection on Sentence Embeddings", "comment": "arXiv admin note: substantial text overlap with arXiv:2510.03437. substantial text overlap with arXiv:2510.03437. substantial text overlap with arXiv:2510.03437. substantial text overlap with arXiv:2510.03437", "summary": "Unsupervised text segmentation is crucial because boundary labels are expensive, subjective, and often fail to transfer across domains and granularity choices. We propose Embed-KCPD, a training-free method that represents sentences as embedding vectors and estimates boundaries by minimizing a penalized KCPD objective. Beyond the algorithmic instantiation, we develop, to our knowledge, the first dependence-aware theory for KCPD under $m$-dependent sequences, a finite-memory abstraction of short-range dependence common in language. We prove an oracle inequality for the population penalized risk and a localization guarantee showing that each true change point is recovered within a window that is small relative to segment length. To connect theory to practice, we introduce an LLM-based simulation framework that generates synthetic documents with controlled finite-memory dependence and known boundaries, validating the predicted scaling behavior. Across standard segmentation benchmarks, Embed-KCPD often outperforms strong unsupervised baselines. A case study on Taylor Swift's tweets illustrates that Embed-KCPD combines strong theoretical guarantees, simulated reliability, and practical effectiveness for text segmentation.", "AI": {"tldr": "Embed-KCPD\uff1a\u4e00\u79cd\u65e0\u76d1\u7763\u6587\u672c\u5206\u5272\u65b9\u6cd5\uff0c\u4f7f\u7528\u53e5\u5b50\u5d4c\u5165\u548c\u60e9\u7f5aKCPD\u76ee\u6807\u68c0\u6d4b\u8fb9\u754c\uff0c\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u6a21\u62df\u9a8c\u8bc1", "motivation": "\u8fb9\u754c\u6807\u6ce8\u6210\u672c\u9ad8\u3001\u4e3b\u89c2\u6027\u5f3a\uff0c\u4e14\u96be\u4ee5\u8de8\u9886\u57df\u548c\u7c92\u5ea6\u8fc1\u79fb\uff0c\u9700\u8981\u6709\u6548\u7684\u65e0\u76d1\u7763\u6587\u672c\u5206\u5272\u65b9\u6cd5", "method": "\u5c06\u53e5\u5b50\u8868\u793a\u4e3a\u5d4c\u5165\u5411\u91cf\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u60e9\u7f5aKCPD\u76ee\u6807\u4f30\u8ba1\u8fb9\u754c\uff1b\u63d0\u51fam-\u4f9d\u8d56\u5e8f\u5217\u7406\u8bba\uff0c\u5f00\u53d1LLM\u6a21\u62df\u6846\u67b6\u9a8c\u8bc1", "result": "\u5728\u6807\u51c6\u5206\u5272\u57fa\u51c6\u4e0a\u5e38\u4f18\u4e8e\u5f3a\u65e0\u76d1\u7763\u57fa\u7ebf\uff1b\u7406\u8bba\u8bc1\u660eoracle\u4e0d\u7b49\u5f0f\u548c\u5b9a\u4f4d\u4fdd\u8bc1\uff1b\u6a21\u62df\u9a8c\u8bc1\u9884\u6d4b\u7684\u7f29\u653e\u884c\u4e3a", "conclusion": "Embed-KCPD\u7ed3\u5408\u4e86\u7406\u8bba\u4fdd\u8bc1\u3001\u6a21\u62df\u53ef\u9760\u6027\u548c\u5b9e\u9645\u6709\u6548\u6027\uff0c\u4e3a\u65e0\u76d1\u7763\u6587\u672c\u5206\u5272\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.18790", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18790", "abs": "https://arxiv.org/abs/2601.18790", "authors": ["Etienne Lanzeray", "Stephane Meilliez", "Malo Ruelle", "Damien Sileo"], "title": "MortalMATH: Evaluating the Conflict Between Reasoning Objectives and Emergency Contexts", "comment": null, "summary": "Large Language Models are increasingly optimized for deep reasoning, prioritizing the correct execution of complex tasks over general conversation. We investigate whether this focus on calculation creates a \"tunnel vision\" that ignores safety in critical situations. We introduce MortalMATH, a benchmark of 150 scenarios where users request algebra help while describing increasingly life-threatening emergencies (e.g., stroke symptoms, freefall). We find a sharp behavioral split: generalist models (like Llama-3.1) successfully refuse the math to address the danger. In contrast, specialized reasoning models (like Qwen-3-32b and GPT-5-nano) often ignore the emergency entirely, maintaining over 95 percent task completion rates while the user describes dying. Furthermore, the computational time required for reasoning introduces dangerous delays: up to 15 seconds before any potential help is offered. These results suggest that training models to relentlessly pursue correct answers may inadvertently unlearn the survival instincts required for safe deployment.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u4e13\u95e8\u4f18\u5316\u7684\u63a8\u7406\u6a21\u578b\u5728\u7528\u6237\u9762\u4e34\u751f\u547d\u5371\u9669\u65f6\u4ecd\u575a\u6301\u5b8c\u6210\u6570\u5b66\u4efb\u52a1\uff0c\u5ffd\u89c6\u5b89\u5168\u8b66\u544a\uff0c\u800c\u901a\u7528\u6a21\u578b\u80fd\u4f18\u5148\u5904\u7406\u7d27\u6025\u60c5\u51b5", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6df1\u5ea6\u63a8\u7406\u4f18\u5316\u8fc7\u7a0b\u4e2d\u662f\u5426\u5f62\u6210\u4e86\"\u96a7\u9053\u89c6\u91ce\"\uff0c\u5373\u5728\u8ffd\u6c42\u6b63\u786e\u6267\u884c\u590d\u6742\u4efb\u52a1\u65f6\u5ffd\u89c6\u4e86\u5b89\u5168\u8003\u8651\uff0c\u7279\u522b\u662f\u5728\u7528\u6237\u63cf\u8ff0\u751f\u547d\u5a01\u80c1\u7d27\u6025\u60c5\u51b5\u65f6", "method": "\u5f15\u5165MortalMATH\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b150\u4e2a\u573a\u666f\uff0c\u7528\u6237\u8bf7\u6c42\u4ee3\u6570\u5e2e\u52a9\u7684\u540c\u65f6\u63cf\u8ff0\u65e5\u76ca\u4e25\u91cd\u7684\u751f\u547d\u5a01\u80c1\u7d27\u6025\u60c5\u51b5\uff08\u5982\u4e2d\u98ce\u75c7\u72b6\u3001\u81ea\u7531\u843d\u4f53\uff09\uff0c\u8bc4\u4f30\u4e0d\u540c\u6a21\u578b\u7684\u884c\u4e3a\u53cd\u5e94", "result": "\u53d1\u73b0\u660e\u663e\u7684\u884c\u4e3a\u5206\u5316\uff1a\u901a\u7528\u6a21\u578b\uff08\u5982Llama-3.1\uff09\u6210\u529f\u62d2\u7edd\u6570\u5b66\u4efb\u52a1\u4ee5\u5904\u7406\u5371\u9669\uff1b\u800c\u4e13\u95e8\u63a8\u7406\u6a21\u578b\uff08\u5982Qwen-3-32b\u548cGPT-5-nano\uff09\u5e38\u5b8c\u5168\u5ffd\u89c6\u7d27\u6025\u60c5\u51b5\uff0c\u4fdd\u6301\u8d85\u8fc795%\u7684\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u5373\u4f7f\u7528\u6237\u63cf\u8ff0\u6fd2\u6b7b\u72b6\u6001\u3002\u63a8\u7406\u8ba1\u7b97\u65f6\u95f4\u5f15\u5165\u5371\u9669\u5ef6\u8fdf\uff1a\u6700\u591a15\u79d2\u540e\u624d\u53ef\u80fd\u63d0\u4f9b\u5e2e\u52a9", "conclusion": "\u8bad\u7ec3\u6a21\u578b\u4e0d\u61c8\u8ffd\u6c42\u6b63\u786e\u7b54\u6848\u53ef\u80fd\u65e0\u610f\u4e2d\u4f7f\u5176\u4e27\u5931\u4e86\u5b89\u5168\u90e8\u7f72\u6240\u9700\u7684\u751f\u5b58\u672c\u80fd\uff0c\u9700\u8981\u5728\u6a21\u578b\u4f18\u5316\u4e2d\u5e73\u8861\u63a8\u7406\u80fd\u529b\u4e0e\u5b89\u5168\u54cd\u5e94"}}
{"id": "2601.18791", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18791", "abs": "https://arxiv.org/abs/2601.18791", "authors": ["Iaroslav Chelombitko", "Mika H\u00e4m\u00e4l\u00e4inen", "Aleksey Komissarov"], "title": "Subword-Based Comparative Linguistics across 242 Languages Using Wikipedia Glottosets", "comment": "15 pages, 4 figues, 4 tables", "summary": "We present a large-scale comparative study of 242 Latin and Cyrillic-script languages using subword-based methodologies. By constructing 'glottosets' from Wikipedia lexicons, we introduce a framework for simultaneous cross-linguistic comparison via Byte-Pair Encoding (BPE). Our approach utilizes rank-based subword vectors to analyze vocabulary overlap, lexical divergence, and language similarity at scale. Evaluations demonstrate that BPE segmentation aligns with morpheme boundaries 95% better than random baseline across 15 languages (F1 = 0.34 vs 0.15). BPE vocabulary similarity correlates significantly with genetic language relatedness (Mantel r = 0.329, p < 0.001), with Romance languages forming the tightest cluster (mean distance 0.51) and cross-family pairs showing clear separation (0.82). Analysis of 26,939 cross-linguistic homographs reveals that 48.7% receive different segmentations across related languages, with variation correlating to phylogenetic distance. Our results provide quantitative macro-linguistic insights into lexical patterns across typologically diverse languages within a unified analytical framework.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528BPE\u5b50\u8bcd\u65b9\u6cd5\u5bf9242\u79cd\u62c9\u4e01\u548c\u897f\u91cc\u5c14\u6587\u5b57\u8bed\u8a00\u8fdb\u884c\u5927\u89c4\u6a21\u6bd4\u8f83\u5206\u6790\uff0c\u53d1\u73b0BPE\u5206\u5272\u4e0e\u8bed\u7d20\u8fb9\u754c\u9ad8\u5ea6\u4e00\u81f4\uff0c\u8bcd\u6c47\u76f8\u4f3c\u6027\u4e0e\u8bed\u8a00\u9057\u4f20\u5173\u7cfb\u663e\u8457\u76f8\u5173\uff0c\u8de8\u8bed\u8a00\u540c\u5f62\u8bcd\u5206\u6790\u63ed\u793a\u4e86\u8bed\u8a00\u8ddd\u79bb\u5bf9\u5206\u5272\u5dee\u5f02\u7684\u5f71\u54cd\u3002", "motivation": "\u9700\u8981\u5728\u5927\u89c4\u6a21\u8de8\u8bed\u8a00\u6bd4\u8f83\u4e2d\u5efa\u7acb\u7edf\u4e00\u7684\u5206\u6790\u6846\u67b6\uff0c\u91cf\u5316\u7814\u7a76\u62c9\u4e01\u548c\u897f\u91cc\u5c14\u6587\u5b57\u8bed\u8a00\u4e4b\u95f4\u7684\u8bcd\u6c47\u6a21\u5f0f\u3001\u8bed\u8a00\u76f8\u4f3c\u6027\u548c\u9057\u4f20\u5173\u7cfb\uff0c\u586b\u8865\u5b8f\u89c2\u8bed\u8a00\u5b66\u5b9a\u91cf\u5206\u6790\u7684\u7a7a\u767d\u3002", "method": "\u4ece\u7ef4\u57fa\u767e\u79d1\u8bcd\u5178\u6784\u5efa\"glottosets\"\u8bed\u6599\u96c6\uff0c\u91c7\u7528\u57fa\u4e8e\u5b57\u8282\u5bf9\u7f16\u7801\uff08BPE\uff09\u7684\u5b50\u8bcd\u65b9\u6cd5\uff0c\u4f7f\u7528\u57fa\u4e8e\u6392\u540d\u7684\u5b50\u8bcd\u5411\u91cf\u5206\u6790\u8bcd\u6c47\u91cd\u53e0\u3001\u8bcd\u6c47\u5206\u5316\u548c\u8bed\u8a00\u76f8\u4f3c\u6027\uff0c\u6db5\u76d6242\u79cd\u8bed\u8a00\u7684\u5927\u89c4\u6a21\u6bd4\u8f83\u3002", "result": "BPE\u5206\u5272\u4e0e\u8bed\u7d20\u8fb9\u754c\u7684\u4e00\u81f4\u6027\u6bd4\u968f\u673a\u57fa\u7ebf\u9ad895%\uff08F1=0.34 vs 0.15\uff09\uff1bBPE\u8bcd\u6c47\u76f8\u4f3c\u6027\u4e0e\u8bed\u8a00\u9057\u4f20\u5173\u7cfb\u663e\u8457\u76f8\u5173\uff08Mantel r=0.329, p<0.001\uff09\uff1b\u7f57\u66fc\u8bed\u65cf\u5f62\u6210\u6700\u7d27\u5bc6\u805a\u7c7b\uff08\u5e73\u5747\u8ddd\u79bb0.51\uff09\uff1b\u8de8\u8bed\u7cfb\u8bed\u8a00\u5bf9\u660e\u663e\u5206\u79bb\uff080.82\uff09\uff1b26,939\u4e2a\u8de8\u8bed\u8a00\u540c\u5f62\u8bcd\u4e2d48.7%\u5728\u4e0d\u540c\u76f8\u5173\u8bed\u8a00\u4e2d\u83b7\u5f97\u4e0d\u540c\u5206\u5272\uff0c\u53d8\u5f02\u4e0e\u7cfb\u7edf\u53d1\u80b2\u8ddd\u79bb\u76f8\u5173\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u57fa\u4e8eBPE\u7684\u5b50\u8bcd\u65b9\u6cd5\u5728\u5b8f\u89c2\u8bed\u8a00\u5b66\u5206\u6790\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u8de8\u7c7b\u578b\u591a\u6837\u8bed\u8a00\u7684\u8bcd\u6c47\u6a21\u5f0f\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u5b9a\u91cf\u5206\u6790\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u8bed\u8a00\u76f8\u4f3c\u6027\u3001\u9057\u4f20\u5173\u7cfb\u548c\u8bcd\u6c47\u5206\u5272\u4e4b\u95f4\u7684\u7cfb\u7edf\u6027\u8054\u7cfb\u3002"}}
{"id": "2601.18796", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18796", "abs": "https://arxiv.org/abs/2601.18796", "authors": ["Brian Ondov", "Chia-Hsuan Chang", "Yujia Zhou", "Mauro Giuffr\u00e8", "Hua Xu"], "title": "ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models", "comment": null, "summary": "Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. We develop an open-source, domain-agnostic ELM architecture and training framework, design training tasks for clinical trials, and introduce an expert-validated synthetic dataset. We then train a series of ELMs exploring the impact of tasks and training regimes. Our final model, ctELM, can accurately describe and compare unseen clinical trials from embeddings alone and produce plausible clinical trials from novel vectors. We further show that generated trial abstracts are responsive to moving embeddings along concept vectors for age and sex of study subjects. Our public ELM implementation and experimental results will aid the alignment of Large Language Models to embedding spaces in the biomedical domain and beyond.", "AI": {"tldr": "\u63d0\u51factELM\u6a21\u578b\uff0c\u901a\u8fc7Embedding Language Model\u65b9\u6cd5\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4e34\u5e8a\u8bd5\u9a8c\u5d4c\u5165\u7a7a\u95f4\u5bf9\u9f50\uff0c\u5b9e\u73b0\u4ece\u5d4c\u5165\u5411\u91cf\u751f\u6210\u4e34\u5e8a\u8bd5\u9a8c\u63cf\u8ff0\u548c\u6bd4\u8f83\uff0c\u5e76\u5c55\u793a\u6cbf\u5e74\u9f84\u548c\u6027\u522b\u6982\u5ff5\u5411\u91cf\u79fb\u52a8\u5d4c\u5165\u80fd\u751f\u6210\u54cd\u5e94\u6027\u8bd5\u9a8c\u6458\u8981\u3002", "motivation": "\u6587\u672c\u5d4c\u5165\u5df2\u6210\u4e3a\u591a\u79cd\u8bed\u8a00\u5e94\u7528\u7684\u6838\u5fc3\u7ec4\u4ef6\uff0c\u4f46\u89e3\u91ca\u3001\u63a2\u7d22\u548c\u53cd\u8f6c\u5d4c\u5165\u7a7a\u95f4\u7684\u65b9\u6cd5\u6709\u9650\uff0c\u8fd9\u964d\u4f4e\u4e86\u900f\u660e\u5ea6\u5e76\u963b\u788d\u4e86\u6f5c\u5728\u6709\u4ef7\u503c\u7684\u751f\u6210\u5e94\u7528\u3002\u7279\u522b\u662f\u5728\u4e34\u5e8a\u8bd5\u9a8c\u9886\u57df\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u6765\u7406\u89e3\u548c\u64cd\u4f5c\u5d4c\u5165\u8868\u793a\u3002", "method": "\u91c7\u7528Embedding Language Model\u65b9\u6cd5\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4e34\u5e8a\u8bd5\u9a8c\u5d4c\u5165\u5bf9\u9f50\u3002\u5f00\u53d1\u4e86\u5f00\u6e90\u3001\u9886\u57df\u65e0\u5173\u7684ELM\u67b6\u6784\u548c\u8bad\u7ec3\u6846\u67b6\uff0c\u8bbe\u8ba1\u4e86\u9488\u5bf9\u4e34\u5e8a\u8bd5\u9a8c\u7684\u8bad\u7ec3\u4efb\u52a1\uff0c\u5e76\u5f15\u5165\u4e86\u4e13\u5bb6\u9a8c\u8bc1\u7684\u5408\u6210\u6570\u636e\u96c6\u3002\u8bad\u7ec3\u4e86\u4e00\u7cfb\u5217ELM\u6a21\u578b\u63a2\u7d22\u4efb\u52a1\u548c\u8bad\u7ec3\u673a\u5236\u7684\u5f71\u54cd\u3002", "result": "\u6700\u7ec8\u6a21\u578bctELM\u80fd\u591f\u4ec5\u4ece\u5d4c\u5165\u5411\u91cf\u51c6\u786e\u63cf\u8ff0\u548c\u6bd4\u8f83\u672a\u89c1\u8fc7\u7684\u4e34\u5e8a\u8bd5\u9a8c\uff0c\u5e76\u80fd\u4ece\u65b0\u9896\u5411\u91cf\u751f\u6210\u5408\u7406\u7684\u4e34\u5e8a\u8bd5\u9a8c\u3002\u751f\u6210\u7684\u8bd5\u9a8c\u6458\u8981\u80fd\u591f\u54cd\u5e94\u6cbf\u5e74\u9f84\u548c\u6027\u522b\u6982\u5ff5\u5411\u91cf\u79fb\u52a8\u5d4c\u5165\u7684\u64cd\u4f5c\u3002", "conclusion": "\u516c\u5f00\u7684ELM\u5b9e\u73b0\u548c\u5b9e\u9a8c\u7ed3\u679c\u5c06\u6709\u52a9\u4e8e\u5728\u751f\u7269\u533b\u5b66\u9886\u57df\u53ca\u5176\u4ed6\u9886\u57df\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u5d4c\u5165\u7a7a\u95f4\u5bf9\u9f50\uff0c\u63d0\u9ad8\u5d4c\u5165\u7a7a\u95f4\u7684\u900f\u660e\u5ea6\u548c\u751f\u6210\u80fd\u529b\u3002"}}
